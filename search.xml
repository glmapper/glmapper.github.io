<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[springsessionthree]]></title>
    <url>%2F2018%2F11%2F24%2Fspringsessionthree%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[SpringSession：请求与响应重写]]></title>
    <url>%2F2018%2F11%2F24%2Fspringsessiontwo%2F</url>
    <content type="text"><![CDATA[我们知道，HttpServletRequset和HttpServletResponse是Servlet标准所指定的Java语言与Web容器进行交互的接口。接口本身只规定java语言对web容器进行访问的行为方式，而具体的实现是由不同的web容器在其内部实现的。 那么在运行期，当我们需要对HttpServletRequset和HttpServletResponse的默认实例进行扩展时，我们就可以继承HttpServletRequestWrapper和HttpServletResponseWrapper来实现。 在 SpringSession中因为我们要实现不依赖容器本身的getSession 实现，因此需要扩展 HttpServletRequset，通过重写getSession来实现分布式session的能力。下面就来看下SpringSession中对于HttpServletRequset的扩展。 1、请求重写SpringSession 中对于请求重写，在能力上主要体现在存储方面，也就是getSession方法上。在 SessionRepositoryFilter 这个类中，是通过内部类的方式实现了对HttpServletRequset和HttpServletResponse的扩展。 1.1 HttpServletRequset 扩展实现12345678910111213141516171819private final class SessionRepositoryRequestWrapper extends HttpServletRequestWrapper &#123; // HttpServletResponse 实例 private final HttpServletResponse response; // ServletContext 实例 private final ServletContext servletContext; // requestedSession session对象 private S requestedSession; // 是否缓存 session private boolean requestedSessionCached; // sessionId private String requestedSessionId; // sessionId 是否有效 private Boolean requestedSessionIdValid; // sessionId 是否失效 private boolean requestedSessionInvalidated; // 省略方法&#125; 1.2 构造方法123456private SessionRepositoryRequestWrapper(HttpServletRequest request, HttpServletResponse response, ServletContext servletContext) &#123; super(request); this.response = response; this.servletContext = servletContext;&#125; 构造方法里面将 HttpServletRequest、HttpServletResponse 以及 ServletContext 实例传递进来，以便于后续扩展使用。 1.3 getSession 方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Overridepublic HttpSessionWrapper getSession(boolean create) &#123; // 从当前请求线程中获取 session HttpSessionWrapper currentSession = getCurrentSession(); // 如果有直接返回 if (currentSession != null) &#123; return currentSession; &#125; // 从请求中获取 session，这里面会涉及到从缓存中拿session的过程 S requestedSession = getRequestedSession(); if (requestedSession != null) &#123; // 无效的会话id(不支持的会话存储库)请求属性名称。 // 这里看下当前的sessionId是否有效 if (getAttribute(INVALID_SESSION_ID_ATTR) == null) &#123; // 设置当前session的最后访问时间，用于延迟session的有效期 requestedSession.setLastAccessedTime(Instant.now()); // 将requestedSessionIdValid置为true this.requestedSessionIdValid = true; // 包装session currentSession = new HttpSessionWrapper(requestedSession, getServletContext()); // 不是新的session，如果是新的session则需要改变sessionId currentSession.setNew(false); // 将session设置到当前请求上下文 setCurrentSession(currentSession); // 返回session return currentSession; &#125; &#125; else &#123; // 这里处理的是无效的sessionId的情况，但是当前请求线程 session有效 if (SESSION_LOGGER.isDebugEnabled()) &#123; SESSION_LOGGER.debug( "No session found by id: Caching result for getSession(false) for this HttpServletRequest."); &#125; // 将invalidSessionId置为true setAttribute(INVALID_SESSION_ID_ATTR, "true"); &#125; // 是否需要创建新的session if (!create) &#123; return null; &#125; if (SESSION_LOGGER.isDebugEnabled()) &#123; SESSION_LOGGER.debug( "A new session was created. To help you troubleshoot where the session was created we provided a StackTrace (this is not an error). You can prevent this from appearing by disabling DEBUG logging for " + SESSION_LOGGER_NAME, new RuntimeException( "For debugging purposes only (not an error)")); &#125; // 创建新的session S session = SessionRepositoryFilter.this.sessionRepository.createSession(); // 设置最后访问时间，也就是指定了当前session的有效期限 session.setLastAccessedTime(Instant.now()); // 包装下当前session currentSession = new HttpSessionWrapper(session, getServletContext()); //设置到当前请求线程 setCurrentSession(currentSession); return currentSession;&#125; 上面这段代码有几个点，这里单独来解释下。 getCurrentSession 这是为了在同一个请求过程中不需要重复的去从存储中获取session，在一个新的进来时，将当前的 session 设置到当前请求中，在后续处理过程如果需要getSession就不需要再去存储介质中再拿一次。 getRequestedSession 这个是根据请求信息去取session，这里面就包括了sessionId解析，从存储获取session对象等过程。 是否创建新的session对象 在当前请求中和存储中都没有获取到session信息的情况下，这里会根据create参数来判断是否创建新的session。这里一般用户首次登录时或者session失效时会走到。 1.4 getRequestedSession根据请求信息来获取session对象 1234567891011121314151617181920212223private S getRequestedSession() &#123; // 缓存的请求session是否存在 if (!this.requestedSessionCached) &#123; // 获取 sessionId List&lt;String&gt; sessionIds = SessionRepositoryFilter.this.httpSessionIdResolver .resolveSessionIds(this); // 通过sessionId来从存储中获取session for (String sessionId : sessionIds) &#123; if (this.requestedSessionId == null) &#123; this.requestedSessionId = sessionId; &#125; S session = SessionRepositoryFilter.this.sessionRepository .findById(sessionId); if (session != null) &#123; this.requestedSession = session; this.requestedSessionId = sessionId; break; &#125; &#125; this.requestedSessionCached = true; &#125; return this.requestedSession;&#125; 这段代码还是很有意思的，这里获取sessionId返回的是个列表。当然这里是SpringSession的实现策略，因为支持session，所以这里以列表的形式返回的。OK，继续来看如何解析sessionId的： 这里可以看到SpringSession对于sessionId获取的两种策略，一种是基于cookie，一种是基于header；分别来看下具体实现。 1.4.1 CookieHttpSessionIdResolver 获取 sessionIdCookieHttpSessionIdResolver 中获取sessionId的核心代码如下：其实这里没啥好说的，就是读cookie。从request将cookie信息拿出来，然后遍历找当前sessionId对应的cookie,这里的判断也很简单， 如果是以SESSION开头，则表示是 SessionId，毕竟cookie是共享的，不只有sessionId，还有可能存储其他内容。 另外这里面有个 jvmRoute，这个东西实际上很少能够用到，因为大多数情况下这个值都是null。这个我们在分析CookieSerializer时再来解释。 1.4.2 HeaderHttpSessionIdResolver 获取 sessionId这个获取更直接粗暴，就是根据 headerName 从 header 中取值。 回到getRequestedSession，剩下的代码中核心的都是和sessionRepository这个有关系，这部分就会涉及到存储部分。不在本篇的分析范围之内，会在存储实现部分来分析。 1.5 HttpSessionWrapper 上面的代码中当我们拿到session实例是通常会包装下，那么用到的就是这个HttpSessionWrapper。 HttpSessionWrapper 继承了 HttpSessionAdapter，这个HttpSessionAdapter就是将SpringSession 转换成一个标准HttpSession的适配类。HttpSessionAdapter 实现了标准servlet规范的HttpSession接口。 1.5.1 HttpSessionWrapperHttpSessionWrapper 重写了 invalidate方法。从代码来看，调用该方法产生的影响是： requestedSessionInvalidated 置为true，标识当前 session 失效。 将当前请求中的session设置为null，那么在请求的后续调用中通过getCurrentSession将拿不到session信息。 当前缓存的 session 清楚，包括sessionId，session实例等。 删除存储介质中的session对象。 1.5.2 HttpSessionAdapterSpringSession和标准HttpSession的配置器类。这个怎么理解呢，来看下一段代码： 12345@Overridepublic Object getAttribute(String name) &#123; checkState(); return this.session.getAttribute(name);&#125; 对于基于容器本身实现的HttpSession来说，getAttribute的实现也是有容器本身决定。但是这里做了转换之后，getAttribute将会通过SpringSession中实现的方案来获取。其他的API适配也是基于此实现。 SessionCommittingRequestDispatcher实现了 RequestDispatcher 接口。关于RequestDispatcher可以参考这篇文章【Servlet】关于RequestDispatcher的原理。SessionCommittingRequestDispatcher对forward的行为并没有改变。对于include则是在include之前提交session。为什么这么做呢？ 因为include方法使原先的Servlet和转发到的Servlet都可以输出响应信息，即原先的Servlet还可以继续输出响应信息；即请求转发后，原先的Servlet还可以继续输出响应信息，转发到的Servlet对请求做出的响应将并入原先Servlet的响应对象中。 所以这个在include调用之前调用commit，这样可以确保被包含的Servlet程序不能改变响应消息的状态码和响应头。 2 响应重写响应重写的目的是确保在请求提交时能够把session保存起来。来看下SessionRepositoryResponseWrapper类的实现： 这里面实现还就是重写onResponseCommitted，也就是上面说的，在请求提交时能够通过这个回调函数将session保存到存储容器中。 2.1 session 提交最后来看下 commitSession 这个过程不会再去存储容器中拿session信息，而是直接从当前请求中拿。如果拿不到，则在回写cookie时会将当前session对应的cookie值设置为空，这样下次请求过来时携带的sessionCookie就是空，这样就会重新触发登陆。 如果拿到，则清空当前请求中的session信息，然后将session保存到存储容器中，并且将sessionId回写到cookie中。 小结本篇主要对SpringSession中重写Request和Response进行了分析。通过重写Request请求来将session的存储与存储容器关联起来，通过重写Response来处理session提交，将session保存到存储容器中。 后面我们会继续来分析SpringSession的源码。最近也在学习链路跟踪相关的技术，也准备写一写，有兴趣的同学可以一起讨论。 附 SOFA 开源社区 SOFATracer]]></content>
      <categories>
        <category>spring</category>
        <category>session</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SOFABoot 健康检查能力分析]]></title>
    <url>%2F2018%2F11%2F16%2Fsofaboot-health-one%2F</url>
    <content type="text"><![CDATA[Liveness Check &amp; Readiness CheckSpring Boot 提供了一个基础的健康检查的能力，中间件和应用都可以扩展来实现自己的健康检查逻辑。但是 Spring Boot 的健康检查只有 Liveness Check 的能力，缺少 Readiness Check 的能力，这样会有比较致命的问题。当一个微服务应用启动的时候，必须要先保证启动后应用是健康的，才可以将上游的流量放进来（来自于 RPC，网关，定时任务等等流量），否则就可能会导致一定时间内大量的错误发生。 针对 Spring Boot 缺少 Readiness Check 能力的情况，SOFABoot 增加了 Spring Boot 现有的健康检查的能力，提供了 Readiness Check 的能力。利用 Readiness Check 的能力，SOFA 中间件中的各个组件只有在 Readiness Check 通过之后，才将流量引入到应用的实例中，比如 RPC，只有在 Readiness Check 通过之后，才会向服务注册中心注册，后面来自上游应用的流量才会进入。 除了中间件可以利用 Readiness Check 的事件来控制流量的进入之外，PAAS 系统也可以通过访问 http://localhost:8080/actuator/readiness 来获取应用的 Readiness Check 的状况，用来控制例如负载均衡设备等等流量的进入。 使用方式SOFABoot 的健康检查能力需要引入： 1234&lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;healthcheck-sofa-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 区别于SpringBoot的： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 详细工程科参考：sofa-boot 健康检查启动日志 代码分析既然是个Starter，那么就先从 spring.factories 文件来看： 12345org.springframework.context.ApplicationContextInitializer=\com.alipay.sofa.healthcheck.initializer.SofaBootHealthCheckInitializerorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.alipay.sofa.healthcheck.configuration.SofaBootHealthCheckAutoConfiguration SofaBootHealthCheckInitializerSofaBootHealthCheckInitializer 实现了 ApplicationContextInitializer 接口。 ApplicationContextInitializer 是 Spring 框架原有的概念，这个类的主要目的就是在 ConfigurableApplicationContext 类型（或者子类型）的 ApplicationContext 做 refresh 之前，允许我们 对 ConfigurableApplicationContext 的实例做进一步的设置或者处理。 123456789101112131415public class SofaBootHealthCheckInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; Environment environment = applicationContext.getEnvironment(); if (SOFABootEnvUtils.isSpringCloudBootstrapEnvironment(environment)) &#123; return; &#125; // init logging.level.com.alipay.sofa.runtime argument String healthCheckLogLevelKey = Constants.LOG_LEVEL_PREFIX + HealthCheckConstants.SOFABOOT_HEALTH_LOG_SPACE; SofaBootLogSpaceIsolationInit.initSofaBootLogger(environment, healthCheckLogLevelKey); SofaBootHealthCheckLoggerFactory.getLogger(SofaBootHealthCheckInitializer.class).info( "SOFABoot HealthCheck Starting!"); &#125;&#125; SofaBootHealthCheckInitializer 在 initialize 方法中主要做了两件事： 验证当前 environment 是否是 SpringCloud 的（3.0.0 开始支持 springCloud，之前版本无此 check） 初始化 logging.level 这两件事和健康检查没有什么关系，但是既然放在这个模块里面还是来看下。 1、springCloud 环境验证首先就是为什么会有这个验证。SOFABoot 在支持 SpringcLoud 时遇到一个问题，就是当在 classpath 中添加spring-cloud-context 依赖关系时,org.springframework.context.ApplicationContextInitializer会被调用两次。具体背景可参考 # issue1151 &amp;&amp; # issue 232 1234567891011121314private final static String SPRING_CLOUD_MARK_NAME = "org.springframework.cloud.bootstrap.BootstrapConfiguration";public static boolean isSpringCloudBootstrapEnvironment(Environment environment) &#123; if (environment instanceof ConfigurableEnvironment) &#123; return !((ConfigurableEnvironment) environment).getPropertySources().contains( SofaBootInfraConstants.SOFA_BOOTSTRAP) &amp;&amp; isSpringCloud(); &#125; return false;&#125;public static boolean isSpringCloud() &#123; return ClassUtils.isPresent(SPRING_CLOUD_MARK_NAME, null);&#125; 上面这段代码是 SOFABoot 提供的一个用于区分 引导上下文 和 应用上下文 的方法： 检验是否有&quot;org.springframework.cloud.bootstrap.BootstrapConfiguration&quot;这个类来判断当前是否引入了spingCloud的引导配置类 从environment 中获取 MutablePropertySources 实例，验证 MutablePropertySources 中是否包括 sofaBootstrap （ 如果当前环境是 SOFA bootstrap environment，则包含 sofaBootstrap；这个是在 SofaBootstrapRunListener 回调方法中设置进行的 ） 2、初始化 logging.level这里是处理 SOFABoot 日志空间隔离的。 1234567891011121314151617181920public static void initSofaBootLogger(Environment environment, String runtimeLogLevelKey) &#123; // 初始化 logging.path 参数 String loggingPath = environment.getProperty(Constants.LOG_PATH); if (!StringUtils.isEmpty(loggingPath)) &#123; System.setProperty(Constants.LOG_PATH, environment.getProperty(Constants.LOG_PATH)); ReportUtil.report("Actual " + Constants.LOG_PATH + " is [ " + loggingPath + " ]"); &#125; //for example : init logging.level.com.alipay.sofa.runtime argument String runtimeLogLevelValue = environment.getProperty(runtimeLogLevelKey); if (runtimeLogLevelValue != null) &#123; System.setProperty(runtimeLogLevelKey, runtimeLogLevelValue); &#125; // init file.encoding String fileEncoding = environment.getProperty(Constants.LOG_ENCODING_PROP_KEY); if (!StringUtils.isEmpty(fileEncoding)) &#123; System.setProperty(Constants.LOG_ENCODING_PROP_KEY, fileEncoding); &#125;&#125; SofaBootHealthCheckAutoConfiguration这个类是 SOFABoot 健康检查机制的自动化配置实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configurationpublic class SofaBootHealthCheckAutoConfiguration &#123; /** ReadinessCheckListener: 容器刷新之后回调 */ @Bean public ReadinessCheckListener readinessCheckListener() &#123; return new ReadinessCheckListener(); &#125; /** HealthCheckerProcessor: HealthChecker处理器 */ @Bean public HealthCheckerProcessor healthCheckerProcessor() &#123; return new HealthCheckerProcessor(); &#125; /** HealthCheckerProcessor: HealthIndicator处理器 */ @Bean public HealthIndicatorProcessor healthIndicatorProcessor() &#123; return new HealthIndicatorProcessor(); &#125; /** AfterReadinessCheckCallbackProcessor: ReadinessCheck之后的回调处理器 */ @Bean public AfterReadinessCheckCallbackProcessor afterReadinessCheckCallbackProcessor() &#123; return new AfterReadinessCheckCallbackProcessor(); &#125; /** 返回 SofaBoot健康检查指标类 实例*/ @Bean public SofaBootHealthIndicator sofaBootHealthIndicator() &#123; return new SofaBootHealthIndicator(); &#125; @ConditionalOnClass(Endpoint.class) public static class ConditionReadinessEndpointConfiguration &#123; @Bean @ConditionalOnEnabledEndpoint public SofaBootReadinessCheckEndpoint sofaBootReadinessCheckEndpoint() &#123; return new SofaBootReadinessCheckEndpoint(); &#125; &#125; @ConditionalOnClass(Endpoint.class) public static class ReadinessCheckExtensionConfiguration &#123; @Bean @ConditionalOnMissingBean @ConditionalOnEnabledEndpoint public ReadinessEndpointWebExtension readinessEndpointWebExtension() &#123; return new ReadinessEndpointWebExtension(); &#125; &#125;&#125; ReadinessCheckListener12public class ReadinessCheckListener implements PriorityOrdered, ApplicationListener&lt;ContextRefreshedEvent&gt; 从代码来看，ReadinessCheckListener 实现了 ApplicationListener 监听器接口，其所监听的事件对象是ContextRefreshedEvent，即当容器上下文刷新完成之后回调。 SOFABoot 中通过这个监听器来完成 readniess check 的处理。 onApplicationEvent 回调方法： 12345678910public void onApplicationEvent(ContextRefreshedEvent event) &#123; // healthCheckerProcessor init healthCheckerProcessor.init(); // healthIndicatorProcessor init healthIndicatorProcessor.init(); // afterReadinessCheckCallbackProcessor init afterReadinessCheckCallbackProcessor.init(); // readiness health check execute readinessHealthCheck();&#125; 初始化 healthCheckerProcessor，这个里面就是将当前所有的HealthChecker类型的bean找出来，然后放在一个map中，等待后面的 readiness check。 12345678910111213141516171819public void init() &#123; // 是否已经初始化了 if (isInitiated.compareAndSet(false, true)) &#123; // applicationContext 应用上下文不能为null Assert.notNull(applicationContext, () -&gt; "Application must not be null"); // 获取所有类型是 HealthChecker 的bean Map&lt;String, HealthChecker&gt; beansOfType = applicationContext .getBeansOfType(HealthChecker.class); // 排序 healthCheckers = HealthCheckUtils.sortMapAccordingToValue(beansOfType, applicationContext.getAutowireCapableBeanFactory()); // 构建日志信息，对应在健康检查日志里面打印出来的是： // ./logs/health-check/common-default.log:Found 0 HealthChecker implementation StringBuilder healthCheckInfo = new StringBuilder(512).append("Found ") .append(healthCheckers.size()).append(" HealthChecker implementation:") .append(String.join(",", healthCheckers.keySet())); logger.info(healthCheckInfo.toString()); &#125;&#125; 初始化 healthIndicatorProcessor，将所有的healthIndicator 类型的bean 找出来，然后放在一个map中等待readiness check。如果想要在 SOFABoot 的 Readiness Check 里面增加一个检查项，那么可以直接扩展 Spring Boot 的HealthIndicator这个接口。 12345678910111213141516171819202122232425public void init() &#123; // 是否已经初始化 if (isInitiated.compareAndSet(false, true)) &#123; // applicationContext 验证 Assert.notNull(applicationContext, () -&gt; "Application must not be null"); // 获取所有HealthIndicator类型的bean Map&lt;String, HealthIndicator&gt; beansOfType = applicationContext .getBeansOfType(HealthIndicator.class); // 支持 Reactive 方式 if (ClassUtils.isPresent(REACTOR_CLASS, null)) &#123; applicationContext.getBeansOfType(ReactiveHealthIndicator.class).forEach( (name, indicator) -&gt; beansOfType.put(name, () -&gt; indicator.health().block())); &#125; // 排序 healthIndicators = HealthCheckUtils.sortMapAccordingToValue(beansOfType, applicationContext.getAutowireCapableBeanFactory()); // 构建日志信息 // Found 2 HealthIndicator implementation: // sofaBootHealthIndicator, diskSpaceHealthIndicator StringBuilder healthIndicatorInfo = new StringBuilder(512).append("Found ") .append(healthIndicators.size()).append(" HealthIndicator implementation:") .append(String.join(",", healthIndicators.keySet())); logger.info(healthIndicatorInfo.toString()); &#125;&#125; 初始化 afterReadinessCheckCallbackProcessor。如果想要在 Readiness Check 之后做一些事情，那么可以扩展 SOFABoot 的这个接口 12345678910111213141516171819public void init() &#123; // 是否已经初始化 if (isInitiated.compareAndSet(false, true)) &#123; // applicationContext 验证 Assert.notNull(applicationContext, () -&gt; "Application must not be null"); // 找到所有 ReadinessCheckCallback 类型的 bean Map&lt;String, ReadinessCheckCallback&gt; beansOfType = applicationContext .getBeansOfType(ReadinessCheckCallback.class); // 排序 readinessCheckCallbacks = HealthCheckUtils.sortMapAccordingToValue(beansOfType, applicationContext.getAutowireCapableBeanFactory()); // 构建日志 StringBuilder applicationCallbackInfo = new StringBuilder(512).append("Found ") .append(readinessCheckCallbacks.size()) .append(" ReadinessCheckCallback implementation: ") .append(String.join(",", beansOfType.keySet())); logger.info(applicationCallbackInfo.toString()); &#125;&#125; readinessHealthCheck，前面的几个init方法中均是为readinessHealthCheck做准备的，到这里SOFABoot已经拿到了当前多有的HealthChecker、HealthIndicator 和 ReadinessCheckCallback 类型的 bean 信息。 12345678910111213141516171819202122232425262728293031323334// readiness health checkpublic void readinessHealthCheck() &#123; // 是否跳过所有check,可以通过 com.alipay.sofa.healthcheck.skip.all 配置项配置决定 if (skipAllCheck()) &#123; logger.warn("Skip all readiness health check."); &#125; else &#123; // 是否跳过所有 HealthChecker 类型bean的 readinessHealthCheck, // 可以通过com.alipay.sofa.healthcheck.skip.component配置项配置 if (skipComponent()) &#123; logger.warn("Skip HealthChecker health check."); &#125; else &#123; //HealthChecker 的 readiness check healthCheckerStatus = healthCheckerProcessor .readinessHealthCheck(healthCheckerDetails); &#125; // 是否跳过所有HealthIndicator 类型bean的readinessHealthCheck // 可以通过 com.alipay.sofa.healthcheck.skip.indicator配置项配置 if (skipIndicator()) &#123; logger.warn("Skip HealthIndicator health check."); &#125; else &#123; //HealthIndicator 的 readiness check healthIndicatorStatus = healthIndicatorProcessor .readinessHealthCheck(healthIndicatorDetails); &#125; &#125; // ReadinessCheck 之后的回调函数，做一些后置处理 healthCallbackStatus = afterReadinessCheckCallbackProcessor .afterReadinessCheckCallback(healthCallbackDetails); if (healthCheckerStatus &amp;&amp; healthIndicatorStatus &amp;&amp; healthCallbackStatus) &#123; logger.info("Readiness check result: success"); &#125; else &#123; logger.error("Readiness check result: fail"); &#125;&#125; Readiness Check 做了什么前面是 SOFABoot 健康检查组件处理健康检查逻辑的一个大体流程，了解到了 Readiness 包括检查 HealthChecker 类型的bean和HealthIndicator 类型的 bean。其中HealthIndicator是SpringBoot自己的接口 ，而 HealthChecker 是 SOFABoot 提供的接口。下面继续通过 XXXProcess 来看下 Readiness Check 到底做了什么？ HealthCheckerProcessorHealthChecker 的健康检查处理器，readinessHealthCheck 方法 12345678910111213public boolean readinessHealthCheck(Map&lt;String, Health&gt; healthMap) &#123; Assert.notNull(healthCheckers, "HealthCheckers must not be null."); logger.info("Begin SOFABoot HealthChecker readiness check."); boolean result = healthCheckers.entrySet().stream() .map(entry -&gt; doHealthCheck(entry.getKey(), entry.getValue(), true, healthMap, true)) .reduce(true, BinaryOperators.andBoolean()); if (result) &#123; logger.info("SOFABoot HealthChecker readiness check result: success."); &#125; else &#123; logger.error("SOFABoot HealthChecker readiness check result: failed."); &#125; return result;&#125; 这里每个HealthChecker又委托给doHealthCheck来检查 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private boolean doHealthCheck(String beanId, HealthChecker healthChecker, boolean isRetry, Map&lt;String, Health&gt; healthMap, boolean isReadiness) &#123; Assert.notNull(healthMap, "HealthMap must not be null"); Health health; boolean result; int retryCount = 0; // check 类型 readiness ？ liveness String checkType = isReadiness ? "readiness" : "liveness"; do &#123; // 获取 Health 对象 health = healthChecker.isHealthy(); // 获取 健康检查状态结果 result = health.getStatus().equals(Status.UP); if (result) &#123; logger.info("HealthChecker[&#123;&#125;] &#123;&#125; check success with &#123;&#125; retry.", beanId, checkType,retryCount); break; &#125; else &#123; logger.info("HealthChecker[&#123;&#125;] &#123;&#125; check fail with &#123;&#125; retry.", beanId, checkType,retryCount); &#125; // 重试 &amp;&amp; 等待 if (isRetry &amp;&amp; retryCount &lt; healthChecker.getRetryCount()) &#123; try &#123; retryCount += 1; TimeUnit.MILLISECONDS.sleep(healthChecker.getRetryTimeInterval()); &#125; catch (InterruptedException e) &#123; logger .error( String .format( "Exception occurred while sleeping of %d retry HealthChecker[%s] %s check.", retryCount, beanId, checkType), e); &#125; &#125; &#125; while (isRetry &amp;&amp; retryCount &lt; healthChecker.getRetryCount()); // 将当前 实例 bean 的健康检查结果存到结果集healthMap中 healthMap.put(beanId, health); try &#123; if (!result) &#123; logger .error( "HealthChecker[&#123;&#125;] &#123;&#125; check fail with &#123;&#125; retry; fail details:&#123;&#125;; strict mode:&#123;&#125;", beanId, checkType, retryCount, objectMapper.writeValueAsString(health.getDetails()), healthChecker.isStrictCheck()); &#125; &#125; catch (JsonProcessingException ex) &#123; logger.error( String.format("Error occurred while doing HealthChecker %s check.", checkType), ex); &#125; // 返回健康检查结果 return !healthChecker.isStrictCheck() || result;&#125; 这里的 doHealthCheck 结果需要依赖具体 HealthChecker 实现类的处理。通过这样一种方式可以SOFABoot可以很友好的实现对所以 HealthChecker 的健康检查。HealthIndicatorProcessor 的 readinessHealthCheck 和HealthChecker的基本差不多；有兴趣的可以自行阅读源码 Alipay-SOFABoot。 AfterReadinessCheckCallbackProcessor这个接口是 SOFABoot 提供的一个扩展接口， 用于在 Readiness Check 之后做一些事情。其实现思路和前面的XXXXProcessor 是一样的，对之前初始化时得到的所有的ReadinessCheckCallbacks实例bean逐一进行回调处理。 123456789101112131415public boolean afterReadinessCheckCallback(Map&lt;String, Health&gt; healthMap) &#123; logger.info("Begin ReadinessCheckCallback readiness check"); Assert.notNull(readinessCheckCallbacks, "ReadinessCheckCallbacks must not be null."); boolean result = readinessCheckCallbacks.entrySet().stream() .map(entry -&gt; doHealthCheckCallback(entry.getKey(), entry.getValue(), healthMap)) .reduce(true, BinaryOperators.andBoolean()); if (result) &#123; logger.info("ReadinessCheckCallback readiness check result: success."); &#125; else &#123; logger.error("ReadinessCheckCallback readiness check result: failed."); &#125; return result;&#125; 同样也是委托给了doHealthCheckCallback来处理 123456789101112131415161718private boolean doHealthCheckCallback(String beanId, ReadinessCheckCallback readinessCheckCallback, Map&lt;String, Health&gt; healthMap) &#123; Assert.notNull(healthMap, () -&gt; "HealthMap must not be null"); boolean result = false; Health health = null; try &#123; health = readinessCheckCallback.onHealthy(applicationContext); result = health.getStatus().equals(Status.UP); // print log 省略 &#125; catch (Throwable t) &#123; // 异常处理 &#125; finally &#123; // 存入 healthMap healthMap.put(beanId, health); &#125; return result;&#125; 扩展 Readiness Check 能力按照上面的分析，我们可以自己来实现下这几个扩展。 实现 HealthChecker 接口1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class GlmapperHealthChecker implements HealthChecker &#123; @Override public Health isHealthy() &#123; // 可以检测数据库连接是否成功 // 可以检测zookeeper是否启动成功 // 可以检测redis客户端是否启动成功 // everything you want ... if(OK)&#123; return Health.up().build(); &#125; return Health.down().build(); &#125; @Override public String getComponentName() &#123; // 组件名 return "GlmapperComponent"; &#125; @Override public int getRetryCount() &#123; // 重试次数 return 1; &#125; @Override public long getRetryTimeInterval() &#123; // 重试间隔 return 0; &#125; @Override public boolean isStrictCheck() &#123; return false; &#125;&#125; 实现 ReadinessCheckCallback 接口123456789101112@Componentpublic class GlmapperReadinessCheckCallback implements ReadinessCheckCallback &#123; @Override public Health onHealthy(ApplicationContext applicationContext) &#123; Object glmapperHealthChecker = applicationContext.getBean("glmapperHealthChecker"); if (glmapperHealthChecker instanceof GlmapperHealthChecker)&#123; return Health.up().build(); &#125; return Health.down().build(); &#125;&#125; 再来看下健康检查日志： 可以看到我们自己定义的检查类型ready了。 从日志看到有一个 sofaBootHealthIndicator，实现了HealthIndicator 接口。 1234567891011121314151617public class SofaBootHealthIndicator implements HealthIndicator &#123; private static final String CHECK_RESULT_PREFIX = "Middleware"; @Autowired private HealthCheckerProcessor healthCheckerProcessor; @Override public Health health() &#123; Map&lt;String, Health&gt; healths = new HashMap&lt;&gt;(); // 调用了 healthCheckerProcessor 的 livenessHealthCheck boolean checkSuccessful = healthCheckerProcessor.livenessHealthCheck(healths); if (checkSuccessful) &#123; return Health.up().withDetail(CHECK_RESULT_PREFIX, healths).build(); &#125; else &#123; return Health.down().withDetail(CHECK_RESULT_PREFIX, healths).build(); &#125; &#125;&#125; livenessHealthCheck 和 readinessHealthCheck 两个方法都是交给 doHealthCheck 来处理的，没有看出来有什么区别。 小结本文基于 SOFABoot 3.0.0 版本，与之前版本有一些区别。详细变更见：SOFABoot upgrade_3_x。本篇文章简单介绍了 SOFABoot 对 SpringBoot 健康检查能力扩展的具体实现细节。 最后再来补充下 liveness 和 readiness，从字面意思来理解，liveness就是是否是活的，readiness 就是意思是否可访问的。 readiness：应用即便已经正在运行了，它仍然需要一定时间才能 提供 服务，这段时间可能用来加载数据，可能用来构建缓存，可能用来注册服务，可能用来选举 Leader等等。总之 Readiness 检查通过前是不会有流量发给应用的。目前 SOFARPC 就是在 readiness check 之后才会将所有的服务注册到注册中心去。 liveness：检测应用程序是否正在运行]]></content>
      <categories>
        <category>SOFA</category>
      </categories>
      <tags>
        <tag>SOFABoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20181111-书法练习]]></title>
    <url>%2F2018%2F11%2F10%2Fshufa-20181111%2F</url>
    <content type="text"><![CDATA[黄鹤楼送孟浩然之广陵 -李白故人西辞黄鹤楼，烟花三月下扬州孤帆远影碧空尽，唯见长江天际流 将进酒 -李白君不见，黄河之水天上来，奔流到海不复回。君不见，高堂明镜悲白发，朝如青丝暮成雪。人生得意须尽欢，莫使金樽空对月。天生我材必有用，千金散尽还复来。烹羊宰牛且为乐，会须一饮三百杯。岑夫子，丹丘生，将进酒，杯莫停。与君歌一曲，请君为我倾耳听。(倾耳听 一作：侧耳听)钟鼓馔玉不足贵，但愿长醉不复醒。(不足贵 一作：何足贵；不复醒 一作：不愿醒/不用醒)古来圣贤皆寂寞，惟有饮者留其名。(古来 一作：自古；惟 通：唯)陈王昔时宴平乐，斗酒十千恣欢谑。主人何为言少钱，径须沽取对君酌。五花马，千金裘，呼儿将出换美酒，与尔同销万古愁。 青玉案·元夕 -辛弃疾东风夜放花千树。更吹落、星如雨。宝马雕车香满路。凤箫声动，玉壶光转，一夜鱼龙舞。蛾儿雪柳黄金缕。笑语盈盈暗香去。众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。]]></content>
      <categories>
        <category>书法</category>
      </categories>
      <tags>
        <tag>书法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-策略模式]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-design-model-strategy%2F</url>
    <content type="text"><![CDATA[上次在模板方法模式中有提及到，模板方法模式通常不会单独来试用，在一些实际的应用中会搭配其他的模式来使用，比如说今天要学习的策略模式。 一直我都很喜欢策略这个词，有种莫名的高大上，对三国有了解的小伙伴肯定会知道，有的谋士是比较直接的，献计就是献计，有话当面说；但是也有的谋士就是比较喜欢搞一种神秘感，弄个小布袋子里面塞个小布条（简称：锦囊）；对于一件很棘手的事情，在交代下去的时候就会有这样的嘱咐：“此事关系重大，还望XXX（昵称）务必处理妥帖；这里有三个锦囊，如果XXXX，你就拆开第X个锦囊，然后XXXX”；有时候我就很不解，假如真在遇到事情的时候来看，那路上丢了怎么办？一摸口袋就懵逼了有木有？ 扯远了，不过意思就是这个意思，一个锦囊其实就是一种策略；然后它有一个总的背景（我们称之为上下文环境），这个大背景下，每个不同的场景都会有一中策略来对应处理； 我们先以上面的列子为背景来撸一个小的例子，然后再去看一个spring中比较典型的策略模式使用，最后再来探讨下策略模式的类图，并以此来说明策略模式中的一些基本角色及其职责。 锦囊妙计 兵马未动，粮草先行；但是这个运输粮草到底是走水路还是走陆地呢？那这得看往哪运… 12345678910111213141516171819202122232425package com.glmapper.designmode.policy;/** * @description: 大背景，运输粮草 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/5/5 */public class TransportFood &#123; //持有一个运输策略的对象 private TransportFoodStrategy strategy; /** * 构造函数，传入一个具体策略对象 * @param strategy 具体策略对象 */ public TransportFood(TransportFoodStrategy strategy)&#123; this.strategy = strategy; &#125; /** * 策略方法 */ public void trasportFood()&#123; strategy.trasport(); &#125;&#125; 这个是我们的总体背景，就是运输粮草；但是这个只是说要运输粮草，但是并没有说是怎么运？这就得TransportFoodStrategy这个运输策略有具体的运输方案。 运输方案1：如果粮草是从武汉到南京，OK，那就走水运吧。 123456789101112/** * @description: 运输粮草的策略之水运运输 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/5/5 */public class WaterTransportStrategy implements TransportFoodStrategy &#123; @Override public void trasport() &#123; System.out.println("用船，走水运"); &#125;&#125; 运输方案2：如果从内蒙到北京；那就走陆运吧。 123456789101112/** * @description: 运输粮草的策略之陆地运输 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/5/5 */public class LandTransportStrategy implements TransportFoodStrategy &#123; @Override public void trasport() &#123; System.out.println("用马车，走陆运"); &#125;&#125; 好了，来看下妙计使用： 1234567891011121314151617181920212223242526272829303132333435/** * @description: 决策制定-客户端 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/5/5 */public class Client &#123; public static void main(String[] args) &#123; TransportFoodStrategy strategy = getTransportFoodStrategy("内蒙到北京"); TransportFood transportFood = new TransportFood(strategy); transportFood.trasportFood(); &#125; /** * 获取运输方案 * @param lineType 运输路线 * @return */ private static TransportFoodStrategy getTransportFoodStrategy( String lineType)&#123; if (lineType.equals("内蒙到北京"))&#123; return new LandTransportStrategy(); &#125; if (lineType.equals("武汉到南京"))&#123; return new WaterTransportStrategy(); &#125; return null; &#125;&#125;-&gt; 用马车，走陆运 粮草运完了，真正的表演开始了… Spring中典型的策略模式使用我们知道spring加载资源文件是通过ResourceLoader来搞定的。在ResourceLoader中提供了一个： 1Resource getResource(String location); 这个方法的注解中说道 12//允许多个资源调用。allowing for multiple &#123;@link Resource#getInputStream()&#125; calls. 这里就很赤裸裸了，他告诉了你要获取资源，但是如果获取资源呢？这就得看有哪些具体的获取策略了。 上图就是Resource的具体子类实现，也就是一些具体的策略。我们比较常见的应该算是UrlResource（加载URL指定的资源）和ClasspathResource（加载类路径中的资源）这两个。再来看下这个getResource这个方法的实现： getResource方法是在DefaultResourceLoader中具体实现的；DefaultResourceLoader是ResourceLoader的默认实现。 12345678910111213141516171819202122232425262728293031323334@Overridepublic Resource getResource(String location) &#123; Assert.notNull(location, "Location must not be null"); //首先使用ProtocolResolver来通过location参数创建Resource对象 // spring4.3.x开始才有的 for (ProtocolResolver protocolResolver : this.protocolResolvers) &#123; Resource resource = protocolResolver.resolve(location,this); if (resource != null) &#123; return resource; &#125; &#125; //指定路径的 if (location.startsWith("/")) &#123; return getResourceByPath(location); &#125; //以classpath开头的 else if (location.startsWith(CLASSPATH_URL_PREFIX)) &#123; return new ClassPathResource(location.substring( CLASSPATH_URL_PREFIX.length()), getClassLoader()); &#125; //这里是先尝试解析是否是带有网络协议的资源， //如果解析异常，则是在异常处理中使用了一种默认的机制。 else &#123; try &#123; // Try to parse the location as a URL... URL url = new URL(location); return new UrlResource(url); &#125; catch (MalformedURLException ex) &#123; // No URL -&gt; resolve as resource path. return getResourceByPath(location); &#125; &#125;&#125; 关于ProtocolResolver 其实我们可以发现，这里的location其实和我们上面那个例子中的lineType的作用是一样的，根据这个来确定具体使用哪个策略方法。 策略1：使用ProtocolResolver来通过location参数创建Resource对象，在ProtocolResolver中关于ProtocolResolver的解释是：A resolution strategy for protocol-specific resource handles-协议专用资源句柄的解析策略。 策略2：返回给定路径上资源的资源句柄。 策略3：以classpath:为前缀的，这种location参数直接返回一个ClassPathResource对象，表示加载classes路径下的资源； 策略4：使用网络协议作为前缀的，比如http、ftp等，这种直接返回一个UrlResource对象； 策略5：无前缀的，在默认实现中和第三种一样是加载classes路径下的资源，不同的是此处当作是ClassPathContextResource来处理的。 Spring中Resource的策(tao)略(lu)说完了，再回过头来看下策略模式的一些具体理论知识。 策略模式 定义：策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。 结合前面的例子分析和这段定义，可以知道，其实策略模式真的意图不是如何实现策略算法，它更在意的是如何组织这些算法。 这也是策略模式的使用可以让程序结构更灵活，具有更好的维护性和扩展性的重要因素。 类图：这个类图画的确实是有点丑，但是为了亲手绘制一下，所以还请多多见谅！ 类图中的一些角色： context：策略背景，也就是需要使用策略的主体；它持有一个strategy类的引用 strategy：抽象策略，这个角色给出了所有具体策略类所需的接口。所以通常是一个抽象类或者接口。 strategyPolicy：具体策略，它的作用就是包装具体的算法或者行为 那么在实际的应用中，策略模式到底给我们带来的好处是什么，它能够帮助我们解决什么样的问题呢？这个需要从模式本身的优缺点来看： 优点 策略模式提供了管理相关的算法族的办法。策略类的等级结构定义了一个算法或行为族。恰当使用继承可以把公共的代码移到父类里面，从而避免代码重复。 策略模式可以避免使用多重条件(if-else)语句。通常对于一个背景主体，一般只会有一种策略算法可供使用，使用多重条件句的话不易维护；因为它把采取哪一种算法或采取哪一种行为的逻辑与算法或行为的逻辑混合在一起了。 缺点 客户端必须知道所有的策略类，并自行决定使用哪一个策略类。这就意味着客户端必须理解这些算法的区别，以便适时选择恰当的算法类。换言之，策略模式只适用于客户端知道算法或行为的情况。 由于策略模式把每个具体的策略实现都单独封装成为类，如果备选的策略很多的话，那么对象的数目就会很可观。–如果策略很多，通常会采用一些混合策略来避免策略类的不断膨胀。 在了解其优缺点的情况下，我们就可以合理的将其放在一些适当的场景中来；如以下场景： 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 一个系统需要动态地在几种算法中选择一种。 如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 参考 《JAVA与模式》 《JAVA与模式》之策略模式 策略模式]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-模板方法模式]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-design-model-modulemethod%2F</url>
    <content type="text"><![CDATA[模板方法模式在sring中有大量的应用，一般我们会使用模板方法来将当前的实现委托给子类来实现，增强代码的可扩展性和复用性。因为涉及到父子类关系，所以模板方法模式是基于“继承”来实现的；模板方法模式属于行为型模式。 简单地说就是，通过父类来定义一系列的算法骨架，并且约定这些方法及其调用顺序，而具体的某些特定方法由子类实现。 先来看一个小demo；我们以写博客来举例子，一般我们写博客的步骤如下： 打开目标网站 打开编辑器 写文章 发布文章 实例代码首先是定义一个父类，并且提供一个模板方法。 123456789101112131415161718192021222324252627282930313233343536373839404142package com.glmapper.designmode.mudolmethod;/** * @description: 抽象模板父类 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/30 */public abstract class AbstractTemplateMethod &#123; /** * 流程方法1：抽象方法，供子类实现 */ public abstract void openTargetWebSite(); /** * 流程方法2：子类可选择重写 */ public void openMarkDown()&#123; System.out.println("打开编辑器"); &#125; /** * 流程方法3：抽象方法，供子类实现 */ public abstract void writeBlog(); /** * 流程方法4：子类可选择重写 */ protected void publisher()&#123; System.out.println("发布文章"); &#125; /** * 模板方法，此处申明为final，是不希望子类覆盖这个方法，防止更改流程的执行顺序 */ public final void templateWriteBlog()&#123; openTargetWebSite(); openMarkDown(); writeBlog(); publisher(); &#125;&#125; 上面代码中我们提供了一个templateWriteBlog方法，这里方法中包括了写博客的一些流程。在这些流程方法中有些方法父类提供了默认实现，而一些具有差异性的方法则让子类来实现。 123456789101112131415161718package com.glmapper.designmode.mudolmethod;/** * @description: 子类 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/30 */public class JueJinTemplateMethodPolicy extends AbstractTemplateMethod &#123; @Override public void openTargetWebSite() &#123; System.out.println("打开掘金网站"); &#125; @Override public void writeBlog() &#123; System.out.println("写一篇Spring相关的文章"); &#125;&#125; 子类1：JueJinTemplateMethodPolicy，这个子类中实现了父类中的部分方法，包括：openTargetWebSite和writeBlog。（一般情况下不会去重写父类默认已经实现的方法，仅实现父类中预留的抽象方法来实现）。 1234567891011121314151617181920package com.glmapper.designmode.mudolmethod;/** * @description: 子类 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/30 */public class CSDNTemplateMethodPolicy extends AbstractTemplateMethod&#123; @Override public void openTargetWebSite() &#123; System.out.println("打开CSDN网站"); &#125; @Override public void writeBlog() &#123; System.out.println("写一篇设计模式文章"); &#125;&#125; 子类2：CSDNTemplateMethodPolicy,这个子类的作用其实和子类1是一样的，只不过是提供了另外的一种实现策略；（很多情况下，模板方法模式都是和策略模式来联合使用的，通过一套模板机制，对于模板中的部分流程通过不同的策略来实现不同的功能） 1234567891011121314151617181920212223242526package com.glmapper.designmode.mudolmethod;/** * @description: 子类 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/30 */public class MainTest &#123; public static void main(String[] args) &#123; AbstractTemplateMethod csdnTemplate = new CSDNTemplateMethodPolicy(); csdnTemplate.templateWriteBlog(); AbstractTemplateMethod juejinTemplate = new JueJinTemplateMethodPolicy(); juejinTemplate.templateWriteBlog(); &#125;&#125;打开CSDN网站打开编辑器写一篇设计模式文章发布文章打开掘金网站打开编辑器写一篇Spring相关的文章发布文章 上面是客户端代码及输出结果。通过输出我们可以明显的看出，模板中的一些方法将延迟到子类中去实现，模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。因此对于模板方法这个模式来说，父类是始终控制着整个流程主动权的，而子类只是辅助父类实现某些可定制的步骤。 模式解析先看下模板方法模式的类图： 从类图中可以看出，模板方法模式中的角色也是很简单的，主要包括两个角色： 抽象模板（AbstractTemplate）： 定义一个或者多个抽象操作，以便于让子类实现。这些抽象操作就是流程中的基本操作（对应的是模板方法中的某个具体的操作方法）；这些基本操作是一个顶级逻辑的组成步骤 定义并且实现了一个模板方法。这个模板方法一般是一个具体方法，它给出了一个顶级逻辑的骨架，而逻辑的组成步骤在相应的抽象操作中，推迟到子类中取实现，当然，在这个顶级逻辑中，部分方法也可以由父类来提供默认实现的。 具体类（SubTemplateImpl)： 实现父类所定义的一个或者多个抽象方法 每一个抽象模板角色都可以有任意多个具体模板角色与之对应，而每一个具体模板角色都可以给出这些抽象方法的不同实现。 模板方法中的这个方法的概念拆开来说包括两种，一种是模板方法，还有一种是模板方法里面的基本方法。模板方法定义游戏规则，基本方法实现规则中的每个部分。 模板方法带来的优势是显而易见的，它可以帮助我们有效的帮助我们搞定下面的这些场景问题： 封装不变部分，扩展可变部分。 提取公共代码，便于维护。 行为由父类控制，子类实现。 但是缺点也很明显，因为对于每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 典型的模板方法模式的应用最先想到的就是servlet，servlet的生命周期(以前经常遇到的面试点，现在已经没人问了吧) 初始化 init 处理 service 销毁 destroy 其实这里我觉得也是模板方法的一种体现，虽然在servlet中没有定义顶层的模板方法来控制这个流程(我的想法是这个流程是由容器来控制的，也可能是一种默认的约定)。 在其子类GenericServlet中对init和destroy有了默认的实现，而service方法则是交由子类来实现的，也就是说任何servlet类均必须实现service方法。 这里的service方法就是一个模板方法。service方法中调用了7个do方法中的一个或者几个，完成对客户端的响应，这些do方法需要由HttpServlet的具体子类提供。 HttpServlet中的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041protected void service(HttpServletRequest req, HttpServletResponseresp) throws ServletException, IOException &#123; String method = req.getMethod(); long lastModified; if (method.equals("GET")) &#123; lastModified = this.getLastModified(req); if (lastModified == -1L) &#123; this.doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader("If-Modified-Since"); if (ifModifiedSince &lt; lastModified) &#123; this.maybeSetLastModified(resp, lastModified); this.doGet(req, resp); &#125; else &#123; resp.setStatus(304); &#125; &#125; &#125; else if (method.equals("HEAD")) &#123; lastModified = this.getLastModified(req); this.maybeSetLastModified(resp, lastModified); this.doHead(req, resp); &#125; else if (method.equals("POST")) &#123; this.doPost(req, resp); &#125; else if (method.equals("PUT")) &#123; this.doPut(req, resp); &#125; else if (method.equals("DELETE")) &#123; this.doDelete(req, resp); &#125; else if (method.equals("OPTIONS")) &#123; this.doOptions(req, resp); &#125; else if (method.equals("TRACE")) &#123; this.doTrace(req, resp); &#125; else &#123; String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = new Object[]&#123;method&#125;; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(501, errMsg); &#125; &#125; FrameworkServlet中的实现(FrameworkServlet是SpringMVC核心控制器DispatchServlet的父类)： 1234567891011121314151617/** * Override the parent class implementation in order to intercept PATCH requests. */@Overrideprotected void service(HttpServletRequest request,HttpServletResponse response) throws ServletException, IOException &#123; HttpMethod httpMethod = HttpMethod.resolve(request.getMethod()); if (HttpMethod.PATCH == httpMethod || httpMethod == null) &#123; processRequest(request, response); &#125; else &#123; super.service(request, response); &#125;&#125; 关于模板方法模式的学习就到这里了。]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-观察者模式]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-design-model-obs%2F</url>
    <content type="text"><![CDATA[最近想深入研究下响应式编程，作为基础很有必要来把观察者模式撸一遍；一开始我是觉得很easy,然后就直接开撸了，撸着撸着发现撸不动了。因为我突然不太明白这个模式了，说好的观察者，到底发布-订阅的两者执行者谁才是观察者？又或者说还有其他角色？但是根据《JAVA与模式》一书中的结构，并没有额外的角色出现。 思考中….，好吧想不出来….，跑步去… 跑步时我给自己罗列了几个问题： 这里先抛出定义：GOF给观察者模式如下定义：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 既然是对象状态发生变更，那么到底是谁的状态发生了变更，又导致了谁被通知。 观察者模式既然又可以称之为“发布-订阅模式”，那么对应起来，观察者到底承当了“发布”的角色还是“订阅”的角色。就是说观察者到底是主动的还是被动的？ 被观察者又干了什么事？它是主动的还是被动的角色？ 这里由于一些定式思维，总会觉得既然是“被观察者”，那么这个“被”字就是不是就表明“被观察者”是被动接受变更的一方，也就是接受通知的一方呢？ 之前我也是走到这个胡同里了，程序写完总觉得哪里不对；回过头看，还是自己太年轻，没有get到哪些大佬们的点。 先来看程序；这里用掘金来打个比方，我的博客glmmaper作为被观察者，也就是发布者。掘金小伙伴们作为观察者，也就是订阅者。 具体逻辑：小伙伴们（订阅者）关注（订阅）了我的博客（发布者），如果我发布了一篇文章（状态变更），就会通知（推送消息）所有关注我的小伙伴。 123456789101112131415161718192021222324252627package com.glmapper.designmode.observor;/** * @description: 抽象主题接口 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/22 */public interface Subject &#123; /** * 新增关注者 * @param observer 关注的小伙伴 */ void addFocusObserver(Observer observer); /** * 取消关注 * @param observer 取消关注的小伙伴 */ void removeFocusObserver(Observer observer); /** * 通知机制，通知机制由相关事件来触发，比如说发布文章 * @param blogName 博客名 * @param articleName 文章名 */ void notifyObservers(String blogName,String articleName);&#125; 三个方法，一个是博客主页增加了一个关注者；一个是博客主页有小伙伴取消的关注（对于博客来说就是移除一个关注者，这里不知道是否也会觉得别扭？明明你取消的关注，为啥说成是我移除你，也就是不让你关注了，还能这么玩?这里肯定是需要在引入其他的一些辅助机制，比如说你在客户端发起了一个取消关注的请求，后端处理的时候掘金的工程师们就是在我的关注列表中将你移除的，嗯，这么一想确实是我不让你关注了。😄….）；最后一个方法是发起一个通知。下面是一个具体的博客，比如说是glmapper； 1234567891011121314151617181920212223242526272829303132333435363738394041package com.glmapper.designmode.observor;import java.util.ArrayList;import java.util.List;/** * @description: 这个是具体发布者，这里比喻成我的博客glmapper * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/22 */public class ConcreteSubject implements Subject &#123; /** 我的当前关注列表 */ List&lt;Observer&gt; Observers = new ArrayList&lt;&gt;(); /** 我的博客名 ：求关注 */ private static final String blogName = "glmapper"; @Override public void addFocusObserver(Observer observer) &#123; Observers.add(observer); &#125; @Override public void removeFocusObserver(Observer observer) &#123; Observers.remove(observer); &#125; @Override public void notifyObservers(String blogName,String articleName) &#123; for (Observer observer:Observers) &#123; observer.update(blogName,articleName); &#125; &#125; /** * 这里是发布文章，触发通知事件 */ public void publishArticle(String articleName)&#123; notifyObservers(blogName,articleName); &#125;&#125; 前面提到，通知事件肯定是由于某些状态发生变更了，才会进行通知，这里就可以比方为我发布了一篇博客，然后通知你（这里只能假如你关注了）。再来看观察者： 12345678910111213141516package com.glmapper.designmode.observor;/** * @description: 订阅者抽象接口 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/22 */public interface Observer &#123; /** * 调用此方法会更新状态，做出相应的动作 * @param blogName * @param articleName */ void update(String blogName,String articleName);&#125; 抽象订阅者，有一个update方法，通知你去做出相应的动作，具体动作每个观察者都可能不同。 123456789101112131415161718192021package com.glmapper.designmode.observor;/** * @description: 这个是具体订阅者,这里可以比喻成博客关注者， * 收到变更信息之后需要做出相应的动作 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/22 */public class ConcreteObserver implements Observer &#123; @Override public void update(String blogName,String articleName) &#123; System.out.println(blogName+"发布了新的文章，文章名为："+articleName); read(articleName); &#125; private void read(String articleName)&#123; System.out.println("即将阅读 "+articleName+" 这篇文章"); &#125;&#125; 上面是一个具体的关注者，加入说就是你。博客更新之后发了一个通知给你(掘金app推送的消息)，然后你点了一下，这个也是一种动作。例子中举的是read,就是关注者做出阅读的动作。 看下最后的运行结果： 1234567891011121314151617181920212223242526package com.glmapper.designmode.observor;/** * @description: [描述文本] * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: 磊叔 * @date: 18/4/22 */public class MyMainIndex&#123; public static void main(String[] args) &#123; //博客主体 ConcreteSubject subject = new ConcreteSubject(); //关注者：handSome是帅气的意思 Observer handSome = new ConcreteObserver(); //增加一个关注者 subject.addFocusObserver(handSome); //发一篇文章 subject.publishArticle("设计模式-观察者模式"); &#125;&#125;glmapper发布了新的文章，文章名为：设计模式-观察者模式即将阅读 设计模式-观察者模式 这篇文章 酒桶说：啊，欢乐时光总是短暂的 所以作为积累，还是需要将一些基本的概念来罗列一下的。 主要角色： 抽象主题角色（Subject：主题角色将所有对观察者对象的引用保存在一个集合中，每个主题可以有任意多个观察者。抽象主题提供了增加和删除等观察者对象的接口。 抽象观察者角色（Observer）：为所有的具体观察者定义一个接口，在观察的主题发生改变时更新自己。 具体主题角色（ConcreteSubject）(1个)：存储相关状态到具体观察者对象，当具体主题的内部状态改变时，给所有登记过的观察者发出通知。具体主题角色通常用一个具体子类实现。 具体观察者角色（ConcretedObserver）(多个)：存储一个具体主题对象，存储相关状态，实现抽象观察者角色所要求的更新接口，以使得其自身状态和主题的状态保持一致。 具体关系： 抽象主题（Subject）(接口)–&gt;被具体主题（ConcreteSubject）角色(1个)实现 抽象观察者（Observer）(接口)–&gt;被具体观察者（ConcretedObserver）角色(N个)实现 观察者对象载入主题方法,并在主题方法中调用观察者对象实现的接口方法update来让自己发生变更响应。 一些场景： 当对一个对象的的改动会引发其他对象的变动时，而且你无法预测有多少个对象需要被改动。 当一个对象需要有能力通知其他对象，且不需要了解这些对象是什么类型时。 基于发布订阅的具体实现例子还是很多的，比较典型的就是这种订阅一个博客，然后博客更新推送；还有微信公众号，服务号这些。 到这里我们再回过头来看一开始留下的几个问题： 被观察者的状态发生变更，然后“主动通知”观察者，并不是说，观察者主动去获取通知。 被观察者是消息发布者，观察者是消息订阅者；观察者是被动接受者。 被观察者的作用就是存储当前的观察者列表，然后提供一些通知机制来告诉观察者自己发生了状态变更，是主动者。 OK，观察者模式就撸到这里，也欢迎小伙伴们提出自己珍贵的意见；有写的不当之处烦请及时提出。]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC源码系列：九大组件小记]]></title>
    <url>%2F2018%2F11%2F10%2Fspring-base-webmvc5%2F</url>
    <content type="text"><![CDATA[前面几篇文章都是针对于SpringMVC中的具体组件进行源码分析的；本文主要用于补充记录一下关于SpringMVC中九大组件的学习。这个会牵扯出除之前的几篇HandlerMapping之外的其他一些基础组件。 之前简单的有介绍过DispatcherServlet这个类的体系结构，此处就不再赘述了。在DispatcherServlet类中，其在mvc子容器进行初始化时就会完成对九大组件的初始化工作，具体哪九大组件后面会慢慢说到。先来看下在DispatcherServlet中是通过哪些方法来完成初始化工作的,先贴一段代码： 123456789101112131415protected void onRefresh(ApplicationContext context) &#123; this.initStrategies(context);&#125;protected void initStrategies(ApplicationContext context) &#123; this.initMultipartResolver(context); this.initLocaleResolver(context); this.initThemeResolver(context); this.initHandlerMappings(context); this.initHandlerAdapters(context); this.initHandlerExceptionResolvers(context); this.initRequestToViewNameTranslator(context); this.initViewResolvers(context); this.initFlashMapManager(context);&#125; 上面代码中的onRefresh方法就是DispatcherServlet的入口方法。在onRefresh中又通过调用initStrategies方法来将各个组件的初始化逻辑进行整合，个人理解其实就是策略套策略，在一个就是职责也明确。 在initStrategies方法中又通过调用组件各自的初始化方法来完成具体的初始化工作。从这个地方其实就可以清楚的看出SpringMVC中的9个组件名称了。下面就来捋一捋这九大组件的基本职责。 HandlerMapping关于handlermapping在下面几篇文章中做过一些基本介绍，但是还不是很全，对于handlermapping的子类还没有分析完，这个会后期更新的。 SpringMVC源码系列：HandlerMapping SpringMVC源码系列：AbstractHandlerMapping SpringMVC源码系列：AbstractUrlHandlerMapping 对于HandlerMapping来说，其作用就是根据request找到相应的处理器Handler和Intecepter拦截器。具体细节参数上面第一篇文章。 HandlerAdapter如果说HandlerMapping是一支笔，那么HandlerAdapter就是用笔的人。也就是说HandlerAdapter就是使用处理器干活的人。为什么呢？来看下代码： 12345public interface HandlerAdapter &#123; boolean supports(Object var1); ModelAndView handle(HttpServletRequest var1, HttpServletResponse var2, Object var3) throws Exception; long getLastModified(HttpServletRequest var1, Object var2);&#125; 是不是一目了然了，在HandlerAdapter接口中提供了handle这样一个方法，参数中Object handler第三个参数其实就是一个处理器，那我们就知道了，handle方法就是使用handler来处理逻辑的。处理之后返回一个ModelAndView。 HandlerExceptionResolver这个是SpringMVC中的异常处理组件，HandlerExceptionResolver这个组件的作用就是根据异常设置ModelAndView，然后再将处理结果交给render方法进行渲染。当然render也仅仅只是负责将ModelAndView渲染成页面，ModelAndView的具体来源它不关心。 这里需要说明一下，加入在渲染过程中发生异常怎么办？从上面的分析我们可以清楚的知道，HandlerExceptionResolver这个组件对异常的处理结果是ModelAndView，然后再由render方法进行渲染，也就是说HandlerExceptionResolver是在渲染之前工作的，因此渲染过程中发生异常，HandlerExceptionResolver是不会处理的。 123public interface HandlerExceptionResolver &#123; ModelAndView resolveException(HttpServletRequest var1, HttpServletResponse var2, Object var3, Exception var4);&#125; 在HandlerExceptionResolver中也只有一个方法，这个方法就是从异常中解析出ModelAndView。 ViewResolverViewResolver的作用是将String类型的逻辑视图根据local解析为View视图的。下面是ViewResolver的源码接口定义： 123public interface ViewResolver &#123; View resolveViewName(String viewName, Locale local) throws Exception;&#125; 从代码中可以看到，在ViewResolver中也是只有一个方法，从resolveViewName方法的参数和返回结果就很好的解释了其作用。 viewName String类型的视图名 local 区域，可以用来做国际化。 View实际上是用来渲染页面的，也就是说将程序返回的结果填入到具体的模板里面，生成具体的视图文件，比如：jsp，ftl，html等。 但是这里又会牵扯出两个问题： 用什么模板？ 参数怎么填入？ 当然，这两个问题也就是本小节说的ViewResolver需要解决的问题。大体分为两种： 针对单一视图类型的解析器 InternalResourceViewResolver FreeMarkerViewResolver 上面两种是用的最多的两种，InternalResourceViewResolver用来解析jsp，而FreeMarkerViewResolver则是针对FreeMarker。 针对同时解析多种类型视图的解析器 BeanNameViewResolver 需要同时使用视图名和对应的local来解析视图。它需要将每一个视图名和对应的视图类型配置到相应的properties文件中。（后面讲组件实现细节时给出列子） XmlViewResolver XmlViewResolver和BeanNameViewResolver有点差不多，BeanNameViewResolver使用的是xml格式的配置文件。 ResourceBundleViewResolver 这个其实就是根据viewName从Spring容器中查找bean，再根据这个bean来找到对应的视图。 LocalResolver在上面的ViewResolver中提到，解析视图需要两个参数，一个是String类型的逻辑视图名，另外一个是local。LocalResolver的作用就是从request中解析出local的。 12345public interface LocaleResolver &#123; Locale resolveLocale(HttpServletRequest request); void setLocale(HttpServletRequest request, HttpServletResponse response, Locale local);&#125; 第一个方法是从request中解析出local，第二个方法是将local设置到request中。 关于local大多数情况下都是用来做国际化处理的。 ThemeResolver解析主题的。这个我平时除了SpringMVC自己提供的功能外，很少自己去扩展使用，即使是换主题也没有做过。不过既然存在肯定是有存在的原因的。对于我们常见的网页界面活着手机界面来说，一套主题无非就是换一套图片，活着css样式文件等等。我们通过ThemeResolver这个就可以实现这样的功能。具体使用其实也就是配一套properties文件供系统在不同的时候读取切换；当然使用这个也是可以实现国际化的。 12345public interface ThemeResolver &#123; String resolveThemeName(HttpServletRequest request); void setThemeName(HttpServletRequest request, HttpServletResponse response, String themeName);&#125; RequestToViewNameTranslator这个其实还是挺有意思的，就是将request请求转换为视图名称。 123public interface RequestToViewNameTranslator &#123; String getViewName(HttpServletRequest request) throws Exception;&#125; RequestToViewNameTranslator只有一个默认的实现类DefaultRequestToViewNameTranslator。 在DefaultRequestToViewNameTranslator具体实现了getViewName(HttpServletRequest request)方法： 1234public String getViewName(HttpServletRequest request) &#123; String lookupPath = this.urlPathHelper.getLookupPathForRequest(request); return this.prefix + this.transformPath(lookupPath) + this.suffix;&#125; 主要是委派给urlPathHelper帮助类得到请求的后缀名称，比如通过 请求路径比如/glmapper/login.do转换得到/login.do ；具体怎么转换成视图也会在后面的组件介绍中给出具体的例子。 MultipartResolver这个相应小伙伴们也不陌生，做网站多多少少会涉及到文件上传。MultipartResolver就是用来处理上传请求的。其处理方式就是将request包装成MultipartHttpServletRequest。然后我们就可以用MultipartHttpServletRequest这个直接调用getFile获取的文件了。 FlashMapManager这个在redirect是进行参数传递需要用到。 12345public interface FlashMapManager &#123; FlashMap retrieveAndUpdate(HttpServletRequest request, HttpServletResponse response); void saveOutputFlashMap(FlashMap flashMap, HttpServletRequest request, HttpServletResponse response);&#125; retrieveAndUpdate这个方法是用来恢复参数的，对于恢复过的和超时的参数将都会被删除掉。 saveOutputFlashMap这个方法是用来保存参数的。 FlashMapManager的默认实现机制中参数的存储是放在session中的。我之前在一个项目中就有遇到过这种情况，对于一些我们不想暴露在url中的参数，在进行请求转发时，可以使用@RedirectAttributes将参数保存，然后在下一个处理器中获取到。 小结本篇主要是来对九大组件做一个笼统的介绍，细节实现及案例均不涉及；在后续的SpringMVC源码系列中对各个组件的实现细节分析时再一探究竟吧。]]></content>
      <categories>
        <category>spring mvc</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>web</tag>
        <tag>mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC源码系列：AbstractUrlHandlerMapping]]></title>
    <url>%2F2018%2F11%2F10%2Fspring-base-webmvc4%2F</url>
    <content type="text"><![CDATA[AbstractUrlHandlerMapping是通过url来进行匹配的，也就是说通过url与对应的Handler包存到一个Map中，然后在getHandlerInternal方法中使用url作为key从Map中获取我们的handler。 AbstractUrlHandlerMapping实现了从url获取handler的过程，具体的映射关系，也就是handlerMap则是交给具体子类来去完成的。AbstractUrlHandlerMapping中定义了handlerMap用来维护映射关系，如下：12private final Map&lt;String, Object&gt; handlerMap = new LinkedHashMap&lt;String, Object&gt;(); 除此之外，还有一个rootHandler,这个用于处理“/”请求。 在前面三篇文章中提到过，handler的获取是通过getHandlerInternal方法完成的，下面看下具体的源码，分析下handler的获取和handlerMap的构建。 12345678910111213141516171819202122232425262728293031323334353637383940414243//查找给定请求的URL路径的Handler。protected Object getHandlerInternal(HttpServletRequest request) throwsException &#123; String lookupPath = getUrlPathHelper().getLookupPathForRequest(request); //使用lookupPath从Map中查找handler Object handler = lookupHandler(lookupPath, request); if (handler == null) &#123; //临时变量，保存原始的handler Object rawHandler = null; //是否是‘/’根路径 if ("/".equals(lookupPath)) &#123; //获取rootHandler rawHandler = getRootHandler(); &#125; //如果rawHandler是null if (rawHandler == null) &#123; //获取默认的handler rawHandler = getDefaultHandler(); &#125; //如果rawHandler不是null if (rawHandler != null) &#123; // 如果是string类型，则到容器中查找具体的bean if (rawHandler instanceof String) &#123; String handlerName = (String) rawHandler; //容器中获取 rawHandler = getApplicationContext().getBean(handlerName); &#125; //校验handler和request是否匹配 validateHandler(rawHandler, request); //注册拦截器 handler = buildPathExposingHandler(rawHandler, lookupPath, lookupPath, null); &#125; &#125; //日志debug if (handler != null &amp;&amp; logger.isDebugEnabled()) &#123; logger.debug("Mapping [" + lookupPath + "] to " + handler); &#125; else if (handler == null &amp;&amp; logger.isTraceEnabled()) &#123; logger.trace("No handler mapping found for [" + lookupPath + "]"); &#125; //返回handler return handler;&#125; 在getHandlerInternal方法中有几个方法调用，像getLookupPathForRequest、getRootHandler、getDefaultHandler、lookupHandler、buildPathExposingHandler等。其中getLookupPathForRequest、getRootHandler、getDefaultHandler这几个没啥好说的；比较核心的就是lookupHandler、buildPathExposingHandler这两个方法。 lookupHandler lookupHandler使用getUrlPathHelper().getLookupPathForRequest(request)获取到的lookupPath从Map中查找需要的Handler,通常情况下是直接get不到的。为什么呢？原因在于很多的handler都是使用了Pattern的匹配模式，比如说“/user/*”,星号表示匹配任意内容，并非是指定url串中的字符。如果Pattern中包含了PathVariable,也不能直接从Map中获取到。 除此之外，一个url还可能和多个Pattern相匹配，那么这个时候咱们肯定就需要选择最优的，所以说查找过程其实并不是直接从map中获取那么简单。那么就来看下在lookupHandler中都干了哪些事情： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374protected Object lookupHandler(String urlPath, HttpServletRequest request) throws Exception &#123; // 直接匹配，直接从Map中获取 Object handler = this.handlerMap.get(urlPath); //取到了 if (handler != null) &#123; // 如果是string类型，则从容器中获取Bean if (handler instanceof String) &#123; String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); &#125; //验证是否匹配 validateHandler(handler, request); //注册拦截器 return buildPathExposingHandler(handler, urlPath, urlPath, null); &#125; // Pattern 匹配，带*号的模式与url进行匹配 List&lt;String&gt; matchingPatterns = new ArrayList&lt;String&gt;(); for (String registeredPattern : this.handlerMap.keySet()) &#123; if (getPathMatcher().match(registeredPattern, urlPath)) &#123; matchingPatterns.add(registeredPattern); &#125; else if (useTrailingSlashMatch()) &#123; if (!registeredPattern.endsWith("/") &amp;&amp; getPathMatcher().match(registeredPattern + "/", urlPath)) &#123; matchingPatterns.add(registeredPattern +"/"); &#125; &#125; &#125; //获取最佳匹配 String bestPatternMatch = null; Comparator&lt;String&gt; patternComparator = getPathMatcher().getPatternComparator(urlPath); if (!matchingPatterns.isEmpty()) &#123; Collections.sort(matchingPatterns, patternComparator); if (logger.isDebugEnabled()) &#123; logger.debug("Matching patterns for request [" + urlPath + "] are " + matchingPatterns); &#125; bestPatternMatch = matchingPatterns.get(0); &#125; //最佳匹配不为null if (bestPatternMatch != null) &#123; //从Map中看看是否有对应的Handler handler = this.handlerMap.get(bestPatternMatch); //如果Map中没有 if (handler == null) &#123; //是否以/结尾 Assert.isTrue(bestPatternMatch.endsWith("/")); //去除/之后再获取一次 handler = this.handlerMap.get(bestPatternMatch.substring(0, bestPatternMatch.length() - 1)); &#125; // 如果是String类型，则从容器中获取Bean? if (handler instanceof String) &#123; String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); &#125; //验证是否匹配 validateHandler(handler, request); String pathWithinMapping = getPathMatcher().extractPathWithinPattern(bestPatternMatch, urlPath); // 可能有多种最佳模式，让我们确保我们有正确的URI模板变量（译） Map&lt;String, String&gt; uriTemplateVariables = new LinkedHashMap&lt;String, String&gt;(); for (String matchingPattern : matchingPatterns) &#123; if (patternComparator.compare(bestPatternMatch, matchingPattern) == 0) &#123; Map&lt;String, String&gt; vars = getPathMatcher().extractUriTemplateVariables(matchingPattern, urlPath); Map&lt;String, String&gt; decodedVars = getUrlPathHelper().decodePathVariables(request, vars); uriTemplateVariables.putAll(decodedVars); &#125; &#125; if (logger.isDebugEnabled()) &#123; logger.debug("URI Template variables for request [" + urlPath + "] are " + uriTemplateVariables); &#125; return buildPathExposingHandler(handler, bestPatternMatch, pathWithinMapping, uriTemplateVariables); &#125; // No handler found... return null;&#125; 上面代码中，关于译注的部分需要说一下；代码如下： 123456789Map&lt;String, String&gt; uriTemplateVariables = new LinkedHashMap&lt;String, String&gt;();for (String matchingPattern : matchingPatterns) &#123; if (patternComparator.compare(bestPatternMatch, matchingPattern) == 0) &#123; Map&lt;String, String&gt; vars = getPathMatcher().extractUriTemplateVariables(matchingPattern, urlPath); Map&lt;String, String&gt; decodedVars = getUrlPathHelper().decodePathVariables(request, vars); uriTemplateVariables.putAll(decodedVars); &#125;&#125; 之前是通过sort方法进行排序的，然后将第一个作为bestPatternMatch，但是如果多个pattern的顺序相同，也就是说sort返回的是0,存在多种最佳匹配，那就需要确保我们有正确的URI模板变量。上面代码就是处理这种情况的。 buildPathExposingHandler 这个方法在上面的两段代码中都频繁出现，那么这个方法到底有什么作用呢？代码中我注释的是注册拦截器，那么注册的又是什么拦截器？带着这两个问题，我们来看下代码。 123456789101112131415161718//buildPathExposingHandler为给定的rawHandler构建一个Handler对象，并在执//行处理程序之前暴露实际的处理程序PATH_WITHIN_HANDLER_MAPPING_ATTRIBUT//E以及URI_TEMPLATE_VARIABLES_ATTRIBUTE。//默认实现用一个特殊的拦截器构建一个HandlerExecutionChain，该拦截器暴露//path属性和uri模板变量。protected Object buildPathExposingHandler(Object rawHandler, String bestMatchingPattern, String pathWithinMapping, Map&lt;String, String&gt; uriTemplateVariables) &#123; HandlerExecutionChain chain = new HandlerExecutionChain(rawHandler); chain.addInterceptor(new PathExposingHandlerInterceptor(bestMatchingPattern, pathWithinMapping)); if (!CollectionUtils.isEmpty(uriTemplateVariables)) &#123; chain.addInterceptor(new UriTemplateVariablesHandlerInterceptor(uriTemplateVariables)); &#125; return chain;&#125; 四个参数： rawHandler 原始处理程序 bestMatchingPattern 最佳匹配模式 pathWithinMapping 在执行Handler之前公开的路径 uriTemplateVariables 如果没有找到变量，URI模板变量可以是{null} 从代码注释翻译及代码内容可以了解到，buildPathExposingHandler的作用就是给已经查找到的handler注册两个拦截器 ExposingHandlerInterceptor UriTemplateVariablesHandlerInterceptor 这两个类均是AbstractUrlHandlerMapping的内部类，也就是两个内部拦截器。这两个拦截器的主要作用就是将与当前url实际匹配的pattern、匹配条件以及url模板参数等设置到request的属性里面去，这样在后面的处理过程中就可以直接从request属性中获取。看下两个内部类的定义： 123456789101112131415161718192021222324252627282930313233private class PathExposingHandlerInterceptor extends HandlerInterceptorAdapter &#123; private final String bestMatchingPattern; private final String pathWithinMapping; public PathExposingHandlerInterceptor(String bestMatchingPattern, String pathWithinMapping) &#123; this.bestMatchingPattern = bestMatchingPattern; this.pathWithinMapping = pathWithinMapping; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; exposePathWithinMapping(this.bestMatchingPattern, this.pathWithinMapping, request); //设置request属性 request.setAttribute(HandlerMapping.INTROSPECT_TYPE_LEVEL_MAPPING, supportsTypeLevelMappings()); return true; &#125;&#125;private class UriTemplateVariablesHandlerInterceptor extends HandlerInterceptorAdapter &#123; private final Map&lt;String, String&gt; uriTemplateVariables; public UriTemplateVariablesHandlerInterceptor(Map&lt;String, String&gt; uriTemplateVariables) &#123; this.uriTemplateVariables = uriTemplateVariables; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; //这exposeUriTemplateVariables种设置request属性 exposeUriTemplateVariables(this.uriTemplateVariables, request); return true; &#125;&#125; 从内部类的代码可以看出，这两个内部类是通过在preHandle方法中调用exposePathWithinMapping和exposeUriTemplateVariables完成属性设置到request中的。 对于查找handler的关键其实就是维护url和handler的映射关系，也就是handlerMap的构建。在AbstractUrlHandlerMapping中是通过registerHandler这个方法来构建handlerMap的。AbstractUrlHandlerMapping提供了两个registerHandler方法，下面就通过代码来看下具体的实现。 1234567protected void registerHandler(String[] urlPaths, String beanName) throws BeansException, IllegalStateException &#123; Assert.notNull(urlPaths, "URL path array must not be null"); for (String urlPath : urlPaths) &#123; registerHandler(urlPath, beanName); &#125;&#125; 第一个registerHandler是将多个url注册到一个处理器。beanName其实就是咱们处理器的名称，可以通过beanName到容器中去找到真正的处理器Bean。具体处理就是通过遍历所有的url，然后再通过调用第二个registerHandler将handler注册到handlerMap中。来看第二个： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748protected void registerHandler(String urlPath, Object handler) throwsBeansException, IllegalStateException &#123; Assert.notNull(urlPath, "URL path must not be null"); Assert.notNull(handler, "Handler object must not be null"); Object resolvedHandler = handler; // 如果的handler是string类型，并且不是lazyInitHandlers，则从SpringMV //C容器中获取handler if (!this.lazyInitHandlers &amp;&amp; handler instanceof String) &#123; String handlerName = (String) handler; if (getApplicationContext().isSingleton(handlerName)) &#123; resolvedHandler = getApplicationContext().getBean(handlerName); &#125; &#125; Object mappedHandler = this.handlerMap.get(urlPath); if (mappedHandler != null) &#123; if (mappedHandler != resolvedHandler) &#123; //异常处理 &#125; &#125; else &#123; //是否是跟路径 if (urlPath.equals("/")) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Root mapping to " + getHandlerDescription(handler)); &#125; setRootHandler(resolvedHandler); &#125; //是否是*模式 else if (urlPath.equals("/*")) &#123; if (logger.isInfoEnabled()) &#123; logger.info("Default mapping to " + getHandlerDescription(handler)); &#125; setDefaultHandler(resolvedHandler); &#125; //加入到handlerMap中 else &#123; this.handlerMap.put(urlPath, resolvedHandler); if (logger.isInfoEnabled()) &#123; logger.info("Mapped URL path [" + urlPath + "] onto " + getHandlerDescription(handler)); &#125; &#125; &#125;&#125; 这个里面首先是看Map中是否有原来传入的url，如果没有就加入，如果有就看下原来保存的和当前注册的handler是否是同一个，如果不是同一个就抛出异常。（同一个url不可能存在两个不同的handler）。 在put之前，也做了一些“/”和“/*”的验证处理，如果是这两种路径的话就不保存到handlerMap中了。 “/”：setRootHandler(resolvedHandler); “/*”：setDefaultHandler(resolvedHandler); OK，到这AbstractUrlHandlerMapping这个类就分析完了，其实AbstractUrlHandlerMapping做的事情就是定义了一个框子，子类只要完成对Map的初始化就可以了。关于AbstractUrlHandlerMapping的子类后续再谈。]]></content>
      <categories>
        <category>spring mvc</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>web</tag>
        <tag>mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：注解说明]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase13%2F</url>
    <content type="text"><![CDATA[因为要看Spring中注解的具体定义，所以在说之前，先来简单说下JAVA中注解的一些基本知识。 元注解什么是元注解呢，就是注解的注解。java中提供了以下几种： @Target 注解的作用域描述 123456789101112131415161718public enum ElementType &#123; /** 类, 接口 或者枚举 */ TYPE, /** 字段 */ FIELD, /** 方法 */ METHOD, /** 参数 */ PARAMETER, /** 构造方法 */ CONSTRUCTOR, /** 局部变量 */ LOCAL_VARIABLE, /** 注解类型 */ ANNOTATION_TYPE, /** 包 */ PACKAGE&#125; @Retention 生命周期描述 1234567891011121314public enum RetentionPolicy &#123; /** * 在原文件中有效，被编译器丢弃。 */ SOURCE, /** * 在class文件有效，可能会被虚拟机忽略。 */ CLASS, /** * 在运行时有效。 */ RUNTIME&#125; @Inherited 标识性的元注解，它允许子注解继承它。 @Documented 用于标准生成javadoc时会包含的注解。 JAVA中注解的定义方式1public @interface 注解名 &#123;定义体&#125; 上面试一些基本概念点，关注注解其他的一些特性和用法就不细说了。直接看Spring中的注解吧。 1、@Component12345678910111213@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Component &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any */ String value() default "";&#125; 指示注释类是“组件”。 当使用基于注释的配置和类路径扫描时，这些类被认为是自动检测的候选对象。 2、@Controller1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Controller &#123; String value() default "";&#125; 使用过Spring mvc的小伙伴对于这个注解肯定不陌生。@Controller表示注释的类是“控制器”（例如Web控制器）。这个注解作为@Component的一个特定方式存在，允许通过类路径扫描来自动检测实现类。通常情况下会结合RequestMapping注解使用。从它的定义层面来看，这个注解只能用于接口或者类上面，不能用于方法或者属性字段上面。 3、@Service1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Service &#123; String value() default "";&#125; 表示注释类是一个“服务”，最初由Domain-Driven Design （Evans，2003）定义为“作为模型中独立的接口提供的操作，没有封装状态”。 在一般情况下，我们把他用在标准我们的service服务接口的实现类上面，实际上这相当于缩小它们的语义和适当的使用。 @Service这个注释作为 @Component的一个特例，允许通过类路径扫描来自动检测实现类。 4、@Repository123456789101112@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Repository &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any */ String value() default "";&#125; 用于标注数据访问组件，即DAO组件 5、@RequestMapping123456789101112131415161718192021222324@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Mappingpublic @interface RequestMapping &#123; String name() default ""; @AliasFor("path") String[] value() default &#123;&#125;; @AliasFor("value") String[] path() default &#123;&#125;; RequestMethod[] method() default &#123;&#125;; String[] params() default &#123;&#125;; String[] headers() default &#123;&#125;; String[] consumes() default &#123;&#125;; String[] produces() default &#123;&#125;;&#125; @RequestMapping是一个用来处理地址映射请求的注解，从定义可以看出，可作用于方法或者类上。 用于类上，大多数是为了进行区分controller 用于方法上则是对方法进行注解以产生访问的路径。 它包括了几个属性： value 用于设置方法或者类的映射路径，可以直接写路径。我们通常都是直接写，例如：@RequestMapping(“/XXX”); method 用于指定请求的方法，可以设置单个或多个，如果请求方法不满足条件则会请求失败。 params 指定request中必须包含某些参数值是，才让该方法处理。 name 此映射指定一个名称 path 仅在Servlet环境中：路径映射URI（例如“/myPath.do”）。也支持Ant风格的路径模式（例如“/myPath/*.do”）。在方法级别，在类型级别表示的主映射内支持相对路径（例如“edit.do”）。 路径映射URI可能包含占位符（例如“/ $ {connect}”） consumes 指定处理请求的提交内容类型（Content-Type），例如application/json, text/html; produces 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回； headers 指定request中必须包含某些指定的header值，才能让该方法处理请求。 其他的几个没怎么用过，确实不了解，有知道的小伙伴，欢迎留言。 6、@ResponseBody@ResponseBody这个我一般是用在做异步请求调用的方法上来使用的。因为在使用@RequestMapping后，返回值通常解析为跳转路径。加上@responsebody后，返回结果直接写入HTTP response body中，不会被解析为跳转路径。 对于异步请求，我们不希望返回解析视图，二是希望响应的结果是json数据，那么加上@responsebody后，就会直接返回json数据。 7、@AutowiredAutowired就是自动装配的意思，其作用是为了消除代码Java代码里面的getter/setter与bean属性中的property。当然，getter看个人需求，如果私有属性需要对外提供的话，就应该保留。 @Autowired默认按类型匹配的方式，在容器查找匹配的Bean，当有且仅有一个匹配的Bean时，Spring将其注入@Autowired标注的变量中。 但是当接口存在两个实现类的时候必须使用@Qualifier指定注入哪个实现类，否则可以省略，只写@Autowired。 8、@Qualifier@Qualifier用于指定注入Bean的名称，就是上面说到的，如果容器中有一个以上匹配的Bean，则可以通过@Qualifier注解限定Bean的名称。 9、@Resource这个注解不是Spring的，放在这里是为了和@Autowired做一个区别。@Resource默认按名称装配，当找不到与名称匹配的bean才会按类型装配。 10、@PathVariable当使用@RequestMapping URI template 样式映射时， 即 someUrl/{paramId}, 这时的paramId可通过 @Pathvariable注解绑定它传过来的值到方法的参数上。 123456@RequestMapping("/user/&#123;userId&#125;")public ModelAndView userCenter(HttpServletRequest request, HttpServletResponse response, @PathVariable String userId)&#123; //do something &#125; 如果方法参数名称和需要绑定的uri template中变量名称不一致，需要在@PathVariable(“name”)指定uri template中的名称。 11、@RequestParam@RequestParam注解有两个属性： value、required； value用来指定要传入值的id名称 required用来指示参数是否必须绑定； 举个例子： 123456789@RequestMapping("/t_rparam1") public String t_rparam1(@RequestParam Long userId) &#123; //do something &#125; @RequestMapping("/t_rparam2") public String t_rparam2(Long userId) &#123; //do something &#125; t_rparam1 必须带有参数,也就是说你直接输入localhost:8080/t_rparam1 会报错只能输入localhost:8080/t_rparam1?userId=? 才能执行相应的方法 t_rparam2 可带参数也可不带参数;也就是说输入localhost:8080/t_rparam2和输入 localhost:8080/t_rparam2?userId=?都可以正常运行 当然我们也可以设置 @RequestParam 里面的required为false(默认为true 代表必须带参数) 这样t_rparam1就跟t_rparam2是一样的了。 12、@RequestHeader利用@RequestHeader 注解可以把Request请求header部分的值绑定到方法的参数上。 1234567@RequestMapping("/t_heander") public void getRequestHeaderTest(HttpServletRequest request, HttpServletResponse response, @RequestHeader("Accept-Encoding")String encoding) &#123; //do something &#125; 13、@CookieValue@CookieValue就是把Request header中cookie的值绑定到方法的参数上。比如说我们的cookie如下： 1Cookie:JSESSIONID=ka8A5L5t7WTUPXbaLupBieqOdmc0ZpD5MyKvea6oQr7JJSIZzM;userId=001;sysFlag=glmapper 获取如下：1234@RequestMapping("/t_cookie") public void getCookieValueTest(@CookieValue("JSESSIONID") String cookie) &#123; //do something &#125; 14、@RequestBody@RequestBody这个注解常用来处理Content-Type不是application/x-www-form-urlencoded编码的内容，比如说：application/json, application/xml等等；这个和ResonseBody可以反过来理解。 15、@ModelAttribute 方法上 通常用来在处理@RequestMapping之前，为请求绑定需要从后台查询的model； 参数上 用来通过名称对应，把相应名称的值绑定到注解的参数bean上； 参考 《Spring技术内幕》 https://www.cnblogs.com/FrankLei/p/6579843.html]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC·ThreadPoolExecutor 线程池]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-up-juc2%2F</url>
    <content type="text"><![CDATA[ThreadPoolExecutor算是JUC中最常用的类之一了。ThreadPoolExecutor，顾名思义，thread-pool-executor,硬翻译就是“线程-池-执行者”；java中，通过ThreadPoolExecutor可以很容易的创建一个线程池。但是我们为什么要使用线程池？呢？它能够带来什么样的优势呢？它又是怎么实现的呢？OK，带着这几个问题，我们来学习一下JAVA中的线程池技术。 为什么要使用线程池？关于这个问题其实有点鸡肋，我觉得再问这个问题之前更应该问为什么要有线程池。那为什么呢? this is a 例子： 快递行业最近两年发展的灰常火热，听说工资也非常的高，搞得我一天天的都没有心思去好好写代码了... 之前的小快递公司都是没有固定的快递员的，就是说，每次去送一件快递，站点负责人就需要去找一个人来帮忙送，送完之后就没有然后了(当然，钱还是要给的)。 但是后来随着货越来越多，找人给钱成本太大，而且农忙时还需要花很长时间去找人，所以就雇用了5个人，签了合同，长期为站点配送。 以前都是随时用随时找，现在不是，现在是成立了一个物流公司，开了一个配送部，配送部门规定正式配送员最多只能有五个人。 之前配送的缺点是什么： 每次有货，我都会去临时找一个人，然后签订临时合同，送完之后解除合同。很麻烦。这也是不用线程池的缺点，就是任务来了，我们需要频繁的去创建新的线程，用完之后还需要释放线程资源，对于系统的消耗是很大的。 因为配送的货车只有那么几个，如果临时签订的人多了，车子不够用，其他人只能等着车子送完之后才能用。 成立配送部之后解决的问题 成立配送部之后呢，因为签订的是劳务合同，我们可以重复的让配送员配送不同的货物。达到线程资源的复用。 因为限定了最多招聘的人数，可以很好的避免招过多无用的人。 OK，我们以上述例子来对应理解线程池的基本原理 先来看下，JAVA对ThreadPoolExecutor的类申明： 1public class ThreadPoolExecutor extends AbstractExecutorService 在【初识】-JUC·Executor框架中给出了Executor的继承体系。ThreadPoolExecutor就是具备线程池功能的集成者。 构造方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//构造方法一public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; //构造方法二 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);&#125;//构造方法三public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);&#125;//构造方法四public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 从上面的代码可以看出，构造方法（一、二、三）都是通过调用（四）来做具体属性初始化的。那么我们直接来看构造方法四；在构造方法四中总共需要7个参数，先来看下每个参数的具体含义： corePoolSize 核心线程数大小。那么什么是核心线程数呢，我们可以类比于上面例子中的配送部中签订劳动合同的人的个数。 maximumPoolSize 最大线程数。加入说现在是双十一期间，快递异常的多，配送部的5个人完全忙不过来，而且仓库也满了，怎么办呢？这个时候就需要再招聘一些临时配送员，假设maximumPoolSize为10，那么也就是说，临时招聘可以招5个人，配送部签订正式劳动合同的人和签订临时合同的人加一块不能超过配送部规定的最大人数（10人）。所以说，maximumPoolSize就是线程池能够允许的存在的最大线程的数量。 keepAliveTime 存活时间。为什么要有这个呢？想一下，双十一过去了，货物已经配送的差不多了。临时合同写的是如果临时配送员2天没有配送了，那配送部就有权利终止临时合同，现在已经达到2天这个点了，需要开除这些临时配送专员了。对于线程池来说，keepAliveTime就是用来表示，当除核心线程池之外的线程超过keepAliveTime时间之后，就需要被系统回收了。 unit keepAliveTime的时间单位。 workQueue 工作队列。这个就相当于一个仓库，现在配送部5个人都在配送，但是还不断的有新的快递达到，这个时候就需要一个仓库来存放这些快递。对于线程池来说，当核心线程都有自己的任务处理，并且还有任务进来的时候，就会将任务添加到工作队列中去。 threadFactory 线程工厂。就是用来创建线程的。可以类比成招聘组，会给每个线程分配名字或者编号这样。 handler RejectedExecutionHandler 用来描述拒绝策略的。假设现在我的仓库也满足，并且配送部已经达到10个人了。怎么办呢，那么只能采用一些策略来拒绝任务了。 线程池的状态 1234567891011// runState is stored in the high-order bits//RUNNING；该状态的线程池接收新任务，并且处理阻塞队列中的任务private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;//SHUTDOWN；该状态的线程池不接收新任务，但会处理阻塞队列中的任务；private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;//STOP；不接收新任务，也不处理阻塞队列中的任务，并且会中断正在运行的任务；private static final int STOP = 1 &lt;&lt; COUNT_BITS;//所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;//线程池彻底终止，就变成TERMINATED状态。 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 下面是在网上发现的一位大牛的图；感觉可以较为直观的描述状态的变更 工作原理 有几个点需要注意。 1、如何提交一个任务到线程池？12345678910111213141516171819202122public void execute(Runnable command) &#123; //任务为null,直接抛出空指针异常 if (command == null) throw new NullPointerException(); int c = ctl.get(); //如果线程数大于等于基本线程数，将任务加入队列 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command);&#125; 如果少于corePoolSize线程正在运行，请尝试使用给定命令启动一个新线程作为其第一个任务。 对addWorker的调用会自动检查runState和workerCount，从而防止错误报警，在不应该的时候通过返回false来添加线程。 如果一个任务能够成功排队，那么我们仍然需要再次检查是否应该添加一个线程（因为现有的线程自上次检查以来已经死掉）或者自从进入这个方法以来，池关闭了。所以我们重新检查状态，如果当前command已经stop了，那么就退出工作队列，如果没有的话就开始一个新的线程。 如果队列满了，会想尝试去创建一个新的线程去执行，如果创建不了，那就执行拒绝策略。 2、如何创建一个线程去处理任务？通过实现这个接口去创建一个新的线程 123public interface ThreadFactory &#123; Thread newThread(Runnable r);&#125; 3、如何将任务添加到队列？通过addWorker方法来添加，其实在excute中只是作为一个提交任务的入口，实际的处理逻辑都是在addWorker这个方法里来完成的。addWorker有两个参数： firstTask 当前任务 core 用来标注当前需要创建的线程是否是核心线程，如果core为true，则表明创建的是核心线程，也就是说当前还没有达到最大核心线程数。 先来看下这个方法的前半部分：1234567891011121314151617181920212223242526272829private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: //自旋方式 for (;;) &#123; //获取当前线程池的状态 int c = ctl.get(); int rs = runStateOf(c); //如果状态是STOP，TIDYING,TERMINATED状态的话，则会返回false //如果状态是SHUTDOWN，但是firstTask不为空或者workQueue为空的话，那么直接返回false。 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; //通过自旋的方式，判断要添加的worker是否为corePool范畴之内的 for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //如果超过CAPACITY限制了则直接返回false1wc &gt;= CAPACITY //判断当前的workerCount是否大于corePoolsize，否则则判断是否大于maximumPoolSize//具体的比较取决于入参core是true还是false。1wc &gt;= (core ? corePoolSize : maximumPoolSize) 如果上面两个有一个满足了，则直接返回false。 下面是判断WorkerCount通过CAS操作增加1是否成功，成功的话就到此结束12if (compareAndIncrementWorkerCount(c)) break retry; 如果不成功，则再次判断当前线程池的状态，如果现在获取到的状态与进入自旋的状态不一致的话，那么则通过continue retry重新进行状态的判断。123c = ctl.get(); // Re-read ctlif (runStateOf(c) != rs) continue retry; 再来看下这个方法的后面半个部分： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849boolean workerStarted = false;boolean workerAdded = false;Worker w = null;try &#123; final ReentrantLock mainLock = this.mainLock; //创建一个新的Worker对象 w = new Worker(firstTask); final Thread t = w.thread; // if (t != null) &#123; //加锁 mainLock.lock(); try &#123; // 在锁定的情况下重新检查。 // 在一下情况退出：ThreadFactory 创建失败或者在获取锁之前shut down了 int c = ctl.get(); int rs = runStateOf(c); //状态校验 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // 预先检查t是可以启动的 throw new IllegalThreadStateException(); //添加至workers中 workers.add(w); int s = workers.size(); //如果超过了历史最大线程数，则将当前池数量设置为历史最大线程记录数 if (s &gt; largestPoolSize) largestPoolSize = s; //标识添加工作线程成功 workerAdded = true; &#125; &#125; finally &#123; //解锁 mainLock.unlock(); &#125; //如果添加成功则启动当前工作线程 if (workerAdded) &#123; t.start(); //并将当前线程状态设置为已启动 workerStarted = true; &#125; &#125;&#125; finally &#123;//添加失败 if (! workerStarted) addWorkerFailed(w);&#125;return workerStarted;&#125; 拒绝策略有哪些？ 1、AbortPolicy：直接抛出异常，默认策略； 2、CallerRunsPolicy：使用调用者自己的当前线程来执行任务； 3、DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； 4、DiscardPolicy：直接丢弃任务； 当然我们也可以自定义拒绝策略。 常用工作队列类型1、ArrayBlockingQueue 基于数组的阻塞队列，长度有限 2、LinkedBlockingQuene 基于链表的阻塞队列，长度无限，使用这个可能会导致我们的拒绝策略失效。因为可以无限的创建新的工作线程。 3、PriorityBlockingQueue 具有优先级的无界阻塞队列； 3、SynchronousQuene SynchronousQuene是一个是一个不存储元素的BlockingQueue；每一个put操作必须要等待一个take操作，否则不能继续添加元素。所以这个比较特殊，它不存我们的任务，也就说说它的每个put操作必须等到另一个线程调用take操作，否则put操作一直处于阻塞状态。 Worker这个是ThreadPoolExecutor的一个内部类，表示一个工作线程。重要的是这个内部类实现了AbstractQueuedSynchronizer（AQS:抽象队列同步器）抽象类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** 当前work持有的线程 */ final Thread thread; /** 运行的初始任务。 可能为空。*/ Runnable firstTask; /** 每个线程完成任务的计数器 */ volatile long completedTasks; /** * 构造函数 */ Worker(Runnable firstTask) &#123; // 禁止中断，直到runWorker setState(-1); //想提交的任务交给当前工作线程 this.firstTask = firstTask; //通过线程工厂创建一个新的线程 this.thread = getThreadFactory().newThread(this); &#125; /** 将run方法的执行委托给外部runWorker */ public void run() &#123; runWorker(this); &#125; // 是否锁定 // // 0代表解锁状态。 // 1代表锁定状态。 protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; //尝试获取锁（重写AQS的方法） protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; //尝试释放锁（重写AQS的方法） protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; //加锁 public void lock() &#123; acquire(1); &#125; //尝试加锁 public boolean tryLock() &#123; return tryAcquire(1); &#125; //解锁 public void unlock() &#123; release(1); &#125; //是否锁定 public boolean isLocked() &#123; return isHeldExclusively(); &#125; //如果启动则中断 void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; runWorker最后来看下runWorker这个方法（ThreadPoolExecutor中的方法）： 12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 下面是对注释的蹩脚翻译，欢迎吐槽，但注意尺度，O(∩_∩)O哈哈~ 主要工作循环运行。重复地从队列中获取任务并执行它们，同时处理一些问题: 我们可能会从最初的任务开始，在这种情况下，我们不需要得到第一个任务。否则，只要池正在运行，我们就从getTask获得任务。 如果它返回null，则由于更改池状态或配置参数而导致worker退出。其他退出的结果是在外部代码中抛出的异常，在这种情况下completeAbruptly成立，这通常会导致processWorkerExit来取代这个线程。 在运行任何任务之前，获取锁以防止任务正在执行时发生其他池中断，调用clearInterruptsForTaskRun确保除非池正在停止，则此线程没有设置其中断。 每个任务运行之前都会调用beforeExecute，这可能会引发一个异常，在这种情况下，我们会导致线程死亡（断开循环completeAbruptly为true），而不处理任务。 假设beforeExecute正常完成，我们运行任务，收集任何抛出的异常发送到afterExecute。 我们分别处理RuntimeException，Error（这两个规范保证我们陷阱）和任意的Throwables。 因为我们不能在Runnable.run中重新抛出Throwable，所以我们把它们封装在Errors中（到线程的UncaughtExceptionHandler）。 任何抛出的异常也保守地导致线程死亡。 task.run完成后，我们调用afterExecute，这也可能会抛出一个异常，这也会导致线程死亡。 根据JLS Sec 14.20，即使task.run抛出，这个异常也是有效的。 异常机制的最终效果是afterExecute和线程的UncaughtExceptionHandler拥有关于用户代码遇到的任何问题的准确信息。 总结本文是JUC的第二篇，意在通过查看源码来了解线程池的具体工作原理。文中如果存在不当的描述，希望小伙伴们能够及时提出。灰常感谢！ 欢迎关注微信公众号，干货满满哦~]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>线程</tag>
        <tag>thread</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUC·Executor 框架]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-up-juc1%2F</url>
    <content type="text"><![CDATA[前言多线程和并发这两个东西真的是向往已久，总是有一种神秘的感觉，想去探索一波，又担心水平不够无法驾驭。想以读书笔记的方式来写，但是又觉得缺少自己的一些思考；但是在没有足够并发编程经验的情况下又没法去写出很深刻的东西，毕竟没有踩过坑。所以在阅读spring源码的同时，也想抽点时间来看一看JUC的东西，关于这块只能说是记录自己学习JUC的一个过程，尝试用一些具体的代码demo来加深理解。所以就把本系列写成《【 初识】-JUC·XXXX》，用来让自己打开并发编程的大门。 JUCJUC即java.util.concurrent；也就是java提供的并发包。JUC中从包结构上来看主要是： java.util.concurrent 在这个包下面主要是线程池、并发集合以及一些并发工具类。线程池相关是围绕Excetor框架来构建；这也是本文下面部分的重点。 java.util.concurrent.atomic 这个包下面是一些原子操作类，算是并发辅助工具类，基本实现依赖于CAS； java.util.concurrent.locks 这个从名字就可以知道它的作用，就是提供锁。 JUC各个模块的类 整体框架 atomic locks 并发集合 并发工具 forkJoin fork-join在JUC中有下面三个类： 1public class ForkJoinPool extends AbstractExecutorService 1public abstract class ForkJoinTask&lt;V&gt; implements Future&lt;V&gt;, Serializable 1public class ForkJoinWorkerThread extends Thread FutureFuture提供了可以获取异步执行结果的方法，区别于Runnable的run方法，run是不提供返回结果的。1234567891011121314public interface Future&lt;V&gt; &#123; //取消 boolean cancel(boolean mayInterruptIfRunning); //如果任务完成前被取消，则返回true。 boolean isCancelled(); //如果任务执行结束，无论是正常结束或是中途取消还是发生异常，都返回true。 boolean isDone(); //获取异步执行的结果，如果没有结果可用，此方法会阻塞直到异步计算完成。 V get() throws InterruptedException, ExecutionException; //获取异步执行结果，如果没有结果可用，此方法会阻塞，但是会有时间限制， //如果阻塞时间超过设定的timeout时间，该方法将抛出异常。 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; Callable声明了一个名称为call()的方法，同时这个方法可以有返回值V，也可以抛出异常123public interface Callable&lt;V&gt; &#123; V call() throws Exception; &#125; 关于Callable和Future的使用一般情况下都是结合我们的线程池来使用的。 ExecutorExecutor接口是线程池实现的顶级接口，其和spring中的BeanFactory所承担的角色差不多，就是提供顶级的功能约束，具体实现交于不同子类来完成。12345678910111213public interface Executor &#123; /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the &lt;tt&gt;Executor&lt;/tt&gt; implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution. * @throws NullPointerException if command is null */ void execute(Runnable command);&#125; 下面是JUC中Executor框架的整体结构： ExecutorService12345678910111213141516171819202122232425262728293031323334353637383940414243public interface ExecutorService extends Executor &#123; //关闭线程池 void shutdown(); List&lt;Runnable&gt; shutdownNow(); //是否为Shutdown状态 boolean isShutdown(); //是否为Terminated状态 boolean isTerminated(); //超过超时时间时，会监测ExecutorService是否已经关闭 //若关闭则返回true，否则返回false。 //一般情况下会和shutdown方法组合使用。 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; //返回一个Future对象，参数接收的是一个Callable的实现 //Callable接口中的call()方法有一个返回值，可以返回任务的执行结果 //区别于Runnable接口中的run()方法（void修饰，没有返回值）。 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); //返回一个Future对象，通过返回的Future对象，我们可以检查提交的任务是否执行完成了。 Future&lt;?&gt; submit(Runnable task); //返回一个Future的List，其中对应着每个Callable任务执行后的Future对象。 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; //增加了超时控制 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; //接收参数是一个Callable的集合， //返回的是所有Callable集合任务中某一个任务的执行结果 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; //增加了超时控制 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ExecutorService 再Executor接口的基础上扩展了对线程池状态的控制以及提交任务执行的超时控制。线程池的基本功能还不够完善，不能真正的具备处理具体业务的能力（毕竟是个接口，O(∩_∩)O哈哈~）。 开个篇，慢慢学~]]></content>
      <categories>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>线程</tag>
        <tag>thread</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：BeanWrapper]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase12%2F</url>
    <content type="text"><![CDATA[BeanWrapper 是Spring提供的一个用来操作javaBean属性的工具，使用它可以直接修改一个对象的属性。 对于bean属性的操作，大家熟知的主要有下面这些工具类： 1.Apache的BeanUtils和PropertyUtils 2.cglib的BeanMap和BeanCopier 3.spring的BeanUtils Spring中BeanWrapper 的主要功能在于： 1.支持设置嵌套属性 2.支持属性值的类型转换（设置ConversionService） 3.提供分析和操作标准JavaBean的操作：获取和设置属性值（单独或批量），获取属性描述符以及查询属性的可读性/可写性的能力。 BeanWrapper本身是一个接口，它提供了一整套处理Bean的方法。源码如下： 1234567891011121314public interface BeanWrapper extends ConfigurablePropertyAccessor &#123; //为数组和集合自动增长指定一个限制。在普通的BeanWrapper上默认是无限的。 void setAutoGrowCollectionLimit(int autoGrowCollectionLimit); //返回数组和集合自动增长的限制。 int getAutoGrowCollectionLimit(); //如果有的话,返回由此对象包装的bean实例 Object getWrappedInstance(); //返回被包装的JavaBean对象的类型。 Class&lt;?&gt; getWrappedClass(); //获取包装对象的PropertyDescriptors（由标准JavaBeans自省确定）。 PropertyDescriptor[] getPropertyDescriptors(); //获取包装对象的特定属性的属性描述符。 PropertyDescriptor getPropertyDescriptor(String propertyName) throws InvalidPropertyException;&#125; 上面的BeanWrapper是基于4.3.6版本的，这个接口在4.1版本之后略有改动。BeanWrapperImpl是BeanWrapper的实现类，BeanWrapperImpl的父类是AbstractNestablePropertyAccessor，通过这个使得BeanWrapper具有处理属性的能力。 下面是一个使用BeanWrapper 包装对象的例子： 1234567891011121314151617181920212223242526272829303132package com.glmapper.spring.test;import org.springframework.beans.BeanWrapper;import org.springframework.beans.PropertyAccessorFactory;import org.springframework.beans.PropertyValue;/** * BeanWrapper 测试类 */public class BeanWrapperTest &#123; public static void main(String[] args) &#123; User user=new User(); //通过PropertyAccessorFactory将user对象封装成BeanWrapper BeanWrapper bw=PropertyAccessorFactory.forBeanPropertyAccess(user); //方式一：直接对属性值进行设置 bw.setPropertyValue("userName", "张三"); //方式二：通过PropertyValue进行设置 PropertyValue pv=new PropertyValue("userName","李四"); bw.setPropertyValue(pv); System.out.println(user.getUserName()); &#125;&#125;//一个User类class User&#123; private String userName; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125;&#125; 在Spring中，有很多Bean属性的操作都是通过BeanWrapper来完成的，比如常见的HttpServletBean的属性设置就是。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：依赖注入（四）-总结]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase11%2F</url>
    <content type="text"><![CDATA[Spring源码系列：依赖注入（一）getBean Spring源码系列：依赖注入（二）createBean Spring源码系列：依赖注入（三）-属性注入 在上面三篇文章中对依赖注入做了一个大致的梳理；里面都是大量代码的分析，本文在此基础上进行一个总结归纳。 依赖注入调用过程 如前几篇文章所述，依赖注入是由getBean来触发的；然后涉及到bean实例的创建、依赖关系的建立、属性注入等子过程。 getBean 方法触发依赖注入 doGetBean 从容器中查找Bean（BeanFactory链，当前容器-&gt;双亲容器-双亲容器…） 当然，在获取到某个Bean的时候也会通过递归的方式来依赖注入依赖的bean createBeanInstance 生成了Bean所包含的Java对象，Spring中用SimpleInstantiationStrategy类来生成Bean对象的实例，实例化Java对象的方法有两种（CGlib是默认方式）： 通过BeanUtils，它使用了JVM的反射功能来生成Java对象实例 用CGLIB来生成，CGLIB是一种常用的字节码生成器的类库 populateBean 设置Bean对象的依赖关系 resolveValueIfNecessary 注入类型的处理；解析不同类型的属性 setPropertyValues 属性注入 关于lazy-initIoc容器的初始化过程中，主要的工作就是对BeanDefinition的定位、载入、解析和注册；但是就像之前说过的，此时依赖注入还没有发生。在Spring源码系列：依赖注入（一）getBean文中提到，依赖注入发生在应用第一次向容器获取Bean的时候；也就是上面说到的通过getBean来触发。 当然，依赖注入也可以在容器初始化的过程中就完成。这个就是lazy-init属性的存在意义了。就是说我们可以通过设置Bean的lazy-init属性来控制预实例化的过程。 预实例化：在初始化容器时完成Bean的依赖注入 这种做法的好处在于提高了我们第一次获取Bean的的效率，但是它也降低了容器初始化的速度。（这个其实很好理解的，因为第一次获取Bean的时候，依赖注入已经完成了，直接拿过来用就行） 关于lazy-init属性的处理也是在wac.refresh这个方法中完成的，具体是在finishBeanFactoryInitialization方法中。如果继续追溯的话，最终是交给DefaultListableBeanFactory容器中的preInstantiateSingletons方法中完成。 lazy-init这种实例化方式就是通过将依赖注入委托给容器来处理，而不是在用户第一向容器申请的Bean的时候完成依赖注入，不同的阶段，也有不同的优劣。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：依赖注入（三）-属性注入]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase10%2F</url>
    <content type="text"><![CDATA[前面文章中对依赖注入的触发和bean的创建做了学习记录，本文将来记录一下bean的属性注入过程。Bean的属性注入发生在BeanDefinitionValueResolver这个类中，BeanDefinitionValueResolver这类是用于bean工厂实现的Helper类，职责就是将bean定义对象中包含的值解析为应用于目标bean实例的实际值。 BeanDefinitionValueResolver类中的resolveValueIfNecessary()方法包含了对所有注入类型的处理。所以本文主要围绕这个方法展开来说。 resolveValueIfNecessary方法resolveValueIfNecessary():给定一个PropertyValue，返回一个value，解析对工厂中其他bean的引用。 value可能是： RuntimeBeanReference : 在解析到依赖的Bean的时侯，解析器会依据依赖bean的name创建一个RuntimeBeanReference对像，将这个对像放入BeanDefinition的MutablePropertyValues中。 ManagedList：用来保存它所管理的List元素，它可以包含运行时期的bean引用(将被解析为bean对象). ManagedSet ：用来保存它所管理的set值，它可以包含运行时期的bean引用(将被解析为bean对象) ManagedMap ：用来保存它所管理的map值，它可以包含运行时期的bean引用(将被解析为bean对象) 1、方法申明 argName ：为其定义的参数的名称 value ：要解析的值对象1public Object resolveValueIfNecessary(Object argName, Object value) 2、RuntimeBeanReference 当在beanfactory中作为另外一个bean的引用时，作为属性值对象，将在运行时进行解析。 RuntimeBeanReference是在对BeanDefinition进行解析时生成的数据对象。1234if (value instanceof RuntimeBeanReference) &#123; RuntimeBeanReference ref = (RuntimeBeanReference) value; return resolveReference(argName, ref);&#125; 3、RuntimeBeanNameReference 当在beanfactory中作为另外一个bean名称的引用时，作为属性值对象，将在运行时进行解析。12345678else if (value instanceof RuntimeBeanNameReference) &#123; String refName = ((RuntimeBeanNameReference) value).getBeanName(); refName = String.valueOf(doEvaluate(refName)); if (!this.beanFactory.containsBean(refName)) &#123; //异常：Invalid bean name '" + refName + "' in bean reference for " + argName &#125; return refName;&#125; 4、BeanDefinitionHolder 解析BeanDefinitionHolder：包含具有名称和别名的BeanDefinition。BeanDefinitionHolder就是使用名称或者别名来保存BeanDefinition的。1234else if (value instanceof BeanDefinitionHolder) &#123; BeanDefinitionHolder bdHolder = (BeanDefinitionHolder) value; return resolveInnerBean(argName, bdHolder.getBeanName(), bdHolder.getBeanDefinition());&#125; 5、BeanDefinition 解析纯粹的BeanDefinition1234567else if (value instanceof BeanDefinition) &#123; // Resolve plain BeanDefinition, without contained name: use dummy name. BeanDefinition bd = (BeanDefinition) value; String innerBeanName = "(inner bean)" + BeanFactoryUtils.GENERATED_BEAN_NAME_SEPARATOR + ObjectUtils.getIdentityHexString(bd); return resolveInnerBean(argName, innerBeanName, bd); &#125; 6、ManagedArray 包含运行时期的bean引用(将被解析为bean对象)1234567891011121314151617181920212223else if (value instanceof ManagedArray) &#123; // May need to resolve contained runtime references. ManagedArray array = (ManagedArray) value; Class&lt;?&gt; elementType = array.resolvedElementType; if (elementType == null) &#123; String elementTypeName = array.getElementTypeName(); if (StringUtils.hasText(elementTypeName)) &#123; try &#123; elementType = ClassUtils.forName(elementTypeName, this.beanFactory.getBeanClassLoader()); array.resolvedElementType = elementType; &#125; catch (Throwable ex) &#123; // Improve the message by showing the context. //异常：Error resolving array type for " + argName &#125; &#125; else &#123; elementType = Object.class; &#125; &#125; return resolveManagedArray(argName, (List&lt;?&gt;) value, elementType);&#125; 7、ManagedList，ManagedSet，ManagedMap 包含运行时期的bean引用(将被解析为bean对象)123456789101112//对ManagedList进行解析else if (value instanceof ManagedList) &#123; return resolveManagedList(argName, (List&lt;?&gt;) value);&#125;//对ManagedSet进行解析else if (value instanceof ManagedSet) &#123; return resolveManagedSet(argName, (Set&lt;?&gt;) value);&#125;//对ManagedMap进行解析else if (value instanceof ManagedMap) &#123; return resolveManagedMap(argName, (Map&lt;?, ?&gt;) value);&#125; 8、ManagedProperties ManagedProperties表示的是一个spring管理的属性实例，它支持父/子 definition的合并。1234567891011121314151617//对ManagedProperties进行解析else if (value instanceof ManagedProperties) &#123; Properties original = (Properties) value; Properties copy = new Properties(); for (Map.Entry&lt;Object, Object&gt; propEntry : original.entrySet()) &#123; Object propKey = propEntry.getKey(); Object propValue = propEntry.getValue(); if (propKey instanceof TypedStringValue) &#123; propKey = evaluate((TypedStringValue) propKey); &#125; if (propValue instanceof TypedStringValue) &#123; propValue = evaluate((TypedStringValue) propValue); &#125; copy.put(propKey, propValue); &#125; return copy;&#125; 9、TypedStringValue TypedStringValue保存的是一个类型的属性值。1234567891011121314151617181920//对TypedStringValue进行解析else if (value instanceof TypedStringValue) &#123; // Convert value to target type here. TypedStringValue typedStringValue = (TypedStringValue) value; Object valueObject = evaluate(typedStringValue); try &#123; Class&lt;?&gt; resolvedTargetType = resolveTargetType(typedStringValue); if (resolvedTargetType != null) &#123; return this.typeConverter.convertIfNecessary(valueObject, resolvedTargetType); &#125; else &#123; return valueObject; &#125; &#125; catch (Throwable ex) &#123; // Improve the message by showing the context. throw new BeanCreationException( //异常：Error converting typed String value for " + argName &#125;&#125; 10、作为表达式进行评估 将给定的值作为表达式进行评估。123else &#123; return evaluate(value);&#125; 在完成上述解析之后，已经为我们的依赖注入做好了准备。这是真正把Bean对象设置到它所依赖的另一个Bean的属性中去的地方，可以看到，处理的属性也是各式各样的。具体属性的注入是在之前提到的BeanWrapper接口的实现类BeanWrapperImpl的setPropertyValue方法来完成。 setPropertyValue方法a、方法声明这个方法是私有的，是BeanWrapperImpl实际处理的方法，其对外也提供了setPropertyValue的其它重载方法来提供服务。 12private void setPropertyValue(PropertyTokenHolder tokens, PropertyValue pv) throws BeansException b、PropertyTokenHolder是BeanWrapperImpl的内部类12345private static class PropertyTokenHolder &#123; public String canonicalName; public String actualName; public String[] keys;&#125; 在setPropertyValue方法中会根据tokens变量是否为null,有两个不同的分支。其中当tokens为null时，则会对属性名进行递归调用分析处理，返回分析处理后的BeanWrapImpl对象nestedBw。如果nestedBw==this,则会设置pv的resolvedTokens属性值，最后将调用nestedBw对象的设置属性值方法设置属性。来具体看看： c、其中当tokens为null时，即对集合类的域进行注入1234567891011121314// 设置tokens的索引和keysPropertyTokenHolder getterTokens = new PropertyTokenHolder();getterTokens.canonicalName = tokens.canonicalName;getterTokens.actualName = tokens.actualName;getterTokens.keys = new String[tokens.keys.length - 1];System.arraycopy(tokens.keys, 0, getterTokens.keys, 0, tokens.keys.length - 1);Object propValue;//getPropertyValue用来获取Bean中对对象注入的引用；try &#123; propValue = getPropertyValue(getterTokens);&#125;catch (NotReadablePropertyException ex) &#123;//异常：Cannot access indexed value in property referenced &#125; 1、propValue为null propValue为null12345678910111213if (propValue == null) &#123; // 空值映射的情况 if (this.autoGrowNestedPaths) &#123; // TODO: cleanup, this is pretty hacky int lastKeyIndex = tokens.canonicalName.lastIndexOf('['); getterTokens.canonicalName = tokens.canonicalName.substring(0, lastKeyIndex); propValue = setDefaultValue(getterTokens); &#125; else &#123; //异常：Cannot access indexed value in property referenced " + "in indexed property path '" + propertyName + "': returned null" &#125;&#125; 2、对array进行注入 对array进行注入1234567891011121314151617if (propValue.getClass().isArray()) &#123; PropertyDescriptor pd = getCachedIntrospectionResults().getPropertyDescriptor(actualName); Class requiredType = propValue.getClass().getComponentType(); int arrayIndex = Integer.parseInt(key); Object oldValue = null; try &#123; if (isExtractOldValueForEditor() &amp;&amp; arrayIndex &lt; Array.getLength(propValue)) &#123; oldValue = Array.get(propValue, arrayIndex); &#125; Object convertedValue = convertIfNecessary(propertyName, oldValue, pv.getValue(), requiredType, TypeDescriptor.nested(property(pd), tokens.keys.length)); Array.set(propValue, arrayIndex, convertedValue); &#125; catch (IndexOutOfBoundsException ex) &#123; //异常：Invalid array index in property path '" + propertyName &#125;&#125; 2、对list进行注入 对list进行注入123456789101112131415161718192021222324252627282930313233else if (propValue instanceof List) &#123; PropertyDescriptor pd = getCachedIntrospectionResults().getPropertyDescriptor(actualName); Class requiredType = GenericCollectionTypeResolver.getCollectionReturnType( pd.getReadMethod(), tokens.keys.length); List list = (List) propValue; int index = Integer.parseInt(key); Object oldValue = null; if (isExtractOldValueForEditor() &amp;&amp; index &lt; list.size()) &#123; oldValue = list.get(index); &#125; Object convertedValue = convertIfNecessary(propertyName, oldValue, pv.getValue(), requiredType, TypeDescriptor.nested(property(pd), tokens.keys.length)); int size = list.size(); if (index &gt;= size &amp;&amp; index &lt; this.autoGrowCollectionLimit) &#123; for (int i = size; i &lt; index; i++) &#123; try &#123; list.add(null); &#125; catch (NullPointerException ex) &#123; //异常：InvalidPropertyException &#125; &#125; list.add(convertedValue); &#125; else &#123; try &#123; list.set(index, convertedValue); &#125; catch (IndexOutOfBoundsException ex) &#123; //异常：Invalid list index in property path '" + propertyName + "'" &#125; &#125;&#125; 2、对map进行注入 对map进行注入1234567891011121314151617181920else if (propValue instanceof Map) &#123; PropertyDescriptor pd = getCachedIntrospectionResults().getPropertyDescriptor(actualName); Class mapKeyType = GenericCollectionTypeResolver.getMapKeyReturnType( pd.getReadMethod(), tokens.keys.length); Class mapValueType = GenericCollectionTypeResolver.getMapValueReturnType( pd.getReadMethod(), tokens.keys.length); Map map = (Map) propValue; //重要提示：不要在这里传递完整的属性名称 TypeDescriptor typeDescriptor = (mapKeyType != null ? TypeDescriptor.valueOf(mapKeyType) : TypeDescriptor.valueOf(Object.class)); Object convertedMapKey = convertIfNecessary(null, null, key, mapKeyType, typeDescriptor); Object oldValue = null; if (isExtractOldValueForEditor()) &#123; oldValue = map.get(convertedMapKey); &#125; // 在这里传递完整的属性名称和旧值，因为希望对map值有完整的转换能力。 Object convertedMapValue = convertIfNecessary(propertyName, oldValue, pv.getValue(), mapValueType, TypeDescriptor.nested(property(pd), tokens.keys.length)); map.put(convertedMapKey, convertedMapValue);&#125; 其中当tokens不为null时，即对非集合类的域进行注入这里是核心的地方，取得注入属性的set方法，通过反射机制，把对象注入进去。123final Method writeMethod = (pd instanceof GenericTypeAwarePropertyDescriptor ? ((GenericTypeAwarePropertyDescriptor) pd).getWriteMethodForActualAccess() : pd.getWriteMethod()); 总结通过上面的几篇分析我们大概的熟悉了Bean创建和对象依赖注入的一个过程，在这个过程中，spring需要根据Beandefinition中的信息来递归完成依赖注入。并且这些递归的入口都是getBean这个方法。 一个递归是在上下文体系中查找需要的Bean和创建Bean的递归调用； 另一个递归是在依赖注入时通过递归调用容器的getBean方法，得到当前Bean的依赖Bean，同时也触发对依赖Bean的创建和注入。 在对Bean的属性进行依赖注入时解析的过程也是一个递归的过程。这样就可以根据依赖关系，一层一层的完成Bean的创建和注入，直到最后完成当前Bean的创建。 参考 《Spring技术内幕》 https://www.cnblogs.com/davidwang456/p/4213652.html]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：依赖注入（二）createBean]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase9%2F</url>
    <content type="text"><![CDATA[在Spring源码系列：依赖注入（一）（AbstractBeanFactory-getBean）最后说道getBean是依赖注入的起点，bean的创建都是通过createBean来完成具体的创建的。createBean的具体实现是在AbstractAutowireCapableBeanFactory中的。本篇就捋一捋这个方法看下bean的创建过程。 这个方法是AbstractAutowireCapableBeanFactory这个类的中心方法，其作用就是创建一个bean实例，填充bean实例，后置处理等。 在createBean中主要做了三件事： 判断需要创建的Bean是否可以实例化，这个类是否可以通过类装载器来载入 是否配置了后置处理器相关处理（如果配置了则返回一个代理） 创建Bean 具体来看方法： 123456789101112131415161718192021222324252627282930313233343536373839404142protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating instance of bean '" + beanName + "'"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. //判断需要创建的Bean是否可以实例化，这个类是否可以通过类装载器来载入 Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; //异常：Validation of method overrides failed &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target //bean instance. //是否配置了后置处理器相关处理（如果配置了则返回一个代理） Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; //异常:BeanPostProcessor before instantiation of bean failed &#125; //创建Bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance;&#125; 从上面的代码中可以看到，创建bean是交给doCreateBean方法来创建的。继续看doCreateBean这个方法：（这里面涉及到一个BeanWrapper这个接口，小伙伴可以移步了解一下《Spring源码系列：BeanWrapper》） 代码 1：123456789101112131415// 用BeanWrapper来持有创建出来的Bean对象BeanWrapper instanceWrapper = null;//如果是单例的话，则先把缓存中的同名bean清除if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName);&#125;//实际创建的交给createBeanInstance来完成，//bean的生成，这里会使用默认的类生成器，包装成BeanWrapperImpl类，//为了下面的populateBean方法的属性注入做准备 if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args);&#125;final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null);Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null);mbd.resolvedTargetType = beanType; 代码 2： 允许后处理器修改合并的bean定义。1234567891011synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; //异常：Post-processing of merged bean definition failed &#125; mbd.postProcessed = true; &#125; &#125; 代码 3 ： 即使被BeanFactoryAware等生命周期接口触发，也要尽快地缓存singletons 以便能够解析循环引用。1234567891011121314boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName));if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Eagerly caching bean &apos;&quot; + beanName + &quot;&apos; to allow for resolving potential circular references&quot;); &#125; addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;);&#125; 代码 4: 这里是对bean的初始化的地方，一般情况下依赖注入就在这里发生；这个exposedObject变量保存的是在初始化处理完以后返回的作为依赖注入完成之后的bean。123456789101112131415161718// Initialize the bean instance.Object exposedObject = bean;try &#123; populateBean(beanName, mbd, instanceWrapper); if (exposedObject != null) &#123; exposedObject = initializeBean(beanName, exposedObject, mbd); &#125;&#125;catch (Throwable ex) &#123; //抛出 if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; //异常:Initialization of bean failed &#125;&#125; 代码 5: 这里是注册bean12345678try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd);&#125;catch (BeanDefinitionValidationException ex) &#123; //异常处理&#125;//返回结果return exposedObject; 上面的5个代码段均是doCreateBean中的处理逻辑，有兴趣的小伙伴可以自行查阅源码。从上面的代码中我们依然没有得到具体创建的过程，因为在doCreateBean中又依赖：createBeanInstance和populateBean两个方法。 在createBeanInstance中生成了Bean所包含的java对象。来看是怎么生成的： 12345678910111213141516171819202122232425262728293031323334353637383940414243protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) &#123; // 确保bean类实际上已经解析过了，可以实例化 Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; //异常：Bean class isn't public, and non-public access not allowed:beanName &#125; //1. 使用工厂方法来进行bean的实例化 if (mbd.getFactoryMethodName() != null) &#123; return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // 重新创建相同的bean时快捷方式... boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; if (resolved) &#123; if (autowireNecessary) &#123; return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; return instantiateBean(beanName, mbd); &#125; &#125; // 2.需要确定构造函数...,使用构造函数进行bean实例化 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; return autowireConstructor(beanName, mbd, ctors, args); &#125; //3.没有特殊的处理：只需使用无参数构造函数。（默认构造函数） return instantiateBean(beanName, mbd);&#125; 从上面这段代码可以看出，对象的生成有许多不同的方式，有通过工厂的，也有通过容器的autowire特性生成的。当然这些生成方式都是由相关的BeanDefinition来指定的。 Spring中配置Bean的方式我们常用的一种是通过xml文件来配置，还有就是通过注解的方式来配置。 demo1 123&lt;bean id="user" class="com.glmapper.test.User"&gt; &lt;property name="name" value="glmapper"&gt;&lt;/property&gt; &lt;/bean&gt; 这种方式，通过class提供的权限定名，spring就可以利用反射机制创建这个bean。 demo2 123&lt;bean id="user" class="com.glmapper.test.UserFactory" factory-method="getUser"&gt; &lt;constructor-arg value="glmapper"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; 这种是利用静态工厂方法来创建的，提供的class并非是类的权限定名， 而是静态工厂的全类名；除此之外还需要指定获取bean的方法（此处是getUser）和参数（参数是glmapper）。 demo3 123456789101112131415161718192021222324252627&lt;bean id=&quot;userFactory&quot; class=&quot;com.glmapper.test.UserInstanceFactory&quot;&gt; &lt;!--用一个集合来保存我当前的对象实例--&gt; &lt;property name=&quot;map&quot;&gt; &lt;map&gt; &lt;entry key=&quot;user1&quot;&gt; &lt;bean class=&quot;com.glmapper.test.User&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;glmapper1&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/entry&gt; &lt;entry key=&quot;user2&quot;&gt; &lt;bean class=&quot;com.glmapper.test.User&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;glmapper2&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; //实例1 &lt;bean id=&quot;user1&quot; factory-bean=&quot;userFactory&quot; factory-method=&quot;getUserInstance&quot;&gt; &lt;constructor-arg value=&quot;user1&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt;//实例2 &lt;bean id=&quot;user2&quot; factory-bean=&quot;userFactory&quot; factory-method=&quot;getUserInstance&quot;&gt; &lt;constructor-arg value=&quot;user2&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean 这种方式和静态工厂的区别在于我们需要先实例化一个工厂对象，然后才能使用这个工厂对象来创建我们的bean。getUserInstance通过key值来获取我们已经实例化好的对象（当然方式有很多，此处以map来举个例子）。关于注解的和使用FactoryBean接口的这里就暂时不说，后期再聊 OK，继续来分钟，上面说到的是以工厂方法创建bean，具体的源码有点长，这里就不放了，大概思路就如上面所提到的那几种方式。接下来看下常见的使用instantiateBean方式（使用它的默认构造函数）来构建bean的代码： 1234567891011121314151617181920212223242526protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &#123; try &#123; Object beanInstance; final BeanFactory parent = this; //获取系统安全接口。 //如果已经为当前应用程序建立了安全管理器，则返回该安全管理器; //否则，返回null。 if (System.getSecurityManager() != null) &#123; beanInstance = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; return getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; &#125;, getAccessControlContext()); &#125; else &#123; beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; BeanWrapper bw = new BeanWrapperImpl(beanInstance); initBeanWrapper(bw); return bw; &#125; catch (Throwable ex) &#123; //异常：Instantiation of bean failed &#125;&#125; 可以看出，上面的创建都是通过： 1getInstantiationStrategy().instantiate(mbd, beanName, parent); 这样一段代码来完成的，是的，这里已经快接近真相了。从语义上来分析，先是获取了一种策略，然后利用当前获取的策略再去执行实例化。OK，我们看下getInstantiationStrategy()拿到的是什么： 123456//返回实例化策略用于创建bean实例。protected InstantiationStrategy getInstantiationStrategy() &#123; return this.instantiationStrategy;&#125;//默认的实例化测试是使用CGLIB代理private InstantiationStrategy instantiationStrategy = new CglibSubclassingInstantiationStrategy(); 看到这里我们清楚了，默认构造函数的情况下，在spring中会使用Cglib来进行bean的实例化（关于cglib此处不再赘述）。我们看下CglibSubclassingInstantiationStrategy这个类的申明： 1public class CglibSubclassingInstantiationStrategy extends SimpleInstantiationStrategy 它继承自SimpleInstantiationStrategy ，这个又是什么鬼呢？ SimpleInstantiationStrategy是Spring用来生成Bean对象的默认类，在这个类中提供了两种实例化java对象的方法，一种是基于java自身反射机制的BeanUtils，还有一种就是基于Cglib。 如何创建的就不说了；到这里createBeanInstance就说完了（Bean已经创建了）；但是仅仅是创建，spring还没有处理它们，比如说bean对象的属性，依赖关系等等。这些就是上面提到的另外一个方法populateBean； 这个方法其实就做了一件事：使用bean定义中的属性值在给定的BeanWrapper中填充bean实例。分段来看：下面这段代码是先将BeanDefinition中设置的property值封装成PropertyValues，然后检测我们的BeanWrapper是否为Null，如果为null则抛出异常或者跳过当前空实例赋值阶段1234567891011//获取到BeanDefinition中设置的property值，封装成PropertyValuesPropertyValues pvs = mbd.getPropertyValues();if (bw == null) &#123; if (!pvs.isEmpty()) &#123; //异常：Cannot apply property values to null instance &#125; else &#123; // Skip property population phase for null instance. return; &#125;&#125; 下面这段代码的意思是给任何InstantiationAwareBeanPostProcessors提供在设置属性之前修改bean状态的机会。12345678910111213141516boolean continueWithPropertyPopulation = true;if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125;&#125;if (!continueWithPropertyPopulation) &#123; return;&#125; 下面就是对具体注入方式的处理： 1234567891011121314151617//处理autowire的注入；可以根据bean的名称和类型来注入if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // 则根据名称添加基于自动装配的属性值。 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // 根据类型添加基于自动装配的属性值。 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs;&#125; 两个判断条件，在满足的情况下做的处理分别是： 在工厂将给定属性值应用到给定的bean后，对其进行后处理。 允许检查所有的依赖关系是否被满足，例如基于bean属性设置器上的“Required”注解。还允许替换要应用的属性值，通常通过创建基于原始PropertyValues的新MutablePropertyValues实例，添加或删除特定值。 执行依赖性检查 123456789101112131415161718192021222324//返回这个工厂是否拥有一个InstantiationAwareBeanPostProcessorboolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();//返回依赖检查代码。boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);if (hasInstAwareBpps || needsDepCheck) &#123;//从给定的BeanWrapper中提取一组已过滤的PropertyDescriptors，//不包括在被忽略的依赖性接口上定义的被忽略的依赖类型或属性（译注）。 PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125;&#125; 最后是对属性进行注入： 1applyPropertyValues(beanName, mbd, bw, pvs); 这个方法描述的是对属性进行解析然后注入的过程；先来分析下applyPropertyValues的申明：12protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) beanName bean名称 mbd 合并的bean definition bw 包装目标对象的BeanWrapper pvs 新的属性值 代码分段来看： 参数验证 123if (pvs == null || pvs.isEmpty()) &#123; return;&#125; pvs参数处理 1234567891011121314151617if (pvs instanceof MutablePropertyValues) &#123; mpvs = (MutablePropertyValues) pvs; if (mpvs.isConverted()) &#123; // 使用预先转换后的值。 try &#123; bw.setPropertyValues(mpvs); return; &#125; catch (BeansException ex) &#123; //异常：Error setting property values &#125; &#125; original = mpvs.getPropertyValueList(); &#125; else &#123; original = Arrays.asList(pvs.getPropertyValues()); &#125; valueResolver来解析BeanDefinition 12BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); 为解析值创建一个副本，注入到bean中的是副本的数据 12// Create a deep copy, resolving any references for values.List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;PropertyValue&gt;(original.size()); 遍历处理 123456789101112131415161718192021222324252627282930313233343536boolean resolveNecessary = false;for (PropertyValue pv : original) &#123; //返回此持有者是否已经包含转换后的值（true），还是需要转换值（false）。 if (pv.isConverted()) &#123; deepCopy.add(pv); &#125; else &#123; String propertyName = pv.getName(); Object originalValue = pv.getValue(); //看下面的注释resolveValueIfNecessary Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); Object convertedValue = resolvedValue; boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) &#123; convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); &#125; // 可能将转换的值存储在合并的bean定义中，以避免为每个创建的bean实例重新转换。 if (resolvedValue == originalValue) &#123; if (convertible) &#123; pv.setConvertedValue(convertedValue); &#125; deepCopy.add(pv); &#125; else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &#123; pv.setConvertedValue(convertedValue); deepCopy.add(pv); &#125; else &#123; resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); &#125; &#125;&#125; resolveValueIfNecessary 给定一个PropertyValue，返回一个value，必要时解析对工厂中其他bean的引用。value可以是： 一个BeanDefinition，它导致创建一个相应的新的bean实例。 Singleton标志和这样的”inner beans”的名字被忽略：内部beans是匿名原型。 RuntimeBeanReference(必须解析) ManagedList ManagedSet ManagedMap 一个普通的对象或null，在这种情况下，它是孤立的。 下面这段代码时依赖注入发生的地方，其实际上是在BeanWrapperImpl中来完成。123456try &#123; bw.setPropertyValues(new MutablePropertyValues(deepCopy));&#125;catch (BeansException ex) &#123; //异常：Error setting property values&#125; 上面说到spring是通过BeanDefinitionValueResolver来解析BeanDefinition的，然后再注入到property中，关于这个过程在下一篇中来说。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：依赖注入（一）getBean]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase8%2F</url>
    <content type="text"><![CDATA[在Spring源码系列：BeanFactory的创建文章中我们谈到了BeanFactory这容器，这个里面提供了注入的实现接口。其具体的实现还需要从AbstractBeanFactory和DefaultListableBeanFactory中来看。今天就先撸一下AbstractBeanFactory这个类中的getBean这个方法。 1、getBean方法 getBean提供了四个重载方法，如下：12345678910111213141516171819//通过name获取Bean@Overridepublic Object getBean(String name) throws BeansException &#123; return doGetBean(name, null, null, false);&#125;//通过name和类型获取Bean@Overridepublic &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException &#123; return doGetBean(name, requiredType, null, false);&#125;//通过name和对象参数获取Bean@Overridepublic Object getBean(String name, Object... args) throws BeansException &#123; return doGetBean(name, null, args, false);&#125;//通过name、类型和参数获取Beanpublic &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType, Object... args) throws BeansException &#123; return doGetBean(name, requiredType, args, false);&#125; 从这四个重载方法的方法体中可以看出，他们都是通过doGetBean来实现的。所以doGetBean其实才是真正获取Bean的地方，也是触发依赖注入发生的地方。（这个方法比较长，分段来说） 2、doGetBean 先来看下方法的定义： 1234@SuppressWarnings("unchecked") protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; name 要检索的bean的名称 requiredType 要检索的bean所需的类型 args 使用显式参数创建bean实例时使用的参数（仅在创建新实例时应用，而不是在检索现有实例时应用） typeCheckOnly 是否为类型检查而获得实例，而不是实际使用 12345678//返回bean名称，剥离工厂引用前缀，并将别名解析为规范名称。final String beanName = transformedBeanName(name);//声明当前需要返回的bean对象Object bean;// 先从缓存中获取bean，处理已经被创建的单例模式的bean，//对于此类bean的请求不需要重复的创建(singleton)Object sharedInstance = getSingleton(beanName); 如果当前获取到的sharedInstance不为null并且参数为空，则进行FactoryBean的相关处理，并获取FactoryBean的处理结果。1234567891011121314if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; //返回指定的singleton bean是否正在创建（在整个工厂内）。 if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("Returning eagerly cached instance of singleton bean '" + beanName +"' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; //完成FactoryBean的相关处理，并用来获取FactoryBean的处理结果 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);&#125; 如果当前获取到的sharedInstance为null，我们再来看下做了哪些处理（下面的都在一个大的else里面）： 123else &#123; //分解到下面&#125; 1234//在当前线程中，返回指定的prototype bean是否正在创建。if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName);&#125; 下面这段的作用是对Ioc容器中的BeanDefinition是否存在进行检测，先是检测当前BeanFactory中是否能够获取到，如果取不到则继续到双亲容器中进行尝试获取，如果双亲还是取不到，则继续向上一级父容器中尝试获取。1234567891011121314// 检查该工厂是否存在bean定义。BeanFactory parentBeanFactory = getParentBeanFactory();if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // 如果没有，则继续检查父类 String nameToLookup = originalBeanName(name); if (args != null) &#123; // 用明确的参数代表父项。 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // 如果没有args - &gt;委托给标准的getBean方法。 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125;&#125; 将指定的bean标记为已经创建（或即将创建）；这里允许bean工厂优化其缓存以重复创建指定的bean。123if (!typeCheckOnly) &#123; markBeanAsCreated(beanName);&#125; 先根据beanName来获取BeanDefinition，然后获取当前bean的所有依赖bean，这里是通过递归调用getBean来完成，直到没有任何依赖的bean为止。12345678910111213141516final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);//检查给定的合并bean定义，可能抛出验证异常。checkMergedBeanDefinition(mbd, beanName, args);// 保证当前bean依赖的bean的初始化。String[] dependsOn = mbd.getDependsOn();if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; registerDependentBean(dep, beanName); //递归处理依赖bean getBean(dep); &#125;&#125; 下面这段就是创建一个bean实例；这里通过调用getSingleton方法来创建一个单例bean实例；从代码中可以看到，getSingleton的调用是通过getObject这个回调函数来间接调用createBean完成的。 12345678910111213141516171819if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; //回调函数getObject @Override public Object getObject() throws BeansException &#123; try &#123; //创建bean return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; //发生异常则销毁 destroySingleton(beanName); throw ex; &#125; &#125; &#125;); //获取给定bean实例的对象，无论是bean实例本身，还是FactoryBean创建的对象。 bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125; 下面是创建prototype bean123456789101112else if (mbd.isPrototype()) &#123; Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); //创建prototype bean prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);&#125; 最后是对创建的bean进行类型检查，没有问题就返回已经创建好的bean；此时这个bean是包含依赖关系的bean 1234567891011121314if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123; try &#123; return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Failed to convert bean &apos;&quot; + name + &quot;&apos; to required type &apos;&quot; + ClassUtils.getQualifiedName(requiredType) + &quot;&apos;&quot;, ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125;&#125;//返回beanreturn (T) bean; getBean是依赖注入的起点，从上面的分析可以看出，bean的创建都是通过createBean来完成具体的创建的。createBean的具体实现是在AbstractAutowireCapableBeanFactory中的，这里createBean不仅仅负责创建bean，还需要完成对bean的初始化。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：依赖注入-引言]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase7%2F</url>
    <content type="text"><![CDATA[Spring源码系列：BeanDefinition源码解析 Spring源码系列：BeanDefinition载入(上) Spring源码系列：BeanDefinition载入(中) Spring源码系列：BeanDefinition载入(下) 在上面四篇文章中大概分析了一下Bean的载入，其实这个过程就是在Ioc容器中建立BeanDefinition的数据映射。但是对于Bean的实例化并未涉及，在之前的分析中也提到，bean的实例化是在依赖注入是才具体完成。 关于依赖注入关于Spring，我们最先想到的就两个Ioc和Aop；然后关于Ioc我们又能牵扯出两个：控制反转和依赖注入。控制反转和依赖注入在网上被无数大神亦或菜鸟解读过，这里就不罗列那些概念了，直接看： 不使用Spring1234567public class UserService &#123; //手动new一个 UserDao userDao = new UserDaoImpl(); public int insertUser(String userName) &#123; return userDao.insertUser(userName); &#125;&#125; 使用Spring(以注解方式) 1234567public class UserService &#123; @Autowired private UserDao userDao; public int insertUser(String userName) &#123; return userDao.insertUser(userName); &#125;&#125; 看起来貌似没有啥很大的改变，区别呢？ 我们先来分析下在一个类中这两种申明的区别： UserDao userDao; userDao是UserDao类型的引用名称。仅仅是声明了一个变量引用名称。并没有做实例化，userDao的实例化可以通过set方法进行设置（Spring中之前常用的就是set方法注入）；当我们初始化持有userDao的这个类时我们还不知道userDao到底具体指向哪个堆中的对象地址。 UserDao userDao = new UserDaoImpl(); 而这个，申明一个变量名称，并将userDao直接指向new UserDaoImpl()创建的对象。 我们来看Spring中关于注入之后对象地址以及不使用注入方式对象的地址： 1、直接注入2、注入覆盖了我自己的对象3、自己手动new 通过上面三幅图可以明显的看出，自己手动new的对象没有使用代理的方式，而托管给Spring注入的对象均是通过动态代理来完成的。 关于动态代理：《猪弟拱Java》连载番外篇：Java代理（中） 总结：当某个角色(可能是一个Java实例，调用者)需要另一个角色(另一个Java实例，被调用者)的协助时，在未使用Spring来管理Bean的程序设计过程中，通常由调用者来创建被调用者的实例。但在Spring里，创建被调用者的工作不再由调用者来完成，因此称为控制反转;创建被调用者实例的工作通常由Spring容器来完成，然后注入调用者，因此也称为依赖注入。 三个问题那么现在要考虑问题就是，什么时候会触发我们的依赖注入呢？Bean的实例化是否必须在依赖注入时才能完成呢？在Spring中又是通过哪些类来完成注入工作的呢？ 1、什么时候会触发我们的依赖注入 答：用户第一次向容器获取Bean的时候出发。 2、Bean的实例化是否必须在依赖注入时才能完成 这个其实不是必须的，咱们都知道BeanDefinition中有lazy-init这样一个属性，我们可以通过控制这个属性的设置来让容器完成对Bean的预实例化。预实例化就是说它的依赖注入是在实例化过程中完成的。 第一和第二个问题将会在分析第三个问题的时候慢慢的细化分析。所以第三个问题其实没啥鸟用，但也是最最最核心的，就是为了引出后面关于一些具体类的分析的。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：Spring的版本变更]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase0%2F</url>
    <content type="text"><![CDATA[Spring是一个开放源代码的设计层面框架，它解决的是业务逻辑层和其他各层的松耦合问题，因此它将面向接口的编程思想贯穿整个系统应用。Spring是于2003 年兴起的一个轻量级的Java 开发框架，由Rod Johnson创建。简单来说，Spring是一个分层的JavaSE/EEfull-stack(一站式) 轻量级开源框架【来自百度百科】。 目前Spring已经发展到5.0.4 版本了，今天咱们就来聊一聊spring各个版本都提供了哪些新的特性。 spring 2.xspring的2.x包括下面两个： 2.0.0-2.0.8 2.5.0-2.5.6此时的spring还是很年轻的，所包含的模块也不是很多。如下图： 2.0 新特性 XML Schema的新XML配置语法的出现 新的Bean的作用域 以前的Spring版本对IoC容器级支持两个不同的bean作用域（singleton和prototype）。Spring 2.0在这方面进行了改进，不仅根据部署Spring的环境（例如Web环境中的请求和会话作用域Bean）提供了一些额外的作用域，还提供了“挂钩”），使Spring用户可以创建自己的范围。 应该注意的是，虽然singleton和prototype作用域bean的底层（和内部）实现已经改变，但是所述改变对于最终用户是完全透明的…不需要改变现有的配置，并且不存在现有的配置将会中断。 可扩展的XML 支持@AspectJ方面 更加简单XML配置(aop&amp;事务) 异步JMS Spring MVC的表单标签库 Java 5（Tiger）支持 Spring 2.0现在支持用Java以外的语言编写的bean，目前支持的动态语言是JRuby，Groovy和BeanShell 提供了一个关于任务调度的抽象概念 引入了对各种注释的支持，用于配置目的，例如@ Transactional， @Required和@PersistenceContext / @PersistenceUnit。 2.5 新特性 在Spring 2.0在整个框架中对Java 5的深入支持之后，Spring 2.5引入了对Java 6的专门支持。 @Autowired结合对JSR-250注释@Resource，@ PostConstruct和@PreDestroy的支持 。 在类路径中自动检测组件 Spring 2.5引入了支持组件扫描：在类路径中自动检测带注释的组件。典型地，这样的组件类将与定型如进行注释@Component， @Repository，@Service， @Controller。根据应用程序的上下文配置，这些组件类将被自动检测并转换为Spring bean定义，而不需要为每个这样的bean显式配置。 支持bean名称切入点元素 Spring 2.5引入了对bean（…） pointcut元素的支持，根据Spring定义的bean名称匹配特定的命名bean 支持AspectJ加载时织入 Spring 2.5显着扩展了SimpleJdbcTemplate的功能， 并引入了 SimpleJdbcCall和SimpleJdbcInsert 操作对象。 基于注释的控制器。 Spring 2.5为MVC控制器引入了一个基于注释的编程模型，使用@ RequestMapping，@ RequestParam，@ ModelAttribute等注解。这个注解支持可用于Servlet MVC和Portlet MVC。以这种风格实现的控制器不必扩展特定的基类或实现特定的接口。此外，他们通常不直接依赖于Servlet或Portlet API，尽管他们可以很容易地访问Servlet或Portlet设施。 引入了Spring TestContext框架 Spring 3.xspring 3.x包括以下几个系列： 3.0.0-3.0.7 3.1.0-3.1.4 3.2.0-3.2.18 在2.x的模块上页拓展了新的模块 3.0.x 新特性 针对Java 5更新的核心API spring 表达语言 基于Java的bean元数据和在组件中定义bean元数据 通用型转换系统和现场格式化系统 全面的REST支持 声明式模型验证 早期支持Java EE 6 支持嵌入式数据库 3.1.x 新特性 缓存抽象 Bean定义配置文件 环境抽象 PropertySource抽象 Spring的XML名称空间的代码等价物 支持Hibernate 4.x TestContext框架支持@Configuration类和bean定义配置文件 更简洁的构造函数注入的命名空间 支持针对非标准JavaBeans设置器的注入 支持Servlet 3基于代码的Servlet Container配置 支持Servlet 3 MultipartResolver 没有persistence.xml的JPA EntityManagerFactory引导 用于注释的控制器处理的新的基于HandlerMethod的支持类 Flash属性和RedirectAttributes(请求重定向参数的支持) “consumes” and “produces” conditions in @RequestMapping 改进了对通过’Content-Type’标题指定方法消耗的媒体类型以及通过标题指定的可生成类型的支持’Accept’ URI模板变量增强 @Valid on @RequestBody控制器方法参数 控制器方法参数上的@RequestPart注释 UriComponentsBuilder和UriComponents 3.2.x 新特性 支持基于Servlet 3的异步请求处理 Spring MVC测试框架 @ControllerAdvice注解 基于代码的Servlet 3+容器初始化的抽象基类 ResponseEntityExceptionHandler类引入 在RestTemplate和中的 @RequestBody参数支持泛型类型 JackJSON 2和相关的改进 @RequestBody改进 HTTP PATCH方法 使用注释点和bean定义方法的元注释 初步支持JCache 0.5 全球日期和时间格式 整个框架的并发优化 新的基于Gradle的构建和移动到GitHub 精炼的Java SE 7 / OpenJDK 7支持 Spring 4.xspring 4包括以下系列版本： 4.0.0-4.0.9 4.1.0-4.1.9 4.2.0-4.2.9 4.3.0-4.3.13 spring 4.0.x 新特性 删除弃用的软件包和方法 可选的第三方依赖已被提升到2010/2011最低（即Spring 4通常只支持2010年末或之后发布的版本）：特别是，Hibernate 3.6+，EhCache 2.1+，Quartz 1.8+，Groovy 1.8+和Joda-Time 2.0+。作为规则的一个例外，Spring 4需要最近的Hibernate Validator 4.3+，并且对Jackson的支持已经集中在2.0+以上（当前Spring 3.2已经保留了对Jackson 1.8 / 1.9的支持;现在只是弃用了形成）。 Java 8（以及6和7） 可以使用Spring的回调接口使用 lambda表达式和方法引用 Java EE 6和7 Java EE 6或更高版本现在被认为是Spring Framework 4的基准，JPA 2.0和Servlet 3.0规范特别相关。为了与Google App Engine和较早的应用程序服务器保持兼容，可以将Spring 4应用程序部署到Servlet 2.5环境中。不过，强烈建议使用Servlet 3.0+，这是Spring开发环境中测试设置的测试和模拟包中的先决条件。 Groovy Bean定义DSL 核心容器改进 Spring现在将泛型类型作为注入Beans时限定符的形式 。例如，如果您正在使用Spring Data Repository，则现在可以轻松注入一个特定的实现： @Autowired Repository customerRepository。 如果您使用Spring的元注释支持，现在可以开发自定义注释来 显示源注释中的特定属性。 bean现在可以在自动装配到列表和数组中时进行排序。无论是标注和接口的支持。 @OrderOrdered 该@Lazy注释现在可以在注入点使用，以及对@Bean 定义。 该@Description批注已经推出了使用基于Java的配置开发。 已经通过注释添加 了有条件地过滤bean的通用模型@Conditional。这与@Profile支持类似，但允许以编程方式开发用户定义的策略。 基于CGLIB的代理类不再需要默认的构造函数。支持通过提供objenesis 其重新打包库在线，并将其作为Spring框架的一部分。有了这个策略，所有的构造函数都不再被调用代理实例。 整个框架现在都有管理时区的支持，例如LocaleContext。 web 模块支持 可以在Spring MVC应用程序中使用新的@RestController注释，不需要添加@ResponseBody到每个 @RequestMapping方法中。 该AsyncRestTemplate已添加，允许异步非阻塞支持开发REST客户端时。 开发Spring MVC应用程序时提供了全面的时区支持。 测试改进 WebSocket，SockJS和STOMP消息传递 spring 4.1.x 新特性 JMS改进 缓存改进 网络改进 WebSocket消息传递改进 测试改进 spring 4.2.x 新特性 Spring 4 官方文档 核心容器改进 数据访问改进 spring 4.3.x 新特性 支持新的包和服务 相关改进 目前还没有用过spring5，总会有憧憬。当我们使用spring越来越简单时，危机也在一步步逼近；看到表象，进一步，再进一步！]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：BeanDefinition载入(下)]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase5%2F</url>
    <content type="text"><![CDATA[在Spring源码系列：BeanDefinition载入(上)中已经大概捋了一下解析过程，本篇将记录一下bean的注册过程。bean的注册就是DefaultListableBeanFactory中registerBeanDefinition方法来完成的。那我就来看registerBeanDefinition这个方法的具体逻辑。1、beanDefinition类型判断和验证这里的验证主要是验证不能将静态工厂方法与方法重写相结合(静态工厂方法必须创建实例);if (beanDefinition instanceof AbstractBeanDefinition) { try { ((AbstractBeanDefinition) beanDefinition).validate(); } catch (BeanDefinitionValidationException ex) { throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,“Validation of bean definition failed”, ex); }}2、尝试从beanDefinitionMap中获取老的bean这里就是先根据beanName从beanDefinitionMap去取BeanDefinition，并将结果给oldBeanDefinition。BeanDefinition oldBeanDefinition;oldBeanDefinition = this.beanDefinitionMap.get(beanName);3、beanDefinitionMap中已经存在名为beanName的Beandefinition如果当前beanDefinitionMap中已经存在名为beanName的Beandefinition了(即检查是否有相同名称的beanDefinition已经在Ioc容器中注册过了)。，如果有，则进行以下具体策略：如果不允许bean被覆盖，则直接抛出不能重新注册，bean已经存在这样的异常信息使用框架生成的Bean来代替用户自定义的bean覆盖原有的Beandefinitionif (oldBeanDefinition != null) { if (!isAllowBeanDefinitionOverriding()) { //省略异常代码 } else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) { //省略异常代码 } else if (!beanDefinition.equals(oldBeanDefinition)) { //提示覆盖log信息 } else { //提示覆盖log信息 } //覆盖原有的Beandefinition this.beanDefinitionMap.put(beanName, beanDefinition);}4、beanDefinitionMap不存在名为beanName的Beandefinition//检查bean的创建阶段是否已经开始，也就是说是否已经创建了if (hasBeanCreationStarted()) { //Cannot modify startup-time collection elements anymore (for stable iteration) // 无法修改启动时间收集元素（用于稳定迭代）（译注） //注册过程需要保证数据的一致性，所有需要加锁同步 synchronized (this.beanDefinitionMap) { //注册到beanDefinitionMap中 this.beanDefinitionMap.put(beanName, beanDefinition); //下面就是将当前beanName存放到beanDefinitionNames中 List&lt;String&gt; updatedDefinitions = new ArrayList&lt;String&gt;( this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; //如果单例模式的bean名单中有该bean的name，那么移除掉它。 //也就是说着，将一个原本是单例模式的bean重新注册成一个普通的bean if (this.manualSingletonNames.contains(beanName)) { Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;String&gt;(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; } }}// 仍处于启动阶段，bean还没有开始注册else { // Still in startup registration phase this.beanDefinitionMap.put(beanName, beanDefinition); this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName);}this.frozenBeanDefinitionNames = null;5、执行缓存清除1：oldBeanDefinition如果存在，且执行到了这里也没有抛出异常，说明该BeanDefinition已经被覆盖，缓存需要更新。2：如果是单例模式的bean对象则Set中包含该beanName，执行到这里说明该BeanDefinition已经从一个单例模式的bean变为了一个普通的bean，所以缓存也需要更新。if (oldBeanDefinition != null || containsSingleton(beanName)) { resetBeanDefinition(beanName);}OK，我们来看下resetBeanDefinition这个方法:这个方法的作用就是重置给定bean的所有bean定义缓存，包括从它派生的bean的缓存。protected void resetBeanDefinition(String beanName) { // 如果已经创建，则删除给定bean的合并bean定义。 clearMergedBeanDefinition(beanName); // 如果有的话，从singleton 高速缓存中删除相应的bean。 //但是这也不是必须的，而只是为了覆盖上下文的默认bean //（就是从manualSingletonNames中移除） destroySingleton(beanName); //递归的方式来 重置具有给定bean作为父项的所有bean定义。 for (String bdName : this.beanDefinitionNames) { if (!beanName.equals(bdName)) { BeanDefinition bd = this.beanDefinitionMap.get(bdName); if (beanName.equals(bd.getParentName())) { resetBeanDefinition(bdName); } } }}Bean的注册就到这里了，下一篇学习的是DefaultListableBeanFactory这个集大成者容器。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：BeanDefinition载入（中）]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase6%2F</url>
    <content type="text"><![CDATA[上一篇是将Bean的解析注册流程进行了梳理，对于一些细节问题没有进行细究，比如说元素属性值的处理，构造函数的处理等等。本篇就学习记录一下相关点。 首先来看下是在哪个地方具体生成BeanDefinitiond的。下面是方法请求的顺序。 DefaultBeanDefinitionDocumentReader.parseDefaultElement DefaultBeanDefinitionDocumentReader.processBeanDefinition BeanDefinitionParserDelegate.parseBeanDefinitionElement 关于元素的解析绝大多数都是在BeanDefinitionParserDelegate及其子类中完成的。OK，来看下parseBeanDefinitionElement这个方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public AbstractBeanDefinition parseBeanDefinitionElement( Element ele, String beanName, BeanDefinition containingBean) &#123; this.parseState.push(new BeanEntry(beanName)); String className = null; //在这里是读取&lt;bean&gt;的class名字，然后载入到BeanDefinition中，并未做实例化 if (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123; className = ele.getAttribute(CLASS_ATTRIBUTE).trim(); &#125; try &#123; String parent = null; if (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123; parent = ele.getAttribute(PARENT_ATTRIBUTE); &#125; //生成BeanDefinition对象 AbstractBeanDefinition bd = createBeanDefinition(className, parent); //解析当前bean的属性 parseBeanDefinitionAttributes(ele, beanName, containingBean, bd); //设置description信息 bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT)); //对bean的元素信息进行解析 parseMetaElements(ele, bd); parseLookupOverrideSubElements(ele, bd.getMethodOverrides()); parseReplacedMethodSubElements(ele, bd.getMethodOverrides()); //解析bean的构造函数设置 parseConstructorArgElements(ele, bd); //解析property设置 parsePropertyElements(ele, bd); parseQualifierElements(ele, bd); bd.setResource(this.readerContext.getResource()); bd.setSource(extractSource(ele)); return bd; &#125; //异常1：ClassNotFoundException catch (ClassNotFoundException ex) &#123; error("Bean class [" + className + "] not found", ele, ex); &#125; //异常2：NoClassDefFoundError catch (NoClassDefFoundError err) &#123; error("Class that bean class [" + className + "] depends on not found", ele, err); &#125; //其他未知错误 catch (Throwable ex) &#123; error("Unexpected failure during bean definition parsing", ele, ex); &#125; finally &#123; this.parseState.pop(); &#125; return null;&#125; 此处我们以解析property为例，看下具体的处理细节： 12345678910111213//解析给定bean元素的属性子元素。public void parsePropertyElements(Element beanEle, BeanDefinition bd) &#123; //获取子元素节点 NodeList nl = beanEle.getChildNodes(); //遍历 for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); //是否包含property标识 if (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, PROPERTY_ELEMENT)) &#123; parsePropertyElement((Element) node, bd); &#125; &#125;&#125; 接着是执行具体property,在parsePropertyElement中完成： 12345678910111213141516171819202122232425262728//解析一个property元素。public void parsePropertyElement(Element ele, BeanDefinition bd) &#123; //首先获取到property的名称 String propertyName = ele.getAttribute(NAME_ATTRIBUTE); //检查是否有name if (!StringUtils.hasLength(propertyName)) &#123; error("Tag 'property' must have a 'name' attribute", ele); return; &#125; this.parseState.push(new PropertyEntry(propertyName)); try &#123; //验证在同一个bean中存在同名的property，存在的话就不解析了，直接返回 if (bd.getPropertyValues().contains(propertyName)) &#123; error("Multiple 'property' definitions for property '" + propertyName + "'", ele); return; &#125; //解析出property的值 Object val = parsePropertyValue(ele, bd, propertyName); //封装成PropertyValue对象 PropertyValue pv = new PropertyValue(propertyName, val); parseMetaElements(ele, pv); pv.setSource(extractSource(ele)); bd.getPropertyValues().addPropertyValue(pv); &#125; finally &#123; this.parseState.pop(); &#125;&#125; 在parsePropertyValue中，是对所有的property子元素进行具体解析的。我们知道property中除了单值之外，还会包括如：list，set，map，prop等集合元素；这些都会被封装成对应的Managerd对象。比如：ManagedList等。不同的集合类型页同样对应一种解析方法，比如解析list的是使用parseListElement。这些解析都是在BeanDefinitionParserDelegate类中完成的。这个后面我会抽一篇来学习BeanDefinitionParserDelegate这个类。 Bean的载入过程就是这样通过层层解析来完成的，但是对于目前的Ioc容器来说，仅仅是完成了对Bean对象管理的一些数据准备工作，也就是初始化工作，目前的BeanDefginiton中包含的就是一些静态的配置信息，Bean的实例化还没有进行，这个实例化的过程是在依赖注入时候完成的。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：BeanDefinition载入(上)]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase4%2F</url>
    <content type="text"><![CDATA[继上一篇BeanFactory的创建之后，其实就是BeanDefinition载入了。同样也是在AbstractRefreshableApplicationContext类的refreshBeanFactory方法中完成：//创建默认的DefaultListableBeanFactory工厂DefaultListableBeanFactory beanFactory = createBeanFactory();//设置IdbeanFactory.setSerializationId(getId());//这个方法其实就是设置了allowBeanDefinitionOverriding和allowCircularReferences两个属性customizeBeanFactory(beanFactory);//调用子类的加载bean定义方法，这里会调用XmlWebApplicationContext子类的复写方法loadBeanDefinitions(beanFactory);这里的loadBeanDefinitions也是一个抽象方法，AbstractRefreshableApplicationContext类中并没有给出具体的实现，二是通过子类XmlWebApplicationContext的loadBeanDefinitions完成具体实现。protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException { //创建XmlBeanDefinitionReader，并通过回调设置到BeanFactory中 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); //为XmlBeanDefinitionReader配置Environment beanDefinitionReader.setEnvironment(getEnvironment()); //为XmlBeanDefinitionReader配置ResourceLoader， //因为DefaultResourceLoader是父类，所以this可以直接被使用 beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // 允许子类提供reader的自定义初始化，然后继续实际加载bean定义。 initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader);}initBeanDefinitionReader初始化用于加载此上下文的bean定义的bean定义读取器；默认实现是空的。然后下面通过重载的loadBeanDefinitions来做具体的bean解析（这里用到的是XmlBeanDefinitionReader这个解析器）；使用给定的XmlBeanDefinitionReader加载bean definitions。protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws IOException { String[] configLocations = getConfigLocations(); //遍历xml文件 if (configLocations != null) { for (String configLocation : configLocations) { reader.loadBeanDefinitions(configLocation); } }}此时会将我们的applicationContext.xml读入（当然如何还有其他的spring配置文件，同样会一块拿到路径），如下图所示：然后继续通过loadBeanDefinitions的重载方法继续委托调用。最后交给AbstractBeanDefinitionReader的loadBeanDefinitions来完成；这个代码比较长，拆开一步一步来说，先看下整体的：public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException { //获取ResourceLoader资源定位器 ResourceLoader resourceLoader = getResourceLoader(); //如果定位器为null，则抛出异常 if (resourceLoader == null) { throw new BeanDefinitionStoreException( “Cannot import bean definitions from location [“ + location + “]: no ResourceLoader available”); } //是否是ResourcePatternResolver类型的定位器 if (resourceLoader instanceof ResourcePatternResolver) { // Resource pattern matching available. try { Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); int loadCount = loadBeanDefinitions(resources); if (actualResources != null) { for (Resource resource : resources) { actualResources.add(resource); } } if (logger.isDebugEnabled()) { logger.debug(“Loaded “ + loadCount + “ bean definitions from location pattern [“ + location + “]”); } return loadCount; } catch (IOException ex) { throw new BeanDefinitionStoreException( “Could not resolve bean definition resource pattern [“ + location + “]”, ex); } } //非ResourcePatternResolver类型的 else { // Can only load single resources by absolute URL. Resource resource = resourceLoader.getResource(location); int loadCount = loadBeanDefinitions(resource); if (actualResources != null) { actualResources.add(resource); } if (logger.isDebugEnabled()) { logger.debug(“Loaded “ + loadCount + “ bean definitions from location [“ + location + “]”); } return loadCount; }}上面的代码中需要说明下为什么要判断当前resourceLoader是否是ResourcePatternResolver类型的，因为ResourceLoader只是提供了对classpath前缀的支持。而ResourcePatternResolver提供了对classpath前缀的支持。也就是说ResourceLoader提供classpath下单资源文件的载入，而ResourcePatternResolver提供多资源文件的载入。先看下假如是ResourcePatternResolver类型的（略去了部分log代码）：try { //先得到我们的resources Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); //解析并返回beanDefinition的数量 int loadCount = loadBeanDefinitions(resources); //加载过程中已经被解析过的实际的Resource的填充集合 if (actualResources != null) { for (Resource resource : resources) { actualResources.add(resource); } } return loadCount;}catch (IOException ex) { throw new BeanDefinitionStoreException( “Could not resolve bean definition resource pattern [“ + location + “]”, ex);}非ResourcePatternResolver类型情况：// Can only load single resources by absolute URL.//只能通过绝对URL加载单个资源Resource resource = resourceLoader.getResource(location);//解析并返回beanDefinition的数量int loadCount = loadBeanDefinitions(resource);if (actualResources != null) { actualResources.add(resource);}return loadCount;然后继续通过重载方法loadBeanDefinitions(Resource… resources)来解析（AbstractBeanDefinitionReader类中）public int loadBeanDefinitions(Resource… resources) throws BeanDefinitionStoreException { Assert.notNull(resources, “Resource array must not be null”); //初始化beanDefiniton个数 int counter = 0; //遍历当前资源数组 for (Resource resource : resources) { //解析具体resource中的bean counter += loadBeanDefinitions(resource); } return counter;}然后交给子类XmlBeanDefinitionReader中的loadBeanDefinitions(Resource resource)方法：public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException { return loadBeanDefinitions(new EncodedResource(resource));}继续通过重载方法loadBeanDefinitions(EncodedResource encodedResource)执行，这个方法我们只关注最核心的代码：//获取输入流InputStream inputStream = encodedResource.getResource().getInputStream();try { //资源读取inputSource InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) { inputSource.setEncoding(encodedResource.getEncoding()); } //委托给doLoadBeanDefinitions来完成 return doLoadBeanDefinitions(inputSource, encodedResource.getResource());}finally { inputStream.close();}doLoadBeanDefinitions是XmlBeanDefinitionReader中的方法，来看核心代码：//解析成符合w3c标准的DocumentDocument doc = doLoadDocument(inputSource, resource);//继续交给registerBeanDefinitions来处理return registerBeanDefinitions(doc, resource);这个时候已经将loadBeanDefinitions换成registerBeanDefinitions了，也就是载入并注册；registerBeanDefinitions同样也是XmlBeanDefinitionReader中的方法：public int registerBeanDefinitions(Document doc, Resource resource) throwsBeanDefinitionStoreException { //得到documentReader用来读取document文档 BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); //注册之前的bean个数 int countBefore = getRegistry().getBeanDefinitionCount(); //解析并注册bean documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore;}仍然没有处理，继续交给BeanDefinitionDocumentReader的registerBeanDefinitions方法来完成：//这个实现根据“spring-beans”XSD（或DTD）解析bean定义。public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) { this.readerContext = readerContext; logger.debug(“Loading bean definitions”); Element root = doc.getDocumentElement(); doRegisterBeanDefinitions(root);}还是没处理，又细化一步，交给DefaultBeanDefinitionDocumentReader的doRegisterBeanDefinitions(Element root)方法：protected void doRegisterBeanDefinitions(Element root) { BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) { String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE); if (StringUtils.hasText(profileSpec)) { String[] specifiedProfiles = StringUtils.tokenizeToStringArray( profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS); if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) { if (logger.isInfoEnabled()) { logger.info(“Skipped XML bean definition file due to specified profiles [“ + profileSpec + “] not matching: “ + getReaderContext().getResource()); } return; } } } preProcessXml(root); parseBeanDefinitions(root, this.delegate); postProcessXml(root); this.delegate = parent;}任何嵌套的&lt;beans&gt;元素都将导致此方法的递归。 为了正确传播和保存&lt;beans&gt; default- 属性，请跟踪当前（父）委托，该委托可能为null。 为了回退的目的，创建一个引用父对象的新（子）委托，然后最终重置this.delegate回到它的原始（父）引用。这个行为模仿了一堆委托，而实际上并不需要一个委托。（翻译的有点蹩脚，大概意思就是这）所以说DefaultBeanDefinitionDocumentReader自己也没干这事，又给了BeanDefinitionParserDelegate，然后就是preProcessXml()、parseBeanDefinitions()、postProcessXml()方法；其中preProcessXml()和postProcessXml()默认是空方法，自己没有实现。具体解析在parseBeanDefinitions(root, this.delegate)中完成。BeanDefinitionParserDelegate用于将 Document 的内容转成 BeanDefinition实例；BeanDefinitionDocumentReader 本身不具备该功能而是交给了该类来完成。protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) { //查看定义的命名空间是否为默认的命名空间 if (delegate.isDefaultNamespace(root)) { NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) { Node node = nl.item(i); if (node instanceof Element) { Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) { parseDefaultElement(ele, delegate); } else { delegate.parseCustomElement(ele); } } } } else { delegate.parseCustomElement(root); }}这个方法就是解析文档中根目录下的元素：“import”，“alias”，“bean”。private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) { //解析一个“import”元素，并将给定资源的bean定义加载到bean工厂中。 if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) { importBeanDefinitionResource(ele); } //处理给定的别名元素，向注册表注册别名。 else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) { processAliasRegistration(ele); } //处理给定的bean元素，解析bean定义并将其注册到注册表中。 else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) { processBeanDefinition(ele, delegate); } //在给定的根&lt;beans /&gt;元素内注册每个bean定义。 else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) { // recurse doRegisterBeanDefinitions(ele); }}先来看processBeanDefinition这个方法；BeanDefinitionHolder是一个BeanDefinition的持有者，其定义了一下变量，并对以下变量提供get和set操作。这个在后面的说道BeanDefinition体系的时候再聊。protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) { //获取一个BeanDefinitionHolder BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) { //首先根据自定义属性进行装饰。 //基于自定义嵌套元素进行装饰。 bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try { // 注册最终装饰的实例。 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry()); } catch (BeanDefinitionStoreException ex) { getReaderContext().error(“Failed to register bean definition with name ‘“ + bdHolder.getBeanName() + “‘“, ele, ex); } // 发送注册事件。 getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); }}接着看registerBeanDefinition这个方法：通过给定的bean工厂注册给定的bean definition 。public static void registerBeanDefinition( BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException { // 在主名称下注册bean定义。 String beanName = definitionHolder.getBeanName(); registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 如果有的话，注册bean名称的别名， String[] aliases = definitionHolder.getAliases(); if (aliases != null) { for (String alias : aliases) { registry.registerAlias(beanName, alias); } }}registerBeanDefinition里面又通过调用BeanDefinitionRegistry接口的实现DefaultListableBeanFactory来完成具体的注册过程。关于DefaultListableBeanFactory中registerBeanDefinition方法的解析逻辑将在Spring源码系列：BeanDefinition载入(下)中来说.欢迎关注微信公众号]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：BeanFactory的创建]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase3%2F</url>
    <content type="text"><![CDATA[Spring的Ioc容器其实就是一个bean的关系网，依赖于core，bean，context三个组件来构建的。在spring中最核心的就是对于bean的管理。而bean又依托于我们的容器。本文将从顶层分析一下spring中beanFactory的具体创建过程，为后续的bean的生命周期提供一个基础。 BeanFactory的继承体系 从上图可以看到，BeanFactory有三个子类： ListableBeanFactory HierarchicalBeanFactory AutowireCapableBeanFactory （上述三个类的子类体系小伙伴们可以自己对着源码看下，实在太多） 看下上图中最底层的DefaultListableBeanFactory类的定义：12public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory implements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable 这个其实就是BeanFactory的默认实现类，它直接或者间接的实现了所有的接口。其实在看spring源码的时候都会遇到类似的设计模式，对于某一个具体的功能，通常都会定义很多层的接口，层层包装，层层委托。这种做法的好处就是，对于不同的场合都会有特定的接口；这样一来就可以在spring内部对对象的传递和转化操作都会有一些访问限制。 例如ListableBeanFactory接口表示这些Bean是可列表的，而HierarchicalBeanFactory表示的是这些Bean是有继承关系的，也就是每个Bean有可能有父Bean。AutowireCapableBeanFactory接口定义Bean的自动装配规则。这四个接口共同定义了Bean的集合、Bean之间的关系、以及Bean行为。 BeanFactory的创建 在之前的文章中说过了容器的刷新过程。BeanFactory的创建也在wac.refresh()方法中。具体看下到底是通过哪些子类来完成的： 12// 通知子类刷新内部的bean工厂。ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); 1.AbstractApplicationContext中的obtainFreshBeanFactory 下面是obtainFreshBeanFactory的方法逻辑：12345678910protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; //这个是具体创建的方法，由子类实现 refreshBeanFactory(); //获取BeanFactory实例对象（ConfigurableListableBeanFactory类型的） ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug("Bean factory for " + getDisplayName() + ": " + beanFactory); &#125; return beanFactory;&#125; refreshBeanFactory并未有具体的实现逻辑，这个方法主要是通过委托给子类的refreshBeanFactory方法来实现，在AbstractApplicationContext中refreshBeanFactory是一个抽象模板方法： 1protected abstract void refreshBeanFactory() throws BeansException, IllegalStateException; 2.refreshBeanFactory方法(AbstractRefreshableApplicationContext类中)： 下面只注释与beanFactory创建相关的代码 1234567891011121314151617181920212223protected final void refreshBeanFactory() throws BeansException &#123; //是否已经有BeanFactory了 if (hasBeanFactory()) &#123; //销毁原有的Bean destroyBeans(); //关闭工厂 closeBeanFactory(); &#125; try &#123; //创建一个新的beanFactory DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException("I/O error parsing bean definition source for " + getDisplayName(), ex); &#125;&#125; 这个方法是实现执行这个上下文的底层bean工厂的实际刷新，如果有的话之前有BeanFactory存在，则关闭以前的bean工厂。并为上下文生命周期的下一个阶段初始化一个新鲜的bean工厂。 3.createBeanFactory(AbstractRefreshableApplicationContext类中) 123protected DefaultListableBeanFactory createBeanFactory() &#123; return new DefaultListableBeanFactory(getInternalParentBeanFactory());&#125; 这个方法就是为当前上下文创建一个内部的bean工厂。每次调用refresh()方法是都会创建尝试创建。默认实现是创建一个DefaultListableBeanFactory。并通过getInternalParentBeanFactory（）获取内部bean工厂来作为父级bean工厂。可以在子类中重写，例如自定义DefaultListableBeanFactory的设置。 getInternalParentBeanFactory（AbstractApplicationContext类中） 1234protected BeanFactory getInternalParentBeanFactory() &#123; return (getParent() instanceof ConfigurableApplicationContext) ? ((ConfigurableApplicationContext) getParent()).getBeanFactory() : getParent();&#125; 4.DefaultListableBeanFactory的构造函数 1234567/** * 通过给定的父类创建一个新的DefaultListableBeanFactory容器 * @param parentBeanFactory the parent BeanFactory */public DefaultListableBeanFactory(BeanFactory parentBeanFactory) &#123; super(parentBeanFactory);&#125; super(parentBeanFactory)调用的是AbstractAutowireCapableBeanFactory的构造函数123456789/** * 通过给定的父类构建新的AbstractAutowireCapableBeanFactory * @param parentBeanFactory parent bean factory, or &#123;@code null&#125; if none */public AbstractAutowireCapableBeanFactory(BeanFactory parentBeanFactory) &#123; this(); //设置父工厂 setParentBeanFactory(parentBeanFactory);&#125; this(),还是AbstractAutowireCapableBeanFactory的构造函数：123456789/** * 构建一个新的AbstractAutowireCapableBeanFactory. */public AbstractAutowireCapableBeanFactory() &#123; super(); ignoreDependencyInterface(BeanNameAware.class); ignoreDependencyInterface(BeanFactoryAware.class); ignoreDependencyInterface(BeanClassLoaderAware.class);&#125; super() ; AbstractBeanFactory的构造函数 12345/** * 构建一个新的AbstractBeanFactory. */public AbstractBeanFactory() &#123;&#125;]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：BeanDefinition 源码解析]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase2%2F</url>
    <content type="text"><![CDATA[Bean的定义主要由BeanDefinition来描述的。作为Spring中用于包装Bean的数据结构，今天就来看看它的面纱下的真容吧。 首先就是BeanDefinition的类定义：1public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement 对，没错，这货是个接口，而不是类，是不是有点莫名奇妙呢？我们都知道在JAVA中，接口是不能用来new出新的对象的，那么在Spring中，到底将XML解析出来的Bean包装成了什么呢？（这个密等下揭开） 先来看看BeanDefinition一个继承结构吧（均是与BeanDefinition有直接关联的类或者接口）！ 从类图中可以看出，BeanDefinition继承了AttributeAccessor和BeanMetadataElement两个接口；一个一个看。 AttributeAccessor AttributeAccessor接口定义了最基本的对任意对象的元数据的修改或者获取，主要方法有：1234567891011//将name定义的属性设置为提供的value值。如果value的值为null，则该属性为&#123;@link #removeAttribute removed&#125;。//通常，用户应该注意通过使用完全限定的名称（可能使用类或包名称作为前缀）来防止与其他元数据属性重叠。void setAttribute(String name, Object value);//获取标识为name的属性的值。Object getAttribute(String name);//删除标识为name的属性，并返回属性值Object removeAttribute(String name);//如果名为name的属性是否存在，存在返回true，否则返回false。boolean hasAttribute(String name);//返回所有属性的名称。String[] attributeNames(); BeanMetadataElement BeanMetadataElement接口提供了一个getResource()方法,用来传输一个可配置的源对象。 12//返回此元数据元素的配置源对象（可能为null）。Object getSource(); BeanDifinition源码分析一个BeanDefinition描述了一个bean的实例，包括属性值，构造方法参数值和继承自它的类的更多信息。BeanDefinition仅仅是一个最简单的接口，主要功能是允许BeanFactoryPostProcessor 例如PropertyPlaceHolderConfigure 能够检索并修改属性值和别的bean的元数据（译注）。 123//标准单例作用域的作用域标识符：“singleton”。//对于扩展的bean工厂可能支持更多的作用域。String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON; 123//标准原型作用域的范围标识符：“prototype”。//对于扩展的bean工厂可能支持更多的作用域。String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE; 12//表示BeanDefinition是应用程序主要部分的角色提示。 通常对应于用户定义的bean。int ROLE_APPLICATION = 0; ROLE_SUPPORT =1实际上就是说，我这个Bean是用户的，是从配置文件中过来的。1234//表示BeanDefinition是某些大型配置的支持部分的角色提示，通常是一个外部ComponentDefinition。//当查看某个特定的ComponentDefinition时，认为bean非常重要，//以便在查看应用程序的整体配置时能够意识到这一点。int ROLE_SUPPORT = 1; ROLE_INFRASTRUCTURE = 2就是我这Bean是Spring自己的，和你用户没有一毛钱关系。123//角色提示表明一个BeanDefinition是提供一个完全背景的角色，并且与最终用户没有关系。//这个提示用于注册完全是ComponentDefinition内部工作的一部分的beanint ROLE_INFRASTRUCTURE = 2; 上面是BeanDifinition的一些基本属性信息，一个就是标识下当前Bean的作用域，另外就是标识一下这个Bean是内部的还是外部的。下面来看这个接口为其子类都提供了哪些具体的行为方法： 1.当前Bean父类名称get&amp;set方法1234//如果父类存在，设置这个bean定义的父定义的名称。void setParentName(String parentName);//如果父类存在，则返回当前Bean的父类的名称String getParentName(); 2.当前Bean的className get&amp;set方法123456789//指定此bean定义的bean类名称。//类名称可以在bean factory后期处理中修改，通常用它的解析变体替换原来的类名称。void setBeanClassName(String beanClassName);//返回此bean定义的当前bean类名称。//需要注意的是，这不一定是在运行时使用的实际类名，以防子类定义覆盖/继承其父类的类名。//此外，这可能只是调用工厂方法的类，或者它 在调用方法的工厂bean引用的情况下甚至可能是空的。//因此，不要认为这是在运行时定义的bean类型，而只是将其用于在单独的bean定义级别进行解析。String getBeanClassName(); 3.Bean的作用域get&amp;set方法1234//覆盖此bean的目标范围，指定一个新的范围名称。void setScope(String scope);//返回此bean的当前目标作用域的名称，如果没有确定，返回nullString getScope(); 4.懒加载的get&amp;set方法 123456//设置这个bean是否应该被延迟初始化。如果&#123;false&#125;，那么这个bean将在启动时由bean工厂实例化，//这些工厂执行单例的立即初始化。//懒加载 &lt;bean lazy-init="true/false"&gt;void setLazyInit(boolean lazyInit);//返回这个bean是否应该被延迟初始化，即不是在启动时立即实例化。只适用于单例bean。boolean isLazyInit(); 5.依赖关系设置12345//设置这个bean依赖被初始化的bean的名字。 bean工厂将保证这些bean首先被初始化。//&lt;bean depends-on=""&gt;void setDependsOn(String... dependsOn);//返回这个bean依赖的bean名称。String[] getDependsOn(); 6.是否是自动转配设置123456789//设置这个bean是否是获得自动装配到其他bean的候选人。//需要注意是，此标志旨在仅影响基于类型的自动装配。//它不会影响按名称的显式引用，即使指定的bean没有标记为autowire候选，也可以解决这个问题。//因此，如果名称匹配，通过名称的自动装配将注入一个bean。void setAutowireCandidate(boolean autowireCandidate);//返回这个bean是否是自动装配到其他bean的候选者。就是是否在其他类中使用autowired来注入当前Bean的//是否为被自动装配 &lt;bean autowire-candidate="true/false"&gt;boolean isAutowireCandidate(); 7.主候选Bean1234//是否为主候选bean 使用注解：@Primaryvoid setPrimary(boolean primary);//返回这个bean是否是主要的autowire候选者。boolean isPrimary(); 8.定义创建该Bean对象的工厂类1234//指定要使用的工厂bean（如果有的话）。 这是调用指定的工厂方法的bean的名称。void setFactoryBeanName(String factoryBeanName);//返回工厂bean的名字，如果有的话。String getFactoryBeanName(); 9.创建该Bean对象的工厂方法 123456//如果有的话，指定工厂方法。//这个方法先将通过构造函数参数被调用，或者如果参数，将调用该方法的无参数构造。//方法将在指定的工厂bean（如果有的话）上被调用，或者作为本地bean类的静态方法被调用。void setFactoryMethodName(String factoryMethodName);//如果存在，返回工厂方法名String getFactoryMethodName(); 10.返回此bean的构造函数参数值。12//返回此bean的构造函数参数值。ConstructorArgumentValues getConstructorArgumentValues(); 11.获取普通属性集合12//获取普通属性集合MutablePropertyValues getPropertyValues(); 12.当前Bean的基本特性123456//是否是单例的boolean isSingleton();//是否是多例的boolean isPrototype();//是否是抽象类boolean isAbstract(); 13.当前Bean的应用12//获取这个bean的应用int getRole(); 13.可读描述12//返回对bean定义的可读描述。String getDescription(); 12//返回该bean定义来自的资源的描述String getResourceDescription(); 123//返回原始的BeanDefinition;如果没有，则返回null。允许检索装饰的bean定义（如果有的话）。//注意，这个方法返回直接的发起者。 迭代原始链，找到用户定义的原始BeanDefinition。BeanDefinition getOriginatingBeanDefinition(); 从上面的属性和方法分析可以看出，BeanDefinition对于一个Bean的描述做了较为完整的一套约束。这为后续的子类提供的最基本的职责和属性。 欢迎关注glmapper工作室公众号]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC系列源码：DispatcherServlet]]></title>
    <url>%2F2018%2F11%2F10%2Fspring-base-webmvc3%2F</url>
    <content type="text"><![CDATA[前面两篇文章直接对SpringMVC里面的组件进行了源码分析，可能很多小伙伴都会觉得有点摸不着头脑。所以今天再岔回来说一说SpringMVC的核心控制器，以此为轴心来学习整个SpringMVC的知识体系。 SpringMVC在项目中如何使用的？前面在《项目开发框架-SSM》一篇文章中已经详细的介绍过了SSM项目中关于Spring的一些配置文件，对于一个Spring应用，必不可少的是： 12345678910&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;!-- &lt;param-value&gt;classpath*:config/applicationContext.xml&lt;/param-value&gt; --&gt; &lt;param-value&gt;classpath:spring/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!-- 配置一个监听器将请求转发给 Spring框架 --&gt;&lt;!-- Spring监听器 --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; 通过ContextLoadListener来完成Spring容器的初始化以及Bean的装载《Spring技术内幕学习：Spring的启动过程》。那么如果在我们需要提供WEB功能，则还需要另外一个，那就是SpringMVC,当然我们同样需要一个用来初始化SpringMVC的配置（初始化9大组件的过程：前面两篇《SpringMVC源码系列：HandlerMapping》和《SpringMVC源码系列：AbstractHandlerMapping》是关于HnadlerMapping的，当然不仅仅这两个，还有其他几个重要的子类，后续会持续更新）： 1234567891011121314151617&lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置springMVC需要加载的配置文件 spring-dao.xml,spring-service.xml,spring-web.xml Mybatis（如果有） - &gt; spring -&gt; springmvc --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;!-- 默认匹配所有的请求 --&gt; &lt;url-pattern&gt;*.htm&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 当我们在web.xml中配置好上述内容（当然还得保证咱们的Spring的配置以及SpringMVC的配置文件没有问题的情况下），启动web容器（如jetty），就可以通过在浏览器输入诸如：http://localhost:80/myproject/index.do 的方式来访问我们的应用了。 俗话说知其然，之气所以然；那么为什么在配置好相关的配置文件之后，我们就能访问我们的SSM项目了呢？从发送一条那样的请求（http://localhost:80/myproject/index.do）展示出最后的界面，这个过程在，Spring帮我们做了哪些事情呢？（SpringIOC容器的初始化在《[Spring技术内幕-容器刷新：wac.refresh](https://juejin.im/post/5a3f5b43f265da432e5c37ea)》文中已经大概的说了下大家可以参考一下） SpringMVC处理请求的过程先通过下面这张图来整个了解下SpringMVC请求处理的过程；图中从1-13，大体上描述了请求从发送到界面展示的这样一个过程。从上面这张图中，我们可以很明显的看到有一个DispatcherServlet这样一个类，处于各个请求处理过程中的分发站。实际上，在SpringMVC中，整个处理过程的顶层设计都在这里面。通常我们将DispatcherServlet称为SpringMVC的前端控制器，它是SpringMVC中最核心的类。下面我们就来揭开DispatcherServlet的面纱吧！ DispatcherServletOK，我们直接来看DispatcherServlet的类定义：1public class DispatcherServlet extends FrameworkServlet DispatcherServlet继承自FrameworkServlet，就这样？下面才是他家的族谱： 首先为什么要有绿色的部门，有的同学可能已经想到了，绿色部分不是Spring的，而是java自己的；Spring通过HttpServletBean这位年轻人成功的拥有了JAVA WEB 血统（本来Spring就是用JAVA写的，哈哈）。关于Servlet这个小伙伴可以看下我之前的文章，有简单的介绍了这个接口。 话说回来，既然DispatcherServlet归根揭底是一个Servlet，那么就肯定具有Servlet功能行为。 敲黑板！！！Servlet的生命周期是啥（init-&gt;service-&gt;destroy ： 加载-&gt;实例化-&gt;服务-&gt;销毁）。 其实这里我想说的就是service这个方法，当然，在DispatcherServlet中并没有service方法，但是它有一个doService方法！（引的好难…） doService是DispatcherServlet的入口，我们来看下这个方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (logger.isDebugEnabled()) &#123; String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? " resumed" : ""; logger.debug("DispatcherServlet with name '" + getServletName() + "'" + resumed + " processing " + request.getMethod() + " request for [" + getRequestUri(request) + "]"); &#125; // 在include的情况下保留请求属性的快照，以便能够在include之后恢复原始属性。 Map&lt;String, Object&gt; attributesSnapshot = null; //确定给定的请求是否是包含请求，即不是从外部进入的顶级HTTP请求。 //检查是否存在“javax.servlet.include.request_uri”请求属性。 可以检查只包含请求中的任何请求属性。 //(可以看下面关于isIncludeRequest解释) if (WebUtils.isIncludeRequest(request)) &#123; attributesSnapshot = new HashMap&lt;String, Object&gt;(); Enumeration&lt;?&gt; attrNames = request.getAttributeNames(); while (attrNames.hasMoreElements()) &#123; String attrName = (String) attrNames.nextElement(); if (this.cleanupAfterInclude || attrName.startsWith("org.springframework.web.servlet")) &#123; attributesSnapshot.put(attrName, request.getAttribute(attrName)); &#125; &#125; &#125; // 使框架可用于handler和view对象。 request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); //FlashMap用于保存转发请求的参数的 FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response); if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap)); &#125; request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); try &#123; doDispatch(request, response); &#125; finally &#123; if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123; // Restore the original attribute snapshot, in case of an include. if (attributesSnapshot != null) &#123; restoreAttributesAfterInclude(request, attributesSnapshot); &#125; &#125; &#125;&#125; PS：“javax.servlet.include.request_uri”是INCLUDE_REQUEST_URI_ATTRIBUTE常量的值。isIncludeRequest(request)方法的作用我们可以借助一条JSP的指令来理解： 1&lt;jsp:incluede page="index.jsp"/&gt; 这条指令是指在一个页面中嵌套了另一个页面，那么我们知道JSP在运行期间是会被编译成相应的Servlet类来运行的，所以在Servlet中也会有类似的功能和调用语法，这就是RequestDispatch.include()方法。 那么在一个被别的servlet使用RequestDispatcher的include方法调用过的servlet中，如果它想知道那个调用它的servlet的上下文信息该怎么办呢，那就可以通过request中的attribute中的如下属性获取： 12345javax.servlet.include.request_urijavax.servlet.include.context_pathjavax.servlet.include.servlet_pathjavax.servlet.include.path_infojavax.servlet.include.query_string 在doService中，下面的try块中可以看到： 123try &#123; doDispatch(request, response);&#125; doService并没有直接进行处理，二是将请求交给了doDispatch进行具体的处理。当然在调用doDispatch之前，doService也是做了一些事情的，比如说判断请求是不是inclde请求，设置一些request属性等。 FlashMap支撑的Redirect参数传递问题在doService中除了webApplicationContext、localeResolver、themeResolve和themeSource四个提供给handler和view使用的四个参数外，后面的三个都是和FlashMap有关的，代码如下：1234567//FlashMap用于保存转发请求的参数的FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response);if (inputFlashMap != null) &#123; request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap));&#125;request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap());request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager); 注释中提到，FlashMap主要用于Redirect转发时参数的传递； 就拿表单重复提交这个问题来说,一种方案就是：在处理完post请求之后，然后Redirect到一个get的请求，这样即使用户刷新也不会有重复提交的问题。但是问题在于,前面的post请求时提交订单，提交完后redirect到一个显示订单的页面，显然在显示订单的页面我们需要知道订单的信息，但是redirect本身是没有参数传递功能的，按照普通的模式如果想传递参数，就只能将参数拼接在url中，但是url在get请求下又是有长度限制的；另外，对于一些场景下，我们也不希望自己的参数暴露在url中。 对于上述问题，我们就可以用FlashMap来进行参数传递了；我们需要在redirect之前将需要的参数写入OUTPUT_FLASH_MAP_ATTRIBUTE，例如： 1234ServletRequestAttributes SRAttributes = (ServletRequestAttributes)(RequestContextHolder.getRequestAttributes());HttpServletRequest req = SRAttributes.getRequest();FlashMap flashMap = (FlashMap)(req.getAttribute(DispatcherServlet.OUTPUT_FLASH_MAP_ATTRIBUTE));flashMap.put("myname","glmapper_2018"); 这样在redirect之后的handler中spring就会自动将其设置到model里面。但是如果仅仅是这样，每次redirect时都写上面那样一段代码是不是又显得很鸡肋呢？当然，spring也为我们提供了更加方便的用法，即在我们的handler方法的参数中使用RedirectAttributes类型变量即可（前段时间用到这个，本来是想单独写一篇关于参数传递问题的，借此机会就省略一篇吧，吼吼…），来看一段代码： 123456789101112131415161718@RequestMapping("/detail/&#123;productId&#125;")public ModelAndView detail(HttpServletRequest request,HttpServletResponse response,RedirectAttributes attributes, @PathVariable String productId) &#123; if (StringUtils.isNotBlank(productId)) &#123; logger.info("[产品详情]:detail = &#123;&#125;",JSONObject.toJSONString(map)); mv.addObject("detail",JSONObject.toJSONString(getDetail(productId))); mv.addObject("title", "详情"); mv.setViewName("detail.ftl");&#125;//如果没有获取到productIdelse&#123; attributes.addFlashAttribute("msg", "产品不存在"); attributes.addFlashAttribute("productName", productName); attributes.addFlashAttribute("title", "有点问题！"); mv.setViewName("redirect:"/error/fail.htm");&#125;return mv;&#125; 这段代码时我前段时间做全局错误处理模块时对原有业务逻辑错误返回的一个抽象，因为要将错误统一处理，就不可能在具体的handler中直接返回到错误界面，所以就将所有的错误处理都redirect到error/fail.htm这个handler method中处理。redirect的参数问题上面已经描述过了，这里就不在细说，就是简单的例子和背景，知道怎么去使用RedirectAttributes。 RedirectAttributes这个原理也很简单，就是相当于存在了一个session中，但是这个session在用过一次之后就销毁了，即在fail.htm这个方法中获取之后如果再进行redirect，参数还会丢失，那么就在fail.htm中继续使用RedirectAttributes来存储参数再传递到下一个handler。 doDispatch方法为了偷懒，上面强行插入了对Spring中redirect参数传递问题的解释。回归到咱们的doDispatch方法。 作用：处理实际的调度到handler。handler将通过按顺序应用servlet的HandlerMappings来获得。HandlerAdapter将通过查询servlet已安装的HandlerAdapter来查找支持处理程序类的第一个HandlerAdapter。所有的HTTP方法都由这个方法处理。这取决于HandlerAdapter或处理程序自己决定哪些方法是可以接受的。 其实在doDispatch中最核心的代码就4行，我们来看下： 根据request找到我们的handler 12// Determine handler for the current request. mappedHandler = getHandler(processedRequest); 根据handler找到对应的HandlerAdapter 12// Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); HandlerAdapter处理handler 12// Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); 调用processDispatchResult方法处理上述过程中得结果综合，当然也包括找到view并且渲染输出给用户1processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); 我们以上述为轴心，来看下它的整个源码(具体代码含义在代码中标注)： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //当前请求request HttpServletRequest processedRequest = request; //处理器链（handler和拦截器） HandlerExecutionChain mappedHandler = null; //用户标识multipartRequest（文件上传请求） boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; //很熟悉吧，这个就是我们返回给用户的包装视图 ModelAndView mv = null; //处理请求过程中抛出的异常。这个异常是不包括渲染过程中抛出的异常的 Exception dispatchException = null; try &#123; //检查是不是上传请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // 通过当前请求确定相应的handler mappedHandler = getHandler(processedRequest); //如果没有找到：就会报异常，这个异常我们在搭建SpringMVC应用时会经常遇到： //No mapping found for HTTP request with URI XXX in //DispatcherServlet with name XXX if (mappedHandler == null || mappedHandler.getHandler() == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // 根据handler找到HandlerAdapter HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); //处理GET和Head请求的Last-Modified //获取请求方法 String method = request.getMethod(); //这个方法是不是GET方法 boolean isGet = "GET".equals(method); if (isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug("Last-Modified value for [" + getRequestUri(request) + "] is: " + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; //这里就是我们SpringMVC拦截器的preHandle方法的处理 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 调用具体的Handler，并且返回我们的mv对象. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); //如果需要异步处理的话就直接返回 if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; //这个其实就是处理视图（view）为空的情况，会根据request设置默认的view applyDefaultViewName(processedRequest, mv); //这里就是我们SpringMVC拦截器的postHandle方法的处理 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException("Handler dispatch failed", err); &#125; //处理返回结果；（异常处理、页面渲染、拦截器的afterCompletion触发等） processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException("Handler processing failed", err)); &#125; finally &#123; //判断是否执行异步请求 if (asyncManager.isConcurrentHandlingStarted()) &#123; // 如果是的话，就替代拦截器的postHandle 和 afterCompletion方法执行 if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // 删除上传请求的资源 if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 整体来看，doDispatch做了两件事情： 处理请求 页面渲染 doDispatch处理过程流程图 那上面就是整个DispatcherServlet的一个大概内容了，关于SpringMVC容器的初始化，我们在先把DispatcherServlet中涉及到的九大组件撸完之后再回头来学习。关于九大组件目前已经有过两篇是关于HandlerMapping的了，由于我们打算对于整个SpringMVC体系结构都进行一次梳理，因此，会将九大组件从接口设计以及子类都会通过源码的方式来呈现。 大家如果有什么意见或者建议可以在下方评论区留言，也可以给我们发邮件（glmapper_2018@163.com）!欢迎小伙伴与我们一起交流，一起成长。]]></content>
      <categories>
        <category>spring mvc</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>web</tag>
        <tag>mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC源码系列：AbstractHandlerMapping]]></title>
    <url>%2F2018%2F11%2F10%2Fspring-base-webmvc2%2F</url>
    <content type="text"><![CDATA[AbstractHandlerMapping是实现HandlerMapping接口的一个抽象基类。支持排序，默认处理程序，处理程序拦截器，包括由路径模式映射的处理程序拦截器。所有的HandlerMapping都继承自AbstractHandlerMapping。另外，此基类不支持PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE的暴露，此属性的支持取决于具体的子类，通常基于请求URL映射。 前面说到，HandlerMapping的作用就是通过request查找Handler和Interceptors。具体的获取均是通过子类来实现的。 1.AbstractHandlerMapping 的类定义12public abstract class AbstractHandlerMapping extends WebApplicationObjectSupport implements HandlerMapping, Ordered &#123; AbstractHandlerMapping继承了WebApplicationObjectSupport，初始化时会自动调用模板方法initApplicationContext；AbstractHandlerMapping的创建也就是在这个方法里面完成的。同时实现了HandlerMapping和Ordered接口，这也就是上面提到的支持排序的原因。 2.AbstractHandlerMapping属性分析 排序值 order 默认值为Integer的最大值，后面注释的意思是和没有排序是一样的，因为只有理论上才可能超过Integer.MAX_VALUE。 1private int order = Integer.MAX_VALUE; // default: same as non-Ordered 默认处理器 defaultHandler 1private Object defaultHandler; Spring工具类 urlPathHelper Helper类用于URL路径匹配。提供对RequestDispatcher中URL路径的支持，包括并支持一致的URL解码。 1private UrlPathHelper urlPathHelper = new UrlPathHelper(); spring工具类 PathMatcher(AntPathMatcher) 用于基于字符串的路径匹配的策略接口。 1private PathMatcher pathMatcher = new AntPathMatcher(); 拦截器列表 interceptors 用于配置SpringMVC的拦截器，配置方式由两种： 1.注册HandlerMapping时通过属性设置 2.通过子类的extendInterceptors钩子方法进行设置（extendInterceptors方法是在initApplicationContext中调用的） interceptors并不会直接使用，二是通过initInterceptors方法按照类型分配到mappedInterceptors和adaptedInterceptors中进行使用，interceptors只用于配置。 1private final List&lt;Object&gt; interceptors = new ArrayList&lt;Object&gt;(); adaptedInterceptors 被分配到adaptedInterceptors中的类型的拦截器不需要进行匹配，在getHandler中会全部添加到返回值HandlerExecutionChain里面。他 只能从 interceptors中获取。 1private final List&lt;HandlerInterceptor&gt; adaptedInterceptors = new ArrayList&lt;HandlerInterceptor&gt;(); corsProcessor CorsProcessor作用是接受请求和CorsConfiguration并更新响应的策略。 此组件不关心如何选择CorsConfiguration，而是采取后续操作，例如应用CORS验证检查，并拒绝响应或将CORS头添加到响应中。 1private CorsProcessor corsProcessor = new DefaultCorsProcessor(); corsConfigSource 根据路径模式上映射的CorsConfiguration集合提供每个请求的CorsConfiguration实例。支持精确的路径映射URI（如“/ admin”）以及Ant样式的路径模式（如“/ admin / **”） 12private final UrlBasedCorsConfigurationSource corsConfigSource = new UrlBasedCorsConfigurationSource(); 跨域相关问题 CorsConfiguration 具体封装跨域配置信息的pojoCorsConfigurationSource request与跨域配置信息映射的容器CorsProcessor 具体进行跨域操作的类 3.AbstractHandlerMapping 中的get&amp;set方法3.1 setOrder指定此HandlerMapping bean的排序值。123public final void setOrder(int order) &#123; this.order = order;&#125; 3.2 setDefaultHandler指定此HandlerMapping bean的排序值。设置此处理程序映射的默认处理程序。如果没有找到特定的映射，这个处理程序将被返回。缺省值为null，表示没有默认处理程序。123public void setDefaultHandler(Object defaultHandler) &#123; this.defaultHandler = defaultHandler;&#125; 3.3 getDefaultHandler返回此处理程序映射的默认处理程序，如果没有，则返回null。123public Object getDefaultHandler() &#123; return this.defaultHandler;&#125; 3.4 setAlwaysUseFullPath如果URL查找始终使用当前servlet上下文中的完整路径，请进行设置。 否则，如果适用，则使用当前servlet映射中的路径（即，在web.xml中“… / *”servlet映射的情况下）。默认是“false”。setAlwaysUseFullPath中的实现具体是委托给urlPathHelper和corsConfigSource来完成的。1234public void setAlwaysUseFullPath(boolean alwaysUseFullPath) &#123; this.urlPathHelper.setAlwaysUseFullPath(alwaysUseFullPath); this.corsConfigSource.setAlwaysUseFullPath(alwaysUseFullPath);&#125; 3.5 setUrlDecode如果上下文路径和请求URI应该被URL解码，则设置。两者都是由Servlet API返回“undecoded”，与servlet路径相反。根据Servlet规范（ISO-8859-1）使用请求编码或默认编码。setUrlDecode中的实现具体是委托给urlPathHelper和corsConfigSource来完成的。1234public void setUrlDecode(boolean urlDecode) &#123; this.urlPathHelper.setUrlDecode(urlDecode); this.corsConfigSource.setUrlDecode(urlDecode);&#125; 3.6 setRemoveSemicolonContent如果“;” （分号）内容应该从请求URI中去除,则设置。默认值是true。setRemoveSemicolonContent中的实现具体是委托给urlPathHelper和corsConfigSource来完成的。1234public void setRemoveSemicolonContent(boolean removeSemicolonContent) &#123; this.urlPathHelper.setRemoveSemicolonContent(removeSemicolonContent); this.corsConfigSource.setRemoveSemicolonContent(removeSemicolonContent);&#125; 3.7 setUrlPathHelper设置UrlPathHelper以用于解析查找路径。使用它可以用自定义子类覆盖默认的UrlPathHelper，或者跨多个HandlerMappings和MethodNameResolvers共享通用的UrlPathHelper设置。12345public void setUrlPathHelper(UrlPathHelper urlPathHelper) &#123; Assert.notNull(urlPathHelper, &quot;UrlPathHelper must not be null&quot;); this.urlPathHelper = urlPathHelper; this.corsConfigSource.setUrlPathHelper(urlPathHelper);&#125; 3.8 getUrlPathHelper返回UrlPathHelper实现以用于解析查找路径。123public UrlPathHelper getUrlPathHelper() &#123; return urlPathHelper;&#125; 3.9 setPathMatcher将PathMatcher实现设置为用于匹配注册的URL模式的URL路径。 默认是AntPathMatcher。12345public void setPathMatcher(PathMatcher pathMatcher) &#123; Assert.notNull(pathMatcher, &quot;PathMatcher must not be null&quot;); this.pathMatcher = pathMatcher; this.corsConfigSource.setPathMatcher(pathMatcher);&#125; 3.10 setInterceptors设置拦截器以应用此处理程序映射映射的所有处理程序。支持的拦截器类型是HandlerInterceptor，WebRequestInterceptor和MappedInterceptor。映射拦截器仅适用于请求与其路径模式相匹配的URL。映射的拦截器Bean在初始化期间也会按类型检测到。123ublic void setInterceptors(Object... interceptors) &#123; this.interceptors.addAll(Arrays.asList(interceptors));&#125; 其他几个get&amp;set方法就不列出来了，有兴趣的小伙伴可以自行阅读... 4. AbstractHandlerMapping的创建因为AbstractHandlerMapping继承了WebApplicationObjectSupport类，因此AbstractHandlerMapping的创建就是依托于模板方法initApplicationContext来完成的。123456@Overrideprotected void initApplicationContext() throws BeansException &#123; extendInterceptors(this.interceptors); detectMappedInterceptors(this.adaptedInterceptors); initInterceptors();&#125; 从方法结构可以了解到，initApplicationContext中包括三个子处理方法。 extendInterceptors：这也是一个模板方法，在AbstractHandlerMapping中并没有具体实现（方法体是空的），主要是用于给子类提供一个添加（修改）Interceptors的入口（现有的SpringMVC实现中均未使用）。 detectMappedInterceptors：用于将SpringMVC容器及父容器中的所有MappedInterceptor类型的Bean添加到MappedInterceptors属性中。 检测MappedInterceptor类型的bean，并将它们添加到映射的拦截器列表中。 除了可能通过setInterceptors提供的任何MappedInterceptors之外，还会调用此方法，默认情况下将从当前上下文及其祖先中添加所有MappedInterceptor类型的Bean。子类可以覆盖和优化这个策略。 12345protected void detectMappedInterceptors(List&lt;HandlerInterceptor&gt; mappedInterceptors) &#123; mappedInterceptors.addAll( BeanFactoryUtils.beansOfTypeIncludingAncestors( getApplicationContext(), MappedInterceptor.class, true, false).values());&#125; initInterceptors：初始化指定的拦截器，检查MappedInterceptors并根据需要调整HandlerInterceptors和WebRequestInterceptors。（当前Spring版本时4.3.6） 1234567891011protected void initInterceptors() &#123; if (!this.interceptors.isEmpty()) &#123; for (int i = 0; i &lt; this.interceptors.size(); i++) &#123; Object interceptor = this.interceptors.get(i); if (interceptor == null) &#123; throw new IllegalArgumentException(&quot;Entry number &quot; + i + &quot; in interceptors array is null&quot;); &#125; this.adaptedInterceptors.add(adaptInterceptor(interceptor)); &#125; &#125;&#125; 这个是4.1.5版本的initInterceptors方法： 12345678910111213141516protected void initInterceptors() &#123; if (!this.interceptors.isEmpty()) &#123; for (int i = 0; i &lt; this.interceptors.size(); i++) &#123; Object interceptor = this.interceptors.get(i); if (interceptor == null) &#123; throw new IllegalArgumentException(&quot;Entry number &quot; + i + &quot; in interceptors array is null&quot;); &#125; if (interceptor instanceof MappedInterceptor) &#123; this.mappedInterceptors.add((MappedInterceptor) interceptor); &#125; else &#123; this.adaptedInterceptors.add(adaptInterceptor(interceptor)); &#125; &#125; &#125; &#125; 在4.1.5中版本中，initInterceptors的工作是将interceptors属性里面所包含的对象按照类型添加到adaptedInterceptors或者mappedInterceptors中。在4.1.5版本中mappedInterceptors是AbstractHandlerMapping的属性之一。主要原因是因为，springMVC自4.2开始添加了跨域的支持，也就是上面属性中的后两个。PS：在阅读Spring相关源码时需要关注不同版本的变更及区别，不要只关注某一个版本，另外就是个人觉得阅读源码的关注点应该在编码方式、设计模式使用、设计思想及理念，而不仅仅是知道他是如何实现的】 这里顺便说下mappedInterceptors的作用：mappedInterceptors中的拦截器在使用时需要与请求的url进行匹配，只有匹配成功后才会添加到getHandler的返回值HandlerExecytionChain里。 adaptInterceptor方法: 使给定的拦截器对象适配HandlerInterceptor接口。默认情况下，支持的拦截器类型是HandlerInterceptor和WebRequestInterceptor。每个给定的WebRequestInterceptor将被封装在WebRequestHandlerInterceptorAdapter中。可以在子类中重写。1234567891011protected HandlerInterceptor adaptInterceptor(Object interceptor) &#123; if (interceptor instanceof HandlerInterceptor) &#123; return (HandlerInterceptor) interceptor; &#125; else if (interceptor instanceof WebRequestInterceptor) &#123; return new WebRequestHandlerInterceptorAdapter((WebRequestInterceptor) interceptor); &#125; else &#123; throw new IllegalArgumentException(&quot;Interceptor type not supported: &quot; + interceptor.getClass().getName()); &#125;&#125; 5.Handler和Interceptor的获取HandlerMapping是通过getHandler方法来获取Handler和Interceptor的。因此在抽象基类AbstractHandlerMapping中提供了具体的实现。并且在AbstractHandlerMapping中，getHandler使用final关键字修饰的，也就是说，子类不能再进行对此方法进行覆盖重写了。 getHandler的作用就是查找给定请求的handler，如果找不到特定请求，则返回到默认handler。123456789101112131415161718192021222324252627282930@Overridepublic final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception &#123; //通过getHandlerInternal方法来获取handler Object handler = getHandlerInternal(request); //如果前一个方法没有获取到，则使用默认的handler if (handler == null) &#123; //默认的Handler就是AbstractHandlerMapping中的handler属性通过set得到的值 handler = getDefaultHandler(); &#125; //如果还是没有找到Hander，则直接返回Null if (handler == null) &#123; return null; &#125; // Bean name or resolved handler? //如果找到的handler是String类型的， if (handler instanceof String) &#123; //则以它为名到spring Mvc的容器中查找相应的Bean String handlerName = (String) handler; handler = getApplicationContext().getBean(handlerName); &#125; //先根据handler和request创建一个HandlerExecutionChain对象， HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); if (CorsUtils.isCorsRequest(request)) &#123; CorsConfiguration globalConfig = this.corsConfigSource.getCorsConfiguration(request); CorsConfiguration handlerConfig = getCorsConfiguration(handler, request); CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig); executionChain = getCorsHandlerExecutionChain(request, executionChain, config); &#125; return executionChain;&#125; getHandlerInternal： 1protected abstract Object getHandlerInternal(HttpServletRequest request) throws Exception; 查找给定请求的handler，如果找不到特定请求，则返回null。 这个方法被getHandler调用; 如果设置了null返回值，将导致默认handler。在CORS pre-flight请求上，这个方法应该返回一个不匹配飞行前请求的匹配项，而是根据URL路径，“Access-Control-Request-Method”头中的HTTP方法和头文件 从“Access-Control-Request-Headers”头部获得，从而允许CORS配置通过getCorsConfigurations获得，注意：这个方法也可以返回一个预先构建的HandlerExecutionChain，将一个处理程序对象与动态确定的拦截器组合在一起。状态指定的拦截器将被合并到这个现有的链中。 getHandlerExecutionChain： getLookupPathForRequest:返回给定请求的映射查找路径，如果适用的话，在当前的servlet映射中，或者在web应用程序中返回。如果在RequestDispatcher中调用include请求，则检测包含请求URL。1234567891011121314151617181920212223protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) &#123; //如果handler是HandlerExecutionChain类型则直接强转为HandlerExecutionChain类型， //如果不是则根据handler创建一个新的HandlerExecutionChain实例对象 HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler)); //返回给定请求的映射查找路径 String lookupPath = this.urlPathHelper.getLookupPathForRequest(request); //遍历当前adaptedInterceptors链表 for (HandlerInterceptor interceptor : this.adaptedInterceptors) &#123; //如果是MappedInterceptor类型则 if (interceptor instanceof MappedInterceptor) &#123; MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor; //拦截器是否应用于给定的请求路径，如果是则返回true if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) &#123; chain.addInterceptor(mappedInterceptor.getInterceptor()); &#125; &#125; else &#123; chain.addInterceptor(interceptor); &#125; &#125; return chain;&#125; 为给定的handler构建一个HandlerExecutionChain，包括可用的拦截器。默认实现用给定的handler，handler映射的通用拦截器以及与当前请求URL相匹配的任何MappedInterceptors构建标准的HandlerExecutionChain。拦截器按照他们注册的顺序添加。为了扩展/重新排列拦截器列表，子类可以覆盖它。 需要注意的是，传入的handler对象可能是原始handler或预构建的HandlerExecutionChain。这个方法应该明确地处理这两种情况，建立一个新的HandlerExecutionChain或者扩展现有的链。为了简单地在自定义子类中添加拦截器，可以考虑调用super.getHandlerExecutionChain（handler，request）并在返回的链对象上调用HandlerExecutionChain＃addInterceptor。 getCorsHandlerExecutionChain： 1234567891011121314protected HandlerExecutionChain getCorsHandlerExecutionChain(HttpServletRequest request, HandlerExecutionChain chain, CorsConfiguration config) &#123; //通过请求头的http方法是否options判断是否预请求， if (CorsUtils.isPreFlightRequest(request)) &#123; HandlerInterceptor[] interceptors = chain.getInterceptors(); //如果是使用PreFlightRequest替换处理器 chain = new HandlerExecutionChain(new PreFlightHandler(config), interceptors); &#125; else &#123; //如果是普通请求，添加一个拦截器CorsInterceptor。 chain.addInterceptor(new CorsInterceptor(config)); &#125; return chain;&#125; 更新HandlerExecutionChain进行与CORS（HTTP访问控制：跨域资源共享）相关的处理。 对于pre-flight请求，默认实现用一个简单的HttpRequestHandler来替换选择的handler，该HttpRequestHandler调用已配置的setCorsProcessor。（将处理器替换为内部类PreFlightHandler） 对于普通的请求，默认实现插入一个HandlerInterceptor，它执行与CORS有关的检查并添加CORS头。（添加CorsInterceptor拦截器） AbstractHandlerMapping中的两个内部类这两个内部类就是用来校验request是否cors，并封装对应的Adapter的。 PreFlightRequest是CorsProcessor对于HttpRequestHandler的一个适配器。这样HandlerAdapter直接使用HttpRequestHandlerAdapter处理。 CorsInterceptor 是CorsProcessor对于HandlerInterceptorAdapter的适配器。 具体的类信息如下： PreFlightHandler123456789101112131415161718private class PreFlightHandler implements HttpRequestHandler, CorsConfigurationSource &#123; private final CorsConfiguration config; public PreFlightHandler(CorsConfiguration config) &#123; this.config = config; &#125; @Override public void handleRequest(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; corsProcessor.processRequest(this.config, request, response); &#125; @Override public CorsConfiguration getCorsConfiguration(HttpServletRequest request) &#123; return this.config; &#125;&#125; CorsInterceptor1234567891011121314151617181920private class CorsInterceptor extends HandlerInterceptorAdapter implements CorsConfigurationSource &#123; private final CorsConfiguration config; public CorsInterceptor(CorsConfiguration config) &#123; this.config = config; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return corsProcessor.processRequest(this.config, request, response); &#125; @Override public CorsConfiguration getCorsConfiguration(HttpServletRequest request) &#123; return this.config; &#125;&#125; 至此AbstractHandlerMapping中的一些源码就结束了，AbstractHandlerMapping为HandlerMapping的功能提供的一些具体的模板描述，但是具体的细节实现还需要从其子类中来慢慢分析。关于这部分中涉及到的如HandlerExecutionChain，cors跨域等问题，后面会根据实际情况另开篇幅来学习。 大家如果有什么意见或者建议可以在下方评论区留言，也可以给我们发邮件（glmapper_2018@163.com）!欢迎小伙伴与我们一起交流，一起成长。]]></content>
      <categories>
        <category>spring mvc</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>web</tag>
        <tag>mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC源码系列：HandlerMapping]]></title>
    <url>%2F2018%2F11%2F10%2Fspring-base-webmvc1%2F</url>
    <content type="text"><![CDATA[HandlerMapping接口是用来查找Handler的。在SpringMvc中，DispatcherServlet处理分发很多请求，而每个请求都需要一个Handler来处理，具体接受到一个请求后使用哪个Handler来处理呢？这就是Handler要做的事情。因此，HandlerMapping的作用就是根据request找到相应的处理器Handler和Interceptors。 下面是Spring中对HandlerMapping接口的说明： This class can be implemented by application developers, although this is not necessary, as BeanNameUrlHandlerMapping and DefaultAnnotationHandlerMapping are included in the framework. The former is the default if no HandlerMapping bean is registered in the application context.这个类可以由应用程序开发人员实现，尽管这不是必须的，因为BeanNameUrlHandlerMapping和DefaultAnnotationHandlerMapping已经包含在框架中，作为HandlerMapping的默认实现。 如果在应用程序上下文中没有注册HandlerMapping bean，BeanNameUrlHandlerMapping是默认值。 HandlerMapping implementations can support mapped interceptors but do not have to. A handler will always be wrapped in a HandlerExecutionChain instance, optionally accompanied by some HandlerInterceptor instances.The DispatcherServlet will first call each HandlerInterceptor&#39;s preHandle method in the given order, finally invoking the handler itself if all preHandle methods have returned trueHandlerMapping实现可以支持映射的拦截器，但不必如此；handler将始终被封装在HandlerExecutionChain实例中，并可由一些HandlerInterceptor实例执行。在给定的顺序中，DispatcherServlet将首先调用每个HandlerInterceptor的preHandle方法，如果所有的preHandle方法都返回true，那么最后调用handler本身。 The ability to parameterize this mapping is a powerful and unusual capability of this MVC framework. For example, it is possible to write a custom mapping based on session state, cookie state or many other variables. No other MVC framework seems to be equally flexible.参数化这个映射的能力是这个MVC框架的一个强大且不同寻常的能力。 例如，可以根据会话状态，cookie状态或许多其他变量编写自定义映射。 没有其他MVC框架似乎同样灵活。 Note: Implementations can implement the Ordered interface to be able to specify a sorting order and thus a priority for getting applied by DispatcherServlet. Non-Ordered instances get treated as lowest priority.注：实现可以实现Ordered接口，以便能够指定排序顺序，从而指定由DispatcherServlet应用的优先级。 无序实例被视为最低优先级。 1.接口常量1.1、PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTEHttpServletRequest属性的名称，它包含处理程序映射中的路径，比如模式匹配，或者完全相关的URI(通常在DispatcherServlet的映射中)。此属性不需要所有HandlerMapping实现支持。基于url的HandlerMappings通常会支持它，但是处理程序不应该期望这个请求属性在所有场景中都存在。12345678910/** * Name of the &#123;@link HttpServletRequest&#125; attribute that contains the path * within the handler mapping, in case of a pattern match, or the full * relevant URI (typically within the DispatcherServlet&apos;s mapping) else. * &lt;p&gt;Note: This attribute is not required to be supported by all * HandlerMapping implementations. URL-based HandlerMappings will * typically support it, but handlers should not necessarily expect * this request attribute to be present in all scenarios. */String PATH_WITHIN_HANDLER_MAPPING_ATTRIBUTE = HandlerMapping.class.getName() + &quot;.pathWithinHandlerMapping&quot;; 1.2、BEST_MATCHING_PATTERN_ATTRIBUTEHttpServletRequest属性的名称，包括处理程序映射中的最佳匹配模式123456789/** * Name of the &#123;@link HttpServletRequest&#125; attribute that contains the * best matching pattern within the handler mapping. * &lt;p&gt;Note: This attribute is not required to be supported by all * HandlerMapping implementations. URL-based HandlerMappings will * typically support it, but handlers should not necessarily expect * this request attribute to be present in all scenarios. */String BEST_MATCHING_PATTERN_ATTRIBUTE = HandlerMapping.class.getName() + &quot;.bestMatchingPattern&quot;; 1.3、INTROSPECT_TYPE_LEVEL_MAPPINGHttpServletRequest属性的名称，指示是否应该检查类型级别的映射。 1234567/** * Name of the boolean &#123;@link HttpServletRequest&#125; attribute that indicates * whether type-level mappings should be inspected. * &lt;p&gt;Note: This attribute is not required to be supported by all * HandlerMapping implementations. */String INTROSPECT_TYPE_LEVEL_MAPPING = HandlerMapping.class.getName() + &quot;.introspectTypeLevelMapping&quot;; 1.4、URI_TEMPLATE_VARIABLES_ATTRIBUTE包含URI模板映射的HttpServletRequest属性的名称，将变量名称映射到值。123456789/** * Name of the &#123;@link HttpServletRequest&#125; attribute that contains the URI * templates map, mapping variable names to values. * &lt;p&gt;Note: This attribute is not required to be supported by all * HandlerMapping implementations. URL-based HandlerMappings will * typically support it, but handlers should not necessarily expect * this request attribute to be present in all scenarios. */String URI_TEMPLATE_VARIABLES_ATTRIBUTE = HandlerMapping.class.getName() + &quot;.uriTemplateVariables&quot;; 1.5、MATRIX_VARIABLES_ATTRIBUTE包含带有URI矩阵变量的映射的HttpServletRequest属性的名称。此属性不需要所有HandlerMapping实现支持，也可能不存在，这取决于HandlerMapping是否被配置为在请求URI中保留矩阵变量内容。 123456789/** * Name of the &#123;@link HttpServletRequest&#125; attribute that contains a map with * URI matrix variables. * &lt;p&gt;Note: This attribute is not required to be supported by all * HandlerMapping implementations and may also not be present depending on * whether the HandlerMapping is configured to keep matrix variable content * in the request URI. */String MATRIX_VARIABLES_ATTRIBUTE = HandlerMapping.class.getName() + &quot;.matrixVariables&quot;; 1.6、PRODUCIBLE_MEDIA_TYPES_ATTRIBUTEHttpServletRequest属性的名称，该属性包含可用于映射处理程序的可生成的MediaTypes集合。 12345678/** * Name of the &#123;@link HttpServletRequest&#125; attribute that contains the set of * producible MediaTypes applicable to the mapped handler. * &lt;p&gt;Note: This attribute is not required to be supported by all * HandlerMapping implementations. Handlers should not necessarily expect * this request attribute to be present in all scenarios. */String PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE = HandlerMapping.class.getName() + &quot;.producibleMediaTypes&quot;; 2.核心方法HandlerMapping接口中只有一个方法，如下：1HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception; 从方法定义可以看出，getHandler方法就是通过request来获取一个HandlerExecutionChain；该方法在不同的子类中都有实现，具体的实现后面说子类的时候在详细分析。 3.HandlerMapping的子类图中黄色部分表示已经过时的类，时间开发中不建议再使用。 在HandlerMapping的体系中可以看出，HandlerMapping下属子类可分为两个分支； AbstractHandlerMethodMapping AbstractUrlHandlerMapping 上述两个抽象类又均是AbstractHandlerMapping的子类。关于AbstractHandlerMapping我们下篇文章来学习。 大家如果有什么意见或者建议可以在下方评论区留言，也可以给我们发邮件（glmapper_2018@163.com）!欢迎小伙伴与我们一起交流，一起成长。]]></content>
      <categories>
        <category>spring mvc</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>web</tag>
        <tag>mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-Builder 建造者模式]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-design-model-builder%2F</url>
    <content type="text"><![CDATA[菜鸟成长系列-面向对象的四大基础特性菜鸟成长系列-多态、接口和抽象类菜鸟成长系列-面向对象的6种设计原则菜鸟成长系列-单例模式菜鸟成长系列-工厂模式 建造者模式也是创建型中的一种，用于负责创建对象。建造者模式可以将一个产品的内部表象与产品的生成过程分割开来，从而可以使一个建造过程生成具有不同的内部表象的产品对象。 什么是产品的内部表象？一个产品常有不用的组成成分作为产品的零件，这些零件有可能是对象，也有可能不是对象，他们通常又叫做产品的内部表象。不同的产品可以有不同的内部表象，也就是可以有不同的零件。使用建造者模式可以使客户端不需要知道所生成的产品对象有哪些零件，每个产品的对应零件彼此有何不同，是怎么建造出来的，以及怎样组成产品。 工厂模式与建造者模式上一篇我们讨论了工厂模式，我们知道工厂模式一般都是创建一个产品，注重的是把这个产品创建出来就行，只要创建出来，不关心这个产品的组成部分。从代码上看，工厂模式就是一个方法，用这个方法就能生产出产品。那么对于建造者模式呢？建造者模式也是创建一个产品，但是不仅要把这个产品创建出来，还要关系这个产品的组成细节， 组成过程。从代码上看（下面给出），建造者模式在建造产品时，这个产品有很多方法，建造者模式会根据这些相同方法但是不同执行顺序建造出不同组成细节的产品。 建造者模式的结构结构组件角色说明： 抽象建造者（Builder）:抽象类， 规范产品的组建，一般是由子类实现具体的组件过程 具体建造者（ConcreteBuilder ）：具体的构建器 导演者（Director） : 统一组装过程(可省略) 产品（Product）:产品的抽象类 Director角色是与客户端打交道的角色。Director将客户端创建产品的请求划分为对各个零件的建造请求，再将这些请求委派给具体的ConcreteBuilder角色。ConcreteBuilder是做具体建造工作的，但是对客户端是透明的。 一般来说，每有一个产品类，就有一个相应的具体建造者类。这些产品应当有一样数目的零件，而每有一个零件就相应的在所有的建造者角色里有一个建造方法。 建造一封邮件通过代码来看下各个角色的职责： Director 123456789101112131415161718192021222324package com.glmapper.model.builder;/** * * 导演者类 * @author glmapper * @time 2017年12月30日上午11:33:26 * @version glmapper_v1.0 * */public class Director &#123; private Builder builder; /** * 产品构造方法，负责调用各个零件建造方法 */ public EmailProduct construct()&#123; builder = new ConcreteBuilder(); builder.buildFromAddress(); builder.buildToAddress(); builder.buildSubject(); builder.buildContent(); builder.buildSupplement(); return builder.returnEmailProduct(); &#125;&#125; Builder 1234567891011121314151617181920212223242526272829303132333435package com.glmapper.model.builder;/** * 抽象建造者 提供不同的构建组件方法 * @author glmapper * @time 2017年12月30日上午11:31:34 * @version glmapper_v1.0 * */public interface Builder &#123; /** * 构建发件人信息 */ public void buildFromAddress(); /** * 构建收件人信息 */ public void buildToAddress(); /** * 构建邮件内容 */ public void buildContent(); /** * 构建邮件附件 */ public void buildSupplement(); /** * 构建邮件主题 */ public void buildSubject(); /** * 返回构建的产品 */ public EmailProduct returnEmailProduct(); &#125; ConcreteBuilder 1234567891011121314151617181920212223242526272829303132333435363738package com.glmapper.model.builder;/** * * 具体产品的建造器 * @author glmapper * @time 2017年12月30日上午11:31:11 * @version glmapper_v1.0 * */public class ConcreteBuilder implements Builder&#123; private EmailProduct emailProduct = new EmailProduct(); public void buildFromAddress() &#123; emailProduct.setFromAddress(&quot;00001111@glmapper.com&quot;); &#125; public void buildToAddress() &#123; emailProduct.setToAddress(&quot;00001112@glmapper.com&quot;); &#125; public void buildContent() &#123; emailProduct.setContent(&quot;我写了一个建造者模式的例子，希望大佬给点意见&quot;); &#125; public void buildSupplement() &#123; emailProduct.setSupplement(&quot;附件：BuilderDemo.rar&quot;); &#125; public void buildSubject() &#123; emailProduct.setSubject(&quot;给大佬的一封建造者模式的Demo&quot;); &#125; public EmailProduct returnEmailProduct() &#123; System.out.println(emailProduct.toString()); return emailProduct; &#125;&#125; Product 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.glmapper.model.builder;/** * 产品类（产品类中包括不同组件：此处使用字段方式模式组件） * @author glmapper * @time 2017年12月30日上午11:30:13 * @version glmapper_v1.0 * */public class EmailProduct &#123; /** * 发件地址 */ private String fromAddress; /** * 收件地址 */ private String toAddress; /** * 邮件主题 */ private String subject; /** * 邮件内容 */ private String content; /** * 邮件附件 */ private String supplement; public String getFromAddress() &#123; return fromAddress; &#125; public void setFromAddress(String fromAddress) &#123; this.fromAddress = fromAddress; &#125; public String getToAddress() &#123; return toAddress; &#125; public void setToAddress(String toAddress) &#123; this.toAddress = toAddress; &#125; public String getSubject() &#123; return subject; &#125; public void setSubject(String subject) &#123; this.subject = subject; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public String getSupplement() &#123; return supplement; &#125; public void setSupplement(String supplement) &#123; this.supplement = supplement; &#125; @Override public String toString() &#123; return &quot;EmailProduct [fromAddress=&quot; + fromAddress + &quot;, toAddress=&quot; + toAddress + &quot;, subject=&quot; + subject + &quot;, content=&quot; + content + &quot;, supplement=&quot; + supplement + &quot;]&quot;; &#125;&#125; 客户端 12345678910111213package com.glmapper.model.builder;/** * 客户端 * @author glmapper * @time 2017年12月30日上午11:45:53 * @version glmapper_v1.0 * */public class MainTest &#123; public static void main(String[] args) &#123; new Director().construct(); &#125;&#125; 结果 1234567891011121314建造发件人信息组件...建造收件人信息组件...建造邮件主题信息组件...建造邮件内容信息组件...建造邮件附件信息组件...（为了方便看，这里把结果的显示做了调整）EmailProduct ：[ fromAddress=00001111@glmapper.com, toAddress=00001112@glmapper.com, subject=给大佬的一封建造者模式的Demo, content=我写了一个建造者模式的例子，希望大佬给点意见, supplement=附件：BuilderDemo.rar] 建造者模式的关注点有些情况下，一个对象会有一些重要的性质，在他们没有恰当的值之前，对象不能作为一个完整的产品来使用。就如上面发送一个电子邮件所示，电子邮件有发件人地址、收件人地址、主题、内容、附录等部分，而在收件人地址没有赋值之前，这个电子邮件是不能发送的。在某些情况下，一个对象的一些性质必须按照某个顺序赋值才有意义，在某个性质没有赋值之前，另一个性质则无法赋值。这些情况使得性质本身的建造涉及到复杂的业务逻辑。 而此时，对象相当于一个有待建造的产品，而对象的这些性质相当于产品的零件，建造产品的过程是建造零件的过程。由于建造零件的过程很复杂，因此，这些零件的健在过程往往会被“外部化”到另一个称作为建造者的对象里，建造者对象返回给客户端的是一个全部零件都建造完毕的产品对象。 在实际的应用过程中，建造者模式也有不同的变种，比如说省略抽象建造者角色或者省略导演者角色等等，在某些情况下，建造者模式可以通过省略某些角色来达到过度到模板方法模式。 OK，关于建造者模式的其他变种这里就不讨论了，留一个想象空间！（这段字代表一个微笑的表情(*￣︶￣)） java中建造者模式：JavaMailJavaMail是一组J2SE的扩展API的一个类库，我们可以使用这个API来开发一个功能完备的电子邮件客户端软件。在JavaMail中就主要使用了建造者模式，当然还有我们上一篇中说道的抽象工厂模式。 建造者模式在JavaMail中的使用1234567891011121314151617181920212223242526272829303132333435363738394041package com.glmapper.model.builder;import java.util.Properties;import javax.mail.Message;import javax.mail.Session;import javax.mail.Transport;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeMessage;/** * 邮件发送-建造者模式 * @author glmapper * @time 2017年12月30日下午2:04:46 * @version glmapper_v1.0 * */public class MailSender &#123; private static MimeMessage message; public static void main(String[] args) &#123; //基本属性 String smptHost = &quot;smpt.xxx.com&quot;; String fromAddress = &quot;00001111@glmapper.com&quot;; String toAddress = &quot;00001112@glmapper.com&quot;; Properties p= new Properties(); p.put(&quot;mail.smtp.host&quot;, smptHost); Session session = Session.getDefaultInstance(p); try &#123; InternetAddress to = new InternetAddress(toAddress); InternetAddress from = new InternetAddress(fromAddress); //创建message对象 message = new MimeMessage(session); //下面就是组装零件的过程 message.setFrom(from); message.setRecipient(Message.RecipientType.TO, to); message.setSubject(&quot;hello builder&quot;); message.setText(&quot;我写了一个建造者模式的例子，希望大佬给点意见&quot;); Transport.send(message); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; OK,建造者模式就到这里了!]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列-容器刷新]]></title>
    <url>%2F2018%2F11%2F10%2Fspring-base-context-refresh%2F</url>
    <content type="text"><![CDATA[Spring对于程序员说来说都不陌生；作为一个强大的开源技术，帮助我们能够更好的进行项目的开发与维护。 上次在Spring的启动过程文章中对Spring的启动过程做了一个较为详细的说明和分析。那么在实际的过程中，Spring的启动实际上就是Spring容器的初始化过程。本文将从源码的角度结合自己断点执行过程中保留的现场来分析一下容器的刷新过程（主要分析前几个方法，后面几个会分开来说）。 Spring的启动是通过ContextLoaderListener来进行的，在ContextLoaderListener中通过委托父类ContextLoader的initWebApplicationContext来完成具体的初始化过程。具体的启动过程可以看下之前的那篇文章。 在initWebApplicationContext方法是用来创建容器的，核心代码如下： 今天主要来看configureAndRefreshWebApplicationContext方法中最后的wac.refresh()到底发生了哪些事; 1、obtainFreshBeanFactory：BeanFactory的刷新和创建refresh()方法主要为IoC容器Bean的生命周期管理提供条件，Spring IoC容器载入Bean定义资源文件从其子类容器的refreshBeanFactory()方法启动，所以整个refresh()中“ConfigurableListableBeanFactory beanFactory =obtainFreshBeanFactory();”这句以后代码的都是注册容器的信息源和生命周期事件，载入过程就是从这句代码启动。AbstractApplicationContext的obtainFreshBeanFactory()方法调用子类容器的refreshBeanFactory()方法，启动容器载入Bean定义资源文件的过程。refresh()方法的作用是：在创建IoC容器前，如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的IoC容器。refresh的作用类似于对IoC容器的重启，在新建立好的容器中对容器进行初始化，对Bean定义资源进行载入。和refreshBeanFactory方法类似，载入Bean定义的方法loadBeanDefinitions也使用了委派模式，在AbstractRefreshableApplicationContext类中只定义了抽象方法，具体的实现调用子类容器中的方法实现。 //通知子类去刷新内部bean 工厂 再来看refreshBeanFactory 此实现执行该上下文的底层bean工厂的实际刷新，关闭以前的bean工厂（如果有的话），并为上下文生命周期的下一阶段初始化一个新的bean工厂。 customizeBeanFactory(DefaultListableBeanFactory beanFactory) 1234567891011121314151617181920212223/** //通过当前上下文来自定义内部bean工厂&lt;br&gt; * Customize the internal bean factory used by this context. * Called for each &#123;@link #refresh()&#125; attempt. * &lt;p&gt;The default implementation applies this context&apos;s * &#123;@linkplain #setAllowBeanDefinitionOverriding &quot;allowBeanDefinitionOverriding&quot;&#125; * and &#123;@linkplain #setAllowCircularReferences &quot;allowCircularReferences&quot;&#125; settings, * if specified. Can be overridden in subclasses to customize any of * &#123;@link DefaultListableBeanFactory&#125;&apos;s settings. * @param beanFactory the newly created bean factory for this context * @see DefaultListableBeanFactory#setAllowBeanDefinitionOverriding * @see DefaultListableBeanFactory#setAllowCircularReferences * @see DefaultListableBeanFactory#setAllowRawInjectionDespiteWrapping * @see DefaultListableBeanFactory#setAllowEagerClassLoading */ protected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) &#123; if (this.allowBeanDefinitionOverriding != null) &#123; beanFactory.setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.allowCircularReferences != null) &#123; beanFactory.setAllowCircularReferences(this.allowCircularReferences); &#125; &#125; XmlWebApplicationContext类中loadBeanDefinitions（beanFactory）12345678910111213141516@Override protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context&apos;s // resource loading environment. beanDefinitionReader.setEnvironment(getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader); &#125; AbstractApplicationContext调用loadBeanDefinitions(DefaultListableBeanFactory beanFactory) ，此方法根据首先创建XmlBeanDefinitionReader对象，然后配置该对象的上下文和资源加载环境，同时调用子类实现的initBeanDefinitionReader对XmlBeanDefinitionReader进行个性化配置，最近后入到initBeanDefinitionReader(beanDefinitionReader)的调用： 据给定的BeanFactory创建XmlBeanDefinitionReader 对象 配置beanDefinitionReader的上下文和资源加载环境 用子类实现的initBeanDefinitionReader对XmlBeanDefinitionReader进行个性化配置initBeanDefinitionReader(beanDefinitionReader); 调用载入Bean定义的方法，在当前类中只定义了抽象的loadBeanDefinitions方法，具体的实现调用子类容器 装载bean定义通过XmlBeanDefinitionReader。 123456789101112// Create a new XmlBeanDefinitionReader for the given BeanFactory. 通过给定的bean工厂创建一个新的XmlBeanDefinitionReader1.XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);2.使用上下文的资源加载环境配置bean定义读取器。 beanDefinitionReader.setEnvironment(getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this));3.允许子类提供reader的自定义初始化，然后继续实际加载bean定义。 //通过制定的XmlBeanDefinitionReader来载入beandefinitionReader initBeanDefinitionReader(beanDefinitionReader) // 通过制定的XmlBeanDefinitionReader来载入bean definitions loadBeanDefinitions(beanDefinitionReader) AbstractApplicationContext调用loadBeanDefinitions(beanDefinitionReader)，这个方法是取得资源或资源路径然后通过传入的reader去加载BeanDefinitions。 2、loadBeanDefinitions目前使用Spring的配置都是基于XML的，因此使用XmlBeanDefinitionReader 中的loadBeanDefinitions方法。 看doLoadBeanDefinitions,这个就是具体的读取文件配置，然后注册成Bean 3、prepareBeanFactory配置工厂的标准上下文特性，如上下文的类装载器和后处理器。 告诉内部bean工厂使用上下文的类装入器等。 上下文回调配置bean工厂。 BeanFactory接口未登记为普通工厂的解析式。MessageSource登记（为自动装配创建）作为一个Bean 如果创建；就去寻找LoadTimeWeaver，然后准备组织 注册默认环境bean。 通过断点来看下当前的beanFactory 继续执行… beanDefinitionMap manualSingletonNames 4、postProcessBeanFactory注册web特性的全局域 1).registerWebApplicationScopes注册具有web特性的域；包括：”request”, “session”, “globalSession”, “application” 看下存储结构：registerScope方法2).registerEnvironmentBeans 注册web特性 环境bean（“contextparameters”、“ContextAttribute”）与给定的WebApplicationContext使用BeanFactory。 1.servletContext2.servletConfig3.registerSingleton 这里是找到了我们默认的配置文件参数：beanName=contextParameters 最后是将contextAttributes放入；contextAttributes中包含的属性值比较多，具体如下面所示： 主要包括：javax.servlet.context.tempdir,org.apache.catalina.resources, org.springframework.web.context.support.ServletContextScope, org.apache.tomcat.util.scan.MergedWebXml,org.apache.tomcat.InstanceManager,org.apache.catalina.jsp_classpath,javax.websocket.server.ServerContainer,org.apache.tomcat.JarScanner 这里是把需要的东西全部载入进来了，有很多。就不贴了(mime-mapping)…. 5、invokeBeanFactoryPostProcessorsBeanDefinitionRegistryPostProcessor实例化：标准BeanFactoryPostProcessor的扩展，BeanFactoryPostProcessor的作用是用来进一步定义注册的BeanDefinition，IoC容器本质就是Bean管理，所以BeanFactoryPostProcessor本身也是Bean，要对BeanFactoryPostProcessor的BeanDefinition进一步定义就通过BeanDefinitionRegistryPostProcessor进行注册，BeanDefinitionRegistryPostProcessor及其子类是Ioc容器最实例化的一类Bean。它们在ConfigurableApplicationContext（ApplicationContext子接口）实现类调用refresh()方法调用invokeBeanFactoryPostProcessors(beanFactory);方法时就被实例化。 OK，今天关于这部分的分析就到此结束了，后面的过程会在下一篇Spring系列文章中继续来讲refresh中的过程。 如果您对系列文章有任何意见，可以给我留言，感谢大家。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-工厂模式]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-design-model-factory%2F</url>
    <content type="text"><![CDATA[菜鸟成长系列-面向对象的四大基础特性菜鸟成长系列-多态、接口和抽象类菜鸟成长系列-面向对象的6种设计原则菜鸟成长系列-单例模式 上一篇我们已经对创建型模式中的单例模式进行了学习，今天来学习另外一个比较重要并且经常使用的模式-工厂模式；工厂模式专门负责将大量有共同接口的类实例化。其可以动态的决定将哪一个类实例化，不必事先知道每次要实例化哪一个类。 工厂模式具有以下三种形态： 简单工厂模式：又称静态工厂模式 工厂方法模式：又称多态性工厂模式或者虚拟构造子模式 抽象工厂模式：又称工具箱模式 本篇文章将对这三种形态的工厂模式进行一些基本的学习，并通过例子来直观的感受下不同形态的具体实现方式。最后再分析下JAVA以及Spring中是如何使用的。 1、简单工厂模式从上图可以看出，简单工厂模式涉及到工厂角色、抽象产品角色以及具体产品角色等三个角色。各角色职能如下： 工厂类：担任这个角色的是工厂方法模式的核心，含有与应用紧密相关的具体业务逻辑。工厂类在客户端的直接调用下创建产品对象，它往往由一个具体的java类实现 抽象产品：担任这个角色的类是工厂方法模式所创建的对象的父类，或它们共同拥有的接口。抽象产品角色可以用一个java接口或者抽象类来实现 具体产品：工厂方法模式所创建的任何对象都是这个角色的实例，具体产品角色由一个java类实现 来看例子，考虑到今天有小伙伴来我这做客，本demo将以做菜来实现一波。首先工厂就是厨房，抽象类就是笼统的菜，实现类就是具体哪个菜。 抽象产品 1234567891011121314package com.glmapper.design.factory;/** * 抽象类角色：food接口，约束类型 * @author glmapper * @date 2017年12月24日上午10:38:36 * */public interface IFood &#123; /** * 提供一个展示食物细节的方法 * @param foodName 食物名称 */ public void showFood();&#125; 具体产品-鱼 1234567891011121314package com.glmapper.design.factory;/** * 具体产品-食物鱼 * @author glmapper * @date 2017年12月24日上午10:51:29 * */public class FishFood implements IFood&#123; @Override public void showFood() &#123; System.out.println(&quot;一盘鱼&quot;); &#125;&#125; 具体产品-土豆丝 123456789101112131415package com.glmapper.design.factory;/** * * 具体食物：土豆丝 * @author glmapper * @date 2017年12月24日上午10:47:17 * */public class ShreddedPotatoesFood implements IFood&#123; @Override public void showFood() &#123; System.out.println(&quot;一盘土豆丝&quot;); &#125;&#125; 工厂角色 - 食物工厂 12345678910111213141516171819202122232425package com.glmapper.design.factory;/** * 工厂角色-食物工厂 * * @author glmapper * @date 2017年12月24日上午10:41:10 * */public class SimpleFoodFactory &#123; /** * 提供一个静态方法，用于获取食物 * @param foodType 食物类型 * @return 具体食物 */ public static IFood getFood(String foodType)&#123; IFood food = null; if (foodType.equals(&quot;fish&quot;)) &#123; food = new FishFood(); &#125; if (foodType.equals(&quot;potatoes&quot;)) &#123; food = new ShreddedPotatoesFood(); &#125; return food; &#125;&#125; 客户端 12345678910111213141516package com.glmapper.design.factory;/** * 客户端 * @author glmapper * @date 2017年12月24日上午10:45:17 * */public class MainTest &#123; public static void main(String[] args) &#123; IFood fishfood = SimpleFoodFactory.getFood(&quot;fish&quot;); fishfood.showFood(); IFood potatoesfood = SimpleFoodFactory.getFood(&quot;potatoes&quot;); potatoesfood.showFood(); &#125;&#125; 结果 12一盘鱼一盘土豆丝 OK，菜做完了，可以吃了。。。 我们来讨论下简单工厂模式的优缺点： 优点：模式的核心是工厂类，这个类含有必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例。而客户端则可以免除直接创建产品对象的责任，而仅仅负责消费产品即可。用一句话来说就是：简单工厂模式这个做法实现了对责任的分割。缺点：集中了所有产品的创建逻辑，形成了一个无所不能的全职类，但是之前我们在讨论设计原则的时候说过，我们要尽量避免这种情况的发生，这种就很明显破坏了单一职责这条原则，另外也不满足开闭原则的约束。当我们需要进行品类扩展时，我们需要不断的去修改我们的工厂的业务逻辑，一方面是工厂类会急速的膨胀，另一方面因为囊括了不同的产品对于我们后期的维护造成一定的影响。 2、工厂方法模式这个时候一个同事说他是南方人，另外一个同事说他是北方人，吃不惯今天的菜。 好吧，既然这样，那我就只能点外卖了。。。但是为了防止他们变卦自己的家乡，我需要做一个计划，下面就是计划图： 从上图中我们可以看出，工厂方法模式的角色包括以下几种： 抽象工厂：是工厂方法模式的核心，与应用程序无关。任何在模式中创建的对象的工厂类必须实现这个接口。 具体工厂：这是实现抽象工厂接口的具体工厂类，包含与应用程序密切相关的逻辑，并且受到应用程序调用以创建产品对象。 抽象产品：工厂方法模式所创建的对象的超类型，也就是产品对象的共同父类或共同拥有的接口 具体产品：这个角色实现了抽象产品角色所定义的接口。某具体产品有专门的具体工厂创建，它们之间往往一一对应。 因为我的同事都是来自不同地方的，他们的口味也都不一样，但是呢同事都是第一次来我家吃饭，所以为了招待周全，根据同事不同的口味叫不同口味的鱼。 抽象工厂角色：获取食物 1234567891011package com.glmapper.design.factory;/** * * 角色1：抽象工厂 - 负责获取食物 * @author glmapper * @date 2017年12月24日下午1:59:28 */public interface MethodFoodFactory &#123; //获取食物的方法 public IFishFood getFood();&#125; 具体工厂1：获取南方食物-鱼 123456789101112package com.glmapper.design.factory;/** * 南方口味外卖 - 鱼 * @author glmapper * @date 2017年12月24日下午2:03:36 */public class SouthFishFactory implements MethodFoodFactory&#123; @Override public IFishFood getFood() &#123; return new SouthFishFood(); &#125;&#125; 具体工厂2：获取北方食物-鱼 1234567891011121314package com.glmapper.design.factory;/** * 北方口味外卖 - 鱼 * @author glmapper * @date 2017年12月24日下午2:03:36 */public class NorthFishFactory implements MethodFoodFactory&#123; @Override public IFishFood getFood() &#123; // TODO Auto-generated method stub return new NorthFishFood(); &#125;&#125; 具体产品1：南方食物- 鱼 123456789101112package com.glmapper.design.factory;/** * 南方口味-鱼 * @author glmapper * @date 2017年12月24日下午2:16:17 */public class SouthFishFood implements IFishFood&#123; @Override public void showFood() &#123; System.out.println(&quot;来自南方厨师做的鱼&quot;); &#125;&#125; 具体产品2：北方食物-鱼 123456789101112package com.glmapper.design.factory;/** * 北方口味 - 鱼 * @author glmapper * @date 2017年12月24日下午2:12:55 */public class NorthFishFood implements IFishFood &#123; @Override public void showFood() &#123; System.out.println(&quot;来自北方厨师做的鱼&quot;); &#125;&#125; 客户端 123456789101112131415161718package com.glmapper.design.factory;/** * 客户端 * @author glmapper * @date 2017年12月24日上午10:45:17 */public class MainTest &#123; public static void main(String[] args) &#123; //点一个南方口味外卖 MethodFoodFactory southFoodFactory = new SouthFishFactory(); //点一个北方口味外卖 MethodFoodFactory northFoodFactory = new NorthFishFactory(); //拿到南方口味外卖鱼 southFoodFactory.getFood().showFood(); //拿到北方口味外卖鱼 northFoodFactory.getFood().showFood(); &#125;&#125; 结果：12来自南方厨师做的鱼来自北方厨师做的鱼 OK，这样我们就满足了不同区域同时关于鱼口味的需求了，以后升值加薪就指望他们了。。。 关于工厂方法模式的优缺点： 优点：1、 在工厂方法中，用户只需要知道所要产品的具体工厂，无须关系具体的创建过程，甚至不需要具体产品类的类名。2、 在系统增加新的产品时，我们只需要添加一个具体产品类和对应的实现工厂，无需对原工厂进行任何修改，很好地符合了“开闭原则”缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，是的系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 3、抽象工厂模式准备吃饭的时候突然又来了几位同事，而且他们有的喜欢吃酸菜鱼，有的喜欢吃红烧鱼，这就很头疼。于是，只能根据他们的需要继续点外卖。（这个就给出一个结构图，并且将每种角色都用具体的场景来说明了，具体的代码可以参考这个图例自己尝试一下。） OK，终于可以吃饭了！ 4、三种形态的工厂模式在java中的使用4.1、简单工厂模式在java中的使用java.text.DateFormat （一个抽象类）这个类相信很多小伙伴都用到过，在java API中，这个类算是一个简单工厂模式的典型应用了（此处还是与上篇一样，不考虑期源码细节，也不介绍基本用法）。来看它的几个方法： public final static DateFormat getDateInstance() public final static DateFormat getDateInstance(int style) public final static DateFormat getDateInstance(int style, Locale aLocale) 作为一个抽象类，却提供了很多的静态工厂方法，就像上面列举的那三个一样。有小伙伴可能会疑惑，为啥子一个抽象类阔以有自己的实例，并通过几个方法提供自己的实例。我们知道，抽象类是不可以有自己的实例对象的，但是需要注意的是，DateFormat的工厂方法是静态的，并不是普通的方法，也就是说，不需要通过创建实例对象的方式去调用。 1234public final static DateFormat getDateInstance()&#123; return get(0, DEFAULT, 2, Locale.getDefault(Locale.Category.FORMAT));&#125; getDateInstance方法并没有通过调用DateFormat的构造方法来创建对象。 4.2、工厂方法模式在java中的应用java.net.URL类，类图如下，URL对象通过一个工厂方法openConnection()返回一个URLConnection类型的对象。URLConnection是一个抽象类，因此所返还的不可能是这个抽象类的实例，而必然是其具体子类的实例。 4.3、抽象工厂模式在java中的应用根据java与模式一书的介绍，在java中使用抽象工厂模式的是 JAVA awt的peer架构，通过抽象工厂模式来构建分属于不同操作系统的peer构件。这个我也没用过，了解即可。 关于Spring中工厂模式的使用会在后续Spring源码分析系列中给大家详细分析，这里就不重复了。 今天的学习就到此结束了，祝大家周末愉快。话说今天平安夜，大家都是在家写代码吗？ 如果您对系列文章有任何意见，可以给我留言，感谢大家。]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-单例模式]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-design-model-singleton%2F</url>
    <content type="text"><![CDATA[菜鸟成长系列-面向对象的四大基础特性菜鸟成长系列-多态、接口和抽象类菜鸟成长系列-面向对象的6种设计原则 前面已经将设计模式中的基本内容撸了一下，今天开始正式开始设计模式系列的内容，因为网上也有很多关于设计模式的技术博客，从不同的角度对设计模式都做了很详细的解读；本系列的模式除了基本的概念和模型之外，还会结合java自身使用的和Spring中使用的一些案例来进行学习分析。水平有限，如果存在不当之处，希望大家多提意见，灰常感谢！设计模式中总体分为三类:一、创建型(5)： 工厂方法[Factory Method] 抽象工厂[Abstract Factory] 原型[Prototype] 建造者[Builder] 单例[Singleton] 还有一个简单工厂[Simple Factory]，目前有两种，有的把单例模式作为这5种之一，有的是将简单工厂作为这5种之一。这里不做讨论，原则上两个都是，只是划分规则不同。 二、结构型(7) 适配器[Adapter] 桥接[Bridge] 组合[Composite] 装饰[Decorator] 外观[Facade] 享元[Flyweight] 代理[Proxy] 三、行为型(11) 策略[Strategy] 模板方法[Template method] 职责链[Chain of Responsibility] 迭代器[Iterator] 状态[State] 访问者[Visitor] 命令[Command] 备忘录[Memento] 观察者[Observer] 中介者[Mediator] 解释器[Interpreter] 单例模式首先它是一种创建型模式，与其他模式区别在于：单例模式确保被创建的类只有一个实例对象，而且自行实例化并向整个系统提供这个实例。一般情况下我们称当前这个类为单例类。 从上面这段话中我们可以了解到，单例模式具备以下三个要点： 某个类只能有一个实例 必须自行创建这个实例[具体的对象创建由类本身负责，其他类不负责当前类的创建] 必须向整个系统提供这个实例[也就是说，当前类需要对外提供一个获取当前实例的一个方法，且该方法不能是私有的] OK，来看单例模式的几种实现方式。 方式一：饿汉式123456789101112131415161718192021222324252627package com.glmapper.design.singleton;/** * 单例模式-饿汉式 * @author glmapper * @date 2017年12月17日下午10:30:38 */public class EagerSingleton &#123; /** * 内部直接提供一个eagerSingletonInstance； * 我们知道，一般情况下，如果一个变量被static final修饰了，那么该变量将会被视为常量。 * 满足要点：自行创建 */ private static final EagerSingleton eagerSingletonInstance = new EagerSingleton(); /** * 提供一个私有的构造函数，这样其他类就无法通过new * EagerSingleton()来获取对象了，同样也保证了当前类不可以被继承 * 满足要点：某个类只能有一个实例 */ private EagerSingleton()&#123;&#125; /** * 对外提供一个获取实例的方法 * 满足要点：向整个系统提供这个实例 */ public static EagerSingleton getInstance()&#123; return eagerSingletonInstance; &#125;&#125; 方式二：懒汉式 1234567891011121314151617181920212223package com.glmapper.design.singleton;/** * 单例模式-懒汉式 * @author glmapper * @date 2017年12月17日下午10:45:54 */public class LazySingleton &#123; //提供一个私有静态变量，注意区别与饿汉式中的static final。 private static LazySingleton lazySingletonInstance = null ; //同样需要提供一个私有的构造方法，其作用与饿汉式中的作用一样 private LazySingleton()&#123;&#125; /** * 1.使用synchronized来保证线程同步 * 2.实例的具体创建被延迟到第一次调用getInstance方法时来进行 * 3.如果当前实例已经存在，不再重复创建 */ public synchronized static LazySingleton getInstance()&#123; if (lazySingletonInstance == null) &#123; lazySingletonInstance = new LazySingleton(); &#125; return lazySingletonInstance; &#125;&#125; 饿汉式单例类在自己被加载时就自己实例化了，即便加载器是静态的，在饿汉式单例类被加载时仍会将自己实例化。从资源利用角度来说，这个比懒汉式单例类稍微的差一些。如果从速度和响应时间来看，饿汉式就会比懒汉式好一些。懒汉式在单例类进行实例化时，必须处理好在多个线程同时首次引用此类时的访问限制问题。 方式三：登记式 123456789101112131415161718192021222324252627282930313233343536373839package com.glmapper.design.singleton;import java.util.HashMap;/** * 单例模式-登记式 * @author glmapper * @date 2017年12月17日下午10:58:36 */public class RegisterSingleton &#123; //提供一个私有的HashMap类型的registerSingletonInstance存储该RegisterSingleton类型的单例 private static HashMap&lt;String,Object&gt; registerSingletonInstance = new HashMap&lt;&gt;(); //通过static静态代码块来进行初始化RegisterSingleton当前类的实例，并将当前实例存入registerSingletonInstance static &#123; RegisterSingleton singleton = new RegisterSingleton(); registerSingletonInstance.put(singleton.getClass().getName(), singleton); &#125; /** * 注意区别，此处提供的是非private类型的，说明当前类可以被继承 */ protected RegisterSingleton()&#123;&#125; /** * 获取实例的方法 */ public static RegisterSingleton getInstance(String name)&#123; //如果name为空，则那么默认为当前类的全限定名 if (name == null) &#123; name =&quot;com.glmapper.design.singleton.RegisterSingleton&quot;; &#125; //如果map中没有查询到指定的单例，则将通过Class.forName(name)来创建一个实例对象，并存入map中 if (registerSingletonInstance.get(name)==null) &#123; try &#123; registerSingletonInstance.put(name, Class.forName(name).newInstance()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; //返回实例 return (RegisterSingleton) registerSingletonInstance.get(name); &#125;&#125; 登记式单例是Gof为了克服饿汉式和懒汉式单例类均不可被继承的缺点而设计的。 12345678910111213141516171819202122232425262728package com.glmapper.design.singleton;/** * 登记式-单例-子类 * @author glmapper * @date 2017年12月17日下午11:14:03 * */public class ChildRegisterSingleton extends RegisterSingleton&#123; /** * 由于子类必须允许父类以构造方法调用产生实例，因此，子类的构造方法必须 * 是public类型的。但是这样一来，就等于说可以允许以new * ChildRegisterSingleton()的方式产生实例，而不必在父类的登记中。 */ public ChildRegisterSingleton()&#123;&#125; //客户端测试获取实例 public static void main(String[] args) &#123; ChildRegisterSingleton crs1 = (ChildRegisterSingleton) getInstance( &quot;com.glmapper.design.singleton.ChildRegisterSingleton&quot;); ChildRegisterSingleton crs2 = (ChildRegisterSingleton) getInstance( &quot;com.glmapper.design.singleton.ChildRegisterSingleton&quot;); System.out.println(crs1 == crs2); &#125;&#125;返回：true 这个同志们可以自行验证，肯定是一样的。但是不能使用new，因为前提约束是，需在父类中登记的才是单例。 方式四：双重检测模式，双重检测方式在某些书上或者文献中说对于java语言来说是不成立的，但是目前确实是通过某种技巧完成了在java中使用双重检测机制的单例模式的实现，；这种技巧后面来说；关于为什么java语言对于双重检测成例不成立，大家可以在[BLOCH01]文献中看下具体情况。先来看一个单线程模式下的情况： 123456789101112131415package com.glmapper.design.singleton;/** * 一个错误的单例例子 * @author glmapper * @date 2017年12月17日下午11:53:04 */public class DoubleCheckSingleton &#123; private static DoubleCheckSingleton instance=null; public static DoubleCheckSingleton getDoubleCheckSingleton()&#123; if (instance == null) &#123; instance = new DoubleCheckSingleton(); &#125; return instance; &#125;&#125; 这个很明显是一个错误的例子，对于A/B两个线程，因为step 1并没有使用同步策略，因此线程A/B可能会同时进行// step 2，这样的话，就会可能创建两个对象。那么正确的方式如下：使用synchronized关键字来保证同步。 12345678910111213141516package com.glmapper.design.singleton;/** * 这是一个正确的打开方式哦。。。 * @author glmapper * @date 2017年12月17日下午11:53:04 */public class DoubleCheckSingleton &#123; private static DoubleCheckSingleton instance=null; //使用synchronized来保证getDoubleCheckSingleton同一时刻只能被一个线程访问 public synchronized static DoubleCheckSingleton getDoubleCheckSingleton()&#123; if (instance == null) &#123; instance = new DoubleCheckSingleton(); &#125; return instance; &#125;&#125; 这种方式虽然保证了线程安全性，但是也存在另外一种问题：同步化操作仅仅在instance首次初始化操作之前会起到作用，如果instance已经完成了初始化，对于getDoubleCheckSingleton每一次调用来说都会阻塞其他线程，造成一个不必要的瓶颈。那我们就通过使用更加细粒度化的锁，来适当的减小额外的开销。OK，下面再来一个错误的例子： 1234567891011121314151617181920212223package com.glmapper.design.singleton;/** * 一个错误的单例例子 * @author glmapper * @date 2017年12月17日下午11:53:04 */public class DoubleCheckSingleton &#123; private static DoubleCheckSingleton instance=null; //使用synchronized来保证getDoubleCheckSingleton同一时刻只能被一个线程访问 public static DoubleCheckSingleton getDoubleCheckSingleton()&#123; if (instance == null) &#123; //1 // B线程检测到uniqueInstance不为空 synchronized (DoubleCheckSingleton.class) &#123; //2 if (instance == null) &#123; //3 instance = new DoubleCheckSingleton();//4 // A线程被指令重排了，刚好先赋值了；但还没执行完构造函数。 &#125; &#125; &#125; // 后面B线程执行时将引发：对象尚未初始化错误。 return instance;//5 &#125;&#125; 看起来没什么毛病呀？我们来分析，两个线程A和B，同时到达1,且都通过了1的检测。此时A到了4，B在2。此时B线程检测到instance不为空，A线程被指令重排了，刚好先赋值了；但还没执行完构造函数；再接下来B线程执行时将引发：对象尚未初始化错误（5）。 对于上面的问题，我们可以通过volatile关键字来修饰instance对象，来保证instance对象的内存可见性和防止指令重排序。这个也就是前面说到的“技巧”。 123private static DoubleCheckSingleton instance=null;改为：private static volatile DoubleCheckSingleton instance=null; 本篇将单例模式的几种情况进行了分析。后面将会对将java中和Spring中所使用的单例场景进行具体的案例分析。 JAVA中的单例模式使用JAVA中对于单例模式的使用最经典的就是RunTime这个类。注释解读：每个Java应用程序都有一个Runtime类的单个实例，允许应用程序与运行应用程序的环境进行交互。 当前运行时可以从getRuntime方法获得。应用程序不能创建它自己的这个类的实例。 看过上篇文章的小伙伴可能比较清楚，这里RunTime使用的是懒汉式单例的方式来创建的。Runtime提供了一个静态工厂方法getRuntime方法用于获取Runtime实例。Runtime这个类的具体源码分析和只能此处不做分析。 Spring中的单例Spring依赖注入Bean实例默认是单例的。Spring中bean的依赖注入都是依赖AbstractBeanFactory的getBean方法来完成的。那我们就来看看在getBean中都发生了什么。 org.springframework.beans.factory.suppor.AbstractBeanFactory从上面这张图中我们啥也看不出，只知道在getBean中又调用了doGetBean方法（Spring中还有java源码中有很多类似的写法，好处在于我们可以通过子类继承，继而编写我们自己的处理逻辑）。OK，再来看看doGetBean方法。 来看下这个方法的注释：返回指定的bean可以共享或独立的实例 （谷歌+有道+百度） name:要检索的bean的名称 requiredType:要检索的bean所需的类型 args:如果使用静态工厂方法的显式参数创建原型，则使用参数。 在其他情况下使用非空args值是无效的。 typeCheckOnly:获得实例是否是为了类型检查，而不是实际的使用 这个方法体内的代码非常的多，那么我们本文不是来学习Spring的，所以我们只看我们关心的部分，为手工注册的singleton检查单例缓存。,从这个注释可以看出，此处就是我们获取实例的地方，再往下看。 此处和上面的getBean一样，也是通过模板方法的方式进行调用的。OK，这里我们看到了获取单例实例的具体实现过程。返回注册在给定名称下的(原始的)singleton对象。检查已经实例化的单例，并且还允许提前引用当前创建的单例（解析循环引用）。这里使用的是饿汉式中的双重检测机制来实现的。 OK，至此单例模式的学习就结束了，下一篇文章将会介绍工厂模式（简单工厂，工厂方法，抽象工厂）。]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[怎么写一个死锁？]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-base-thread-deadlock%2F</url>
    <content type="text"><![CDATA[刚把手头上的项目代码撸完，闲来看看博客，然后就看到了线程这块的东西。之前有简单的记录过线程和进行的零碎知识。JAVA基础知识系列—进程、线程安全 看着看着就想着怎么能写一个死锁呢，打开eclipse，突然感觉无从下手；之前都是一直在解决阻塞、死锁这些问题，现在反过来去写一个死锁感觉有点莫名奇妙。。。 ok,写一个死锁就要有一种场景，并且满足死锁的条件。 互斥条件：一个资源每次只能被一个进程使用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 首先要有竞争的资源，并且两个线程要同时都在等待对方释放资源。那我们先弄两个资源： 12Object lock=new Object();Object lock2=new Object(); 然后有两个线程： 12345Tr1 tr1=new Tr1(lock, lock2);Tr2 tr2=new Tr2(lock, lock2); Thread t1=new Thread(tr1);Thread t2=new Thread(tr2); 启动： 12t1.start();t2.start(); 那么对于lock，lock2怎么再线程内部产生竞争关系呢？来看代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.glmapper.base.synchronize;public class Tr1 implements Runnable &#123; Object lock; Object lock2; public Tr1(Object lock,Object lock2)&#123; this.lock= lock; this.lock2= lock2; &#125; @Override public void run() &#123; //获取lock synchronized (lock) &#123; System.out.println(Thread.currentThread().getName()+&quot;获取了lock锁&quot;); try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; &#125; //获取lock2 synchronized (lock2) &#123; System.out.println(Thread.currentThread().getName()+&quot;获取了lock2锁&quot;); &#125; &#125; &#125;&#125;public class Tr2 implements Runnable &#123; Object lock; Object lock2; public Tr2(Object lock,Object lock2)&#123; this.lock= lock; this.lock2= lock2; &#125; @Override public void run() &#123; //获取lock2 synchronized (lock2) &#123; System.out.println(Thread.currentThread().getName()+&quot;获取了lock2锁&quot;); try &#123; Thread.sleep(3000); &#125; catch (Exception e) &#123; &#125; //获取lock synchronized (lock) &#123; System.out.println(Thread.currentThread().getName()+&quot;获取了lock锁&quot;); &#125; &#125; &#125;&#125; 分析一下：当线程1获取lock时，线程2获取了lock2锁；然后线程1继续执行，到这里， 123synchronized (lock2) &#123; System.out.println(Thread.currentThread().getName()+&quot;获取了lock2锁&quot;);&#125; 此时需要获取到lock2这个锁，但是lock2现在被线程2持有；同时，线程2也开始执行到： 123synchronized (lock) &#123; System.out.println(Thread.currentThread().getName()+&quot;获取了lock锁&quot;);&#125; 此时线程2也在尝试获取lock这把锁，但是lock又被线程1持有了。两个线程都在等待对方释放资源，造成了死锁。OK，完成了。。。当我准备关机时，发现还在等呢？？？那为什么呢？？我们开看下发生了什么…. 通过jps来看下我们程序进程 使用jstack -l 【pid】 来看下信息 两个线程都处于BLOCKED状态了…,继续往下看found 1 deadlock.如我们所愿，死锁发生了！]]></content>
      <categories>
        <category>java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>线程</tag>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-面向对象的6种设计原则]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-bird-three%2F</url>
    <content type="text"><![CDATA[菜鸟成长系列拖了一周多了，今天继续之前的思路来进行。按照之前的规划，这篇主要来学习设计原则先关知识。通过本文学习，希望大家一方面能是能够认识这些原则是什么，能够在日常的开发中起到怎样的约束，并且用这些原则来提高代码的复用性和可维护性，另一方面是对后续的设计模式的学习能够有一些基础。 菜鸟成长系列-概述菜鸟成长系列-面向对象的四大基础特性菜鸟成长系列-多态、接口和抽象类 设计原则，在java与模式这本书中有提到，用于提高系统可维护性的同时，也提高系统的可复用性。这本书中主要讲了六种设计原则： “开-闭”原则 里氏替换原则 依赖倒置原则 接口隔离原则 单一职责原则 迪特米法则 这些设计原则首先都是复用的原则，遵循这些原则可以有效的提高系统的复用性，同时也提高了系统的可维护性。 “开-闭”原则网上看到一个人的解释，他是这样来比喻的：一个本子，已经写完了，你不可能撕几张纸粘上去吧，最好的办法是买个新的。道理就是这样，一个已经做好的程序，不支持修改的，因为修改的话，有可能造成程序无法运行或报错，所以，通常程序只支持扩展，不支持修改。 1.为什么会有这样一个原则来作为程序设计的一种约束呢？在软件的生命周期内，由于软件功能或者结构的变化、升级和维护等原因需要对软件原有代码进行修改，在修改的过程中可能会给旧代码中引入错误，也可能会使我们不得不对整个功能进行重构，并且还需要进行软件的重新测试，因此我们希望在软件设计之初，能够用一种原则来进行一些基本的约束，使得在软件后期的功能变更、扩展或者维护更加容易 2.开闭原则解决的问题是什么？当软件需要进行改变时，我们应该尽量通过扩展软件实体的行为来实现变化，而不是通过修改已有的代码来实现变化。通过这样一种原则，可以很好的实现在保证原有功能稳定的前提下扩展新的功能 3.什么是开闭原则呢？一个软件实体(类、模块或函数)应当对扩展开放，对修改关闭。也就是说在扩展或者修改软件功能时，应尽量在不修改原有代码的情况下进行 举个简单的栗子：现在有这样一个需求，系统需要通过QQ来进行验证登录。OK，我们来撸代码： 用户类User 1234567891011121314151617181920212223package com.glmapper.framerwork;/** * 用户信息类 * @author glmapper * @date 2017年12月9日下午10:54:09 * */public class User &#123; private String userName;//用户名 private String passWord;//密码 public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getPassWord() &#123; return passWord; &#125; public void setPassWord(String passWord) &#123; this.passWord = passWord; &#125;&#125; QQ核心验证逻辑 12345678910111213141516package com.glmapper.framerwork;/** * QQ验证器 * @author glmapper * @date 2017年12月9日下午10:49:24 */public class QQAuther &#123; /** * 用于验证QQ登录信息 */ public boolean validateQQ(User user) &#123; //模拟下逻辑 return user.toString()==null?false:true; &#125;&#125; 核心验证服务类 12345678910111213141516171819202122package com.glmapper.framerwork;/** * * 用于验证的核心服务 * @author glmapper * @date 2017年12月9日下午10:47:04 * */public class AuthService &#123; //持有一个QQ验证器对象 private QQAuther qqAuther; //通过构造器注入qqAuther对象 public AuthService(QQAuther qqAuther) &#123; this.qqAuther = qqAuther; &#125; /* * 验证用户合法性 */ public boolean validateUser(User user)&#123; return qqAuther.validateQQ(user); &#125;&#125; 客户端 12345678910111213141516171819package com.glmapper.framerwork;/** * 客户端调用验证 * @author glmapper * @date 2017年12月9日下午10:50:13 * */public class AuthClient &#123; public static void main(String[] args) &#123; //获取用户信息 User user = UserHolder.getUser(); QQAuther qqAuther = new QQAuther(); AuthService authService = new AuthService(qqAuther); //获取验证结果 boolean isOK = authService.validateUser(user); System.out.println(isOK); &#125;&#125; OK,完事了！但是现在需要接入微博的开放平台接口；修改代码…。增加一个微博验证器：123456789101112131415package com.glmapper.framerwork;/** * 微博核心验证器 * @author glmapper * @date 2017年12月9日下午11:01:10 */public class WeiBoAuther &#123; /** * 用于验证QQ登录信息 */ public boolean validateWeiBo(User user) &#123; return user.toString()==null?false:true; &#125;&#125; 核心验证服务修改： 1234567891011121314151617181920212223242526272829package com.glmapper.framerwork;/** * * 用于验证的核心服务 * @author glmapper * @date 2017年12月9日下午10:47:04 * */public class AuthService &#123; //持有一个QQ验证器对象 private Object obj; //通过构造器注入qqAuther对象 public AuthService(Object obj) &#123; this.obj = obj; &#125; /* * 验证用户合法性 */ public boolean validateUser(User user)&#123; //这里仅作为模拟，一般情况下会通过使用定义枚举&amp;工厂模式来完成 if (obj instanceof QQAuther) &#123; return new QQAuther().validateQQ(user); &#125; if(obj instanceof WeiBoAuther)&#123; return new WeiBoAuther().validateWeiBo(user); &#125; return false; &#125;&#125; 客户端改变： 12345678910111213141516171819202122232425package com.glmapper.framerwork;/** * 客户端调用验证 * @author glmapper * @date 2017年12月9日下午10:50:13 * */public class AuthClient &#123; public static void main(String[] args) &#123; //获取用户信息 User user = UserHolder.getUser(); //QQ QQAuther qqAuther = new QQAuther(); boolean isQQOK = new AuthService(qqAuther).validateUser(user); System.out.println(isQQOK); //微博 WeiBoAuther weiBoAuther = new WeiBoAuther(); boolean isWeiBoOK = new AuthService(weiBoAuther).validateUser(user); System.out.println(isWeiBoOK); &#125;&#125; OK，改进完成！但是又有新的需求，接入微信….。假如我们现在把微信开放平台也接入了，然后又来需求要接入支付宝账户、苏宁易购账户等等。。。就需要不断的修改代码。那么这个时候就需要在设计之初用到我们的开闭原则来做一个约束了。继续撸：首先我们需要需要定义一个接口用于约束： 验证器接口，用于被QQ/WEIBO/微信/苏宁易购等开发平台验证器实现 12345678910111213package com.glmapper.framerwork;/** * 定义一个约束接口 * @author glmapper * @date 2017年12月9日下午11:32:32 * */public interface ValidateInteface &#123; /** * 提供一个验证入口 */ boolean validate(User user);&#125; QQ修改之后 123456789101112131415package com.glmapper.framerwork;/** * QQ验证器 * @author glmapper * @date 2017年12月9日下午10:49:24 */public class QQAuther implements ValidateInteface&#123; /** * 用于验证QQ登录信息 */ @Override public boolean validate(User user) &#123; return user.toString()==null?false:true; &#125;&#125; 微博修改之后 12345678910111213141516package com.glmapper.framerwork;/** * 微博核心验证器 * @author glmapper * @date 2017年12月9日下午11:01:10 */public class WeiBoAuther implements ValidateInteface&#123; /** * 用于验证QQ登录信息 */ @Override public boolean validate(User user) &#123; // TODO Auto-generated method stub return user.toString()==null?false:true; &#125;&#125; 核心验证服务 1234567891011121314151617181920package com.glmapper.framerwork;/** * 用于验证的核心服务 * @author glmapper * @date 2017年12月9日下午10:47:04 */public class AuthService &#123; //持有一个QQ验证器对象 private ValidateInteface validate; //通过构造器注入qqAuther对象 public AuthService(ValidateInteface validate) &#123; this.validate = validate; &#125; /* * 验证用户合法性 */ public boolean validateUser(User user)&#123; return validate.validate(user); &#125;&#125; 客户端 123456789101112131415161718192021package com.glmapper.framerwork;/** * 客户端调用验证 * @author glmapper * @date 2017年12月9日下午10:50:13 * */public class AuthClient &#123; public static void main(String[] args) &#123; //获取用户信息 User user = UserHolder.getUser(); //QQ ValidateInteface qqAuther = new QQAuther(); boolean isQQOK = new AuthService(qqAuther).validateUser(user); System.out.println(isQQOK); //微博 ValidateInteface weiBoAuther = new WeiBoAuther(); boolean isWeiBoOK = new AuthService(weiBoAuther).validateUser(user); System.out.println(isWeiBoOK); &#125;&#125; 改进之后我们可以发现，对于原来的核心验证服务类、各验证器类，无论增加什么方式接入，我们都不需要去修改它的代码了。而此时我们需要做的就是新增一个验证器（例如苏宁易购验证器），然后继承ValidateInterface接口就行了。总体来首，开闭原则的核心是： 抽象化 对可变性的封装原则（1.不可变性不应该散落在代码的多处，而应当被封装到一个对象里面；2.一种可变性不应当与另外一种可变性混合在一起） （大家如果有更简单暴力的例子，可以留言；这个例子想了很多都感觉不是很恰当，还是从工作中抽象出来的）。 里氏替换原则任何父类可以出现的地方，子类一定可以出现里氏替换原则算是对“开闭”原则的补充，上面也提到，实现“开闭”原则的关键步骤是抽象化，而父类与子类的继承关系就是抽象化的一种具体体现，所以里氏替换原则是对实现抽象化的具体步骤的规范。 摘自java与模式中的定义:如果对每一个类型为 T1的对象 o1，都有类型为 T2 的对象o2，使得以 T1定义的所有程序 P 在所有的对象 o1 都代换成 o2 时，程序 P 的行为没有发生变化，那么类型 T2 是类型 T1 的子类型。 下图中描述了一种继承关系，从最高层的动物一直衍生出具体的动物。OK，写一段断码来看看： 顶层抽象父类-Animal 12345678910package com.glmapper.framework.model.lsp;/** * 顶层抽象父类动物类 * @author glmapper * @date 2017年12月10日上午10:51:30 */public abstract class Animal &#123; //提供一个抽象方法，以供不同子类来进行具体的实现 public abstract void eatFood(String foodName);&#125; 具体动物类型-Dog 12345678910111213 package com.glmapper.framework.model.lsp;/** *子类-小狗 * @author glmapper * @date 2017年12月10日上午10:54:17 * */public class Dog extends Animal&#123; @Override public void eatFood(String foodName) &#123; System.out.println(&quot;小狗吃&quot;+foodName); &#125;&#125; 具体动物-哈士奇 12345678910111213141516 package com.glmapper.framework.model.lsp;/** * 具体小狗的种类-子类哈士奇 * @author glmapper * @date 2017年12月10日上午10:56:59 * */public class HSQDog extends Dog&#123; /** * 重写父类方法 */ @Override public void eatFood(String foodName) &#123; System.out.println(&quot;哈士奇吃&quot;+foodName); &#125;&#125; 客户端 123456789101112131415package com.glmapper.framework.model.lsp;//客户端程序public class ClientMain &#123; public static void main(String[] args) &#123; //子类 HSQDog hsqdog=new HSQDog(); hsqdog.eatFood(&quot;饼干&quot;); //父类 Dog dog = new HSQDog(); dog.eatFood(&quot;饼干&quot;); //顶层父类 Animal animal = new HSQDog(); animal.eatFood(&quot;饼干&quot;); &#125;&#125; 运行结果 123哈士奇吃饼干哈士奇吃饼干哈士奇吃饼干 可以看出我们最开始说的那句话任何父类可以出现的地方，子类一定可以出现，反过来是不成立的。我的理解是子类通过集成获取的父类的属性和行为，并且子类自身也具有自己的属性和行为；父类可以出现的地方必然是需要用到父类的属性或者行为，而子类都涵盖了父类的这些信息，因此可以做到替换。反过来不行是因为父类在上述的例子中只是充当了一种类型约束，它可能不具有子类的某些特征，因此就无法做到真正的替换。 里氏替换原则是继承复用的基石，只有当子类可以替换掉基类，软件单位的功能不会受到影响时，基类才能被真正的复用，而子类也才能够在基类的基础上增加新的功能。 依赖倒转原则实现“开闭”原则的关键是抽象化，并且从抽象化导出具体化实现。如果说开闭原则是面向对象设计的目标的话，依赖倒转原则就是面向对象设计的主要机制（java与模式）。依赖倒转原则：要依赖与抽象，不依赖于具体实现。 怎么理解呢? 1）高层模块不应该直接依赖于底层模块的具体实现，而应该依赖于底层的抽象。换言之，模块间的依赖是通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生的。 2）接口和抽象类不应该依赖于实现类，而实现类依赖接口或抽象类。这一点其实不用多说，很好理解，“面向接口编程”思想正是这点的最好体现 首先是第一点，从复用的角度来说，高层次的模块是设计者应当复用的。但是在传统的过程性的设计中，复用却侧重于具体层次模块的复用。比如算法的复用，数据结构的复用，函数库的复用等，都不可避免是具体层次模块里面的复用。较高层次的结构依赖于较低层次的结构，然后较低层次的结构又依赖于更低层次的结构，直到依赖到每一行代码为止。然后对低层次修改也会逐层修改，一直到最高层的设计模块中。 对于一个系统来说，一般抽象层次越高，它的稳定性就越好，因此也是作为复用的重点。 “倒转”，实际上就是指复用应当将复用的重点放在抽象层上，如果抽象层次的模块相对独立于具体层次模块的话，那么抽象层次的模块的复用便是相对较为容易的了。 在很多情况下，一个java程序需要引用一个对象，如果这个对象有一个抽象类型的话，应当使用这个抽象类型作为变量的静态类型。在上面我们画了动物和小狗的类图关系，在客户端调用的时候有三种方式： 123456789//子类(方式1)HSQDog hsqdog=new HSQDog();hsqdog.eatFood(&quot;饼干&quot;);//父类（方式2）Dog dog = new HSQDog();dog.eatFood(&quot;饼干&quot;);//顶层父类（方式3）Animal animal = new HSQDog();animal.eatFood(&quot;饼干&quot;); 如果我们需要一个哈士奇（HSQDog）的话，我们不应当使用方式1，而是应当使用方式2或者方式3。 接口隔离原则接口隔离原则：使用多个专门的接口比使用单一的总接口要好。换句话说，从一个客户类的角度来讲：一个类对另外一个类的依赖性应当是建立在最小的接口上的。这个其实在我们实际的开发中是经常遇到的。比如我们需要编写一个完成一个产品的一些操作接口。12345678910111213141516package com.glmapper.framework.model.isp;/** * 一个产品服务接口 * @author glmapper * @date 2017年12月10日下午12:01:31 */public interface ProductService &#123; //增加产品 public int addProduct(Product p); //删除产产品 public int deleteProduct(int pId); //修改产品 public int updateProduct(Product p); //查询一个产品 public Product queryProduct(int pId);&#125; OK，我们在ProductService中提供了对产品的增删改查；但是随着需求升级，我们需要可以增加对产品新的批量导入和导出。OK，这时在接口中继续新增两个方法：1234//从excel中批量导入public void batchImportFromExcel();//从excel中批量导导出public void batchExportFromExcel(); 然后需求又需要扩展，需要增加增加购买产品、产品订单生产、查询订单、订单详情….；这样一来，我们的ProductService就会慢慢的急速膨胀。与此对应的具体的实现逻辑ProductServiceImpl类也会变得非常的庞大，可能单类会超过数千行代码。 那么我们就需要进行接口隔离，将产品的基本操作如增删改查放在一个接口，将产品订单处理放在一个接口，将产品申购放在一个接口，将批量操作放在一个接口等等…对于每一个接口我们只关心某一类特定的职责，这个其实就是和单一职责原则有点挂钩了。通过这种设计，降低了单个接口的复杂度，使得接口的“内聚性”更高，“耦合性”更低。由此可以看出接口隔离原则的必要性。 迪特米法则迪特米法则：又称为最少知识原则，就是说一个对象应当对其他对象尽可能少的了解；看下迪特米法则的几种表述：1.只与你直接的朋友们通信2.不跟陌生人说话3.每一个软件单位对其他的单位都只有最少知识，而且局限于那些与本单位密切相关的软件单位 也就是说，如果两个雷不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。如果其中一个类需要电泳另一个类的某一个方法的话，可以通过第三者进行消息的转发。代码看下： 某个人 1234567891011121314package com.glmapper.framework.model.isp;/** * 某个人 * @author glmapper * @date 2017年12月10日下午12:39:45 */public class SomeOne &#123; //具体oprateion行为 public void oprateion(Friend friend)&#123; Stranger stranger =friend.provide(); stranger.oprateion3(); &#125;&#125;SomeOne具有一个oprateion方法，该方法接受Friend为参数，根据上面的定义可以知道Friend是SomeOne的“朋友”（直接通信了） 朋友 123456789101112131415package com.glmapper.framework.model.isp;/** * 朋友 * @author glmapper * @date 2017年12月10日下午12:40:09 */public class Friend &#123; private Stranger stranger = new Stranger(); public Stranger provide()&#123; return stranger; &#125; public void opration2()&#123; &#125;&#125;很明显SomeOne的opration方法不满足迪特米法则，因为这个方法中涉及到了陌生人Stranger,Stranger不是SomeOne的朋友 OK，我们来通过迪特米法则进行改造。 改造之后的SomeOne 12345678910111213package com.glmapper.framework.model.isp;/** * 某个人 * @author glmapper * @date 2017年12月10日下午12:39:45 * */public class SomeOne &#123; //具体oprateion行为 public void oprateion(Friend friend)&#123; friend.forward(); &#125;&#125; 改造之后的朋友 1234567891011121314151617package com.glmapper.framework.model.isp;/** * 朋友 * @author glmapper * @date 2017年12月10日下午12:40:09 * */public class Friend &#123; private Stranger stranger = new Stranger(); public void opration2()&#123; &#125; //进行转发 public void forward() &#123; stranger.oprateion3(); &#125;&#125; 由于调用了转发，因此SomeOne中就不会和陌生人Stranger直接的关系就被忽略了。满足了直接和朋友通信、不与陌生人说话的条件。但是迪特米法则带来的问题也是很明显的：即会在系统中造出大量的小方法散落在系统的各个角落，这些方法仅仅是传递消息的调用，与系统的业务逻辑没有任何关系。 单一职责上面在接口隔离中有提到过，单一职责其实很好理解，解释尽量的使得我们的每一个类或者接口只完成本职工作以内的事情，不参与其他任何逻辑。比如说苹果榨汁机我就只用来榨苹果汁，如果你需要榨黄瓜汁的话，你就得买一个黄瓜榨汁机。 总结OK ，至此，设计原则部分就复习完了。总结一下： 单一职责原则要求实现类要职责单一； 里氏替换原则要求不要去破坏继承系统； 依赖倒置原则要求面向接口编程； 接口隔离原则要求在设计接口的时候要精简单一； 迪米特法则要求要降低耦合； 开闭原则是总纲，要求对扩展开发，对修改关闭。 大家周末愉快！（如果有不当之处，希望大家及时指出，多谢！）]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从源码来聊一聊hashmap]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-base-hashmap%2F</url>
    <content type="text"><![CDATA[HashMap为什么会是面试中的常客呢？我觉得有以下几点原因：* 考察你阅读源码的能力* 是否了解内部数据结构* 是否了解其存储和查询逻辑* 对非线程安全情况下的使用考虑前段时间一同事面试蚂蚁金服，就被问到了这个问题；其实很多情况下都是从hashMap,hashTable,ConcurrentHahMap三者之间的关系衍生而出，当然也有直接就针对hashMap原理直接进行考察的。实际上本质都一样，就是为了考察你是否对集合中这些常用集合的原理、实现和使用场景是否清楚。一方面是我们开发中用的多，当然用的人也就多，但是用的好的人却不多（我也用的多，用的也不好）。所以就借此机会（强行蹭一波）再来捋一捋这个HashMap。本文基于jdk1.7.0_80；jdk 1.8之后略有改动，这个后面细说。 继承关系123public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable hashMap实现了Map、Cloneable、Serializable三个接口，并且继承了AbstractMap这个抽象类。hashTable继承的是Dictionary这个类，同时也实现了Map、Cloneable、Serializable三个接口。 主要属性 DEFAULT_INITIAL_CAPACITY 默认初始容量 16 （hashtable 是11） 常量 12345/** * The default initial capacity - MUST be a power of two. * 默认初始容量-必须是2的幂。 */ static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 MAXIMUM_CAPACITY 默认最大容量 常量 1234567/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. *如果有一个更大的值被用于构造HashMap,则使用最大值 */ static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; DEFAULT_LOAD_FACTOR 负载因子(默认0.75) 常量 12345/** * The load factor used when none specified in constructor. * 加载因子，如果构造函数中没有指定，则使用默认的 */ static final float DEFAULT_LOAD_FACTOR = 0.75f; EMPTY_TABLE 默认的空表 12345/** * An empty table instance to share when the table is not inflated. * 当表不膨胀时共享的空表实例。 */ static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;; table 表，必要时调整大小。长度必须是两个幂。这个也是hashmap中的核心的存储结构 1234/** * The table, resized as necessary. Length MUST Always be a power of two. */ transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; size 表示HashMap中存放KV的数量（为链表/树中的KV的总和） 1234/** * The number of key-value mappings contained in this map. */ transient int size; threshold 扩容变量，表示当HashMap的size大于threshold时会执行resize操作。threshold=capacity*loadFactor 1234567/** * The next size value at which to resize (capacity * load factor). * @serial */ // If table == EMPTY_TABLE then this is the initial capacity at which the // table will be created when inflated. int threshold; loadFactor 负载因子 负载因子用来衡量HashMap满的程度。loadFactor的默认值为0.75f。计算HashMap的实时装载因子的方法为：size/capacity，而不是占用桶的数量去除以capacity。（桶的概念后续介绍） 123456/** * The load factor for the hash table. * * @serial */final float loadFactor; modCount这个HashMap的结构修改的次数是那些改变HashMap中的映射数量或修改其内部结构(例如rehash)的那些。这个字段用于使迭代器对HashMap失败快速的集合视图。(见ConcurrentModificationException)。 12345678/** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount; hashSeed 与此实例相关联的随机值，用于哈希键的散列代码，使散列冲突更难找到。如果0，那么替代哈希是禁用的。 123456/** * A randomizing value associated with this instance that is applied to * hash code of keys to make hash collisions harder to find. If 0 then * alternative hashing is disabled. */ transient int hashSeed = 0; 结构分析1static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; hashmap中是通过使用一个继承自Map中内部类Entry的Entry静态内部类来存储每一个K-V值的。看下具体代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; //键对象 V value; //值对象 Entry&lt;K,V&gt; next; //指向链表中下一个Entry对象，可为null，表示当前Entry对象在链表尾部 int hash; //键对象的hash值 /** * 构造对象 */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; /** * 获取key */ public final K getKey() &#123; return key; &#125; /** * 获取value */ public final V getValue() &#123; return value; &#125; /** * 设置value，这里返回的是oldValue(这个不太明白，哪位大佬清楚的可以留言解释下，非常感谢) */ public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; /** * 重写equals方法 */ public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; /** * 重写hashCode方法 */ public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + &quot;=&quot; + getValue(); &#125; /** * This method is invoked whenever the value in an entry is * overwritten by an invocation of put(k,v) for a key k that&apos;s already * in the HashMap. */ void recordAccess(HashMap&lt;K,V&gt; m) &#123; &#125; /** * This method is invoked whenever the entry is * removed from the table. */ void recordRemoval(HashMap&lt;K,V&gt; m) &#123; &#125; &#125; HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫做Entry。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是HashMap的主干（也就是上面的table–桶）。看一张图： hashmap初始化时各个空间的默认值为null，当插入元素时（具体插入下面分析），根据key值来计算出具体的索引位置，如果重复，则使用尾插入法进行插入后面链表中。 尾插法之前我是通过插入17条数据来试验的（具体数据数目随意，越大重复的几率越高）1234567public static void main(String[] args) throws Exception &#123; HashMap&lt;String, Object&gt; map=new HashMap&lt;&gt;(); for (int i = 0; i &lt; 170; i++) &#123; map.put(&quot;key&quot;+i, i); &#125; System.out.println(map); &#125; 通过断点查看next，可以得出我们上面的结论：1.索引冲突时会使用链表来存储；2.插入链表的方式是从尾部开始插入的（官方的解释是一般情况下，后来插入的数据被使用的频次较高），这样的话有利于查找。 主要方法我们平时在开发是最常用的hashMap中的方法无非就是先创建一个HashMap对象，然后存，接着取；对应的方法就是： 构造函数 put函数 get函数 构造函数 12345678910111213141516171819202122232425262728/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity 指定的初始化容量大小 * @param loadFactor the load factor 指定的负载因子 * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; //如果初始化容量小于0，则抛出异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); //如果初始化容量大于最大容量，则使用默认最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //如果负载因子小于0或者非数值类型，则抛出异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); //初始化负载因子 this.loadFactor = loadFactor; //初始化threshold threshold = initialCapacity; //这个初始化方法是个空方法，应该是意在HashMap的子类中由使用者自行重写该方法的具体实现 init(); &#125; 另外两个构造方法实际上都是对上面这个构造方法的调用： 12345678//只制定默认容量 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; //使用HashMap默认的容量大小和负载因子 public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; 还有一个是：1234567public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m); &#125; 构造一个映射关系与指定 Map 相同的新 HashMap。所创建的 HashMap 具有默认加载因子 (0.75) 和足以容纳指定 Map 中映射关系的初始容量。 put方法首先，我们都知道hashmap中的key是允许为null的，这一点也是面试中最常问到的点。那我先看下为什么可以存null作为key值。 123456789101112131415161718192021222324252627282930public V put(K key, V value) &#123; //如果table是空的 if (table == EMPTY_TABLE) &#123; //inflate：扩容/膨胀的意思 inflateTable(threshold); &#125; //如果key为null 此处敲下桌子，为什么可以存null？ if (key == null) //执行putForNullKey方法，这个方法的作用是如果key为null，就将当前的k-v存放到table[0],即第一个桶。 return putForNullKey(value); //对key进行一次hash运算，获取hash值 int hash = hash(key); //根据key值得hash值和表的长度来计算索引位置 int i = indexFor(hash, table.length); //移动数据，插入数据 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); //上面Entry中的setValue中也有提到，返回的都是旧的数据 return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; hash方法：检索对象哈希代码，并将附加哈希函数应用于结果哈希，该哈希函数防止质量差的哈希函数。 这是至关重要的，因为HashMap使用两个长度的哈希表，否则会碰到hashCode的冲突，这些hashCodes在低位上没有区别。 注意：空键总是映射到散列0，因此索引为0。1234567891011121314/** final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); //这个函数确保在每个比特位置上仅以恒定倍数不同 //的散列码具有有限数量的冲突（在默认加载因子下大约为8）。 h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 冲突具体过程描述： 一个空的hashmap表 插入元素，通过hash计算得出索引为3，因为当前3的位置没有元素，因此直接插入进去即可 再次插入元素，通过hash计算得出索引还是3，发生冲突，则将当前新插入的元素放在原来的已有的元素位置，并将其next指向原来已经存在的元素。get方法返回指定键映射到的值;如果此映射不包含键映射，则返回null。123456789public V get(Object key) &#123; //和存null key一样，取的时候也是从table[0]取 if (key == null) return getForNullKey(); //获取entry Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); &#125; getEntry方法 12345678910111213141516171819final Entry&lt;K,V&gt; getEntry(Object key) &#123; //size等于0，说明当前hashMap中没有元素，直接返回null（每个entry默认值为null） if (size == 0) &#123; return null; &#125; //根据key值计算hash值 int hash = (key == null) ? 0 : hash(key); //通过hash值获取到索引位置，找到对应的桶链进行遍历查找 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; //如果找到则返回，如果没有链表指针移动到下一个节点继续查找。 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; 扩容机制在前面提到过threshold，扩容变量，表示当HashMap的size大于threshold时会执行resize操作。其计算方式是：threshold=capacity*loadFactor。从上面的式子中我们可以得知hashmap的扩容时机是当前当前size的值超过容量乘以负载因子时就会触发扩容。来看下源码： 123456789101112131415161718192021void addEntry(int hash, K key, V value, int bucketIndex) &#123; //如果当前size超过threshold 并且满足桶索引位置不为null的情况下，扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; //扩容之后为原来的两倍 resize(2 * table.length); //重新计算hash值 hash = (null != key) ? hash(key) : 0; //重写计算索引 bucketIndex = indexFor(hash, table.length); &#125; //执行具体的插入操作 createEntry(hash, key, value, bucketIndex); &#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; //先取到当前桶的entry Entry&lt;K,V&gt; e = table[bucketIndex]; //将新的数据插入到table[bucketIndex]，再将之前的entry通过链表简介到table[bucketIndex]的next指向；前面的图已经进行了描述。 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++; &#125; 需要注意的是，扩容并不是在hashmap满了之后才进行的，看下面断点： 通过默认构造函数new了一个map对象出来，通过for循环插入12条数据，断点到执行结束，我们看到当前table的容量是16，扩容变量threshold为12（16x0.75），现在我们将12改为13.此时13还是小于16的，但是还是触发了hashmap 的扩容。当前table容量为32（扩容为了之前的两倍），threshold为24（32x0.75），通过这两种图我们得知： 每次扩容之后的容量为原有容量的两倍（2n） 触发扩容并不是因为当前hashmap对象已经满了，而是通过threhold扩容变量来控制触发时机的。 小结本文就单纯的扒了一波源码，并对源码中的注释并结合自己的理解进行了翻译，通过断点调试简单的介绍了尾插法在hashmap的应用。最后通过几张图描述了下hashmap发生索引冲突时的解决方案。hashmap在面试时真的是可深可浅，但是源码的阅读还是很有必要的，下面推荐两篇博客给大家。 1.关于hashmap与hashtable的具体对比可以参考这个博客：HashMap和HashTable到底哪不同？ 2.关于为什么hashmap中的容量必须是2的幂，这篇博客大家可以看下：什么是hashmap？ 3.关于hashmap非线程安全的解释并发安全问题之HashMap]]></content>
      <categories>
        <category>java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>hash</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个朋友圈泛型问题引发的“案子”]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-base-one%2F</url>
    <content type="text"><![CDATA[昨天朋友圈问了一个问题：对于下面的list，何如在list添加一个Integer型整数？1ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); 有这样几种回答： 1.不知道（非专业回答） 2.硬塞（非专业回答） 3.把String 改成Integer再添加（违背了问题初衷） 4.把String改成Object，可以加任意类型（违背了问题初衷） 5.String换成通配符 6.反射 对于1、2就不说了，属于搞事情的！3、4、5三种方式违背了问题的初衷，如果可以改，那我们直接new三个ArrayList就可以了。6反射，这个是无限接近的，那么这个和反射有什么关系呢？下来看下下面几个例子： 12345678910111213141516171819public static void main(String[] args) &#123; ArrayList list=new ArrayList(); ArrayList&lt;String&gt; str_list=new ArrayList&lt;String&gt;(); ArrayList&lt;Integer&gt; int_list=new ArrayList&lt;Integer&gt;(); ArrayList&lt;Object&gt; obj_list=new ArrayList&lt;Object&gt;(); //对象比较 System.out.println(list == str_list); System.out.println(list == int_list); System.out.println(list == obj_list); //对象的运行时class比较 System.out.println(list.getClass() == str_list.getClass()); System.out.println(list.getClass() == int_list.getClass()); System.out.println(list.getClass() == obj_list.getClass()); &#125; 结果：123456falsefalsefalsetruetruetrue 其实上面三个很容易理解，不同对象在内存中的地址肯定是不同的，因此均为false;下面三个均为true?是的，确实为true,这就引出了朋友圈的那个问题。为什么不同的三个对象，他们的getClass是一样的，不应该是有三个不同的hashCode吗？这个其实就是泛型编译时和运行时的问题。对于泛型来说，泛型只在编译阶段有效，编译之后，集合的泛型是去泛型化的；原因：由于JVM泛型的擦除机制，在运行时JVM是不知道泛型信息的。因此：java集合中的泛型，是来约束用户的错误输入的，只在编译时有效；在回到问题最初，我们怎么才能将一个Integer对像放入上面定义的list中呢？既然集合中的泛型是编译时有效的，那我我们就可以通过绕过编译的方式进行插入。那么如何绕过编译时的校验呢？答案就是用反射；我们知道JAVA反射机制是指：“在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。OK，再来看程序： 123456789 ArrayList&lt;String&gt; str_list=new ArrayList&lt;String&gt;();//获取类信息Class c=str_list.getClass();//获取add方法Method m=c.getMethod(&quot;add&quot;, Object.class);//运行时调用add方法m.invoke(str_list, 20);//输出当前str_listSystem.out.println(str_list); 结果：1[20] 从结果可以看出，我们完成了在list中添加Integer的任务。【泛型、反射、编译时、运行时】]]></content>
      <categories>
        <category>java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法-排序算法思想及实现]]></title>
    <url>%2F2018%2F11%2F10%2Falg-one%2F</url>
    <content type="text"><![CDATA[排序算法主要有：插入排序，选择排序，冒泡排序，希尔排序，归并排序，快速排序，堆排序。这里的排序指的是内部排序，也就是基于内存的排序，基于内存的排序是基于大O模型的，可以使用大O模型来衡量算法的性能摘自我自己的博客园：http://www.cnblogs.com/myadmin/p/5821158.html 中的部分排序算法。 插入排序基本思想：每一步都将一个待排数据按其大小插入到已经排序的数据中的适当位置，直到全部插入完毕。 1234原始：4 3 1 21) 3 4 1 22) 1 3 4 23) 1 2 3 4 核心代码： 12345678910111213141516/** * 插入排序 */ public static int[] insertSort(int[] arr) &#123; for (int i = 1; i &lt; arr.length; i++) &#123; int index = i;// index当前扫描到的元素下标 int temp = arr[i]; // 寻找插入的位置 while (index &gt; 0 &amp;&amp; temp &lt; arr[index - 1]) &#123; arr[index] = arr[index - 1]; index--; &#125; arr[index] = temp; &#125; return arr; &#125; 选择排序基本思想：从所有序列中先找到最小的，然后放到第一个位置。之后再看剩余元素中最小的，放到第二个位置……以此类推，就可以完成整个的排序工作了。可以很清楚的发现，选择排序是固定位置，找元素。相比于插入排序的固定元素找位置，是两种思维方式。 1234567893 2 1 4 6 5初始化索引位置为0 寻找最小值所在位置交换：1 2 3 4 6 5初始化索引位置为1寻找最小值所在位置交换：1 2 3 4 6 5依次类推！ 核心代码： 123456789101112131415161718/** * 选择排序 */ public static int[] selectSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; int minVal = arr[i]; int index = i; for (int j = i + 1; j &lt; arr.length; j++) &#123;// 找到最小元素 if (arr[j] &lt; minVal) &#123; minVal = arr[j]; index = j; &#125; &#125; arr[index] = arr[i]; arr[i] = minVal; &#125; return arr; &#125; 冒泡排序基本思想：原理是临近的数字两两进行比较,按照从小到大或者从大到小的顺序进行交换。核心代码：12345678910111213141516171819/** * 冒泡排序 * * @param arr * 输入的待排数组 * @return 返回排序号的数组 */ public static int[] bubbleSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; for (int j = 1; j &lt; arr.length; j++) &#123; if (arr[j - 1] &gt; arr[j]) &#123; int temp = arr[j - 1]; arr[j - 1] = arr[j]; arr[j] = temp; &#125; &#125; &#125; return arr; &#125; 希尔排序基本思想：先取一个小于n的整数d1作为第一个增量，把文件的全部记录分组。所有距离为d1的倍数的记录放在同一个组中。先在各组内进行直接插入排序；然后，取第二个增量d2&lt;d1重复上述的分组和排序，直至所取的增量 =1( &lt; …&lt;d2&lt;d1)，即所有记录放在同一组中进行直接插入排序为止。（下图来自百度图片） 核心代码： 12345678910111213141516171819202122232425262728/** * 希尔排序 * * @author sgl * */public class ShellSort &#123; public static int[] shellSort(int[] arr) &#123; int step = arr.length / 2;// 初始步长 while (1 &lt;= step) &#123; for (int i = step; i &lt; arr.length; i++) &#123; if (arr[i] &lt; arr[i - step]) &#123; int temp = arr[i]; arr[i] = arr[i - step]; arr[i - step] = temp; &#125; &#125; step = step / 2; for (int i = 0; i &lt; arr.length; i++) &#123; System.out.print(arr[i]+&quot;,&quot;); &#125; System.out.println(); &#125; return arr; &#125; 归并排序基本思想：将待排序序列R[0…n-1]看成是n个长度为1的有序序列，将相邻的有序表成对归并，得到n/2个长度为2的有序表；将这些有序序列再次归并，得到n/4个长度为4的有序序列；如此反复进行下去，最后得到一个长度为n的有序序列。归并排序其实要做两件事：（1）“分解”——将序列每次折半划分。（2）“合并”——将划分后的序列段两两合并后排序。 核心代码：12345678910111213141516171819202122232425262728293031323334353637public static int[] sort(int[] nums, int low, int high) &#123; int mid = (low + high) / 2; if (low &lt; high) &#123; sort(nums, low, mid);// 左边 sort(nums, mid + 1, high);// 右边 merge(nums, low, mid, high);// 左右归并 &#125; return nums; &#125; public static void merge(int[] nums, int low, int mid, int high) &#123; int[] temp = new int[high - low + 1]; int i = low;// 左指针 int j = mid + 1;// 右指针 int k = 0; // 把较小的数先移到新数组中 while (i &lt;= mid &amp;&amp; j &lt;= high) &#123; if (nums[i] &lt; nums[j]) &#123; temp[k++] = nums[i++]; &#125; else &#123; temp[k++] = nums[j++]; &#125; &#125; // 把左边剩余的数移入数组 while (i &lt;= mid) &#123; temp[k++] = nums[i++]; &#125; // 把右边边剩余的数移入数组 while (j &lt;= high) &#123; temp[k++] = nums[j++]; &#125; // 把新数组中的数覆盖nums数组 for (int k2 = 0; k2 &lt; temp.length; k2++) &#123; nums[k2 + low] = temp[k2]; &#125; &#125;&#125; 快速排序基本思想：快速排序采用的思想是分治思想。快速排序是找出一个元素（理论上可以随便找一个）作为基准,然后对数组进行分区操作,使基准左边元素的值都不大于基准值,基准右边的元素值 都不小于基准值，如此作为基准的元素调整到排序后的正确位置。递归快速排序，将其他n-1个元素也调整到排序后的正确位置。最后每个元素都是在排序后的正 确位置，排序完成。所以快速排序算法的核心算法是分区操作，即如何调整基准的位置以及调整返回基准的最终位置以便分治递归。 核心代码： 123456789101112131415161718192021222324252627282930313233/** * 快速排序 * * @author sgl * */public class QuickSort &#123; static void quicksort(int n[], int left, int right) &#123; int dp; if (left &lt; right) &#123; dp = partition(n, left, right); quicksort(n, left, dp - 1); quicksort(n, dp + 1, right); &#125; &#125; static int partition(int n[], int left, int right) &#123; int pivot = n[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; n[right] &gt;= pivot) right--; if (left &lt; right) n[left++] = n[right]; while (left &lt; right &amp;&amp; n[left] &lt;= pivot) left++; if (left &lt; right) n[right--] = n[left]; &#125; n[left] = pivot; return left; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于maven构建多模块化的SSM框架]]></title>
    <url>%2F2018%2F11%2F10%2Fproject-frame-maven-ssm%2F</url>
    <content type="text"><![CDATA[之前写过一篇SSM的框架整合；项目开发框架-SSM；对SSM中的一些点进行了学习记录,那篇文章也是基于maven来创建的，那么为什么又要搞一篇呢？以我当前公司项目A来说，A项目包括前台、后台子项目【前台用于对外，后台用于管理】，如果按照前一篇文章的那种方式来进行，我们就需要建立两个单独的框架来进行开发，一样的拥有一套从dmo实体类包，util包，dao包，service包以及controller包，这种结构非常的紧凑和独立，但是问题在于，我们前后台使用的是同一个库，dmo、util、dao以及service中都会存在大量重复的代码，很多基础方法无法公用；另外一个原因是，我们还需要包装一些接口向外提供服务【不局限于我们自己的这两个系统】，这样一来，我们又需要再去抽离一次service，非常不方便。因此就使用maven来构建多模块项目，对于util、dao、rpc服务接口以及service进行模块化分离，这样一来，这些模块就可以对我们自己的前后台以及外部提供一些公关的服务，避免了大量的代码重复，也方便管理。 Maven多模块项目，通过合理的模块拆分，实现代码的复用，便于维护和管理。尤其是一些开源框架，也是采用多模块的方式，提供插件集成，用户可以根据需要配置指定的模块。 构建多模块化项目基于maven构建多模块化项目主要依赖于maven可以实现父子项目的关系，子项目可以父项目的依赖Jar包，这样也方便我们去共同管理jar依赖，但是由于一个项目中毕竟会有很多人进行协同开发，在此过程中如果没有很好的约束，对于这种多模块化来说，解决jar包的冲突也很繁琐。 新建一个父工程1.创建maven项目 step1:(新建maven项目) step2:(勾选创建一个简单工程) step3:(填写工程配置：主要是打包方式要选择pom方式)点击finish，父项目就创建成功了！2.创建子项目 step1:(右击父项目-&gt;maven-&gt;New Maven Model Project) step2: step3:(一般情况下，我们项目中的util、dao、service都是可以直接分出来的，这里我们选择quickstart来构建,用于生产后面的jar包提供服务。我们的web子项目选择webapp来构建，用于配置文件、jsp文件/ftl/html/js/css等界面资源文件维护)点击finish，完成子模块的构建！构建之后的项目结构为：此时，我们的父模块中已经有了子模块的项目标识，新建的dao模块中不包括webapp此类的文件夹。那么这时就可以将我们的数据访问相关的类和接口都放在这个子模块中，如果其他项目需要使用，我们直接引入就行，引入方式如下（下面截图是从service模块引入dao模块的，这里的groupId，artifactId，version我们可以在dao的pom文件中直接复制使用）：（上面新建的过程只作为演示而用，下面的引入和上面的新建项目并非一个项目）其他的模块构建和dao的构建过程是一样的，这里就不一一构建了。源码地址在下面，解压之后，以maven项目方式导入，修改下数据库配置文件应该就可以直接运行了（当前项目基于jdk1.7写的，有的小伙伴如果用1.8的话，应该会出现jsp无法编译的一个错误）；源码附件中还有一个setting文件,阿里的，个人觉得用起来很不错，也推荐给大家! 源码地址：http://download.csdn.net/download/sinat_25518349/10124726【这个是csdn的地址，现在资源上传还必需要选择C币，小伙伴如果没有csdn账户或者C币不足，可以在文章留言区留言，留下邮箱，我发给你们】]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>ssm</tag>
        <tag>spring</tag>
        <tag>web</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多态、接口和抽象类]]></title>
    <url>%2F2018%2F11%2F10%2Fglmapper-bird-two%2F</url>
    <content type="text"><![CDATA[面向对象的三大特性：封装、继承、多态。从一定角度来看，封装和继承几乎都是为多态而准备的。这是我们最后一个概念，也是最重要的知识点。 多态的定义：指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用） 动态绑定 静态绑定和动态绑定这里所谓的绑定，即一个方法的调用与方法所在的类（方法主体）关联起来。 静态绑定（前期绑定）：即在程序执行前，即编译的时候已经实现了该方法与所在类的绑定，像C就是静态绑定。 java中只有static，final，private和构造方法是静态绑定，其他的都属于动态绑定，而private的方法其实也是final方法（隐式），而构造 方法其实是一个static方法（隐式），所以可以看出把方法声明为final，第一可以让他不被重写，第二也可以关闭它的动态绑定。 动态绑定（后期绑定）：运行时根据对象的类型进行绑定，java中的大多数方法都是属于动态绑定，也就是实现多态的基础。 java实现了后期绑定，则必须提供一些机制，可在运行期间判断对象的类型，并分别调用适当的方法。 也就是说，编译的时候该方法不与所在类绑定，编译器此时依然不知道对象的类型，但方法调用机制能自己去调查，找到正确的方法主体。java里实现动态绑定的是JVM. 动态绑定是实现多态的技术，是指在执行期间判断所引用对象的实际类型，根据其实际的类型调用其相应的方法。 多态的作用消除类型之间的耦合关系。即：把不同的子类对象都当作父类来看，可以屏蔽不同子类对象之间的差异，写出通用的代码，做出通用的编程，以适应需求的不断变化。 多态存在的三个必要条件一、要有继承；二、要有重写；三、父类引用指向子类对象。 多态的优点1.可替换性（substitutability）。多态对已存在代码具有可替换性。2.可扩充性（extensibility）。多态对代码具有可扩充性。增加新的子类不影响已存在类的多态性、继承性，以及其他特性的运行和操作。实际上新加子类更容易获得多态功能。3.接口性（interface-ability）。多态是超类通过方法签名，向子类提供了一个共同接口，由子类来完善或者覆盖它而实现的。4.灵活性（flexibility）。它在应用中体现了灵活多样的操作，提高了使用效率。5.简化性（simplicity）。多态简化对应用软件的代码编写和修改过程，尤其在处理大量对象的运算和操作时，这个特点尤为突出和重要。 多态的实现方式Java中多态的实现方式： 接口实现 继承父类进行方法重写 同一个类中进行方法重载。例子无论工作还是学习中，笔都是我们经常用到的工具。但是笔的种类又非常的繁多，铅笔、签字笔、水笔、毛笔、钢笔…。现在我们要对“笔”进行抽象，抽象成一个抽象父类“Pen” 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.glmapper.demo.base;/** * 抽象父类：笔 * @author glmapper */public abstract class Pen &#123; //笔的长度 private int length; //颜色 private String color; //类型 private String type; //价格 private double price; //写字 public abstract void write(String cnt); public int getLength() &#123; return length; &#125; public void setLength(int length) &#123; this.length = length; &#125; public String getColor() &#123; return color; &#125; public void setColor(String color) &#123; this.color = color; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; public double getPrice() &#123; return price; &#125; public void setPrice(double price) &#123; this.price = price; &#125; &#125; 现在有两个子类，分别是：铅笔和钢笔。 铅笔类，继承父类Pen，并重写write方法1234567891011121314151617package com.glmapper.demo.base;/** * 铅笔类 继承父类 笔（满足必要条件一：有继承【其实如果是接口的话，implement实现也是可以的】） * @author glmapper * */public class Pencil extends Pen&#123; /** * 父类的抽象方法委托子类具体实现：覆盖 */ //满足必要条件二：要有重写【当然，如果是对于write有重载也是可以的，不同的概念而已】 @Override public void write(String cnt) &#123; System.out.println(&quot;这是一只铅笔写的内容，内容是：&quot;+cnt); &#125;&#125; 钢笔类，继承父类Pen，并重写write方法 1234567891011121314package com.glmapper.demo.base;/** * 钢笔类 继承父类 笔 * @author 17070738 * */public class Fountainpen extends Pen&#123; @Override public void write(String cnt) &#123; System.out.println(&quot;这是一支钢笔写的内容，内容是：&quot;+cnt); &#125;&#125; 测试： 12345678910111213package com.glmapper.demo.base;public class MainTest &#123; public static void main(String[] args) &#123; /* Pen pen= new Pencil();*/ //必要条件三：父类引用指向子类对象。 Pen pen= new Fountainpen(); pen.write(&quot;我是一支笔&quot;); &#125;&#125; 输出结果：这是一支钢笔写的内容，内容是：我是一支笔 说明可替换性：多态对笔Pen类工作，对其他任何子类，如铅笔、钢笔，也同样工作。可扩充性：在实现了铅笔、钢笔的多态基础上，很容易增添“笔”类的多态性。 接口一个Java接口，就是一些方法特征的集合。【本文角度并非是java基础角度来说，主要是以设计模式中的应用为背景，因此对于相关定义及用法请自行学习。http://www.runoob.com/java/java-interfaces.html】我们在平时的工作中，提到接口，一般会含有两种不同的含义， 指的是java接口，这是一种java语言中存在的结构，有特定的语法和结构 指一个类所具有的方法特征的集合，是一种逻辑上的抽象。 前者叫做“java接口”，后者叫着“接口”。例如：java.lang.Runnable就是一个java接口。 为什么使用接口我们考虑一下，假如没有接口会怎么样呢？一个类总归是可以通过继承来进行扩展的，这难道不足以我们的实际应用吗？一个对象需要知道其他的一些对象，并且与其他的对象发生相互的作用，这是因为这些对象需要借住于其他对象的行为以便于完成一项工作。这些关于其他对象的知识，以及对其他对象行为的调用，都是使用硬代码写在类里面的，可插入性几乎为0。如：钢笔中需要钢笔水，钢笔水有不同的颜色：钢笔水类：1234567891011121314151617181920212223package com.glmapper.demo.base;/** * 钢笔墨水 * @author glmapper */public class PenInk &#123; //墨水颜色 private String inkColor; public String getInkColor() &#123; return inkColor; &#125; public void setInkColor(String inkColor) &#123; this.inkColor = inkColor; &#125; public PenInk(String inkColor) &#123; super(); this.inkColor = inkColor; &#125; &#125; 钢笔中持有一个墨水类的对象引用： 123456789101112131415package com.glmapper.demo.base;/** * 钢笔类 继承父类 笔 * @author 17070738 * */public class Fountainpen extends Pen&#123; //引用持有 PenInk ink =new PenInk(&quot;black&quot;); @Override public void write(String cnt) &#123; System.out.println(&quot;钢笔墨水颜色是：&quot;+ink.getInkColor()); System.out.println(&quot;这是一支钢笔写的内容，内容是：&quot;+cnt); &#125;&#125; 但是这种时候，我们需要换一种颜色怎么办呢？就必须要对Fountainpen中的代码进行修改，将创建PenInk对象时的inkColor属性进行更改；现在假如我们有一个具体的类，提供某种使用硬代码写在类中的行为；现在，要提供一些类似的行为，并且可以实现动态的可插入，也就是说，要能够动态的决定使用哪一种实现。一种方案就是为这个类提供一个抽象父类，且声明出子类要提供的行为，然后让这个具体类继承自这个抽象父类。同时，为这个抽象父类提供另外一个具体的子类，这个子类以不同的方法实现了父类所声明的行为。客户端可以动态的决定使用哪一个具体的子类，这是否可以提供可插入性呢？改进之后的代码：子类1：黑色墨水1234567891011package com.glmapper.demo.base;/** * 黑色墨水 * @author glmapper */public class BlackInk extends PenInk&#123; public BlackInk() &#123; super(&quot;black&quot;); &#125;&#125; 子类2：蓝色墨水 1234567891011package com.glmapper.demo.base;/** * 蓝色墨水 * @author glmapper */public class BlueInk extends PenInk&#123; public BlueInk() &#123; super(&quot;blue&quot;); &#125;&#125; 钢笔类引用： 123456789101112131415161718package com.glmapper.demo.base;/** * 钢笔类 继承父类 笔 * @author 17070738 * */public class Fountainpen extends Pen&#123; PenInk ink ; //通过构造函数初始化PenInk ，PenInk由具体子类来实现 public Fountainpen(PenInk ink) &#123; this.ink = ink; &#125; @Override public void write(String cnt) &#123; System.out.println(&quot;钢笔墨水颜色是：&quot;+ink.getInkColor()); System.out.println(&quot;这是一支钢笔写的内容，内容是：&quot;+cnt); &#125;&#125; 客户端调用： 12345678public static void main(String[] args) &#123; /** * 使用黑色墨水子类 */ Pen pen= new Fountainpen(new BlackInk()); pen.write(&quot;我是一支笔&quot;); &#125; 从上面代码可以看出，确实可以在简单的情况下提供了动态可插入性。 但是由于java语言是一个单继承的语言，换言之，一个类只能有一个超类，因此，在很多情况下，这个具体类可能已经有了一个超类，这个时候，要给他加上一个新的超类是不可能的。如果硬要做的话，就只好把这个新的超类加到已有的超类上面，形成超超类的情况，如果这个超超类的位置也已经被占用了，就只好继续向上移动，直到移动到类等级结构的最顶端。这样一来，对一个具体类的可插入性设计，就变成了对整个等级结构中所有类的修改。这种还是假设这些超类是我们可以控制的，如果某些超类是由一些软件商提供的，我们无法修改，怎么办呢？因此，假设没有接口，可插入性就没有了保证。 类型java接口（以及java抽象类）用来声明一个新的类型。java设计师应当主要使用java接口和抽象类而不是具体类进行变量的类型声明、参数的类型声明、方法的返还类型声明，以及数据类型的转换等。当然，一个更好的做法是仅仅使用java接口，而不要使用抽象java类来做到上面这些。在理想的情况下，一个具体java类应当只实现java接口和抽象类中声明过的方法，而不应该给出多余的方法。 类型等级结构java接口（以及抽象类）一般用来作为一个类型的等级结构的起点java的类型是以类型等级结构的方式组织起来的，在一个类型等级结构里面，一个类型可以有一系列的超类型，这时这个类型叫做其超类型的子类型。子类型的关系是传递性：类型甲是类型乙的子类型，类型乙是类型丙的子类型，那么类型甲就是类型丙的子类型。 混合类型如果一个类已经有一个主要的超类型，那么通过实现一个接口，这个类可以拥有另一个次要的超类型。这种次要的超类型就叫做混合类型。例如：在java中， TreeMap类有多个类型，它的主要类型是AbstractMap,这是一种java的聚集；而Cloneable接口则给出了一个次要类型，这个类型说明当前类的对象是可以被克隆；同时Serializable也是一个次要类型，它表明当前类的对象是可以被序列化的。而NavigableMap继承了SortedMap,因为之前说到过，子类型是可以传递的，因此对于TreeMap来说，SortedMap（或者说NavigableMap）表明这个聚集类是可以排序的。 接口的一些用法 单接口方法：接口中只有一个方法；java语言中有很多但方法接口的使用，Runnalble接口中的run（）方法。 1234567891011121314public interface Runnable &#123; /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object&apos;s * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run();&#125; 标识接口：没有任何方法和属性的接口；标识接口不对实现它的类有任何语义上的要求，仅仅是表明实现该接口的类属于一个特定的类型。上面说到的Serializable接口就是一种标识接口。 12public interface Serializable &#123;&#125; 常量接口：用java接口来声明一些常量 12345package com.glmapper.demo.base;public interface MyConstants &#123; public static final String USER_NAME=&quot;admin&quot;;&#125;; 这样一来，凡是实现这个接口的类都会自动继承这些常量，并且都可以像使用自己的常量一样，不需要再用MyConstants.USER_NAME来使用。 抽象类在java语言里面，类有两种，一种是具体类，一种是抽象类。在上面给出的代码中，使用absract修饰的类为抽象类。没有被abstract修饰的类是具体类。抽象类通常代表一个抽象概念，它提供一个继承的出发点。而具体类则不同，具体类可以被实例化，应当给出一个有逻辑实现的对象模板。由于抽象类不可以被实例化，因此一个程序员设计一个新的抽象类，一定是用来被继承的。（不建议使用具体类来进行相关的继承）。 关于代码重构假设有两个具体类，类A和类B，类B是类A的子类，那么一个比较简单的方案应该是建立一个抽象类（或者java接口），暂定为C，然后让类A和类B成为抽象类C的子类【没有使用UML的方式来绘制，请见谅哈】。 上面其实就是里氏替换原则，后面会具体介绍到的。这种重构之后，我们需要做的就是如何处理类A和类B的共同代码和共同数据。下面给出相关准则。 抽象类应当拥有尽可能多的共同代码 在一个继承等级结构中，共同的代码应当尽量向结构的顶层移动，将重复的代码从子类中抽离，放在抽象父类中，提高代码的复用率。这样做的另外一个好处是，在代码发生改变时，我们只需要修改一个地方【因为共同代码均在父类中】。 抽象类应当拥有尽可能少的数据数据的移动方向是从抽象类到具体类，也就是从继承等级的顶层到底层的移动。我们知道，一个对象的数据不论是否使用都会占用资源，因此数据应当尽量放到具体类或者继承等级结构的低端。 Has - A 与Is -A当一个类是另外一个类的角色时【我 有一个 玩具】，这种关系就不应当使用继承来描述了，这个将会在后面说到的“合成/聚合复用原则”来描述。Has - A: 我有一只笔（聚合）Is - A:钢笔是一种笔（继承） 关于子类扩展父类的责任子类应当扩展父类的职责，而不是置换掉或者覆盖掉超类的职责。如果一个子类需要将继承自父类的责任取消或者置换后才能使用的话，就很有可能说明这个子类根本不属于当前父类的子类，存在设计上的缺陷。 最后，说明下，我们在平时的工作中会经常使用的工具类，再次特地申明一下，我们也尽可能少的去从工具类进行继承扩展。 参考： 《Java与模式》电子工业出版社出版，作者：阎宏。 http://www.runoob.com/java/java-interfaces.html]]></content>
      <categories>
        <category>java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象的四大基础特性]]></title>
    <url>%2F2018%2F11%2F10%2Fglmapper-bird-one%2F</url>
    <content type="text"><![CDATA[按照之前的学习规划，开始进行第一部分的学习。那么今天就重新认识一下JAVA中的四大特性：抽象、封装、继承、多态 抽象学习面向对象，抽象还是很重要的。面向对象最接近我们人类的思维，你的抽象能力就是你对万物万事总结和归纳的能力。关于抽象，就是从具体事物抽出、概括出它们共同的方面、本质属性与关系等，而将个别的、非本质的方面、属性与关系舍弃，这种思维过程，称为抽象。在JAVA中表现就是使用abstract来修饰类，被abstract修饰的类成为抽象类，一般是为了为子类提供一些共有的属性和行为，不同的子类根据自身的特性再进行具体的行为实现。 封装封装是面向对象的重要原则，就是把对象的属性和行为（方法）结合为一个独立的整体，并尽可能隐藏对象的内部实现细节；在java中，对于对象的内部属性一般用private来实现隐藏，并通过set和get方法对外提供访问接口。封装实际上是一种信息隐藏技术的实现方式。 对象的数据封装特性彻底消除了传统结构方法中数据与操作分离所带来的种种问题，提高了程序的可复用性和可维护性，降低了程序员保持数据与操作内容的负担。 对象的数据封装特性还可以把对象的私有数据和公共数据分离开，保护了私有数据，减少了可能的模块间干扰，达到降低程序复杂性、提高可控性的目的。 例如：对于客观存在的人这个对象进行属性和行为抽象【此处仅仅是部分抽象】；使用private关键字来修饰人的属性，并通过对应的set和get方法对外界提供访问入口；在行为方面，通过public关键字来修饰，对外提供具体的行为描述。外界对象并不知道“人”这个对象在内部发生了什么，仅仅是通过提供的方法来获得具体的描述信息。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 人 * @author glmapper * */public class Person &#123; //姓名 private String name; //年龄 private int age; //性别 private String sex; //身高 private float high; //体重 private float weight; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public float getHigh() &#123; return high; &#125; public void setHigh(float high) &#123; this.high = high; &#125; public float getWeight() &#123; return weight; &#125; public void setWeight(float weight) &#123; this.weight = weight; &#125; public void eat()&#123; System.out.println(&quot;吃东西&quot;); &#125; public void walk()&#123; System.out.println(&quot;走路&quot;); &#125; public void study()&#123; System.out.println(&quot;学习&quot;); &#125;&#125; 继承继承是面向对象最显著的一个特性，是从已有的类中派生出新的类，我们把它称之为子类，子类继承父类的属性和行为，并能根据自己的需求扩展出新的属性和行为，提高了代码的可复用性。 提高了代码的复用性。 让类与类之间产生了关系，给第三个特征多态提供了前提。 Java的继承通过extends关键字来实现，实现继承的类被称为子类，被继承的类称为父类(有的也称其为基类、超类)，父类和子类的关系，是一种一般和特殊的关系；子类扩展父类，将可以获得父类的全部属性和方法。 男人是人的一种，男人的特征是有胡子，因此也有剪胡子的行为【有胡子和剪胡子并非依赖关系；一个是属性，一个是行为】；但是男人继承了人这个父类，因此，男人也具有例如姓名、性别、身高、体重等属性，同时也具有父类人具有的吃饭、走路和学习的行为。123456789101112131415161718192021/** * 男人 * @author glmapper * */public class Man extends Person&#123; //胡子 private String goatee; public String getGoatee() &#123; return goatee; &#125; public void setGoatee(String goatee) &#123; this.goatee = goatee; &#125; public void shaved()&#123; System.out.println(&quot;剪胡子&quot;); &#125;&#125; 重写父类的方法：大部分的时候，子类总是以父类为基础，额外添加新的属性和方法。但有一种情况例外：子类需要重写父类的方法。例如男人吃东西比较快，女人吃东西比较慢，因此对于eat方法来说，Man可以覆盖父类的eat方法，来描述Man本身的特点。 1234@Overridepublic void eat()&#123; System.out.println(&quot;快速的吃东西&quot;);&#125; 当子父类中出现相同方法时，会先运行子类中的方法。重写的特点：方法名一样，访问修饰符权限不小于父类，返回类型一致，参数列表一致。 多态定义：指允许不同类的对象对同一消息做出响应。即同一消息可以根据发送对象的不同而采用多种不同的行为方式。（发送消息就是函数调用）实现多态的技术称为：动态绑定（dynamic binding），是指在执行期间判断所引用对象的实际类型，根据其实际的类型调用其相应的方法。从语言特点上来说，Java引用变量有两个类型：一个是编译时类型，一个是运行时类型。编译时的类型由声明该变量时使用的类型决定，运行时的类型由实际赋给该变量的对象决定。如果编译时类型和运行时类型不一致，就会出现所谓的多态（Polymorphism）。封装和继承都是为Java语言的多态提供了支撑；多态存在的三个必要条件： 要有继承； 要有重写； 父类引用指向子类对象。 具体的实现方式就是：接口实现，继承父类进行方法重写，同一个类中进行方法重载。 下一篇在说类和接口的时候再用具体的例子来描述覆盖、重载。]]></content>
      <categories>
        <category>java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[菜鸟成长系列-概述]]></title>
    <url>%2F2018%2F11%2F10%2Fglmapper-bird-overall%2F</url>
    <content type="text"><![CDATA[前言作为渣硕一枚，毕业时一线互联网公司招聘基本没有参与过，等回过神准备参加，春招都快结束了【17年毕业】；跌跌撞撞面了几家公司，虽然被虐，但是基本上都给了Offer，几番比较之后到了苏宁，选择做一枚金融码农。虽然网上关于在苏宁做IT有着不同的看法，有好有坏，褒贬不一，但就我而言，作为新人，苏宁还是给我提供了不错的工作和学习环境【入职快4个月了】。言归正传，作为一个初入职场的新人，面对很多复杂的业务场景，不同的开源技术的使用，一开始确实有点“慌”，但是随着慢慢的渗入，从能够将一个项目成功跑起来，到对着详设给代码加注释，到自己去画某一条业务线的流程图，到第一次独立完成一个需求，再到不断的去发现现有框架或者业务逻辑中的问题并去尝试优化；这个过程还是很“吃鸡”的。技术始终是来支撑业务的，熟悉产品很重要，只有深入了解了某一个业务，然后拓展出与其他业务的关系，这样才可以发现问题，找到切入点去做具体的代码优化和业务优化。所以人人都是产品经理这句话很中肯，特别是程序员，要学会和产品经理“讨价还价”。 为什么要写为什么要写，最开始的想法就是把自己工作中的问题和坑记录下来，以便于自己不会再调到坑里面去。但是后来发现跑偏了，在没有具体深入了解的情况下开始“借鉴”+“总结”。后来再去看，该不会的还是不会，这就很无奈。网上有很多什么“JAVA学习路线一览”、“数据库学习路线一览”，“Spring学习路线一览”。。。，实话实说，尝试过，但是都失败了，走不下去。比如说我想学习java集合，然后就去看，去总结，然后就会发现，线程安全和不安全在集合里面的比较很多，然后就去看线程安全相关，然后再走，就会发现从这个坑跳到了另外一个坑，一方面是没有足够的时间去研究，另一方面没有把自己的思维放进去，结果就是学到的还是很碎的东西。因此放弃别人的成功之路，回来走自己的独木桥。结合自己之前的一些技术积累和实际工作的需求，来整合。看了很多，却发现深入的不多。一开始想的是从java的Object开始写，但是当我去尝试一次之后就放弃了【其实从java基础类库学还是很不错的】；我觉得不适合我这种不按套路出牌的人，因此就给自己定了一个框，在框里学。这个框是什么呢？就是设计模式。无论是java基础类库的设计还是Spring体系的设计基本都离不开设计模式的使用，为什么说不从Object开始，不从Spring的启动开始就是因为当我顺着一条线开始走的时候，就会牵扯出无数条线，直到不知道去往哪一条开始。只有当前站在顶层去看整体的时候，才会对全局有一个把握，才能直到不同分支的关系，才能更好的学抓细节。 写什么我的想法是以设计模式为主线来贯穿，开始重新学习。【从java语言的角度】设计模式中基本上都是围绕六种设计原则来约束的，再利用JAVA中提供抽象、继承、多态提供的机制来进行具体的实现。顺着这个思路简单罗列下我自己的学习路线：因为需要使用JAVA，那么就必须先要对抽象、继承和多态有一个比较清楚的理解，因此第一部分将会从java语言本身的特色来学习，主要包括： 1.抽象，继承，多态的理解 2.类和接口 3.面向接口编程的理解OK，到此就收，第一部分就把后面设计模式中我们需要用的方式的基础定了个基调。第二部分就直接进入设计模式范畴之内： 1.设计原则 2.创建型 3.结构型 4.行为型在学习某个具体的设计模式的时候会结合java语言中某些类库来讨论，穿插学习；第二部分之后，对于设计模式、设计模式在java中的应用、Spring的顶层设计以及java中的一些类库会有一个大体的掌握。这个部分会需要很长时间，会涉及到的知识点会很多，有点慌。第三部分开始数据结构，为什么是数据结构而不是并发或者数据库呢。一方面在java中很多关于并发的问题都会涉及到集合的使用，集合内部就依赖于不同的数据结构；数据库方面，如果都不清楚数据库是怎么存数据的，就不可能知道怎么去优化；如果都不知道数据库中的数据的存储结构是什么，又怎么能知道数据是怎么存的呢？上面三个部分结束之后，关于java差不多也就结束了。那么作为一个程序员，对于网络理解和开源技术的使用才是真正快速解决实际问题和吃饭问题的根本。spring、mybatis、redis，struts2,hibernate,以及相关rpc框架。关于java虚拟机这个东西不会单独的写了，感觉写不出来，等有了实际的经验积累之后再去谈吧。。。结束语其实我们每个人每天都会有想法，好坏不说，要去试试，这篇文章写完之后我也不知道自己能走到哪个部分，但是还是回去尝试走一走。我也不知道这种学习的“野路子”适合不适合，但是就现在【2017.11.5 11:59】看，我觉得对我是可以的。]]></content>
      <categories>
        <category>架构之路</category>
      </categories>
      <tags>
        <tag>规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[项目开发框架-SSM]]></title>
    <url>%2F2018%2F11%2F10%2Fproject-frame-ssm%2F</url>
    <content type="text"><![CDATA[1.Spring无需多言，作为开源届数一数二的典例，项目开发中无处不在；核心IOC容器，用来装载bean（java中的类）-用Spring的IOC容器来管理Bean的生命周期，有了这样一种机制，我们就可以不用在代码中去重复的做new操作。aop，面向切面编程，spring中最主要的是用于事务方面的使用。 2.Spring MVC作用于web层，相当于controller，与struts中的action一样，都是用来处理用户请求的。同时，相比于struts2来说，更加细粒度，它是基于方法层面的，而struts是基于类层面的。 3.MyBatisMyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。[来自：http://www.mybatis.org/mybatis-3/zh/index.html] 他人总结 Hibernate功能强大，数据库无关性好，O/R映射能力强，如果你对Hibernate相当精通，而且对Hibernate进行了适当的封装，那么你的项目整个持久层代码会相当简单，需要写的代码很少，开发速度很快，非常爽。 Hibernate的缺点就是学习门槛不低，要精通门槛更高，而且怎么设计O/R映射，在性能和对象模型之间如何权衡取得平衡，以及怎样用好Hibernate方面需要你的经验和能力都很强才行。 MYBATIS入门简单，即学即用，提供了数据库查询的自动对象绑定功能，而且延续了很好的SQL使用经验，对于没有那么高的对象模型要求的项目来说，相当完美。 MYBATIS的缺点就是框架还是比较简陋，功能尚有缺失，虽然简化了数据绑定代码，但是整个底层数据库查询实际还是要自己写的，工作量也比较大，而且不太容易适应快速数据库修改。4.SSM框架整合本项目将以购物为背景，主要包括商品信息及库存【因为想顺便学习一下事务的处理】、订单信息。下面将从数据库创建、项目结构说明、配置文件、业务代码等方面进行一步步说明。4.1 数据库创建1.商品表123456CREATE TABLE `goods` ( `goods_id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;商品ID&apos;, `goodsname` varchar(100) NOT NULL COMMENT &apos;商品名称&apos;, `number` int(11) NOT NULL COMMENT &apos;商品库存&apos;, PRIMARY KEY (`goods_id`)) ENGINE=InnoDB AUTO_INCREMENT=1000 DEFAULT CHARSET=utf8 COMMENT=&apos;商品表&apos; 初始化表数据12INSERT INTO `goods` (`goods_id`, `goodsname`, `number`)VALUES (1001, &apos;SN卫衣&apos;, 15) 2.订单表12345678CREATE TABLE `orderinfo` ( `order_id` varchar(20) NOT NULL COMMENT &apos;订单编号&apos;, `goods_id` bigint(18) NOT NULL COMMENT &apos;商品ID&apos;, `user_id` bigint(10) NOT NULL COMMENT &apos;用户ID&apos;, `order_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;下单时间&apos; , PRIMARY KEY (`order_id`), INDEX `idx_order_id` (`order_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;订单表&apos; OK，至此表结构及初始化数据构建完成，下面说下基于Mavan的项目结构。 项目结构说明因为项目是使用maven来管理jar包的，先来贴一下，pom.xml的配置 pom.xml为了避免学习小伙伴崇尚拿来主义【也就是去除了xmlns之类的东西】，这里只放项目依赖的jar包的dependencies；本案例将本着“需则用”的原则，避免在网上看到的各种乱七八糟的依赖都丢进来的情况，造成资源浪费和干扰阅读。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134&lt;dependencies&gt; &lt;!-- 单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 1.日志 slf4j--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 2.数据库连接驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 2.数据库连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 3.MyBatis 以及 spring-mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 4.Servlet 相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 5.Spring --&gt; &lt;!-- 5.1 Spring核心 ：core bean context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 5.2 Spring jdbc依赖，事务依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 5.3 Spring web依赖&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 5.4 Spring test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 6.redis客户端:Jedis【不使用的话可以直接去除】 --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.7.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt; &lt;version&gt;1.0.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt; &lt;version&gt;1.0.8&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 7.工具类 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; *项目结构图 src/test/java：用于junit的测试类 src/main/java: dao:数据库处理 service:业务处理 enums:项目枚举 mapper:dao中方法对应mybatis映射文件，Sql就在这里面 web：控制器，controller entity:项目中的实体类，如：商品类和订单类 配置文件 jdbc.properties1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://serverName:port/dbname?useUnicode=true&amp;characterEncoding=utf8jdbc.username=[填写自己的数据库用户名]jdbc.password=[填写自己的数据库登录密码] logback.xml这里直接用的是控制台输出，如果是生产环境，可以根据具体的需求进行配置。 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration debug=&quot;true&quot;&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; ch.qos.logback.classic.encoder.PatternLayoutEncoder --&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;debug&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; mybatis-config这里主要是MyBaties全局配置文件的配置，可以将一些类的别名、主键自增配置、驼峰命名规则配置等。 12345678910111213&lt;configuration&gt; &lt;!-- 配置全局属性 --&gt; &lt;settings&gt; &lt;!-- 使用jdbc的getGeneratedKeys获取数据库自增主键值 --&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;true&quot; /&gt; &lt;!-- 使用列别名替换列名 默认:true --&gt; &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot; /&gt; &lt;!-- 开启驼峰命名转换:Table&#123;create_time&#125; -&gt; Entity&#123;createTime&#125; --&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot; /&gt; &lt;/settings&gt;&lt;/configuration&gt; spring 相关配置文件为了更加清晰的了解spring各个组件的作用，这里将数据源的配置、事务配置和视图解析器的配置分开来。spring-dao.xml这里面主要就是spring配置整合mybatis的具体过程，具体包括：1.引入数据库配置文件2.配置数据源【数据库连接池】3.配置SqlSessionFactory对象4.配置扫描Dao接口包，动态实现Dao接口，注入到spring容器中 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- 1.配置数据库相关参数properties的属性：$&#123;url&#125; --&gt;&lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot; /&gt;&lt;!-- 2.数据库连接池 --&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;!-- 配置连接池属性 --&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driver&#125;&quot; /&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot; /&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;!-- c3p0连接池的私有属性 --&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;30&quot; /&gt; &lt;property name=&quot;minPoolSize&quot; value=&quot;10&quot; /&gt; &lt;!-- 关闭连接后不自动commit --&gt; &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;false&quot; /&gt; &lt;!-- 获取连接超时时间 --&gt; &lt;property name=&quot;checkoutTimeout&quot; value=&quot;10000&quot; /&gt; &lt;!-- 当获取连接失败重试次数 --&gt; &lt;property name=&quot;acquireRetryAttempts&quot; value=&quot;2&quot; /&gt;&lt;/bean&gt;&lt;!-- 3.配置SqlSessionFactory对象 --&gt;&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- 配置MyBaties全局配置文件:mybatis-config.xml --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot; /&gt; &lt;!-- 扫描entity包 使用别名 --&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.glmapper.framerwork.entity&quot; /&gt; &lt;!-- 扫描sql配置文件:mapper需要的xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;com.glmapper.framerwork.mapper/*.xml&quot; /&gt;&lt;/bean&gt;&lt;!-- 4.配置扫描Dao接口包，动态实现Dao接口，注入到spring容器中 --&gt;&lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!-- 注入sqlSessionFactory --&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot; /&gt; &lt;!-- 给出需要扫描Dao接口包 --&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.glmapper.framerwork.dao&quot; /&gt;&lt;/bean&gt; spring-service实际的开发过程中事务一般都是在service层进行操作。因此用一个单独的spring-service.xml来进行事务的相关的配置 12345678910 &lt;!-- 扫描service包下所有使用注解的类型 --&gt;&lt;context:component-scan base-package=&quot;com.glmapper.framerwork.service&quot; /&gt;&lt;!-- 配置事务管理器 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;!-- 注入数据库连接池 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;&lt;!-- 配置基于注解的声明式事务 --&gt;&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; /&gt; spring-web.xml配置SpringMVC；需要说明一下，一般我们在实际的开发过程中，会配置json2map解析。这里没有用到就不贴出来，读者可以自行网上搜索一波。 1234567891011121314151617&lt;!-- 1.开启SpringMVC注解模式 --&gt;&lt;mvc:annotation-driven /&gt;&lt;!-- 2.静态资源默认servlet配置 (1)加入对静态资源的处理：js,css,图片等 (2)允许使用&quot;/&quot;做整体映射 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 3.配置视图解析器ViewResolver --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot; /&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot; /&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt; &lt;/bean&gt; &lt;!-- 4.扫描web相关的bean --&gt; &lt;context:component-scan base-package=&quot;com.glmapper.framerwork.web&quot; /&gt; web.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!-- 编码过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;async-supported&gt;true&lt;/async-supported&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- Spring监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 防止Spring内存溢出监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.IntrospectorCleanupListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置DispatcherServlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 配置springMVC需要加载的配置文件 spring-dao.xml,spring-service.xml,spring-web.xml Mybatis - &gt; spring -&gt; springmvc --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/spring-*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;!-- 默认匹配所有的请求 --&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 至此，所有的配置文件结束，下面将进行具体的代码环节 业务代码这里mapper中的xml文件就不贴了，自行脑补。。。。 实体类：包括商品和订单 商品类1234567891011121314151617181920212223242526272829/** * 商品信息类 * @author glmapper * */public class Goods &#123; private long goodsId;// 商品ID private String goodsName;// 商品名称 private int number;// 商品库存 public long getGoodsId() &#123; return goodsId; &#125; public void setGoodsId(long goodsId) &#123; this.goodsId = goodsId; &#125; public String getGoodsName() &#123; return goodsName; &#125; public void setGoodsName(String goodsName) &#123; this.goodsName = goodsName; &#125; public int getNumber() &#123; return number; &#125; public void setNumber(int number) &#123; this.number = number; &#125;&#125; 订单类 1234567891011121314151617181920212223242526272829303132333435/** * 订单信息类 * @author glmapper * */public class OrderInfo &#123; private String orderId;//订单ID private long goodsId;//商品ID private long userId;//用户ID private Date orderTime;//下单时间 public String getOrderId() &#123; return orderId; &#125; public void setOrderId(String orderId) &#123; this.orderId = orderId; &#125; public long getGoodsId() &#123; return goodsId; &#125; public void setGoodsId(long goodsId) &#123; this.goodsId = goodsId; &#125; public long getUserId() &#123; return userId; &#125; public void setUserId(long userId) &#123; this.userId = userId; &#125; public Date getOrderTime() &#123; return orderTime; &#125; public void setOrderTime(Date orderTime) &#123; this.orderTime = orderTime; &#125;&#125; 商品dao 12345678910111213141516171819202122232425262728public interface GoodsDao &#123; /** * 通过ID查询单件商品信息 * * @param id * @return */ Goods queryById(long id); /** * 查询所有商品信息 * * @param offset 查询起始位置 * @param limit 查询条数 * @return */ List&lt;Goods&gt; queryAll(@Param(&quot;offset&quot;) int offset, @Param(&quot;limit&quot;) int limit); /** * 减少商品库存 * * @param bookId * @return 如果影响行数等于&gt;1，表示更新的记录行数 */ int reduceNumber(long goodsId);&#125; 订单dao 1234567891011121314151617public interface OrderInfoDao &#123; /** * 插入订单记录 * * @param OrderInfo orderInfo * @return 插入的行数 */ int insertOrderInfo(OrderInfo orderInfo); /** * 通过主键查询订单记录，返回订单实体 * @param orderId * @return */ OrderInfo queryByOrderId(String orderId);&#125; 下单服务接口orderService 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Service(&quot;orderService&quot;)public class OrderServiceImpl implements OrderService &#123; //log生成器 private Logger logger = LoggerFactory.getLogger(OrderServiceImpl.class); // 注入dao依赖【商品dao，订单dao】 @Autowired private GoodsDao goodsDao; @Autowired private OrderInfoDao orderInfoDao; @Override public Goods getById(long goodsId) &#123; // TODO Auto-generated method stub return goodsDao.queryById(goodsId); &#125; @Override public List&lt;Goods&gt; getList(int offset,int limit) &#123; // TODO Auto-generated method stub return goodsDao.queryAll(offset, limit); &#125; @Override @Transactional public OrderInfo buyGoods(long goodsId, long userId) &#123; //扣减库存，插入订单 =一个事务 如果失败则执行回滚 try &#123; // 减库存 int update = goodsDao.reduceNumber(goodsId); if (update &lt;= 0) &#123;// 库存不足 throw new NoNumberException(&quot;no number&quot;); &#125; else &#123; // 执行预约操作 OrderInfo orderInfo=new OrderInfo(); orderInfo.setGoodsId(goodsId); orderInfo.setUserId(userId); orderInfo.setOrderTime(new Date()); String orderId=getRandomOrderId(goodsId); orderInfo.setOrderId(orderId); int insert = orderInfoDao.insertOrderInfo(orderInfo); if (insert &lt;= 0) &#123;// 重复预约 throw new RepeatAppointException(&quot;repeat appoint&quot;); &#125; else &#123;// 预约成功 return orderInfo; &#125; &#125; &#125; catch (Exception e) &#123; //这里可以丰富下具体的返回信息 logger.error(&quot;下单失败&quot;); &#125; return null; &#125; private String getRandomOrderId(long goodsId) &#123; SimpleDateFormat dateFormater = new SimpleDateFormat(&quot;yyyyMMddhhmmss&quot;); String prefix=dateFormater.format(new Date()); String goodsIdStr=goodsId+&quot;&quot;; String temp=&quot;&quot;; for (int i = 0; i &lt; 6; i++) &#123; Random random=new Random(goodsIdStr.length()-1); temp+=goodsIdStr.charAt(random.nextInt()); &#125; return prefix+temp; &#125;&#125; OK，至此所有核心代码及配置文件罗列完毕；【mapper中的xml和具体的controller就不贴了，相信大家对这个也不陌生。本文主要意图在于梳理下自己学习中的一些点，SSM框架在实际的应用开发中还会有很多其他的开源技术结合进来，如：quartz,redis等。当前本文的列子就是一个空壳子，以备参考吧】]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>ssm</tag>
        <tag>spring</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA基础知识系列---进程、线程安全]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-thread-base%2F</url>
    <content type="text"><![CDATA[1.1 临界区保证在某一时刻只有一个线程能访问数据的简便方法，在任意时刻只允许一个线程对资源进行访问。如果有多个线程试图同时访问临界区，那么在有一个线程进入后，其他所有试图访问临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操作共享资源的目的 1.2 互斥量互斥量和临界区很相似，只能拥有互斥对象的线程才能具有访问资源的权限，由于互斥对象只有一个，因此就决定了任何情况下次共享资源都不会同时被多个线程所访问。当前占据资源的线程在任务处理完后应将拥有的互斥对象交出，以便其他线程在获得后可以访问资源。互斥量比临界区复杂，因为使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。 1.3 管程/信号量管程和信号量是同一个概念。指一个互斥独占锁定的对象或称为互斥体。在给定的时间，仅有一个线程可以获得管程。当一个线程需要锁定，他必须进入管程。所有其他的试图进入已经锁定的管程的线程必须挂起直到第一个线程退出管程。这些其他的线程被称为等待线程。一个拥有管程的线程如果愿意的话可以再次进入相同的管程（可重入性） 1.4 CAS操作CAS操作（compare and swap）CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则返回V。这是一种乐观锁的思路，它相信在它修改之前，没有其它线程去修改它；而Synchronized是一种悲观锁，它认为在它修改之前，一定会有其它线程去修改它，悲观锁效率很低。下面来看一下AtomicInteger是如何利用CAS实现原子性操作的。 1.5 重排序编译器和处理器为了提高性能，而在程序执行时会对程序进行重排序。他的出现是为了提高程序的并发度。从而提高性能；但是对于多线程程序，重排序可能会导致程序执行的结果不是我们需要的结果，重排序分为编译器和处理器俩个方面。而处理器重排序包括指令级重排序和内存重排序。 小节在java中，所有的变量（实例字段，静态字段，构成数组的元素，不包括局部变量和方法参数）都存储在主内存中，内个线程都有自己的工作内存，线程的工作内存保存被线程使用到的变量的主内存副本拷贝。线程对变量的所有操作都必须在工作内存中进行，为不能直接读写主内存的变量。不同线程之间也不恩能够直接访问对方工作内存中的变量，线程间比变量值的传递通过主内存来完成。 JAVA中线程安全相关关键字及类主要包括：synchronized，Volitile，ThreadLocal，Lock，Condition 2.1 Volitile作用： 1）保证了心智能立即存储到主内存才，每次使用前立即从主内存中刷新 2）禁止指令重排序优化 Volitile关键字不能保证在多线程环境下对共享数据的操作的正确性，可以使用在自己状态改变之后需要立即通知所有线程的情况下，只保证可见性，不保证原子性。即通过刷新变量值确保可见性。 Java中synchronized和final也能保证可见性 synchronized：同步快通过变量锁定前必须清空工作内存中的变量值，重新从主内存中读取变量值，解锁前必须把变量值同步回主内存来确保可见性。 final:被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this引用传递进去，那么在其他线程中就能看见final字段的值，无需同步就可以被其他线程正确访问。 2.2 synchronized把代码块声明为synchronized，有俩个作用，通常是指改代码具有原子性和可见性。如果没有同步机制提供的这种可见性，线程看到的共享比那里可能是修改前的值或不一致的值，这将引发许多严重问题。 原理：当对象获取锁是，他首先是自己的高速缓存无效，这样就可以保证直接从主内存中装入变量，同样在对象释放锁之前，他会刷新其高速缓存，强制使已做的任何更改都出现在主内存中，这样会保证在同一个锁上同步的俩个线程看到在synchronized块内修改的变量的相同值。 synchronized释放由JVM自己管理。 存在的问题： 1）无法中断一个正在等待获得锁的线程 2）无法通过投票得到锁，如果不想等待下去，也就没法得到锁 3）同步还需要锁的释放只能在与获得锁所在的堆栈帧相同的堆栈中进行，多数情况下，这没问题（而且与一场处理交互的很好），但是，确实存在一些非块结构的锁定更适合情况。 2.3 LockLock是有JAVA编写而成的，在java这个层面是无关JVM实现的。包括：ReentrantLock，ReadWriteLock。其本质都依赖于AbstractQueueSynchronized类。Lock提供了很多锁的方式，尝试锁，中断锁等。释放锁的过程由JAVA开发人员自己管理。 就性能而言，对于资源冲突不多的情况下synchronized更加合理，但如果资源访问冲突多的情况下，synchronized的性能会快速下降，而Lock可以保持平衡。 2.4 conditionCondition将Object监视器方法（wait，notify,notifyall）分解成截然不同的对象，以便通过这些对象与任意Lock实现组合使用，为每个对象提供多个等待set(wait-set),，其中Lock替代了synchronized方法和语句的使用，condition替代了Object监视器方法的使用。Condition实例实质上被你绑定到一个锁上。要为特定Lock实例获得Condition实例，请使用其newCondition（）方法。 2.5 ThreadLock线程局部变量。 变量是同一个，但是每个线程都使用同一个初始值，也就是使用同一个变量的一个新的副本，这种情况下TreadLocal就非常有用。 应用场景：当很多线程需要多次使用同一个对象，并且需要该对象具有相同初始值的时候，最适合使用TreadLocal。 事实上，从本质上讲，就是每个线程都维持一个MAP，而这个map的key就是TreadLocal,而值就是我们set的那个值，每次线程在get的时候，都从自己的变量中取值，既然从自己的变量中取值，那就肯定不存在线程安全的问题。总体来讲，TreadLocal这个变量的状态根本没有发生变化。它仅仅是充当了一个key的角色，另外提供给每一个线程一个初始值。如果允许的话，我们自己就能实现一个这样的功能，只不过恰好JDK就已经帮助我们做了这个事情。 使用TreadLocal维护变量时，TreadLocal为每个使用该变量的线程提供独立地变量副本，所以每一个线程都可以独立地改变自己的副本，而不会英语其他线程所对应的副本。从线程的角度看，目标变量对象是线程的本地变量，这也是类名中Local所需要表达的意思。 TreadLocal的四个方法： void set(Object val),设置当前线程的线程局部变量的值 Object get（）返回当前线程所对用的线程局部变量。 void remove() 将当前线程局部变量的值删除，目的是为了减少内存的占用，线程结束后，局部变量自动被GC Object initValue() 返回该线程局部变量的初始值，使用protected修饰，显然是为了让子类覆盖而设计的。 线程安全的实现方式3.1 互斥同步在多线程访问的时候，保证同一时间只有一条线程使用。 临界区，互斥量，管程都是同步的一种手段。 java中最基本的互斥同步手段是synchronized，编译之后会形成monitorenter和monitorexit这俩个字节码指令，这俩个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象，还有一个锁的计数器，来记录加锁的次数，加锁几次就要同样解锁几次才能恢复到无锁状态。 java的线程是映射到操作系统的原生线程之上的，不管阻塞还是唤醒都需要操作系统的帮助完成，都需要从用户态转换到核心态，这是很耗费时间的，是java语言中的一个重量级的操作，虽然虚拟机本身会做一点优化的操作，比如通知操作系统阻塞之前会加一段自旋等待的过程，避免频繁切换到核心态。 3.2 非阻塞同步互斥和同步最主要的问题就是阻塞和唤醒所带来的性能的问题，所以这通常叫阻塞同步（悲观的并发策略）.随着硬件指令集的发展，我们有另外的选择：基于冲突检测的乐观并发策略，通俗讲就是先操作，如果没有其他线程争用共享的数据，操作就成功，如果有，则进行其他的补偿（最常见的就是不断的重试）。这种乐观的并发策略许多实现都不需要把线程先挂起，这种同步操作被称为非阻塞同步。 3.3 无同步部分代码天生就是线程安全的，不需要同步。 1）可重入代码：纯代码，具有不依赖存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等特征，它的返回结果是可以预测的。 2）线程本地存储：把共享数据的可见性范围限制在同一个线程之内，这样就无需同步也能保证线程之间不出现数据争用问题。可以通过java.lang.TreadLocal类来实现线程本地存储的功能。]]></content>
      <categories>
        <category>java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>线程</tag>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web核心-Servlet]]></title>
    <url>%2F2018%2F11%2F10%2Fservletbase1%2F</url>
    <content type="text"><![CDATA[Servlet实际上是ServerApplet–小服务程序或服务连接器，用Java编写的服务器端程序，主要功能在于交互式地浏览和修改数据，生成动态Web内容。与常用的协议，如DNS，TCP/IP，HTTP类似，Servlet是作为一整套规范存在的；同时作为J2EE标准的一部分，定义了javaweb开发的标准。Servlet制定了java处理WEB请求的一系列标准，我们只需要按照标准规定的去做就可以了。实际上，无论是Struts2的FilterDispatcher还是SpringMvc的DispatcherServlet,其底层都是通过实现Sevlet或者Servlet类型的扩展【如：GenericServlet】来实现的。 1.Servlet接口下图为Servlet3.1中的结构图：因为Servlet是以规范的方式存在的，实际上就是定义一系列规范接口。在Servlet接口中，主要包括以下几个接口： 1)init方法是在容器启动时被容器调用，且只会被调用一次； 2)getServletConfig方法用于获取ServletConfig； 3)service方法用于处理一个具体的请求 4)getServletInfo方法用于获取Servlet相关的信息：版权等。 5)destroy方法用来销毁一个Servlet，和init一样，只会被调用一次，一般在服务器关闭时用于释放一些资源。 init方法调用时会接受一个ServletConfig类型的参数，用于初始化Servlet，由容器传入。ServletConfig，顾名思义，其包含了Serlvet的配置信息。通常情况下，我们在web.xml文件中定义Serlvet时，会通过init-param标签来进行参数配置。在Springmvc的配置中，通常通过以下方式来配置参数： 2.ServletConfig接口1)getServletName用于获取Servlet的名字，也就是我们在web.xml中定义的servlet-name2)getServletContext返回ServletContext，代表我们当前应用本身3)getInitParameter用于获取init-param配置的参数4)getInitParameterNames用于获取所有init-param配置名字的集合ServletContext和ServletConfig最常见的使用就是传递初始化参数。来看下spring中的contextConfigServlet的参数配置通过context-param配置的contextConfigLocation配置到了ServletContext中，再通过Servlet下的init-param配置的contextConfigLocation配置到ServletConfig中,在Servlet中可以通过getInitParameter方法获取具体的信息。 3.GenericServletGenericServlet是Servlet的默认实现，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package javax.servlet;import java.io.IOException;import java.io.Serializable;import java.util.Enumeration;import java.util.ResourceBundle;public abstract class GenericServlet implements Servlet, ServletConfig, Serializable&#123; private static final String LSTRING_FILE = &quot;javax.servlet.LocalStrings&quot;; private static ResourceBundle lStrings = ResourceBundle.getBundle(&quot;javax.servlet.LocalStrings&quot;); private transient ServletConfig config; public void destroy() &#123; &#125; public String getInitParameter(String name) &#123; ServletConfig sc = getServletConfig(); if (sc == null) &#123; throw new IllegalStateException(lStrings.getString(&quot;err.servlet_config_not_initialized&quot;)); &#125; return sc.getInitParameter(name); &#125; public Enumeration getInitParameterNames() &#123; ServletConfig sc = getServletConfig(); if (sc == null) &#123; throw new IllegalStateException(lStrings.getString(&quot;err.servlet_config_not_initialized&quot;)); &#125; return sc.getInitParameterNames(); &#125; public ServletConfig getServletConfig() &#123; return this.config; &#125; public ServletContext getServletContext() &#123; ServletConfig sc = getServletConfig(); if (sc == null) &#123; throw new IllegalStateException(lStrings.getString(&quot;err.servlet_config_not_initialized&quot;)); &#125; return sc.getServletContext(); &#125; public String getServletInfo() &#123; return &quot;&quot;; &#125; public void init(ServletConfig config) throws ServletException &#123; this.config = config; init(); &#125; public void init() throws ServletException &#123; &#125; public void log(String msg) &#123; getServletContext().log(getServletName() + &quot;: &quot; + msg); &#125; public void log(String message, Throwable t) &#123; getServletContext().log(getServletName() + &quot;: &quot; + message, t); &#125; public abstract void service(ServletRequest paramServletRequest, ServletResponse paramServletResponse) throws ServletException, IOException; public String getServletName() &#123; ServletConfig sc = getServletConfig(); if (sc == null) &#123; throw new IllegalStateException(lStrings.getString(&quot;err.servlet_config_not_initialized&quot;)); &#125; return sc.getServletName(); &#125;&#125; 从其继承和实现关系来看，GenericServlet主要做了3件事：1.实现了ServletConfig接口，这样我们就可以直接调用ServletConfig里面的方法； GenericServlet实现了ServletConfig，可以在需要的时候直接调用ServletConfig中的方法，不需要再先获取ServletConfig对象；比如，获取ServletContext的时候可以直接调用getServletContext,而无需调用getServletConfig().getServletContext(),但是实际上，其底层的内部实现还是在内部还是进行了getServletConfig().getServletContext()的调用。2.提供了无参的init方法 GenericServlet实现了Servlet的init（ServletConfig config）方法，在里面将config设置给了其内部变量config，然后调用了无参的init方法；此方法可以在子类中通过覆盖它来完成初始化工作。这种方式具有的有点包括以下几点： a.config设置为内部属性，这样可以在ServletConfig的接口方法中直接调用Config的相应方法来执行； b.我们在写Serlvet的时候可以不用再关心Config，只需要执行自己的初始化逻辑即可 c.在重写init方法时，不需要再调用super.init(config)。3.提供了Log方法 GenericServlet提供了2个log方法，一个用于记录日志，一个用于记录异常。其具体的实现是通过传给ServletConfig的日志实现的。 GenericServlet是与具体协议无关的。 4.HttpServletHttpServlet是基于Http协议实现的Servlet的基类，写Servlet时直接继承HttpServlet即可,不需要再重头实现Servlet接口，SpringMvc中的dispatcherServlet就是HttpServlet的子类。 HttpServlet是与Http协议相关的，HttpServlet处理请求主要是通过重写父类的service方法来完成具体的请求处理的。在service方法中首先是将ServletRequest和ServletResponse转换成HttpServletRequest和HttpServletResponse，然后根据请求的不同路由到不同的处理过程中去【处理方法就是我们常见的doXXX的方法。最常见的就是doGet和doPost】]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码系列：Spring的启动过程]]></title>
    <url>%2F2018%2F11%2F10%2Fspringbase1%2F</url>
    <content type="text"><![CDATA[Spring对于程序员说来说都不陌生；作为一个强大的开源技术，帮助我们能够更好的进行项目的开发与维护。直接进入主题吧。Spring的启动过程实际上就是Ioc容器初始化以及载入Bean的过程；本文主要是学习记录下前半部分（Ioc容器的初始化），新手上路，如有错误，请指正！1.从配置文件说起 12345678&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt; &lt;/listener&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; 在一般的WEB项目中，项目的启动一般是从web.xml文件的载入开始的。如果我们的项目中使用了Spring，那么你肯定会在你的web.xml文件中看到上面的配置。Spring正是通过ContextLoaderListener监听器来进行容器初始化的。下面通过代码进行分析。 2.Spring容器加载的三步走 step1:创建一个WebApplicationContext step2:配置并且刷新Bean step3：将容器初始化到servlet上下文中 3.WebApplicationContext的创建过程1public class ContextLoaderListener extends ContextLoader implements ServletContextListener 从ContextLoaderListener的定义可以看出，该监听器继承了ContextLoader，并且重写了ServletContextListener中的contextInitialized和contextDestroyed方法。 在contextInitialized中，通过调用父类（ContextLoader）的initWebApplicationContext方法进行容器创建：1234@Overridepublic void contextInitialized(ServletContextEvent event) &#123; initWebApplicationContext(event.getServletContext());&#125; 下面来看initWebApplicationContext的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; //1：判断当前容器是否存在，如果存在则报容器已经存在的异常信息 if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; throw new IllegalStateException( "Cannot initialize context because there is already a root application context present - " + "check whether you have multiple ContextLoader* definitions in your web.xml!"); &#125; Log logger = LogFactory.getLog(ContextLoader.class); //下面这个日志就是我们经常在启动Spring项目时看到的日志信息: //Initializing Spring root WebApplicationContext //Root WebApplicationContext: initialization started servletContext.log("Initializing Spring root WebApplicationContext"); if (logger.isInfoEnabled()) &#123; logger.info("Root WebApplicationContext: initialization started"); &#125; long startTime = System.currentTimeMillis(); try &#123; // Store context in local instance variable, to guarantee that // it is available on ServletContext shutdown. //如果当前容器为null,则创建一个容器，并将servletContext上下文作为参数传递进去， if (this.context == null) &#123; this.context = createWebApplicationContext(servletContext); &#125; //判断当前容器是否为可配置的，只有是Configurable的容器，才能进行后续的配置 if (this.context instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; // determine parent for root web application context, if any. ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); &#125; //三步走中的第二步：配置并且刷新当前容器 configureAndRefreshWebApplicationContext(cwac, servletContext); &#125; &#125; //将配置并且刷新过的容器存入servlet上下文中，并以WebApplicationContext的类名作为key值 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ClassLoader ccl = Thread.currentThread().getContextClassLoader(); if (ccl == ContextLoader.class.getClassLoader()) &#123; currentContext = this.context; &#125; else if (ccl != null) &#123; currentContextPerThread.put(ccl, this.context); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Published root WebApplicationContext as ServletContext attribute with name [" + WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + "]"); &#125; if (logger.isInfoEnabled()) &#123; long elapsedTime = System.currentTimeMillis() - startTime; logger.info("Root WebApplicationContext: initialization completed in " + elapsedTime + " ms"); &#125; //返回创建好的容器 return this.context; &#125; catch (RuntimeException ex) &#123; logger.error("Context initialization failed", ex); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex); throw ex; &#125; catch (Error err) &#123; logger.error("Context initialization failed", err); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err); throw err; &#125; &#125; 下面我们在看下是如何创建WebApplicationContext的 12345678910protected WebApplicationContext createWebApplicationContext(ServletContext sc) &#123; //首先来确定context是由什么类定义的，并且判断当前容器是否为可配置的 Class&lt;?&gt; contextClass = determineContextClass(sc); if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123; throw new ApplicationContextException("Custom context class [" + contextClass.getName() + "] is not of type [" + ConfigurableWebApplicationContext.class.getName() + "]"); &#125; //创建可配置的上下文容器 return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass); &#125; 最后来看下determineContextClass这个方法 12345678910111213141516171819202122232425protected Class&lt;?&gt; determineContextClass(ServletContext servletContext) &#123; //首先从web.xml中查看用户是否自己定义了context String contextClassName = servletContext.getInitParameter(CONTEXT_CLASS_PARAM); //如果有，则通过反射创建实例 if (contextClassName != null) &#123; try &#123; return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( "Failed to load custom context class [" + contextClassName + "]", ex); &#125; &#125; /*如果没有，则去defaultStrategies里面取【defaultStrategies是Propertites类的/对象，在ContextLoader中的静态代码块中初始化的；具体可看下下面的图像】；默认容器是XmlWebApplicationContext*/ else &#123; contextClassName = defaultStrategies.getProperty(WebApplicationContext.class.getName()); try &#123; return ClassUtils.forName(contextClassName, ContextLoader.class.getClassLoader()); &#125; catch (ClassNotFoundException ex) &#123; throw new ApplicationContextException( "Failed to load default context class [" + contextClassName + "]", ex); &#125; &#125; &#125; 总的来说就是：Spring的web工程首先回去检查用户是否自己定义了context，如果有就采用；如果没有就使用Spring默认的。defaultStrategies初始化： 至此，容器创建完成。下面是整个过程的一个流程图（有疏漏，回头补一个时序图）：]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA中的关键字]]></title>
    <url>%2F2018%2F11%2F10%2Fjava-key-word%2F</url>
    <content type="text"><![CDATA[Java中关键字有51个，另外还有俩个保留字；因此总共有53个。本文只将java中的关键字进行罗列和简单介绍，对于部分关键字的理解如sychronized将在其他文章中单独分析。 保留字保留字是指预留的关键字； const用于修饰字段或局部变量的声明；被const修饰的字段或局部变量的值是常数，不能被修改 goto指定跳转到标签，找到标签后，程序将处理从下一行开始的命令。 关键字 数据类型 访问修饰符 类、接口定义相关 流程控制与判断相关 包 变量\类\接口\方法修饰符 异常处理 枚举和断言]]></content>
      <categories>
        <category>java 基础</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每天一道算法题：无重复字符的最长子串]]></title>
    <url>%2F2018%2F11%2F10%2Fleetcode5%2F</url>
    <content type="text"><![CDATA[题目给定一个字符串，找出不含有重复字符的 最长子串 的长度。 示例： 给定 “abcabcbb” ，没有重复字符的最长子串是 “abc” ，那么长度就是3。 给定 “bbbbb” ，最长的子串就是 “b” ，长度是1。 给定 “pwwkew” ，最长子串是 “wke” ，长度是3。请注意答案必须是一个子串，”pwke” 是 子序列 而不是子串。 方案1思路： 字符对应的数字作为下标 初始化一个255的boolean作为所有可能出现的字符对应的存在可能性，不存在重复的均为false，存在重复的，则对应的下标置为true。 两个指针进行移动，前指针先不动，后指针移动并根据当前字符对应整数下标是否为false或者true进行判断。如果是false，则表示没有重复，则指针向后移动一位；如果为true，表示存在重复，则后指针停止移动，并计算当前字串长度，且将boolean数组重置，第一个指针向前移动一位，后指针指向当前前指针。 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int len = 0 ; if (s==null || s.length()== 0 ) &#123; return 0; &#125; if (s.length() == 1)&#123; return 1; &#125; int firstPoint = 0; int nextPoint = 0; boolean[] exist=new boolean[255]; while (nextPoint &lt; s.length()&amp;&amp;firstPoint &lt;s.length())&#123; int currMax = 0; int index = s.charAt(nextPoint)-0; while (exist[index] == false&amp;&amp;nextPoint&lt;s.length())&#123; exist[s.charAt(nextPoint)-0] = true; nextPoint++; if (nextPoint &lt; s.length())&#123; index = s.charAt(nextPoint)-0; &#125; &#125; currMax = Math.max(currMax,nextPoint-firstPoint); firstPoint++; nextPoint=firstPoint; len = Math.max(len,currMax); for (int i = 0 ; i &lt; 255 ; i++) &#123; exist[i] = false; &#125; &#125; return len; &#125;&#125; 方案2思路： 以一个hashmap作为辅助，map的key存储的是字符，value存储的是该字符当前的位置，首先设置一个头指针，指向字符串开头，那么从开始遍历字符串，如果map当中不包含这个字符，那么用这个字符当前所在的位置减去头指针的位置，然后与最大长度做比较，选打的成为最大长度，然后把当前字符的以及位置放入map，以abba为例，头指针指向a，当前为a，那么长度为1，map。put（‘a’,0）,当前为b，那么长度为2，map.put(‘b’,1)，如果说map中存在当前字符，那么把头指针指向，头指针当前的位置与map中存储该字符位置的下一个位置当中的较大者，成为新的头指针位置，比如当走到第二个b的时候，那么头指针原来是0，当前map中存放b的位置是1，那么头指针指向2，所以长度为1，比最大长度小不进行替换，最后将当前的字符及位置放入map，现在是map.put(‘b’,2)，然后走到了a，那么当前map中a的位置是0，那么它的下一个位置是1，与当前头指针位置2相比，小于当前头指针的位置，那么头指针不跟新，所以长度为2，与最大长度相等，所以不替换，最后求出最大长度为2. 12345678910111213141516171819public static int lengthOfLongestSubstring(String s) &#123; Map&lt;Character,Integer&gt; map=new HashMap&lt;Character,Integer&gt;(); int maxLength=0; int now=0; for(int i=0;i&lt;s.length();i++)&#123; if(map.containsKey(s.charAt(i)))&#123; now=Math.max(map.get(s.charAt(i))+1,now); if((i-now+1)&gt;maxLength)&#123; maxLength=i-now+1; &#125; &#125;else&#123; if((i-now+1)&gt;maxLength)&#123; maxLength=i-now+1; &#125; &#125; map.put(s.charAt(i), i); &#125; return maxLength; &#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每天一道算法题：求两个排序数组的中位数]]></title>
    <url>%2F2018%2F11%2F10%2Fleetcode4%2F</url>
    <content type="text"><![CDATA[题目有两个大小为 m 和 n 的排序数组 nums1 和 nums2 。 请找出两个排序数组的中位数并且总的运行时间复杂度为 O(log (m+n)) 。 示例1: 1234nums1 = [1, 3]nums2 = [2]中位数是 2.0 示例2: 12345nums1 = [1, 2]nums2 = [3, 4]中位数是 (2 + 3)/2 = 2.5 归并&amp;topK问题 方案1这个思路就是对于两个有序数组进行合并，合并到一个大的有序的数组中去，然后求合并后数组的中位数。下面代码中使用的是归并排序的方式，对于两个有序数组进行归并排序的。从复杂度的角度来说可以满足题目的要求，但是还是存在一些问题，主要是怎么能够使得时间复杂度变成O{MIN(nums1.length,nums2.leng)}。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Solution &#123; public double findMedianSortedArrays(int[] nums1, int[] nums2) &#123; double result = 0.0d; int[] nums = new int[nums1.length+nums2.length]; int num1index = 0; int num2index = 0; int index = 0; if (nums1.length == 0 &amp;&amp; nums2.length == 0)&#123; return result; &#125; if (nums1.length == 0)&#123; return getResult(nums2); &#125; if (nums2.length == 0)&#123; return getResult(nums1); &#125; while(num1index &lt; nums1.length &amp;&amp; num2index &lt; nums2.length)&#123; if (nums1[num1index] &lt; nums2[num2index])&#123; nums[index]= nums1[num1index]; num1index++; &#125;else&#123; nums[index]= nums2[num2index]; num2index++; &#125; index++; &#125; while (num1index &lt; nums1.length)&#123; nums[index] = nums1[num1index++]; index++; &#125; while (num2index &lt; nums2.length)&#123; nums[index] = nums2[num2index++]; index++; &#125; if (nums.length%2==0) &#123; result = (nums[nums.length/2]+nums[nums.length/2-1])/2.0; &#125; else&#123; result = nums[nums.length/2]; &#125; return result; &#125; private double getResult(int[] nums)&#123; double result = 0.0D; if (nums.length%2==0) &#123; result = (nums[nums.length/2]+nums[nums.length/2-1])/2.0; &#125; else&#123; result = nums[nums.length/2]; &#125; return result; &#125;&#125; 方案2求两个排序数组的中位数 假设nums1.length = m, nums2.length = n; m &lt; n; 若(m + n) % 2 == 0, 表示两数组之和为偶数，应该是有两个中位数，因此最终结果为第9行的代码所示。否则，结果为第7行的代码所示。 为了使得方法的统一，在最初时，对数组进行处理，统一使得传进方法的短数组为nums1，即第14行代码所示。 如果len1-start1 == 0,则表示nums1已经全部加入前k个了，则第k个为nums2[k -1]; 在方法findKth（）中的k是一直变化的，初始时，k为两个数组中排序之后的第k个数的位置；k在方法中的真正含义为“还需要找到多少个数才能达到k个”；因此假设nums1.length ==0;,此时len1-start1 == 0, 则中位数就是nums2[k - 1],即在nums1中找到了0个数，还需要找k个数，第k个数就是nums[k - 1]; 如果k == 1,则表示前k-1小的数已经找过了，则第k个数肯定是nums1[start1]和nums2[start2]中较小的那个数。 下面接着就是常规的情况：即nums1中包含一部分k,nums2中也包含一部分的k,因此就从每个数组的k/2那里开始比较（也相当于每次都会有一半的数被加入前k个，因此时间复杂度为O（log(m + n)））：采用p1和p2分别记录当前nums1和nums2需要比较的那个位，由于nums1比较短，因此有可能2/k的位置已经超出了nums1的长度，因此nums1还需要做特殊处理，即第19行代码所示；由于p1做了特殊处理，那p2也就要做特殊处理。总之，start1~p1和start2~p2的和一定为k。1）若nums1[p1 - 1] &lt; nums[p2 - 1],则表明【start1, p1)之间的值在前k个数中；2）若nums[p1 - 1] &gt; nums2[p2- 1],则表明【start2, p2)之间的值在前k个数中；3）若两值相等，则表明【start1, p1)+【start2， p2）的个数为k,则结果直接返回其中一个即可。为什么比较的p1和p2的前一个位的数，而不是p1和p2位置的数呢？ 举例说明：假设start1== start2 == 0, 则p1 = Math.min(len1, k / 2); p2 = k - p1,即p1 + p2 == k;；假设p1 = 5, p2 = 7;, 则k = 12; 在数组中nums[5]其实是第6个数，nums[7]其实是第8个数，所以我们比较的是nums1[p1 - 1]与nums2[p2 - 1]的值； 1234567891011121314151617181920212223242526272829public class Solution &#123; public double findMedianSortedArrays(int[] nums1, int[] nums2) &#123; int len1 = nums1.length; int len2 = nums2.length; int size = len1 + len2; if(size % 2 == 1) return findKth(nums1, 0, len1, nums2, 0, len2, size / 2 + 1); else return (findKth(nums1, 0, len1, nums2, 0, len2, size / 2) + findKth(nums1, 0, len1, nums2, 0, len2, size / 2 + 1)) /2; &#125; public double findKth(int[] nums1, int start1, int len1, int[] nums2, int start2, int len2, int k) &#123; if(len1 - start1 &gt; len2 -start2) // 传进来的时候统一让短的数组为nums1 return findKth(nums2, start2, len2, nums1, start1, len1, k); if(len1 - start1 == 0) // 表示nums1已经全部加入前K个了，第k个为nums2[k - 1]; return nums2[k - 1]; if(k == 1) return Math.min(nums1[start1], nums2[start2]); // k==1表示已经找到第k-1小的数，下一个数为两个数组start开始的最小值 int p1 = start1 + Math.min(len1 - start1, k / 2); // p1和p2记录当前需要比较的那个位 int p2 = start2 + k - p1 + start1; if(nums1[p1 - 1] &lt; nums2[p2 - 1]) return findKth(nums1, p1, len1, nums2, start2, len2, k - p1 + start1); else if(nums1[p1 - 1] &gt; nums2[p2 -1]) return findKth(nums1, start1, len1, nums2, p2, len2, k - p2 + start2); else return nums1[p1 - 1]; &#125;&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每天一道算法题：最长回文子串]]></title>
    <url>%2F2018%2F11%2F10%2Fleetcode3%2F</url>
    <content type="text"><![CDATA[##题目给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 长度最长为1000。 示例: 12345输入: &quot;babad&quot;输出: &quot;bab&quot;注意: &quot;aba&quot;也是有效答案 示例: 123输入: &quot;cbbd&quot;输出: &quot;bb&quot; 思路一开始是想用最笨的方法来解的，也就是找出所有的字串，然后再对所有的子串进行回文检测，并记录长度。这种方式时间复杂度可想而知，O(n)O(n)O(n)=O(n^3)。所以这种肯定是不能满足我们要求的。 ok，那我们来分析一下这个问题，先把这个问题特殊化； 假如输入的字符串长度就是1 那么这个字符串的最长回文串就是它自己，长度就是1 假如字符串长度为2，它要是回文串的化，就需要两个字符是相等的。 即：s[i] == s[j] 且i-j=1(此处假定i是较大索引位置) 那么对于i－j&gt;1的情况下呢？是不是只要满足下面的条件就可以了： 即:s[i] == s[j]&amp;&amp;s[i-1] == s[j+1] 其实这种思路就是动态规划。关于动态规划的理论性文字就不码了，有兴趣的小伙伴阔以自行学习。下面就针对这个问题码一下代码： 12345678910111213141516171819202122232425262728293031323334353637public String longestPalindrome(String s) &#123; // 长度为1，返回当前串 if (s.length()==1)&#123; return s; &#125; //长度为2并且两个字符相等则返回 if (s.length()==2&amp;&amp;s.charAt(0)==s.charAt(1))&#123; return s; &#125; //用于标记isLongestPalindrome[j][i]即从j到i是否是回文串； //如isLongestPalindrome[1][5]＝＝true则表示字符串索引位置从1到5的子串是回文串。 boolean[][] isLongestPalindrome = new boolean[s.length()][s.length()]; //最长回文串初始最大为0 int maxlen = 0; //对应的maxlen的开始索引位置 int beginIndex = 0; //对应的maxlen的结束索引位置 int lastIndex = 0; for (int i=0;i&lt;s.length();i++)&#123; int j=i; while(j&gt;=0)&#123; //满足上述的第三个条件，即当前s.charAt(i)==s.charAt(j)并 //且s[j＋1到i－1]也是回文串 if (s.charAt(i)==s.charAt(j)&amp;&amp;(i-j&lt;2||isLongestPalindrome[j+1][i-1]))&#123; isLongestPalindrome[j][i]=true; if (maxlen &lt; i-j+1) &#123; beginIndex = j; lastIndex = i+1; maxlen = i-j+1; &#125; &#125; j--; &#125; &#125; return s.substring(beginIndex,lastIndex);&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每天一道算法题：Z字形转换]]></title>
    <url>%2F2018%2F11%2F10%2Fleetcodetwo%2F</url>
    <content type="text"><![CDATA[题目将字符串 “PAYPALISHIRING” 以Z字形排列成给定的行数：（下面这样的形状） 123P A H NA P L S I I GY I R 之后按逐行顺序依次排列：”PAHNAPLSIIGYIR” 实现一个将字符串进行指定行数的转换的函数: 1string convert(string text, int nRows); convert(“PAYPALISHIRING”, 3) 应当返回 “PAHNAPLSIIGYIR” 。 方案12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public String convert(String s, int numRows) &#123; //计算字符串长度 int len = s.length(); //两个周期之间的列数， int slash = numRows - 2; //计算行的长度 int rowLength = 0; while(len &gt; 0)&#123; //竖列 len = len - numRows; rowLength++; //斜着的一列 for(int i = 0; i &lt; slash &amp;&amp; len &gt; 0; i++)&#123; len--; rowLength++; &#125; &#125; //建立一个多一列的数组用于保存我们的字符串,并且全部初始化为空格了 char result[] = new char[numRows* rowLength]; // 初始化为空格 for (int i = 0; i &lt; result.length; i++) &#123; result[i] = ' '; &#125; // 当前处理的行数 int curColumn = 0; int index = 0; // 下面将字符串写入所谓的矩阵中 while(index &lt; s.length())&#123; //写入列 for(int i = 0; i &lt; numRows &amp;&amp; index &lt; s.length(); i++)&#123; result[rowLength * i + curColumn] = s.charAt(index); index++; &#125; curColumn++; //写入斜线 for(int i = numRows - 2; i &gt; 0 &amp;&amp; index &lt; s.length(); i--)&#123; result[rowLength * i + curColumn] = s.charAt(index); curColumn++; index++; &#125; &#125; // 去空格，定义两个指针循环进行操作 index = 0; // 找第一个是空格的字符位置 while (index &lt; s.length() &amp;&amp; result[index] != ' ') &#123; index++; &#125; int next = index + 1; while (index &lt; s.length()) &#123; // 找不是空格的元素 while (next &lt; result.length &amp;&amp; result[next] == ' ') &#123; next++; &#125; result[index] = result[next]; index++; next++; &#125; return new String(result, 0, index);&#125; 这个题目想了两天，之前的思路是建立一个二维数组，然后填充，最后遍历数组拿到结果，但是对于很多边界问题不太好考虑，放弃。这两种方案的首要核心都是计算列数和对斜列的处理，没有数学功底和抽象思维的程序员真的伤不起。]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每天一道算法题：颠倒整数]]></title>
    <url>%2F2018%2F11%2F10%2Fleetcodeone%2F</url>
    <content type="text"><![CDATA[题目给定一个范围为 32 位 int 的整数，将其颠倒。 例 1: 12输入: 123输出: 321 例 2: 12输入: -123输出: -321 例 3: 12输入: 120输出: 21 注意:假设我们的环境只能处理 32 位 int范围内的整数。根据这个假设，如果颠倒后的结果超过这个范围，则返回 0。 方案这个题目其实挺简单的；思路如下： 判断输入的数字是否大于最大整数，其实这里没有必要判断，因为如果参数输入大于最大整数的话会直接报错。 将整数转换成字符串 判断是否是负数，这个依据就是判断字符串中是否存在‘－’ 从后向前开始遍历，注意的是必须后向遍历且初始为0的情况下保持继续向前迭代。 如果转换之后的值大于最大整数，则会导致string转int失败，抛出异常，那么我们直接在这把异常捕获，并且返回0（偷懒一波，丷）1234567891011121314151617181920212223242526272829303132333435363738394041424344 public int reverse(int x) &#123; int result = 0; if (x &gt;Integer.MAX_VALUE)&#123; return 0 ; &#125; String s =String.valueOf(x); int len = 0; if (s!=null&amp;&amp;s.length()!=0&amp;&amp;s.charAt(0)=='-')&#123; len = 1; &#125;else if(s.length() == 1)&#123; return x; &#125; int lastp = s.length()-1; boolean isStart = true; String ints = ""; while( lastp &gt;= len)&#123; if (isStart &amp;&amp; s.charAt(lastp)=='0')&#123; while (s.charAt(lastp)=='0')&#123; lastp--; &#125; isStart = false; &#125; if (isStart)&#123; isStart = false; &#125; ints = ints+s.charAt(lastp); lastp--; &#125; try&#123; result = Integer.parseInt(ints); &#125;catch (NumberFormatException e)&#123; return 0; &#125; return len==0?result:result*(-1);&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于rpc的整理和理解]]></title>
    <url>%2F2018%2F11%2F10%2Frpcone%2F</url>
    <content type="text"><![CDATA[架构演变 所有的界面和服务均在同一个进程下 基于mvc的视图与服务分离，但是实际上还是在一个应用系统中，只不过在功能层次上划分的更加细致 粒度更细，对于不同的功能服务进行切分，并进行单独的部署 面向服务的架构，将应用程序的不同功能单元（称为服务）通过这些服务之间定义良好的接口和契约联系起来 微服务 此处不支持图片展示，自行脑补！！！ 随着业务量和用户量的增加，架构也是从单一系统走向分布式系统，我能想到的是，这种架构的演变主要解决的问题在于： 通过业务模块的拆分，使得每个模块的职责更加清晰，但是模块的职责边界的划分往往也是很疼头的事情。 细致的划分使得项目在管理上面会更加方面，从代码的角度来说，开发和维护的成本也会降低，不会因为一个bug去跑整个项目了。 提高了系统的容错率，单一系统如果宕机那就真的gg了，另外就是，单个环节出现问题也会导致项目无法正常运行（比如数据库出问题了）。对于分布式系统来说，一般都会使用冗余的方式来提高可用性，个人理解就是可以提供多个一样的服务，它们之间可以进行切换。 分布式系统带来的问题一个是成本，硬件成本，运维成本都会增加。 rpc简介及常用的rpc框架随着集中式架构向分布式架构的转变，应用系统之间的服务调用与通讯问题成为了首要解决的需求。 而RPC 的主要目标就是为了让构建分布式计算（应用）变得更加简单，在提供强大的远程调用能力时不损失本地调用的语义简洁性。 为实现该目标，RPC 框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。 如下代码： 123456789101112131415 @Autowiredprivate GlRpcAgent glRpcAgent; //rpc代理/** * @param param 此处约定参数以Map键值对的形式传递 */@Overridepublic List&lt;OrderInfo&gt; queryOrdersByUserId(Map&lt;String, Object&gt; param) &#123; //创建远程调用代理（远程服务的类的全限定名） OrderConsumeAgent orderConsumer=glRpcAgent.getAgent(&quot;com.glmapper.rpc.interface.OrderConsumeInterface&quot;); //通过代理获取返回结果 此处getOrders为远程服务器上的com.glmapper.rpc.interface.OrderConsumeInterface接口中的方法，param为参数 Map&lt;String,Object&gt; resultMap=(Map)orderConsumer.call(&quot;getOrders&quot;,param); //解析返回结果（远程方法同样以Map集合的方式放回） List&lt;OrderInfo&gt; orders = parseResultMap(resultMap); return orders;&#125; 为什么要以全限定名来获取呢，这个我们将会在后面来说。 什么是RPCIn distributed computing a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in another address space(commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction.RPC 的全称是 Remote Procedure Call 是一种进程间通信方式。 它允许程序调用另一个进程上（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。 从定义中可以得知，RPC主要来解决三件事情： 进程间通讯 提供和本地方法调用一样的调用机制 屏蔽程序员对远程调用的细节实现 首先是进程间的通信问题，对于分布式环境，rpc能够帮助我们解决不同服务器之间的通信及数据传输问题，即做好方法调用到数据的转换，然后借助网络进行数据传递；rpc客户端向rpc服务端发起远程服务调用，通过请求的封装，参数的封装，序列化、编码、约定协议传输、解析请求、处理请求、封装返回消息数据、在进行返回数据的序列化、编码、在通过网络返回给客户端。再者是提供和本地方法调用一样的调用机制，为什么这么说，对于业务系统来说，我们更多的关注点在于如何解决实际的业务需求问题，而不想花更多的时间和心思在诸如上述过程中关于网络传输及编解码过程，因此对于rpc来说，需要将这些编解码、协议约定、网络传输等进行一个整体的封装，然后只向业务系统提供最简单的调用方式。最后一个屏蔽程序员对远程调用的细节实现，其实也就是第二点中提到的那些功能的封装，我们不用去关系rpc到底是如何实现的，也不用关心它是如何运作的，对于业务开发人员来说，通过约定的方式进行类似于本地方法调用的形式来调用远程服务接口就可以了。那么如何实现透明化的远程调用呢？什么样的内部封装才能让我们觉得像以本地调用方式调用远程服务呢？对于java来说就是使用代理。java代理有两种方式：1） jdk 动态代理（接口代理）；2）cglib代理（子类代理）。尽管字节码生成方式实现的代理更为强大和高效，但代码不易维护，大部分公司实现RPC框架时还是选择动态代理方式。这部分也将会在后续的章节中展开来说。 RPC基本原理上面说到，rpc需要对一些远程调用的内部实现进行封装。我们说到有以下几个点： 序列化 编解码 协议 网络 从发起远程调用到接收到数据返回结果，大致过程是： 1）服务消费方（client）调用以本地调用方式调用服务；2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；3）client stub找到服务地址，并将消息发送到服务端；4）server stub收到消息后进行解码；5）server stub根据解码结果调用本地的服务；6）本地服务执行并将结果返回给server stub；7）server stub将返回结果打包成消息并发送至消费方；8）client stub接收到消息，并进行解码；9）服务消费方得到最终结果。 那么rpc就相当于将step2-step8的步骤进行了封装。下面借用一张网上的图片来帮助我们理解这个过程。 RPC模型对于上图，我们进行进一步的拆解得到（来自网络）： RPC 服务端通过 RpcServer 去暴露服务接口，而客户端通过 RpcClient 去获取服务接口。客户端像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理 RpcProxy。代理封装调用信息并将调用转交给 RpcInvoker 去实际执行。在客户端的 RpcInvoker 通过连接器 RpcConnector 去维持与服务端的通道 RpcChannel，并使用 RpcProtocol 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务端。RPC 服务端接收器 RpcAcceptor接收客户端的调用请求，同样使用 RpcProtocol 执行协议解码（decode）。解码后的调用信息传递给 RpcProcessor 去控制处理调用过程，最后再委托调用给 RpcInvoker 去实际执行并返回调用结果。 通过上述分析可知，这里面包括以下核心组件： 用于暴露服务接口的RpcServer 用于发现服务接口的RpcClient 远程接口的代理实现RpcProxy 负责协议编解码的RpcProtocol（实际的rpc框架中一般会提供多种不同的实现） 网络连接器（之前看过一篇文章说9个组件，对于咱们这个来说，部分模块可以集成在client和server中） 常见的RPC框架目前常见的分布式RPC框架有以下几个： dubbo阿里巴巴公司开源的一个Java高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成 motan新浪微博开源的一个Java 框架。它诞生的比较晚，起于2013年，2016年5月开源。Motan 在微博平台中已经广泛应用，每天为数百个服务完成近千亿次的调用。 rpcxGo语言生态圈的Dubbo， 比Dubbo更轻量，实现了Dubbo的许多特性，借助于Go语言优秀的并发特性和简洁语法，可以使用较少的代码实现分布式的RPC服务。 gRPCGoogle开发的高性能、通用的开源RPC框架，主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。本身它不是分布式的，所以要实现上面的框架的功能需要进一步的开发。 thriftApache的一个跨语言的高性能的服务框架 RPC与MQMQ(message queue)消息队列，从某种程度上来说，同样可以实现RPC的功能。从功能特点上来说，MQ可以把消息存储，而RPC不行。关于MQ和RPC做了以下简单的对比，如下图所示： 总结本文对RPC的基本原理、特点以及基本组件进行了简单的说明，让我们可以对RPC有一个基本的了解。关于常见的RPC框架也做了基本认识，对于这些优秀的框架，我们在实现我们自己RPC时可以借鉴一下这些架构里的一些模式以及技术。最后说明了下为什么我们会在分布式架构中要使用RPC而不是MQ，对于MQ来说，在处理同步调用无法满足实际的生产需求，而RPC才更加适合分布式应用的实际需要。]]></content>
      <categories>
        <category>rpc</category>
      </categories>
      <tags>
        <tag>rpc</tag>
        <tag>dubbo</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Mybatis中SQL语句的整理]]></title>
    <url>%2F2018%2F11%2F10%2Fmybatisone%2F</url>
    <content type="text"><![CDATA[随着业务的发展，越来越多的应用系统都从一个大的系统分拆成多个小的系统，各个系统之间通过一定的通信协议进行数据交换。这样就会导致一些小的应用系统自己不用去进行数据库的操作，只需要进行一些rpc调用或者缓存就可以拿到数据进行展示。我之前参与的一个项目就是这样的情况，而我也是将近7个多月的时间没有写过一行SQL。 近期参与的一个项目的数据大多都市基于数据库来进行数据交互的，所以免不了的要写大量的SQL，所以本篇就总结一下一些SQL的基本写法，以备后用。 建表12345CREATE TABLE IF NOT EXISTS `user_test` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '自增长id', `user_name` varchar(128) NOT NULL COMMENT '用户名', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='用户表'; 查询 简单的查询 123&lt;select id="queryUserByName" resultMap="userMap" parameterType="java.lang.String"&gt; SELECT * FROM user_test WHERE user_name = #&#123;userName&#125; &lt;/select&gt; 需要注意的是如果这里不指定parameterType，则默认会识别处理；如果指定了类型，则传入的值就需要和当前指定的类型保持一致，不然就会出现数据类型转换异常。 简单分页查询 1234567&lt;select id="queryUsersList" resultMap="userMap"&gt; SELECT * FROM user_test WHERE 1=1 &lt;if test="keyword != null and keyword != ''" &gt; AND user_name LIKE concat('%',#&#123;keyword&#125;,'%') &lt;/if&gt; LIMIT #&#123;currentPage&#125;,#&#123;pageSize&#125;&lt;/select&gt; left join app_info表和app_verion表分别存储的是应用信息和应用版本信息。现在要根据appId和versionId查出一个应用的具体信息【包括信息信息和版本信息】 12345678&lt;select id=&quot;getAppDetail&quot; resultMap=&quot;appDeatilMap&quot;&gt; select m.id id, m.app_name appName, n.version version, from app_info m LEFT JOIN app_version n ON m.id = n.app_id where m.id = #&#123;appId&#125; and n.id = #&#123;versionId&#125; &lt;/select&gt; 查询条件是list 123456789101112131415&lt;select id=&quot;queryAppByAppNames&quot; resultMap=&quot;AppMap&quot; parameterType=&quot;java.util.List&quot;&gt; select a.app_name appName, b.version version from starter_info a,starter_version b where a.id = b.app_id and a.id in ( select id from app_info where app_name in &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; )&lt;/select&gt; 更新 简单的更新 1234567&lt;update id="updateApp" parameterType="java.util.List"&gt; UPDATE app_info SET app_name = #&#123;appName&#125; WHERE app_id = #&#123;appId&#125;&lt;/update&gt; 批量更新 有这样一个需求，把 app_info表中id 为1，2，3的app的app_name改为appName1，appName2，appName3; 使用 case ..when ..then 这样的语法结构来完成： case 是当前的条件，when表示条件值，then后面是当前目前更新字段的值； 下面的说明：当前id=#{item.appId}时,app_name=#{item.appName} 1234567891011&lt;update id="updateApps" parameterType="java.util.List"&gt; UPDATE app_info set app_name = &lt;foreach collection="applList" item="item" index="index" separator=" " open="case ID" close="end"&gt; when #&#123;item.appId,jdbcType=INTEGER&#125; then #&#123;item.appName,jdbcType=INTEGER&#125; &lt;/foreach&gt; where id in &lt;foreach collection="appList" index="index" item="item" separator="," open="(" close=")"&gt; #&#123;item.appId,jdbcType=INTEGER&#125; &lt;/foreach&gt;&lt;/update&gt; OK，现在于这样的需要： 根据应用类型的不同，更新不同的运行环境配置； 123456789101112131415161718192021222324252627282930313233&#123; [ &#123; &quot;appType&quot;:&quot;applet&quot;, &quot;cpu&quot;:5, &quot;memory&quot;:4, &quot;card&quot;:3, &quot;nums&quot;:2, &quot;network&quot;:1, &quot;isInUse&quot;:1 &#125;, &#123; &quot;appType&quot;:&quot;bs&quot;, &quot;cpu&quot;:5, &quot;memory&quot;:4, &quot;card&quot;:3, &quot;nums&quot;:2, &quot;network&quot;:1, &quot;isInUse&quot;:1 &#125;, &#123; &quot;appType&quot;:&quot;cs&quot;, &quot;cpu&quot;:5, &quot;memory&quot;:4, &quot;card&quot;:3, &quot;nums&quot;:2, &quot;network&quot;:1, &quot;isInUse&quot;:1 &#125;, //有几个放几个 ]&#125; trim属性说明 1.prefix,suffix 表示在trim标签包裹的部分的前面或者后面添加内容 2.如果同时有prefixOverrides,suffixOverrides 表示会用prefix,suffix覆盖Overrides中的内容。 3.如果只有prefixOverrides,suffixOverrides 表示删除开头的或结尾的xxxOverides指定的内容。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;update id=&quot;updateBatchApp&quot; parameterType=&quot;java.util.List&quot;&gt; UPDATE app_info &lt;trim prefix=&quot;set&quot; suffixOverrides=&quot;,&quot;&gt; &lt;trim prefix=&quot;cpu = case&quot; suffix=&quot;end,&quot;&gt; &lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt; &lt;if test=&quot;item != null&quot;&gt; when app_type =#&#123;item.appType&#125; then #&#123;item.cpu&#125; &lt;/if&gt; &lt;/foreach&gt; &lt;/trim&gt; &lt;trim prefix=&quot;memory = case&quot; suffix=&quot;end,&quot;&gt; &lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt; &lt;if test=&quot;item != null&quot;&gt; when app_type =#&#123;item.appType&#125; then #&#123;item.memory&#125; &lt;/if&gt; &lt;/foreach&gt; &lt;/trim&gt; &lt;trim prefix=&quot;card = case&quot; suffix=&quot;end,&quot;&gt; &lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt; when app_type =#&#123;item.appType&#125; then #&#123;item.card&#125; &lt;/foreach&gt; &lt;/trim&gt; &lt;trim prefix=&quot;nums = case&quot; suffix=&quot;end,&quot;&gt; &lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt; when app_type =#&#123;item.appType&#125; then #&#123;item.nums&#125; &lt;/foreach&gt; &lt;/trim&gt; &lt;trim prefix=&quot;network = case&quot; suffix=&quot;end,&quot;&gt; &lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt; when app_type =#&#123;item.appType&#125; then #&#123;item.network&#125; &lt;/foreach&gt; &lt;/trim&gt; &lt;trim prefix=&quot;is_in_use = case&quot; suffix=&quot;end,&quot;&gt; &lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt; when app_type =#&#123;item.appType&#125; then #&#123;item.isInUse&#125; &lt;/foreach&gt; &lt;/trim&gt; &lt;/trim&gt; where app_id = #&#123;appId&#125;&lt;/update&gt; 关于性能问题没做研究，之前看过关于不同更新语句写法的一篇性能的分析，大家有兴趣可以看下：批量更新数据两种方法效率对比 删除 简单删除 1DELETE FROM app_info where id = #&#123;id&#125; 批量删除 123456&lt;delete id=&quot;deleteApps&quot; parameterType=&quot;java.util.List&quot;&gt; DELETE FROM app_info where app_id in &lt;foreach item=&quot;item&quot; collection=&quot;appIds&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/delete&gt; 时间字符串 order by不知道各位是否遇到过，之前的前辈们在项目中将时间用字符串的方式存在DB中，而不是使用DATE,然后有一天你的前辈走了，你的主管说查出来按时间来排序….；呵呵，好！！！ 1234567&lt;select id=&quot;querySysParamList&quot; resultMap=&quot;sysParamDO&quot;&gt; SELECT * FROM app_info WHERE 1=1 &lt;if test=&quot;keyword != null and keyword != &apos;&apos;&quot; &gt; AND app_name LIKE concat(&apos;%&apos;,#&#123;keyword&#125;,&apos;%&apos;) &lt;/if&gt; ORDER BY DATE_FORMAT(update_time,&apos;%H %k %I %r %T %S %w&apos;) DESC&lt;/select&gt; 字符串转为日期格式SELECT DATE_FORMAT(‘2011-09-20 08:30:45’, ‘%Y-%m-%d %H:%i:%S’); 把日期转为字符串格式SELECT DATE_FORMAT(NOW(), ‘%Y-%m-%d %H:%i:%S’); 附： 123456789101112131415161718192021222324252627%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59) %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%”。 先记录这些，有坑再补！ 参考：http://www.runoob.com/sql/sql-tutorial.html]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
        <tag>sql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx反向代理和负载均衡策略实战案例]]></title>
    <url>%2F2018%2F11%2F10%2Fnginxone%2F</url>
    <content type="text"><![CDATA[欢迎关注：glmapper_2018 引言先来看下nginx在web服务器排名上的趋势： 存在即合理，那为什么要使用nginx呢？这得看看nginx能帮我们做些什么。 首先，nginx能做反向代理【关于反向代理和正向代理此处不做说明了，感兴趣的小伙伴自行谷歌】；比方说，我想在本地使用 www.glmapper1.com 的域名去访问www.taobao.com。那么这个时候我们就可以通过nginx去实现。 再者，nginx能实现负载均衡，什么是负载均衡呢？就是说应用部署在不同的服务器上，但是通过统一的域名进入，nginx则对请求进行分发，将请求分发到不同的服务器上去处理，这样就可以有效的减轻了单台服务器的压力。 在上面这两种情况下，nginx服务器的作用都只是作为分发服务器，真正的内容，我们可以放在其他的服务器上，这样来，还能起到一层安全隔壁的作用，nginx作为隔离层。 解决跨域问题 同源：URL由协议、域名、端口和路径组成，如果两个URL的协议、域名和端口相同，则表示他们同源。 浏览器的同源策略：浏览器的同源策略，限制了来自不同源的”document”或脚本，对当前”document”读取或设置某些属性。从一个域上加载的脚本不允许访问另外一个域的文档属性。 因为nginx和tomcat不能共用同一端口,url一样，端口不同，这样就会有跨域问题。 PS：点到为止，这里本次测试没有涉及，就不妄自菲薄了！！! 配置文件解析配置文件主要由四部分组成： main(全区设置) server(主机配置) http(控制着nginx http处理的所有核心特性) location(URL匹配特定位置设置)。 upstream(负载均衡服务器设置) 下面以默认的配置文件来说明下具体的配置文件属性含义： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151#Nginx的worker进程运行用户以及用户组#user nobody;#Nginx开启的进程数worker_processes 1;#定义全局错误日志定义类型，[debug|info|notice|warn|crit]#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#指定进程ID存储文件位置#pid logs/nginx.pid;#事件配置events &#123; #use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; #epoll模型是Linux内核中的高性能网络I/O模型，如果在mac上面，就用kqueue模型。 use kqueue; #每个进程可以处理的最大连接数，理论上每台nginx服务器的最大连接数为worker_processes*worker_connections。理论值：worker_rlimit_nofile/worker_processes worker_connections 1024;&#125;#http参数http &#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #日志相关定义 #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #连接日志的路径，指定的日志格式放在最后。 #access_log logs/access.log main; #开启高效传输模式 sendfile on; #防止网络阻塞 #tcp_nopush on; #客户端连接超时时间，单位是秒 #keepalive_timeout 0; keepalive_timeout 65; #开启gzip压缩输出 #gzip on; #虚拟主机基本设置 server &#123; #监听的端口号 listen 80; #访问域名 server_name localhost; #编码格式，如果网页格式与当前配置的不同的话将会被自动转码 #charset koi8-r; #虚拟主机访问日志定义 #access_log logs/host.access.log main; #对URL进行匹配 location / &#123; #访问路径，可相对也可绝对路径 root html; #首页文件，匹配顺序按照配置顺序匹配 index index.html index.htm; &#125; #错误信息返回页面 #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; #访问URL以.php结尾则自动转交给127.0.0.1 # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; #php脚本请求全部转发给FastCGI处理 # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; #禁止访问.ht页面 # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; #第二个虚拟主机配置 # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; #HTTPS虚拟主机定义 # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; include servers/*;&#125; 反向代理实例假设我现在需要本地访问www.baidu.com;配置如下： 1234567891011server &#123; #监听80端口 listen 80; server_name localhost; # individual nginx logs for this web vhost access_log /tmp/access.log; error_log /tmp/error.log ; location / &#123; proxy_pass http://www.baidu.com; &#125; 验证结果： 可以看到，我在浏览器中使用localhost打开了百度的首页… 负载均衡实例下面主要验证最常用的三种负载策略。虚拟主机配置：123456789101112131415161718192021222324server &#123; #监听80端口 listen 80; server_name localhost; # individual nginx logs for this web vhost access_log /tmp/access.log; error_log /tmp/error.log ; location / &#123; #负载均衡 #轮询 #proxy_pass http://polling_strategy; #weight权重 #proxy_pass http://weight_strategy; #ip_hash # proxy_pass http://ip_hash_strategy; #fair # proxy_pass http://fair_strategy; #url_hash # proxy_pass http://url_hash_strategy; #重定向 #rewrite ^ http://localhost:8080; &#125; 轮询策略123456# 1、轮询（默认）# 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 upstream polling_strategy &#123; server glmapper.net:8080; # 应用服务器1 server glmapper.net:8081; # 应用服务器2&#125; 测试结果（通过端口号来区分当前访问）： 12348081：hello8080：hello8081：hello8080：hello 权重策略123456#2、指定权重#指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 upstream weight_strategy &#123; server glmapper.net:8080 weight=1; # 应用服务器1 server glmapper.net:8081 weight=9; # 应用服务器2&#125; 测试结果：总访问次数15次，根据上面的权重配置，两台机器的访问比重：2：13；满足预期！ ip hash策略123456789#3、IP绑定 ip_hash#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，#可以解决session的问题;在不考虑引入分布式session的情况下，#原生HttpSession只对当前servlet容器的上下文环境有效upstream ip_hash_strategy &#123; ip_hash; server glmapper.net:8080; # 应用服务器1 server glmapper.net:8081; # 应用服务器2&#125; iphash 算法:ip是基本的点分十进制，将ip的前三个端作为参数加入hash函数。这样做的目的是保证ip地址前三位相同的用户经过hash计算将分配到相同的后端server。作者的这个考虑是极为可取的，因此ip地址前三位相同通常意味着来着同一个局域网或者相邻区域，使用相同的后端服务让nginx在一定程度上更具有一致性。 为什么说要解释下iphash,因为采坑了；和猪弟在进行这个策略测试时使用了5台机器来测试的，5台机器均在同一个局域网内【192.168.3.X】;测试时发现5台机器每次都路由到了同一个服务器上，一开始以为是配置问题，但是排查之后也排除了这个可能性。最后考虑到可能是对于同网段的ip做了特殊处理，验证之后确认了猜测。 其他负载均衡策略这里因为需要安装三方插件，时间有限就不验证了，知悉即可！1234567891011121314151617#4、fair（第三方）#按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream fair_strategy &#123; server glmapper.net:8080; # 应用服务器1 server glmapper.net:8081; # 应用服务器2 fair; &#125; #5、url_hash（第三方）#按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，#后端服务器为缓存时比较有效。 upstream url_hash_strategy &#123; server glmapper.net:8080; # 应用服务器1 server glmapper.net:8081; # 应用服务器2 hash $request_uri; hash_method crc32; &#125; 重定向rewrite1234location / &#123; #重定向 #rewrite ^ http://localhost:8080;&#125; 验证思路：本地使用localhost:80端口进行访问，根据nginx的配置，如果重定向没有生效，则最后会停留在当前localhost:80这个路径，浏览器中的地址栏地址不会发生改变；如果生效了则地址栏地址变为localhost:8080； 通过验证，满足预期！ 总结本文先对nginx的作用和基本的配置做了简单说明；然后通过负载均衡的实例测试了不同负载均衡算法的具体应用反馈结果。帮助自己更加深刻的理解nginx服务器中的一些配置细节。感谢刘秘提供的helloworld程序【基于springboot的脚手架，有需要的可以联系他获取；还有就是刘秘是个男的…😜】 参考 http://nginx.org/ https://www.nginx.com/ http://www.sohu.com/a/161411719_324809]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>代理模式</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊session和cookie]]></title>
    <url>%2F2018%2F11%2F10%2Fsessionone%2F</url>
    <content type="text"><![CDATA[本来是想写aop设计机制的，但是最近被session这个东西搞得有点头大，所以就抽点时间来整理下关于session的一些东西。 目录 从http协议的无状态性说起 无连接和无状态 持久连接 http无状态 如何保持状态信息 Cookie Cookie机制原理 Cookie在servlet-api中的定义 Cookie属性 创建Cookie Cookie更新 Cookie删除 从请求中获取Cookie Cookie同源与跨域 Cookie数量&amp;大小限制及处理策略 Session session机制原理 HttpSession 创建session 生命周期 session的有效期 分布式session从http协议的无状态性说起 HTTP是一种无状态协议。关于这个无状态之前我也不太理解，因为HTTP底层是TCP，既然是TCP，就是长连接，这个过程是保持连接状态的，又为什么说http是无状态的呢？先来搞清楚这两个概念： 无连接和无状态 无连接 每次连接只处理一个请求，服务端处理完客户端一次请求，等到客户端作出回应之后便断开连接； 无状态 是指服务端对于客户端每次发送的请求都认为它是一个新的请求，上一次会话和下一次会话没有联系； 无连接的维度是连接，无状态的维度是请求；http是基于tcp的，而从http1.1开始默认使用持久连接；在这个连接过程中，客户端可以向服务端发送多次请求，但是各个请求之间的并没有什么联系；这样来考虑，就很好理解无状态这个概念了。 持久连接持久连接，本质上是客户端与服务器通信的时候，建立一个持久化的TCP连接，这个连接不会随着请求结束而关闭，通常会保持连接一段时间。 现有的持久连接类型有两种：HTTP/1.0+的keep-alive和HTTP/1.1的persistent。 HTTP/1.0+的keep-alive 先来开一张图： 这张图是请求www.baidu.com时的请求头信息。这里面我们需要注意的是： 1connection: keep-alive 我们每次发送一个HTTP请求，会附带一个connection:keep-alive，这个参数就是声明一个持久连接。 HTTP/1.1的persistent HTTP/1.1的持久连接默认是开启的，只有首部中包含connection：close，才会事务结束之后关闭连接。当然服务器和客户端仍可以随时关闭持久连接。 当发送了connection：close首部之后客户端就没有办法在那条连接上发送更多的请求了。当然根据持久连接的特性，一定要传输正确的content-length。 还有根据HTTP/1.1的特性，是不应该和HTTP/1.0客户端建立持久连接的。最后，一定要做好重发的准备。 http无状态OK，首先来明确下，这个状态的主体指的是什么？应该是信息，这些信息是由服务端所维护的与客户端交互的信息（也称为状态信息）；因为HTTP本身是不保存任何用户的状态信息的，所以HTTP是无状态的协议。 如何保持状态信息在聊这个这个问题之前，我们来考虑下为什么http自己不来做这个事情：也就是让http变成有状态的。 http本身来实现状态维护 从上面关于无状态的理解，如果现在需要让http自己变成有状态的，就意味着http协议需要保存交互的状态信息；暂且不说这种方式是否合适，但从维护状态信息这一点来说，代价就很高，因为既然保存了状态信息，那后续的一些行为必定也会受到状态信息的影响。 从历史角度来说，最初的http协议只是用来浏览静态文件的，无状态协议已经足够，这样实现的负担也很轻。但是随着web技术的不断发展，越来越多的场景需要状态信息能够得以保存；一方面是http本身不会去改变它的这种无状态的特性（至少目前是这样的），另一方面业务场景又迫切的需要保持状态；那么这个时候就需要来“装饰”一下http，引入一些其他机制来实现有状态。 cookie和session体系 通过引入cookie和session体系机制来维护状态信息。即用户第一次访问服务器的时候，服务器响应报头通常会出现一个Set-Cookie响应头，这里其实就是在本地设置一个cookie，当用户再次访问服务器的时候，http会附带这个cookie过去，cookie中存有sessionId这样的信息来到服务器这边确认是否属于同一次会话。 Cookie cookie是由服务器发送给客户端（浏览器）的小量信息，以{key：value}的形式存在。 Cookie机制原理 客户端请求服务器时，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。而客户端浏览器会把Cookie保存起来。当浏览器再请求 服务器时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器通过检查该Cookie来获取用户状态。 我们通过看下servlet-api中Cookie类的定义及属性，来更加具体的了解Cookie。 Cookie在servlet-api中的定义123456789101112131415161718public class Cookie implements Cloneable, Serializable &#123; private static final long serialVersionUID = -6454587001725327448L; private static final String TSPECIALS; private static final String LSTRING_FILE = "javax.servlet.http.LocalStrings"; private static ResourceBundle lStrings = ResourceBundle.getBundle("javax.servlet.http.LocalStrings"); private String name; private String value; private String comment; private String domain; private int maxAge = -1; private String path; private boolean secure; private int version = 0; private boolean isHttpOnly = false; //....省略其他方法&#125; Cookie属性 name cookie的名字，Cookie一旦创建，名称便不可更改 value cookie值 comment 该Cookie的用处说明。浏览器显示Cookie信息的时候显示该说明 domain 可以访问该Cookie的域名。如果设置为“.baidu.com”，则所有以“baidu.com”结尾的域名都可以访问该Cookie；第一个字符必须为“.” maxAge Cookie失效的时间，单位秒。 正数，则超过maxAge秒之后失效。 负数，该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie。 为0，表示删除该Cookie。 path 该Cookie的使用路径。例如： path=/，说明本域名下contextPath都可以访问该Cookie。 path=/app/，则只有contextPath为“/app”的程序可以访问该Cookie path设置时，其以“/”结尾. secure 该Cookie是否仅被使用安全协议传输。这里的安全协议包括HTTPS，SSL等。默认为false。 version 该Cookie使用的版本号。 0 表示遵循Netscape的Cookie规范，目前大多数用的都是这种规范； 1 表示遵循W3C的RFC2109规范；规范过于严格，实施起来很难。 在servlet规范中默认是0； isHttpOnly HttpOnly属性是用来限制非HTTP协议程序接口对客户端Cookie进行访问；也就是说如果想要在客户端取到httponly的Cookie的唯一方法就是使用AJAX，将取Cookie的操作放到服务端，接收客户端发送的ajax请求后将取值结果通过HTTP返回客户端。这样能有效的防止XSS攻击。 上述的这些属性，除了name与value属性会被提交外，其他的属性对于客户端来说都是不可读的，也是不可被提交的。 创建Cookie12345Cookie cookie = new Cookie("cookieSessionId","qwertyuiop");cookie.setDomain(".baidu.com"); // 设置域名cookie.setPath("/"); // 设置路径cookie.setMaxAge(Integer.MAX_VALUE); // 设置有效期为永久response.addCookie(cookie); // 回写到客户端 创建Cookie只能通过上述方式来创建，因为在Cookie类中只提供了这样一个构造函数。 123456789101112131415161718192021222324252627//Cookie的构造函数public Cookie(String name, String value) &#123; if (name != null &amp;&amp; name.length() != 0) &#123; //判断下是不是token //判断是不是和Cookie的属性字段重复 if (this.isToken(name) &amp;&amp; !name.equalsIgnoreCase("Comment") &amp;&amp; !name.equalsIgnoreCase("Discard") &amp;&amp; !name.equalsIgnoreCase("Domain") &amp;&amp; !name.equalsIgnoreCase("Expires") &amp;&amp; !name.equalsIgnoreCase("Max-Age") &amp;&amp; !name.equalsIgnoreCase("Path") &amp;&amp; !name.equalsIgnoreCase("Secure") &amp;&amp; !name.equalsIgnoreCase("Version") &amp;&amp; !name.startsWith("$")) &#123; this.name = name; this.value = value; &#125; else &#123; String errMsg = lStrings.getString("err.cookie_name_is_token"); Object[] errArgs = new Object[]&#123;name&#125;; errMsg = MessageFormat.format(errMsg, errArgs); throw new IllegalArgumentException(errMsg); &#125; &#125; else &#123; throw new IllegalArgumentException(lStrings.getString ("err.cookie_name_blank")); &#125;&#125; Cookie更新在源码中可以知道，Cookie本身并没有提供修改的方法；在实际应用中，一般通过使用相同name的Cookie来覆盖原来的Cookie,以达到更新的目的。 但是这个修改的前提是需要具有相同domain，path的 Set-Cookie 消息头 12Cookie cookie = new Cookie("cookieSessionId","new-qwertyuiop");response.addCookie(cookie); Cookie删除与Cookie更新一样，Cookie本身也没有提供删除的方法；但是从前面分析Cookie属性时了解到，删除Cookie可以通过将maxAge设置为0即可。 123Cookie cookie = new Cookie("cookieSessionId","new-qwertyuiop");cookie.setMaxAge(0);response.addCookie(cookie); 上面的删除是我们自己可控的；但是也存在一些我们不可控或者说无意识情况下的删除操作： 如果maxAge是负值，则cookie在浏览器关闭时被删除 持久化cookie在到达失效日期时会被删除 浏览器中的 cookie 数量达到上限，那么 cookie 会被删除以为新建的 cookie 创建空间。 其实很多情况下，我们关注的都是后者。关于数量上限后面会说到。 从请求中获取Cookie1Cookie[] cookies = request.getCookies(); Cookie同源与跨域我们知道浏览器的同源策略： URL由协议、域名、端口和路径组成，如果两个URL的协议、域名和端口相同，则表示他们同源。浏览器的同源策略，限制了来自不同源的”document”或脚本，对当前”document”读取或设置某些属性。 对于Cookie来说，Cookie的同源只关注域名，是忽略协议和端口的。所以一般情况下，https://localhost:80/和http://localhost:8080/的Cookie是共享的。 Cookie是不可跨域的；在没有经过任何处理的情况下，二级域名不同也是不行的。(wenku.baidu.com和baike.baidu.com)。 Cookie数量&amp;大小限制及处理策略 IE6.0 IE7.0/8.0 Opera FF Safari Chrome 个数/个 20/域 50/域 30/域 50/域 无限制 53/域 大小/Byte 4095 4095 4096 4097 4097 4097 注：数据来自网络，仅供参考 因为浏览器对于Cookie在数量上是有限制的，如果超过了自然会有一些剔除策略。在这篇文章中Browser cookie restrictions提到的剔除策略如下： The least recently used (LRU) approach automatically kicks out the oldest cookie when the cookie limit has been reached in order to allow the newest cookie some space. Internet Explorer and Opera use this approach. 最近最少使用（LRU）方法：在达到cookie限制时自动地剔除最老的cookie，以便腾出空间给许最新的cookie。Internet Explorer和Opera使用这种方法。 Firefox does something strange: it seems to randomly decide which cookies to keep although the last cookie set is always kept. There doesn’t seem to be any scheme it’s following at all. The takeaway? Don’t go above the cookie limit in Firefox. Firefox决定随机删除Cookie集中的一个Cookie，并没有什么章法。所以最好不要超过Firefox中的Cookie限制。 超过大小长度的话就是直接被截取丢弃； SessionCookie机制弥补了HTTP协议无状态的不足。在Session出现之前，基本上所有的网站都采用Cookie来跟踪会话。 与Cookie不同的是，session是以服务端保存状态的。 session机制原理当客户端请求创建一个session的时候，服务器会先检查这个客户端的请求里是否已包含了一个session标识 - sessionId， 如果已包含这个sessionId，则说明以前已经为此客户端创建过session，服务器就按照sessionId把这个session检索出来使用（如果检索不到，可能会新建一个） 如果客户端请求不包含sessionId，则为此客户端创建一个session并且生成一个与此session相关联的sessionId sessionId的值一般是一个既不会重复，又不容易被仿造的字符串，这个sessionId将被在本次响应中返回给客户端保存。保存sessionId的方式大多情况下用的是cookie。 HttpSessionHttpSession和Cookie一样，都是javax.servlet.http下面的；Cookie是一个类，它描述了Cookie的很多内部细节。而HttpSession是一个接口，它为session的实现提供了一些行为约束。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public interface HttpSession &#123; /** * 返回session的创建时间 */ public long getCreationTime(); /** * 返回一个sessionId,唯一标识 */ public String getId(); /** *返回客户端最后一次发送与该 session 会话相关的请求的时间 *自格林尼治标准时间 1970 年 1 月 1 日午夜算起，以毫秒为单位。 */ public long getLastAccessedTime(); /** * 返回当前session所在的ServletContext */ public ServletContext getServletContext(); public void setMaxInactiveInterval(int interval); /** * 返回 Servlet 容器在客户端访问时保持 session * 会话打开的最大时间间隔 */ public int getMaxInactiveInterval(); public HttpSessionContext getSessionContext(); /** * 返回在该 session会话中具有指定名称的对象， * 如果没有指定名称的对象，则返回 null。 */ public Object getAttribute(String name); public Object getValue(String name); /** * 返回 String 对象的枚举，String 对象包含所有绑定到该 session * 会话的对象的名称。 */ public Enumeration&lt;String&gt; getAttributeNames(); public String[] getValueNames(); public void setAttribute(String name, Object value); public void putValue(String name, Object value); public void removeAttribute(String name); public void removeValue(String name); /** * 指示该 session 会话无效，并解除绑定到它上面的任何对象。 */ public void invalidate(); /** * 如果客户端不知道该 session 会话，或者如果客户选择不参入该 * session 会话，则该方法返回 true。 */ public boolean isNew();&#125; 创建session创建session的方式是通过request来创建；1234// 1、创建Session对象HttpSession session = request.getSession(); // 2、创建Session对象HttpSession session = request.getSession(true); 这两种是一样的；如果session不存在，就新建一个；如果是false的话，标识如果不存在就返回null； 生命周期session的生命周期指的是从Servlet容器创建session对象到销毁的过程。Servlet容器会依据session对象设置的存活时间，在达到session时间后将session对象销毁。session生成后，只要用户继续访问，服务器就会更新session的最后访问时间，并维护该session。 之前在单进程应用中，session我一般是存在内存中的，不会做持久化操作或者说使用三方的服务来存session信息，如redis。但是在分布式场景下，这种存在本机内存中的方式显然是不适用的，因为session无法共享。这个后面说。 session的有效期session一般在内存中存放，内存空间本身大小就有一定的局限性，因此session需要采用一种过期删除的机制来确保session信息不会一直累积，来防止内存溢出的发生。 session的超时时间可以通过maxInactiveInterval属性来设置。 如果我们想让session失效的话，也可以当通过调用session的invalidate()来完成。 分布式session首先是为什么会有这样的概念出现？ 先考虑这样一个问题，现在我的应用需要部署在3台机器上。是不是出现这样一种情况，我第一次登陆，请求去了机器1，然后再机器1上创建了一个session；但是我第二次访问时，请求被路由到机器2了，但是机器2上并没有我的session信息，所以得重新登录。当然这种可以通过nginx的IP HASH负载策略来解决。对于同一个IP请求都会去同一个机器。 但是业务发展的越来越大，拆分的越来越多，机器数不断增加；很显然那种方案就不行了。那么这个时候就需要考虑是不是应该将session信息放在一个独立的机器上，所以分布式session要解决的问题其实就是分布式环境下的session共享的问题。 上图中的关于session独立部署的方式有很多种，可以是一个独立的数据库服务，也可以是一个缓存服务(redis，目前比较常用的一种方式，即使用Redis来作为session缓存服务器)。 参考 https://www.cnblogs.com/icelin/p/3974935.html https://www.nczonline.net/blog/2008/05/17/browser-cookie-restrictions/ https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE]]></content>
      <categories>
        <category>session</category>
      </categories>
      <tags>
        <tag>聊一聊</tag>
        <tag>session</tag>
        <tag>cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊 AOP：Advice 源码解析]]></title>
    <url>%2F2018%2F11%2F10%2Fspringaoptwo%2F</url>
    <content type="text"><![CDATA[在第一篇中的例子和概念介绍中我们对 Advice 有了一个初步的认知。在Spring AOP中，Advice的作用就是用来描述 Spring AOP 围绕方法调用而注入的切面行为。 本篇文章将从源码的角度来看一看 Advice 到底是什么样的？又是怎么完成通知的？ Advice 接口1234567891011package org.aopalliance.aop;/** * Tag interface for Advice. Implementations can be any type * of advice, such as Interceptors. * @author Rod Johnson * @version $Id: Advice.java,v 1.1 2004/03/19 17:02:16 johnsonr Exp $ */public interface Advice &#123;&#125; Advice 接口的定义是在 org.aopalliance.aop 包下面的；从上面的代码中我们可以知道，Advice 接口并没有提供任何的方法；类似的接口定义还有java 中的如Serializable接口，这类接口一般称之为标识接口；标识接口对实现它的类没有任何的语义要求,仅仅是充当一个标示的作用,用来表明实现它的类属于一个特定的类型（从这种标识性角度来说，和注解其实挺像的）； Spring AOP中通过定义和使用这样一个统一的接口，为的就是能够为切面增强的织入功能做更多的细化和扩展。下面就对常见的三个Advice进行分析。 BeforeAdvice12public interface BeforeAdvice extends Advice &#123;&#125; 这个接口也是一个标识接口。看下 BeforeAdvice 的继承关系： MethodBeforeAdvice 是 BeforeAdvice 为待增强的目标方法设置的前置增强接口。 1234public interface MethodBeforeAdvice extends BeforeAdvice &#123; void before(Method method, Object[] args, Object target) throws Throwable;&#125; MethodBeforeAdvice 中提供了一个回调函数 before(…) ； 作为回调函数，before 方法的实现在 Advice 中被配置到目标方法后，会在调用目标方法时被回调。来看下before方法的几个参数： Method method ：（ method being invoked）这个参数是目标方法的反射对象； Object[] args ：（arguments to the method）目标方法的输入参数； Object target ：（target of the method invocation）方法调用的目标 AspectJMethodBeforeAdviceAspectJMethodBeforeAdvice 继承了 AbstractAspectJAdvice 抽象类，并实现了 MethodBeforeAdvice 接口。从 AspectJMethodBeforeAdvice 类中代码可以得知，AspectJMethodBeforeAdvice 重写 before 方法的实现是 通过调用父类的 invokeAdviceMethod 方法完成的。也就是说Spring AOP 的Advice包装了AspectJ的before方法。 Spring AOP的实现后面再说，我们先自己来实现一个简单的通知。 自定义 Advice实现 MethodBeforeAdvice定义我们自己的 GlmapperBeforeMethodAdvice ；这里实现 MethodBeforeAdvice 接口，然后重写 before 这个方法。 1234567891011121314151617181920212223/** * @description: 自定义的 GlmapperBeforeMethodAdvice * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: glmapper@leishu * @date: 18/6/23 */public class GlmapperBeforeMethodAdvice implementsMethodBeforeAdvice,MethodInterceptor &#123; private static final Logger LOGGER = LoggerFactory.getLogger(GlmapperBeforeMethodAdvice.class.getSimpleName()); @Override public void before(Method method, Object[] args, Object target) throws Throwable &#123; LOGGER.info("invoke BeforeAdvice successfully..."); &#125; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; Object result=invocation.proceed(); return result; &#125;&#125; OK，有了这个 GlmapperBeforeMethodAdvice ，再来看看怎么用它；同样本篇文章所使用的案例均使用前一篇博客中的那个脚手架来完成。 12345678910111213141516171819202122232425262728293031&lt;!--我们的目标类--&gt;&lt;bean id="goodsService" class="com.glmapper.framerwork.service.impl.GoodsServiceImpl"/&gt;&lt;!--我们自定义的Advice--&gt;&lt;bean id="glmapperBeforeMethodAdvice" class="com.glmapper.framerwork.Advice.GlmapperBeforeMethodAdvice"&gt;&lt;/bean&gt;&lt;!-- 声明切入点adviser --&gt;&lt;bean id="adviser" class="org.springframework.aop.support.RegexpMethodPointcutAdvisor"&gt; &lt;!--这里使用我们自定义的advice--&gt; &lt;property name="advice" ref="glmapperBeforeMethodAdvice"&gt;&lt;/property&gt; &lt;!-- pattern指定queryAll方法作为切入点； \. 这个是转义使用--&gt; &lt;property name="pattern" value="com\.glmapper\.framerwork\.service\.impl\.GoodsServiceImpl\.queryAll"&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- 定义代理对象 返回实例是目标对象 target属性指定的goodsService对象--&gt;&lt;bean id="proxyService"class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;property name="target"&gt; &lt;ref bean="goodsService" /&gt; &lt;/property&gt; &lt;!--源码内固定的属性private String[] interceptorNames; --&gt; &lt;property name="interceptorNames"&gt; &lt;value&gt;adviser&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 客户端部分，通过SpringContextUtil来拿代理对象； 1234567891011@RequestMapping("/initPage")public ModelAndView initPage(HttpServletRequest request, HttpServletResponse response, ModelAndView view) &#123; //获取代理bean GoodsService proxyService= (GoodsService) SpringContextUtil.getBean("proxyService"); //调用 List&lt;Goods&gt; goods = proxyService.queryAll(10,10); view.addObject("goodsList", goods); view.setViewName("goodslist"); return view;&#125; 日志输出满足我们的期望（如下）： 同样的，在GlmapperBeforeMethodAdvice基础上再实现 AfterReturningAdvice 接口，重写afterReturning方法，就能实现后置通知。 12345@Overridepublic void afterReturning(Object returnValue, Method method, Object[]args, Object target) throws Throwable &#123; LOGGER.info("invoke AfterAdvice successfully...");&#125; 这个方式在聊一聊 AOP ：表现形式与基础概念中有说道。 Advice 在 Aop 中的实现原理这里感觉没什么好说的，上面的案例其实就是Spring提供给我们使用的接口。因为MethodBeforeAdvice等都是继承自 AbstractAspectJAdvice 这个抽象类；我们就来看下这个抽象类里面的一些核心逻辑吧。我们按照AspectJMethodBeforeAdvice这里这个类里面before提供的线索来一步步分析。 首先在AspectJMethodBeforeAdvice里before方法中调用的是这个逻辑： 12345678910111213/** * Invoke the advice method. * @param jpMatch the JoinPointMatch that matched this execution join point * @param returnValue the return value from the method execution (may be null) * @param ex the exception thrown by the method execution (may be null) * @return the invocation result * @throws Throwable in case of invocation failure */protected Object invokeAdviceMethod(JoinPointMatch jpMatch, ObjectreturnValue, Throwable ex) throws Throwable &#123; return invokeAdviceMethodWithGivenArgs(argBinding(getJoinPoint(), jpMatch, returnValue, ex));&#125; 这里 argBinding 方法的作用是获取方法执行连接点上的参数，并将一组参数输出给Advice方法。 继续来看invokeAdviceMethodWithGivenArgs这个方法： 1234567891011121314151617181920212223protected Object invokeAdviceMethodWithGivenArgs(Object[] args) throwsThrowable &#123; //保存一份参数副本 Object[] actualArgs = args; //验证下参数是否不存在 if (this.aspectJAdviceMethod.getParameterTypes().length == 0) &#123; actualArgs = null; &#125; try &#123; //设置下方法的访问权限 ReflectionUtils.makeAccessible(this.aspectJAdviceMethod); // invoke执行；这里先通过aspectInstanceFactory对像拿到我们的目标对象实例，然后再进行invoke调用执行 return this.aspectJAdviceMethod.invoke(this.aspectInstanceFactory.getAspectInstance(), actualArgs); &#125; catch (IllegalArgumentException ex) &#123; throw new AopInvocationException("Mismatch on arguments to advice method [" + this.aspectJAdviceMethod + "]; pointcut expression [" + this.pointcut.getPointcutExpression() + "]", ex); &#125; catch (InvocationTargetException ex) &#123; throw ex.getTargetException(); &#125;&#125; 上面这段代码其实就是通过反射的方式执行了我们的目标方法。我们再回过头来看下我们的目标方法到底在哪里去进行增强的；这里我们通过配置文件来看： 123456789101112&lt;!-- 代理对象 返回实例是目标对象 target属性指定的AOPservice对象--&gt;&lt;bean id="proxyService"class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;property name="target"&gt; &lt;ref bean="goodsService" /&gt; &lt;/property&gt; &lt;!--源码内固定的属性private String[] interceptorNames; --&gt; &lt;property name="interceptorNames"&gt; &lt;value&gt;adviser&lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 代理对象proxyService实现上是ProxyFactoryBean产生的；这里就不在阐述BeanFactory和FactoryBean的区别了。 从上面的配置文件我们可以简单的了解到，代理对象实际上是我们目标对象+adviser共同组成；而在adviser里面又包括了我们的通知。 ProxyFactoryBean继承了FactoryBean，我们知道FactoryBean也是用来生成bean的，但是它生成的bean是通过其getObject方法来获取的。OK，那我们来看下ProxyFactoryBean的getObject方法： 1234567891011121314151617181920212223/** * Return a proxy. Invoked when clients obtain beans from this factory bean. * Create an instance of the AOP proxy to be returned by this factory. * The instance will be cached for a singleton, and create on each call to * &#123;@code getObject()&#125; for a proxy. * @return a fresh AOP proxy reflecting the current state of this factory */@Overridepublic Object getObject() throws BeansException &#123; //初始化Advisor链 initializeAdvisorChain(); //如果是单例，则获取单例对象 if (isSingleton()) &#123; return getSingletonInstance(); &#125; else &#123; if (this.targetName == null) &#123; logger.warn("Using non-singleton proxies with singleton targets is often undesirable. " + "Enable prototype proxies by setting the 'targetName' property."); &#125; return newPrototypeInstance(); &#125;&#125; 返回一个代理。当客户端从这个工厂bean获取bean时调用。创建该工厂返回的AOP代理的一个实例。该实例将被缓存为一个单例，并在每次调用时创建。 initializeAdvisorChain：创建 advisor（拦截器）链。每次添加新的 prototype 实例时，源自 BeanFactory 的 Advisor 都将被刷新。通过工厂 API 以编程方式添加的拦截器不受此类更改的影响。（译注）；其实就是根据我们配置的interceptorNames来初始化我们的advisor（拦截器）链，用来增强我们的目标调用方法。 下面是getSingletonInstance这个方法： 123456789101112131415161718192021222324/** * Return the singleton instance of this class's proxy object, * lazily creating it if it hasn't been created already. * @return the shared singleton proxy */private synchronized Object getSingletonInstance() &#123; if (this.singletonInstance == null) &#123; //创建目标对象的代理 this.targetSource = freshTargetSource(); if (this.autodetectInterfaces &amp;&amp; getProxiedInterfaces().length == 0 &amp;&amp; !isProxyTargetClass()) &#123; // Rely on AOP infrastructure to tell us what interfaces to proxy. //获取目标类 Class&lt;?&gt; targetClass = getTargetClass(); if (targetClass == null) &#123; throw new FactoryBeanNotInitializedException("Cannot determine target class for proxy"); &#125; setInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.proxyClassLoader)); &#125; // Initialize the shared singleton instance. super.setFrozen(this.freezeProxy); this.singletonInstance = getProxy(createAopProxy()); &#125; return this.singletonInstance;&#125; 上面代码最核心的是getProxy这个方法，这里方式有两个方式，一个是cglib，另外一种是jdk动态代理： 这里我们以默认的动态代理的方式来说：(org.springframework.aop.framework.JdkDynamicAopProxy类中) 1234567891011@Overridepublic Object getProxy(ClassLoader classLoader) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating JDK dynamic proxy: target source is " + this.advised.getTargetSource()); &#125; Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);&#125; 这个方法返回的就是指定接口的代理类实例，该接口将方法调用分派给指定的调用处理程序。 到此整个AOP代理生成逻辑就完了。 总结一下就是我们的代理类中其实包括了我们AOP增强的那部分逻辑的，这个其实从上面的配置文件中就很清楚的可以看出来；所以从Adivce介个角度来说，它其实会被抱在advisor中，然后在被传递到代理对象中，代理对象除了拥有我们目标对象的能力之外，还包括了Adivce的能力；通过这种方式就实现了增强。 关于Advice就到这里了，下一章会来单独说一下 PointCut 。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>聊一聊</tag>
        <tag>aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊 AOP ：表现形式与基础概念]]></title>
    <url>%2F2018%2F11%2F10%2Fspringaopone%2F</url>
    <content type="text"><![CDATA[aop 终于提上日程来写一写了。 系列目录本系列分为 上、中、下三篇。上篇主要是介绍如果使用 AOP ，提供了demo和配置方式说明；中篇来对实现 AOP 的技术原理进行分析；下篇主要针对Spring中对于AOP的实现进行源码分析。 从一个例子说起 基于代理的方式 纯POJO切面 配置方式 AspectJ 注解方式 AspectJ XML 配置方式 表达式说明 基础概念 AOP概念 Target Object 织入（Weave Proxy Introduction Aspect Joinpoint Pointcut Advice 概念 分类 关系 一些坑 项目地址项目地址：glmapper-ssm-parent 这个项目里面包含了下面几种 AOP 实现方式的所有代码，有兴趣的同学可以fork跑一下。这个demo中列举了4中方式的实现： 基于代码的方式 基于纯POJO类的方式 基于Aspect注解的方式 基于注入式Aspect的方式 目前我们经常用到的是基于Aspect注解的方式的方式。下面来一个个了解下不同方式的表现形式。 基于代理的方式这种方式看起来很好理解，但是配置起来相当麻烦；小伙伴们可以参考项目来看，这里只贴出比较关键的流程代码。 1、首先定义一个接口：GoodsService12345678910public interface GoodsService &#123; /** * 查询所有商品信息 * * @param offset 查询起始位置 * @param limit 查询条数 * @return */ List&lt;Goods&gt; queryAll(int offset,int limit);&#125; 2、GoodsService 实现类123456789101112@Service@Qualifier("goodsService")public class GoodsServiceImpl implements GoodsService &#123; @Autowired private GoodsDao goodsDao; public List&lt;Goods&gt; queryAll(int offset, int limit) &#123; System.out.println("执行了queryAll方法"); List&lt;Goods&gt; list = new ArrayList&lt;Goods&gt;(); return list; &#125;&#125; 3、定义一个通知类 LoggerHelper，该类继承 MethodBeforeAdvice和 AfterReturningAdvice。123456789101112131415//通知类 LoggerHelperpublic class LoggerHelper implements MethodBeforeAdvice,AfterReturningAdvice &#123; private static final Logger LOGGER = LoggerFactory.getLogger(LoggerHelper.class); //MethodBeforeAdvice的before方法实现 public void before(Method method, Object[] objects, Object o) throws Throwable &#123; LOGGER.info("before current time:"+System.currentTimeMillis()); &#125; //AfterReturningAdvice的afterReturning方法实现 public void afterReturning(Object o, Method method, Object[] objects, Object o1) throws Throwable &#123; LOGGER.info("afterReturning current time:"+System.currentTimeMillis()); &#125;&#125; 4、重点，这个配置需要关注下。这个项目里面我是配置在applicationContext.xml文件中的。12345678910111213141516171819202122232425262728&lt;!-- 定义被代理者 --&gt;&lt;bean id="goodsServiceImpl" class="com.glmapper.framerwork.service.impl.GoodsServiceImpl"&gt;&lt;/bean&gt;&lt;!-- 定义通知内容，也就是切入点执行前后需要做的事情 --&gt;&lt;bean id="loggerHelper" class="com.glmapper.framerwork.aspect.LoggerHelper"&gt;&lt;/bean&gt;&lt;!-- 定义切入点位置 --&gt;&lt;bean id="loggerPointcut" class="org.springframework.aop.support.JdkRegexpMethodPointcut"&gt; &lt;property name="pattern" value=".*query.*"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 使切入点与通知相关联，完成切面配置 --&gt;&lt;!-- 从这里可以帮助我们理解Advisor，advice和pointcut之间的关系--&gt;&lt;!--adivce和pointcut是Advisor的两个属性--&gt;&lt;bean id="loggerHelperAdvisor" class="org.springframework.aop.support.DefaultPointcutAdvisor"&gt; &lt;property name="advice" ref="loggerHelper"&gt;&lt;/property&gt; &lt;property name="pointcut" ref="loggerPointcut"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 设置代理 --&gt;&lt;bean id="proxy" class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;!-- 代理的对象 ，也就是目标类--&gt; &lt;property name="target" ref="goodsServiceImpl"&gt;&lt;/property&gt; &lt;!-- 使用切面 --&gt; &lt;property name="interceptorNames" value="loggerHelperAdvisor"&gt;&lt;/property&gt; &lt;!-- 代理接口，商品接口 --&gt; &lt;property name="proxyInterfaces" value="com.glmapper.framerwork.service.GoodsService"&gt;&lt;/property&gt;&lt;/bean&gt; 5、使用：注解注入方式1234567891011121314151617181920@Controller@RequestMapping("/buy")public class BuyController &#123; @Autowired private OrderService orderService; //因为我们已经在配置文件中配置了proxy， //所以这里可以直接注入拿到我们的代理类 @Autowired private GoodsService proxy; @RequestMapping("/initPage") public ModelAndView initPage(HttpServletRequest request, HttpServletResponse response, ModelAndView view) &#123; //这里使用proxy执行了*query*, List&lt;Goods&gt; goods = proxy.queryAll(10,10); view.addObject("goodsList", goods); view.setViewName("goodslist"); return view; &#125;&#125; 6、使用：工具类方式手动获取bean这个方式是通过一个SpringContextUtil工具类来获取代理对象的。12345678910@RequestMapping(&quot;/initPage&quot;)public ModelAndView initPage(HttpServletRequest request, HttpServletResponse response, ModelAndView view) &#123; //这里通过工具类来拿，效果一样的。 GoodsService proxy= (GoodsService) SpringContextUtil.getBean(&quot;proxy&quot;); List&lt;Goods&gt; goods = proxy.queryAll(10,10); view.addObject(&quot;goodsList&quot;, goods); view.setViewName(&quot;goodslist&quot;); return view;&#125; 7、SpringContextUtil 类的定义这个还是有点坑的，首先SpringContextUtil是继承ApplicationContextAware这个接口，我们希望能够SpringContextUtil可以被Spring容器直接管理，所以，需要使用 @Component 标注。标注了之后最关键的是它得能够被我们配置的注入扫描扫到（亲自踩的坑，我把它放在一个扫不到的包下面，一直debug都是null；差点砸电脑…） 123456789101112131415161718192021222324252627282930313233@Componentpublic class SpringContextUtil implements ApplicationContextAware &#123; // Spring应用上下文环境 private static ApplicationContext applicationContext; /** * 实现ApplicationContextAware接口的回调方法，设置上下文环境 * * @param applicationContext */ public void setApplicationContext(ApplicationContext applicationContext) &#123; SpringContextUtil.applicationContext = applicationContext; &#125; /** * @return ApplicationContext */ public static ApplicationContext getApplicationContext() &#123; return applicationContext; &#125; /** * 获取对象 * 这里重写了bean方法，起主要作用 * @param name * @return Object 一个以所给名字注册的bean的实例 * @throws BeansException */ public static Object getBean(String name) throws BeansException &#123; return applicationContext.getBean(name); &#125;&#125; 8、运行结果12345678921:04:47.940 [http-nio-8080-exec-7] INFO c.g.framerwork.aspect.LoggerHelper - before currenttime:1529413487940执行了queryAll方法21:04:47.940 [http-nio-8080-exec-7] INFO c.g.framerwork.aspect.LoggerHelper - afterReturning currenttime:1529413487940 上面就是最最经典的方式，就是通过代理的方式来实现AOP的过程。 纯POJO切面 aop:config注意这里和LoggerHelper的区别，这里的LoggerAspect并没有继承任何接口或者抽象类。 1、POJO 类定义123456789101112131415161718/** * @description: [描述文本] * @email: &lt;a href="guolei.sgl@antfin.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/6/20 */public class LoggerAspect &#123; private static final Logger LOGGER = LoggerFactory.getLogger(LoggerHelper.class); public void before()&#123; LOGGER.info("before current time:"+System.currentTimeMillis()); &#125; public void afterReturning() &#123; LOGGER.info("afterReturning current time:"+System.currentTimeMillis()); &#125;&#125; 2、配置文件123456789101112131415161718&lt;!-- 定义通知内容，也就是切入点执行前后需要做的事情 --&gt;&lt;bean id="loggerAspect" class="com.glmapper.framerwork.aspect.LoggerAspect"&gt;&lt;/bean&gt;&lt;aop:config&gt; &lt;!--定义切面--&gt; &lt;aop:aspect ref="loggerAspect"&gt; &lt;aop:pointcut id="loggerPointCut" expression= "execution(* com.glmapper.framerwork.service.impl.*.*(..)) " /&gt; &lt;!-- 定义 Advice --&gt; &lt;!-- 前置通知 --&gt; &lt;aop:before pointcut-ref="loggerPointCut" method="before" /&gt; &lt;!-- 后置通知 --&gt; &lt;aop:after-returning pointcut-ref="loggerPointCut" method="afterReturning"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 注意这里LoggerAspect中的before和afterReturning如果有参数，这里需要处理下，否则会报 0 formal unbound in pointcut 异常。 @AspectJ 注解驱动方式这种方式是最简单的一种实现，直接使用 @Aspect 注解标注我们的切面类即可。 1、定义切面类，并使用 @Aspect 进行标注123456789101112131415161718192021222324/** * @description: 使用Aspect注解驱动的方式 * @email: &lt;a href="guolei.sgl@antfin.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/6/20 */@Aspectpublic class LoggerAspectInject &#123; private static final Logger LOGGER = LoggerFactory.getLogger(LoggerAspectInject.class); @Pointcut("execution(* com.glmapper.framerwork.service.impl.*.*(..))") public void cutIn()&#123;&#125; @Before("cutIn()") public void before()&#123; LOGGER.info("before current time:"+System.currentTimeMillis()); &#125; @AfterReturning("cutIn()") public void AfterReturning()&#123; LOGGER.info("afterReturning current time:"+System.currentTimeMillis()); &#125;&#125; 2、使用方式1：配置文件方式声明 bean123456789&lt;aop:aspectj-autoproxy /&gt;&lt;!-- 定义通知内容，也就是切入点执行前后需要做的事情 --&gt;&lt;bean id="loggerAspectInject" class="com.glmapper.framerwork.aspect.LoggerAspectInject"&gt;&lt;/bean&gt;&lt;!-- 定义被代理者 --&gt;&lt;bean id="goodsServiceImpl" class="com.glmapper.framerwork.service.impl.GoodsServiceImpl"&gt;&lt;/bean&gt; 3、客户端使用：1234567891011121314151617181920@Controller@RequestMapping("/buy")public class BuyController &#123; @Autowired private OrderService orderService; @RequestMapping("/initPage") public ModelAndView initPage(HttpServletRequest request, HttpServletResponse response, ModelAndView view) &#123; //通过SpringContextUtil手动获取 代理bean GoodsService goodsService=(GoodsService) SpringContextUtil.getBean("goodsServiceImpl"); List&lt;Goods&gt; goods = goodsService.queryAll(10,10); view.addObject("goodsList", goods); view.setViewName("goodslist"); return view; &#125;&#125; 4、使用方式2：使用@component注解托管给IOC1234567891011121314151617181920@Aspect@Component //这里加上了Component注解，就不需要在xml中配置了public class LoggerAspectInject &#123; private static final Logger LOGGER = LoggerFactory.getLogger(LoggerAspectInject.class); @Pointcut("execution(* com.glmapper.framerwork.service.impl.*.*(..))") public void cutIn()&#123;&#125; @Before("cutIn()") public void before()&#123; LOGGER.info("before current time:"+System.currentTimeMillis()); &#125; @AfterReturning("cutIn()") public void AfterReturning()&#123; LOGGER.info("afterReturning current time:"+System.currentTimeMillis()); &#125;&#125; 5、客户端代码：1234567891011121314151617181920@Controller@RequestMapping("/buy")public class BuyController &#123; @Autowired private OrderService orderService; //直接注入 @Autowired private GoodsService goodsService; @RequestMapping("/initPage") public ModelAndView initPage(HttpServletRequest request, HttpServletResponse response, ModelAndView view) &#123; List&lt;Goods&gt; goods = goodsService.queryAll(10,10); view.addObject("goodsList", goods); view.setViewName("goodslist"); return view; &#125;&#125; 6、比较完整的一个LoggerAspectInject，在实际工程中可以直接参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @description: aop * @email: &lt;a href="henugl@1992.163.com"&gt;&lt;/a&gt; * @author: glmapper@磊叔 * @date: 18/6/4 */@Aspect@Componentpublic class LoggerAspectInject &#123; private static final Logger LOGGER= LoggerFactory.getLogger(LoggerAspectInject.class); @Pointcut("execution(* com.glmapper.book.web.controller.*.*(..))") public void cutIn()&#123; &#125; @Around("cutIn()") // 定义Pointcut，名称即下面的标识"aroundAdvice public Object aroundAdvice(ProceedingJoinPoint poin)&#123; System.out.println("环绕通知"); Object object = null; try&#123; object = poin.proceed(); &#125;catch (Throwable e)&#123; e.printStackTrace(); &#125; return object; &#125; // 定义 advise //这个方法只是一个标识，相当于在配置文件中定义了pointcut的id,此方法没有返回值和参数 @Before("cutIn()") public void beforeAdvice()&#123; System.out.println("前置通知"); &#125; @After("cutIn()") public void afterAdvice()&#123; System.out.println("后置通知"); &#125; @AfterReturning("cutIn()") public void afterReturning()&#123; System.out.println("后置返回 "); &#125; @AfterThrowing("cutIn()") public void afterThrowing()&#123; System.out.println("后置异常"); &#125;&#125; 关于命名切入点：上面的例子中cutIn方法可以被称之为命名切入点，命名切入点可以被其他切入点引用，而匿名切入点是不可以的。只有@AspectJ支持命名切入点，而Schema风格不支持命名切入点。如下所示，@AspectJ使用如下方式引用命名切入点： 12345678@Pointcut("execution(* com.glmapper.book.web.controller.*.*(..))")public void cutIn()&#123;&#125;//引入命名切入点@Before("cutIn()")public void beforeAdvice()&#123; System.out.println("前置通知");&#125; 注入式 AspectJ 切面这种方式我感觉是第二种和第三种的结合的一种方式。 1、定义切面类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/*** @description: 注入式 也是一种通过XML方式配置的方式* @email: &lt;a href="guolei.sgl@antfin.com"&gt;&lt;/a&gt;* @author: guolei.sgl* @date: 18/6/20*/public class LoggerAspectHelper &#123; private static final Logger LOGGER = LoggerFactory.getLogger(LoggerAspectHelper.class); /** * 调动方法前执行 * @param point * @throws Throwable */ public void doBefore(JoinPoint point) throws Throwable &#123; LOGGER.info("before current time:"+System.currentTimeMillis()); &#125; /** * 在调用方法前后执行 * @param point * @return * @throws Throwable */ public Object doAround(ProceedingJoinPoint point) throws Throwable &#123; LOGGER.info("around current time:"+System.currentTimeMillis()); if(point.getArgs().length&gt;0) &#123; return point.proceed(point.getArgs()); &#125;else&#123; return point.proceed(); &#125; &#125; /** * 在调用方法之后执行 * @param point * @throws Throwable */ public void doAfter(JoinPoint point) throws Throwable &#123; LOGGER.info("after current time:"+System.currentTimeMillis()); &#125; /** * 异常通知 * @param point * @param ex */ public void doThrowing(JoinPoint point, Throwable ex) &#123; LOGGER.info("throwing current time:"+System.currentTimeMillis()); &#125;&#125; 2、XML 配置12345678910111213141516171819&lt;bean id="loggerAspectHelper" class="com.glmapper.framerwork.aspect.LoggerAspectHelper"&gt;&lt;/bean&gt;&lt;aop:config&gt; &lt;aop:aspect id="configAspect" ref="loggerAspectHelper"&gt; &lt;!--配置com.glmapper.framerwork.service.imp 包下所有类或接口的所有方法 --&gt; &lt;aop:pointcut id="cutIn" expression= "execution(* com.glmapper.framerwork.service.impl.*.*(..))" /&gt; &lt;aop:before pointcut-ref="cutIn" method="doBefore" /&gt; &lt;aop:after pointcut-ref="cutIn" method="doAfter" /&gt; &lt;aop:around pointcut-ref="cutIn" method="doAround" /&gt; &lt;aop:after-throwing pointcut-ref="cutIn" method="doThrowing" throwing="ex" /&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 3、结果123456723:39:48.756 [http-nio-8080-exec-4] INFO c.g.f.aspect.LoggerAspectHelper- before current time:152950918875623:39:48.757 [http-nio-8080-exec-4] INFO c.g.f.aspect.LoggerAspectHelper- around current time:1529509188757excute queryAll method...23:39:48.757 [http-nio-8080-exec-4] INFO c.g.f.aspect.LoggerAspectHelper- after current time:1529509188757 表达式 从上面的例子中我们都是使用一些正则表达式来指定我们的切入点的。在实际的使用中，不仅仅是execution，还有其他很多种类型的表达式。下面就列举一些： 1、execution用于匹配方法执行的连接点; 1execution(* com.glmapper.book.web.controller.*.*(..)) execution（）表达式的主体； 第一个 “*” 符号表示返回值的类型任意； com.glmapper.book.web.controller AOP所切的服务的包名，即，我们的业务部分 包名后面的”.” 表示当前包及子包 第二个”*” 表示类名，即所有类 .*(..) 表示任何方法名，括号表示参数，两个点表示任何参数类型 2、within用于匹配指定类型内的方法执行; 123456//如果在com.glmapper.book.web.controller包或其下的任何子包中//定义了该类型，则在Web层中有一个连接点。within(com.glmapper.book.web.controller..*)@Pointcut("within(com.glmapper.book.web.controller..*)")public void cutIn()&#123;&#125; @within：用于匹配所以持有指定注解类型内的方法； 12345678910/** * @description: 注解定义 * @email: &lt;a href="henugl@1992.163.com"&gt;&lt;/a&gt; * @author: glmapper@磊叔 * @date: 18/6/4 */@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD,ElementType.FIELD&#125;)public @interface AuthAnnotation &#123;&#125; 任何目标对象对应的类型持有AuthAnnotation注解的类方法；必须是在目标对象上声明这个注解，在接口上声明的对它不起作用。12345@within(com.glmapper.book.common.annotaion.AuthAnnotation)//所有被@AdviceAnnotation标注的类都将匹配@Pointcut("@within(com.glmapper.book.common.annotaion.AuthAnnotation)") public void cutIn()&#123;&#125; 3、this用于匹配当前AOP代理对象类型的执行方法；注意是AOP代理对象的类型匹配，这样就可能包括引入接口也类型匹配；this中使用的表达式必须是类型全限定名，不支持通配符； 12345678//当前目标对象（非AOP对象）实现了 UserService 接口的任何方法this(com.glmapper.book.web.service.UserService)//用于向通知方法中传入代理对象的引用。@Before("cutIn() &amp;&amp; this(proxy)")public void beforeAdvice(ProceedingJoinPoint poin,Object proxy)&#123; System.out.println("前置通知");&#125; 4、target用于匹配当前目标对象类型的执行方法；注意是目标对象的类型匹配，这样就不包括引入接口也类型匹配；target中使用的表达式必须是类型全限定名，不支持通配符；12345678//当前目标对象（非AOP对象）实现了 UserService 接口的任何方法target(com.glmapper.book.web.service.UserService)//用于向通知方法中传入代理对象的引用。@Before("cutIn() &amp;&amp; target(proxy)")public void beforeAdvice(ProceedingJoinPoint poin,Object proxy)&#123; System.out.println("前置通知");&#125; @target：用于匹配当前目标对象类型的执行方法，其中目标对象持有指定的注解；任何目标对象持有Secure注解的类方法；这个和@within一样必须是在目标对象上声明这个注解，在接口上声明的对它同样不起作用。1234@target(com.glmapper.book.common.annotaion.AuthAnnotation)@Pointcut("@target(com.glmapper.book.common.annotaion.AuthAnnotation)")public void cutIn()&#123;&#125; 5、args用于匹配当前执行的方法传入的参数为指定类型的执行方法；参数类型列表中的参数必须是类型全限定名，通配符不支持；args属于动态切入点，这种切入点开销非常大，非特殊情况最好不要使用； 12345678910//任何一个以接受“传入参数类型为java.io.Serializable”开头，//且其后可跟任意个任意类型的参数的方法执行，//args指定的参数类型是在运行时动态匹配的args (java.io.Serializable,..)//用于将参数传入到通知方法中。@Before("cutIn() &amp;&amp; args(age,username)")public void beforeAdvide(JoinPoint point, int age, String username)&#123; //...&#125; @args：用于匹配当前执行的方法传入的参数持有指定注解的执行；任何一个只接受一个参数的方法，且方法运行时传入的参数持有注解AuthAnnotation；动态切入点，类似于arg指示符； 123456@args (com.glmapper.book.common.annotaion.AuthAnnotation)@Before("@args(com.glmapper.book.common.annotaion.AuthAnnotation)")public void beforeAdvide(JoinPoint point)&#123; //...&#125; 6、@annotation使用“@annotation(注解类型)”匹配当前执行方法持有指定注解的方法；注解类型也必须是全限定类型名；1234567//当前执行方法上持有注解 AuthAnnotation将被匹配@annotation(com.glmapper.book.common.annotaion.AuthAnnotation)//匹配连接点被它参数指定的AuthAnnotation注解的方法。//也就是说，所有被指定注解标注的方法都将匹配。@Pointcut("@annotation(com.glmapper.book.common.annotaion.AuthAnnotation)")public void cutIn()&#123;&#125; 还有一种是bean的方式，没用过。有兴趣可以看看。 例子在下面说到的基础概念部分对应给出。 基础概念基础概念部分主要将 AOP 中的一些概念点捋一捋，这部分主要参考了官网上的一些解释。 AOPAOP(Aspect-Oriented Programming)， 即 面向切面编程, 它与 OOP( Object-Oriented Programming, 面向对象编程) 相辅相成, 提供了与 OOP 不同的抽象软件结构的视角。在 OOP 中,我们以类(class)作为我们的基本单元, 而 AOP 中的基本单元是 Aspect(切面)。 横切关注点(Cross Cutting Concern)：独立服务，如系统日志。如果不是独立服务（就是与业务耦合比较强的服务）就不能横切了。通常这种独立服务需要遍布系统各个角落，遍布在业务流程之中。 Target Object目标对象。织入 advice 的目标对象。 目标对象也被称为 advised object。因为 Spring AOP 使用运行时代理的方式来实现 aspect, 因此 adviced object 总是一个代理对象(proxied object)；注意， adviced object 指的不是原来的类, 而是织入 advice 后所产生的代理类。 织入（Weave）即Advice应用在JoinPoint的过程，这个过程叫织入。从另外一个角度老说就是将 aspect 和其他对象连接起来, 并创建 adviced object 的过程。 根据不同的实现技术， AOP织入有三种方式: 编译器织入，这要求有特殊的Java编译器 类装载期织入， 这需要有特殊的类装载器 动态代理织入, 在运行期为目标类添加增强( Advice )生成子类的方式。 Spring 采用动态代理织入, 而AspectJ采用编译器织入和类装载期 代理Spring AOP默认使用代理的是标准的JDK动态代理。这使得任何接口（或一组接口）都可以代理。 Spring AOP也可以使用CGLIB代理。如果业务对象不实现接口，则默认使用CGLIB。对接口编程而不是对类编程是一种很好的做法；业务类通常会实现一个或多个业务接口。在一些特殊的情况下，即需要通知的接口上没有声明的方法，或者需要将代理对象传递给具体类型的方法，有可能强制使用CGLIB。 Introductions我们知道Java语言本身并非是动态的，就是我们的类一旦编译完成，就很难再为他添加新的功能。但是在一开始给出的例子中，虽然我们没有向对象中添加新的方法，但是已经向其中添加了新的功能。这种属于向现有的方法添加新的功能，那能不能为一个对象添加新的方法呢？答案肯定是可以的，使用introduction就能够实现。 introduction：动态为某个类增加或减少方法。为一个类型添加额外的方法或字段。Spring AOP 允许我们为 目标对象 引入新的接口(和对应的实现)。 Aspect切面：通知和切入点的结合。 切面实现了cross-cutting（横切）功能。最常见的是logging模块、方法执行耗时模块，这样，程序按功能被分为好几层，如果按传统的继承的话，商业模型继承日志模块的话需要插入修改的地方太多，而通过创建一个切面就可以使用AOP来实现相同的功能了，我们可以针对不同的需求做出不同的切面。 而将散落于各个业务对象之中的Cross-cutting concerns 收集起来，设计各个独立可重用的对象，这些对象称之为Aspect；在上面的例子中我们根据不同的配置方式，定义了四种不同形式的切面。 JoinpointAspect 在应用程序执行时加入业务流程的点或时机称之为 Joinpoint ，具体来说，就是 Advice 在应用程序中被呼叫执行的时机，这个时机可能是某个方法被呼叫之前或之后（或两者都有），或是某个异常发生的时候。 Joinpoint &amp; ProceedingJoinPoint环绕通知 = 前置+目标方法执行+后置通知，proceed方法就是用于启动目标方法执行的。 环绕通知 ProceedingJoinPoint 执行 proceed 方法 的作用是让目标方法执行 ，这 也是环绕通知和前置、后置通知方法的一个最大区别。 Proceedingjoinpoint 继承了 JoinPoint 。是在JoinPoint的基础上暴露出 proceed 这个方法。proceed很重要，这个是aop代理链执行的方法；暴露出这个方法，就能支持aop:around 这种切面（其他的几种切面只需要用到JoinPoint，这跟切面类型有关）， 能决定是否走代理链还是走自己拦截的其他逻辑。 在环绕通知的方法中是需要返回一个Object类型对象的，如果把环绕通知的方法返回类型是void，将会导致一些无法预估的情况，比如：404。 Pointcut匹配 join points的谓词。Advice与切入点表达式相关联, 并在切入点匹配的任何连接点上运行。（例如，具有特定名称的方法的执行）。由切入点表达式匹配的连接点的概念是AOP的核心，Spring默认使用AspectJ切入点表达式语言。 在 Spring 中, 所有的方法都可以认为是Joinpoint, 但是我们并不希望在所有的方法上都添加 Advice, 而 Pointcut 的作用就是提供一组规则(使用 AspectJ pointcut expression language 来描述) 来匹配Joinpoint, 给满足规则的Joinpoint 添加 Advice。 Pointcut 和 Joinpoint在Spring AOP 中, 所有的方法执行都是 join point。 而 point cut 是一个描述信息，它修饰的是 join point， 通过 point cut，我们就可以确定哪些 join point 可以被织入Advice。 因此join point 和 point cut本质上就是两个不同维度上的东西。 advice 是在 join point 上执行的, 而 point cut 规定了哪些 join point 可以执行哪些 advice。 Advice概念Advice 是我们切面功能的实现，它是切点的真正执行的地方。比如像前面例子中打印时间的几个方法（被@Before等注解标注的方法都是一个通知）；Advice 在 Jointpoint 处插入代码到应用程序中。 分类BeforeAdvice，AfterAdvice，区别在于Advice在目标方法之前调用还是之后调用，Throw Advice 表示当目标发生异常时调用Advice。 before advice： 在 join point 前被执行的 advice. 虽然 before advice 是在 join point 前被执行, 但是它并不能够阻止 join point 的执行, 除非发生了异常(即我们在 before advice 代码中, 不能人为地决定是否继续执行 join point 中的代码) after return advice： 在一个 join point 正常返回后执行的 advice after throwing advice： 当一个 join point 抛出异常后执行的 advice after(final) advice： 无论一个 join point 是正常退出还是发生了异常, 都会被执行的 advice. around advice：在 join point 前和 joint point 退出后都执行的 advice. 这个是最常用的 advice. Advice、JoinPoint、PointCut 关系 下面这张图是在网上一位大佬的博客里发现的，可以帮助我们更好的理解这些概念之间的关系。 上面是对于AOP中涉及到的一些基本概念及它们之间的关系做了简单的梳理。 一些坑在调试程序过程中出现的一些问题记录 1、使用AOP拦截controller层的服务成功，但是页面报错4041234@Around("cutIn()")public void aroundAdvice(ProceedingJoinPoint poin) &#123; System.out.println("环绕通知");&#125; 这里需要注意的是再使用环绕通知时，需要给方法一个返回值。 12345@Around("cutIn()")public Object aroundAdvice(ProceedingJoinPoint poin) throws Throwable &#123; System.out.println("环绕通知"); return poin.proceed();&#125; 2、0 formal unbound in pointcut在spring 4.x中 提供了aop注解方式 带参数的方式。看下面例子： 1234567@Pointcut(value = "execution(* com.glmapper.framerwork.service.impl.*(int,int)) &amp;&amp; args(i,j)") public void cutIn(int i, int j) &#123;&#125; @Before(value="cutIn(i, j)",argNames = "i,j") public void beforeMethod( int i, int j) &#123; System.out.println("---------begins with " + i + "-" +j); &#125; 比如说这里，Before中有两个int类型的参数，如果此时我们在使用时没有给其指定参数，那么就会抛出：Caused by: java.lang.IllegalArgumentException: error at ::0 formal unbound in pointcut 异常信息。 本来是想放在一篇里面的，但是实在太长了，就分开吧；周末更新下]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>聊一聊</tag>
        <tag>aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Guava 在实际场景中的应用封装]]></title>
    <url>%2F2018%2F11%2F10%2Fguavacacheone%2F</url>
    <content type="text"><![CDATA[毕竟西湖六月中，风光不与四时同。 接天莲叶无穷碧，映日荷花别样红。 晓出净慈寺送林子方-杨万里 周末与小伙伴约了一波西湖，这个时间荷花开的正好…，在开始文章之前先放一张“佛系”美图来镇楼！！！ 最近这段时间用了下谷歌的guava，自己封了一个缓存模板方案，特此记录，以备后续所需。 一个缓存定时清除任务带来的GC问题为什么要从这个来说起，因为不说这个就没guava什么事了！ 最近项目中需要使用缓存来对一查查询频繁的数据做缓存处理；首先我们也不希望引入三方的如redis或者memcache这样的服务进来，其次是我们对于数据一致性的要求并不是很高，不需要集群内的查询接口共享到一份缓存数据；所以这样一来我们只要实现一个基于内存的缓存即可。 最开始我并没有考虑使用guava来做这个事情，而是自己写了一套基于CurrentHashMap的缓存方案；这里需要明确一点，因为缓存在这个场景里面希望提供超时清除的能力，而基于所以在自己缓存框架中增加了定时清除过期数据的能力。 这里我就直接把定时清楚的这段代码放上来： 123456789101112131415161718192021222324252627 /** * 静态内部类来进行超时处理 */private class ClearCacheThread extends Thread &#123; @Override public void run() &#123; while (true)&#123; try &#123; long now = System.currentTimeMillis(); Object[] keys = map.keySet().toArray(); for (Object key : keys) &#123; CacheEntry entry = map.get(key); if (now - entry.time &gt;= cacheTimeout) &#123; synchronized (map) &#123; map.remove(key); if (LOGGER.isDebugEnabled())&#123; LOGGER.debug("language cache timeout clear"); &#125; &#125; &#125; &#125; &#125;catch (Exception e)&#123; LOGGER.error("clear out time cache value error;",e); &#125; &#125; &#125;&#125; 这个线程是用来单独处理过期数据的。缓存初始化时就会触发这个线程的start方法开始执行。 正式由于这段代码的不合理导致我在发布dev环境之后，机器GC触发的频次高的离谱。在尝试了不同的修复方案之后，最后选择放弃了；改用guava了！ 小伙伴们可以在下面留言来讨论下这里为什么会存在频繁GC的问题；我会把结论放在评论回复里面。 guava为什么选用guava呢，很显然，是大佬推荐的！！！ guava是谷歌提供的一个基于内存的缓存工具包，Guava Cache 提供了一种把数据（key-value对）缓存到本地（JVM）内存中的机制，适用于很少会改动的数据。Guava Cache 与 ConcurrentMap 很相似，但也不完全一样。最基本的区别是 ConcurrentMap 会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache 为了限制内存占用，通常都设定为自动回收元素。 对于我们的场景，guava 提供的能力满足了我们的需要： 数据改动小 基于内存 可以自动回收 既然选择它了，我们还是有必要来先对它有个大致的了解；先来看看它提供的一些类和接口： 接口/类 详细解释 Cache 【I】;定义get、put、invalidate等操作，这里只有缓存增删改的操作，没有数据加载的操作。 AbstractCache 【C】;实现Cache接口。其中批量操作都是循环执行单次行为，而单次行为都没有具体定义。 LoadingCache 【I】;继承自Cache。定义get、getUnchecked、getAll等操作，这些操作都会从数据源load数据。 AbstractLoadingCache 【C】;继承自AbstractCache，实现LoadingCache接口。 LocalCache 【C】;整个guava cache的核心类，包含了guava cache的数据结构以及基本的缓存的操作方法。 LocalManualCache 【C】;LocalCache内部静态类，实现Cache接口。其内部的增删改缓存操作全部调用成员变量localCache（LocalCache类型）的相应方法。 LocalLoadingCache 【C】;LocalCache内部静态类，继承自LocalManualCache类，实现LoadingCache接口。其所有操作也是调用成员变量localCache（LocalCache类型）的相应方法 CacheBuilder 【C】;缓存构建器。构建缓存的入口，指定缓存配置参数并初始化本地缓存。CacheBuilder在build方法中，会把前面设置的参数，全部传递给LocalCache，它自己实际不参与任何计算 CacheLoader 【C】;用于从数据源加载数据，定义load、reload、loadAll等操作。 整个来看的话，guava里面最核心的应该算是 LocalCache 这个类了。 123@GwtCompatible(emulated = true)class LocalCache&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implementsConcurrentMap&lt;K, V&gt; 关于这个类的源码这里就不细说了，直接来看下在实际应用中我的封装思路【封装满足我当前的需求，如果有小伙伴需要借鉴，可以自己在做扩展】 12345678910111213141516private static final int MAX_SIZE = 1000;private static final int EXPIRE_TIME = 10;private static final int DEFAULT_SIZE = 100;private int maxSize = MAX_SIZE;private int expireTime = EXPIRE_TIME;/** 时间单位（分钟） */private TimeUnit timeUnit = TimeUnit.MINUTES;/** Cache初始化或被重置的时间 */private Date resetTime;/** 分别记录历史最多缓存个数及时间点*/private long highestSize = 0;private Date highestTime;private volatile LoadingCache&lt;K, V&gt; cache; 这里先是定义了一些常量和基本的属性信息，当然这些属性会提供set&amp;get方法，供实际使用时去自行设置。 1234567891011121314151617181920212223242526272829303132333435363738public LoadingCache&lt;K, V&gt; getCache() &#123; //使用双重校验锁保证只有一个cache实例 if(cache == null)&#123; synchronized (this) &#123; if(cache == null)&#123; //CacheBuilder的构造函数是私有的，只能通过其静态方法newBuilder()来获得CacheBuilder的实例 cache = CacheBuilder.newBuilder() //设置缓存容器的初始容量为100 .initialCapacity(DEFAULT_SIZE) //缓存数据的最大条目 .maximumSize(maxSize) //定时回收:缓存项在给定时间内没有被写访问（创建或覆盖），则回收。 .expireAfterWrite(expireTime, timeUnit) //启用统计-&gt;统计缓存的命中率等 .recordStats() //设置缓存的移除通知 .removalListener((notification)-&gt; &#123; if (LOGGER.isDebugEnabled())&#123; LOGGER.debug("&#123;&#125; was removed, cause is &#123;&#125;" ,notification.getKey(), notification.getCause()); &#125; &#125;) .build(new CacheLoader&lt;K, V&gt;() &#123; @Override public V load(K key) throws Exception &#123; return fetchData(key); &#125; &#125;); this.resetTime = new Date(); this.highestTime = new Date(); if (LOGGER.isInfoEnabled())&#123; LOGGER.info("本地缓存&#123;&#125;初始化成功.", this.getClass().getSimpleName()); &#125; &#125; &#125; &#125; return cache;&#125; 上面这段代码是整个缓存的核心，通过这段代码来生成我们的缓存对象【使用了单例模式】。具体的属性参数看注释。 因为上面的那些都是封装在一个抽象类AbstractGuavaCache里面的，所以我又封装了一个CacheManger用来管理缓存，并对外提供具体的功能接口；在CacheManger中，我使用了一个静态内部类来创建当前默认的缓存。 12345678910111213141516171819202122232425262728/** * 使用静态内部类实现一个默认的缓存，委托给manager来管理 * * DefaultGuavaCache 使用一个简单的单例模式 * @param &lt;String&gt; * @param &lt;Object&gt; */private static class DefaultGuavaCache&lt;String, Object&gt; extendsAbstractGuavaCache&lt;String, Object&gt; &#123; private static AbstractGuavaCache cache = new DefaultGuavaCache(); /** * 处理自动载入缓存，按实际情况载入 * 这里 * @param key * @return */ @Override protected Object fetchData(String key) &#123; return null; &#125; public static AbstractGuavaCache getInstance() &#123; return DefaultGuavaCache.cache; &#125;&#125; 大概思路就是这样，如果需要扩展，我们只需要按照实际的需求去扩展AbstractGuavaCache这个抽象类就可以了。具体的代码贴在下面了。 完整的两个类AbstractGuavaCache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137public abstract class AbstractGuavaCache&lt;K, V&gt; &#123; protected final Logger LOGGER = LoggerFactory.getLogger(AbstractGuavaCache.class); private static final int MAX_SIZE = 1000; private static final int EXPIRE_TIME = 10; /** 用于初始化cache的参数及其缺省值 */ private static final int DEFAULT_SIZE = 100; private int maxSize = MAX_SIZE; private int expireTime = EXPIRE_TIME; /** 时间单位（分钟） */ private TimeUnit timeUnit = TimeUnit.MINUTES; /** Cache初始化或被重置的时间 */ private Date resetTime; /** 分别记录历史最多缓存个数及时间点*/ private long highestSize = 0; private Date highestTime; private volatile LoadingCache&lt;K, V&gt; cache; public LoadingCache&lt;K, V&gt; getCache() &#123; //使用双重校验锁保证只有一个cache实例 if(cache == null)&#123; synchronized (this) &#123; if(cache == null)&#123; //CacheBuilder的构造函数是私有的，只能通过其静态方法ne //wBuilder()来获得CacheBuilder的实例 cache = CacheBuilder.newBuilder() //设置缓存容器的初始容量为100 .initialCapacity(DEFAULT_SIZE) //缓存数据的最大条目 .maximumSize(maxSize) //定时回收:缓存项在给定时间内没有被写访问 //（创建或覆盖），则回收。 .expireAfterWrite(expireTime, timeUnit) //启用统计-&gt;统计缓存的命中率等 .recordStats() //设置缓存的移除通知 .removalListener((notification)-&gt; &#123; if (LOGGER.isDebugEnabled())&#123; //... &#125; &#125;) .build(new CacheLoader&lt;K, V&gt;() &#123; @Override public V load(K key) throws Exception &#123; return fetchData(key); &#125; &#125;); this.resetTime = new Date(); this.highestTime = new Date(); if (LOGGER.isInfoEnabled())&#123; //... &#125; &#125; &#125; &#125; return cache; &#125; /** * 根据key从数据库或其他数据源中获取一个value，并被自动保存到缓存中。 * * 改方法是模板方法，子类需要实现 * * @param key * @return value,连同key一起被加载到缓存中的。 */ protected abstract V fetchData(K key); /** * 从缓存中获取数据（第一次自动调用fetchData从外部获取数据），并处理异常 * @param key * @return Value * @throws ExecutionException */ protected V getValue(K key) throws ExecutionException &#123; V result = getCache().get(key); if (getCache().size() &gt; highestSize) &#123; highestSize = getCache().size(); highestTime = new Date(); &#125; return result; &#125; public int getMaxSize() &#123; return maxSize; &#125; public void setMaxSize(int maxSize) &#123; this.maxSize = maxSize; &#125; public int getExpireTime() &#123; return expireTime; &#125; public void setExpireTime(int expireTime) &#123; this.expireTime = expireTime; &#125; public TimeUnit getTimeUnit() &#123; return timeUnit; &#125; public void setTimeUnit(TimeUnit timeUnit) &#123; this.timeUnit = timeUnit; &#125; public Date getResetTime() &#123; return resetTime; &#125; public void setResetTime(Date resetTime) &#123; this.resetTime = resetTime; &#125; public long getHighestSize() &#123; return highestSize; &#125; public void setHighestSize(long highestSize) &#123; this.highestSize = highestSize; &#125; public Date getHighestTime() &#123; return highestTime; &#125; public void setHighestTime(Date highestTime) &#123; this.highestTime = highestTime; &#125;&#125; DefaultGuavaCacheManager123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class DefaultGuavaCacheManager &#123; private static final Logger LOGGER = LoggerFactory.getLogger(DefaultGuavaCacheManager.class); //缓存包装类 private static AbstractGuavaCache&lt;String, Object&gt; cacheWrapper; /** * 初始化缓存容器 */ public static boolean initGuavaCache() &#123; try &#123; cacheWrapper = DefaultGuavaCache.getInstance(); if (cacheWrapper != null) &#123; return true; &#125; &#125; catch (Exception e) &#123; LOGGER.error("Failed to init Guava cache;", e); &#125; return false; &#125; public static void put(String key, Object value) &#123; cacheWrapper.getCache().put(key, value); &#125; /** * 指定缓存时效 * @param key */ public static void invalidate(String key) &#123; cacheWrapper.getCache().invalidate(key); &#125; /** * 批量清除 * @param keys */ public static void invalidateAll(Iterable&lt;?&gt; keys) &#123; cacheWrapper.getCache().invalidateAll(keys); &#125; /** * 清除所有缓存项 ： 慎用 */ public static void invalidateAll() &#123; cacheWrapper.getCache().invalidateAll(); &#125; public static Object get(String key) &#123; try &#123; return cacheWrapper.getCache().get(key); &#125; catch (Exception e) &#123; LOGGER.error("Failed to get value from guava cache;", e); &#125; return null; &#125; /** * 使用静态内部类实现一个默认的缓存，委托给manager来管理 * * DefaultGuavaCache 使用一个简单的单例模式 * @param &lt;String&gt; * @param &lt;Object&gt; */ private static class DefaultGuavaCache&lt;String, Object&gt; extends AbstractGuavaCache&lt;String, Object&gt; &#123; private static AbstractGuavaCache cache = new DefaultGuavaCache(); /** * 处理自动载入缓存，按实际情况载入 * @param key * @return */ @Override protected Object fetchData(String key) &#123; return null; &#125; public static AbstractGuavaCache getInstance() &#123; return DefaultGuavaCache.cache; &#125; &#125;&#125; 参考Google Guava官方教程（中文版）]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>cache</tag>
        <tag>guava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式链路跟踪组件 SOFATracer 和 Zipkin 模型转换原理]]></title>
    <url>%2F2018%2F11%2F10%2Fsofatracertwo%2F</url>
    <content type="text"><![CDATA[SOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 traceId 将调用链路中的各种网络调用情况以日志的方式记录下来或者上报到 zipkin，以达到透视化网络调用的目的。这种以日志的方式记录下来或者上报到zipkin通常称为 Report，即数据上报 SOFATracer 的数据上报是在遵循 OpenTracing 规范基础上扩展出来的能力，OpenTracing 规范本身只是约定了数据模型和行为。本文主要目的在于分析 SOFATracer 的数据上报功能部分，主要内容如下： 基于 OpenTracing 规范的分布式链路跟踪解决方案 SOFATracer Report 数据上报模型 SOFATracer 和 Zipkin 模型转换原理 基于 OpenTracing 规范的分布式链路跟踪解决方案 OpenTracing 是一个轻量级的标准化层，它位于应用程序/类库和追踪或日志分析程序之间。为了解决不同的分布式追踪系统 API 不兼容的问题，OpenTracing 提供了一套平台无关、厂商无关的 API，同时也提供了统一的概念和数据标准。关于对 OpenTracing 标准的版本化描述可以参考 specification.md（https://github.com/opentracing/specification/blob/master/specification.md）。一些具体的概念下面将结合SOFATracer 的实现来一一说明。 目前基于 OpenTracing 规范实现的链路跟踪组件有 Jaeger，Appdash，Apache SkyWalking ，Datadog 等。像谷歌的 StackDriver Tracer 实际上并不是遵循 OpenTracing 规范的，但是都源自于 Dapper 这篇论文。 规范其实就是模型和行为的约束，在 OpenTracing 规范中有三种关键和相互关联的模型：Tracer、Span 和SpanContext；并且在规范中对于每个模型的行为也做了约定。 Tracer Tracer 可以被认为是一个由多个 Span 组成的有向无环图。一个 Tracer 可以用来描述一个请求从发出到收到响应整个链路过程。前提是需要在适当的地方进行埋点。下图就是一条完整的链路的展示： 在 SOFATracer 中 ，SofaTracer 实现了 Tracer 接口，实现了构建 span，数据载入（Inject）和 数据提取（Extract ) 的能力。 Start a new Span ：创建一个新的 Span 。通过指定的 operationName 来创建一个新的 Span。operationName 表示由 Span 完成的具体的工作 ( 例如，RPC 方法名称、函数名称或一个较大的计算任务中的阶段的名称)。 Inject a SpanContext：将 SpanContext 注入到给定类型的 “carrier” 中，用于进行跨进程的传输。 Extract a SpanContext ：从载体中提取中 spanContext 实例对象。这个过程是注入的逆过程。spanContext 中包括了贯穿整个链路的 traceId ，变化的 spanId ，父 spanId 以及透传数据等。 Span 一个 span 代表系统中具有开始时间和执行时长的逻辑运行单元。span 之间通过嵌套或者顺序排列建立逻辑因果关系，然后再通过这种关系来构建整个调用链路（Tracer）。 OpenTracing 规范 API 约定 Span 的模型如下（实际上就是 Span 接口中对应的方法，需要由遵循该规范的实现者必须提供的最小能力的集合）： Get the Span’s SpanContext： 通过 Span 获取 SpanContext （即使 span 已经结束，或者即将结束） Finish：结束一个 Span 。Finish 必须是 span 实例的最后一个被调用的方法。但是在主线程处理失败或者其他程序错误发生时，Finish 方法可能不会被调用。在这种情况下，实现者应该明确的记录 Span，保证数据的持久化（这一点 SOFATracer 其实是没有做的）。 Set a K:V tag on the Span：为 Span 设置 tag 。tag 的 key 必须是 string 类型；value 必须是 string、boolean 或数字类型。通常会使用 Tag 来记录跟踪系统感兴趣的一些指标数据。 Add a new log event：为 Span 增加一个 log 事件，用于记录 Span 生命周期中发生的事件。 Set a Baggage item： 设置一个 string:string 类型的键值对，一般是业务数据在全链路数据透明传输，存储在 SpanContext 中。 Get a Baggage item： 通过 key 获取 Baggage 中的元素。 SpanContext Span 上下文，几乎包含了需要在链路中传递的全部信息。另外，Span 间 References 就是通过 SpanContext 来建立关系的。根据 OpenTracing 规范要求，SpanContext 是不可变的，目的是防止由于 Span 的结束和相互关系，造成的复杂生命周期问题。 SpanContext 表示必须传播到后代 Spans 和跨进程边界的 Span 状态。SpanContext 在逻辑上分为两部分： 跨 Span 边界传播的用户级 “Baggage” 识别或以其他方式关联 Span 实例所需的任何 Tracer 实现特定字段（例如，trace_id，span_id，sampling，元组） Opentracing 中 SpanContext 接口中只有一个 baggageItems 方法，通过这个方法来遍历所有的 baggage 元素。 123public interface SpanContext &#123; Iterable&lt;Map.Entry&lt;String, String&gt;&gt; baggageItems();&#125; SOFATracer 扩展的 Tracer 的能力上面简单介绍了 OpenTracing 规范 API 对于 Tracer、Span、SpanContext 三个核心模型的规范定义。下面来看下 SOFATracer 是如何遵循规范并做扩展的。 在 OpenTracing 规范 基础上，SOFATracer 提供了实现，并在规范基础上提供了扩展功能。本文主要介绍上图中标绿色的部分，即数据上报功能。 SOFATracer 中提供了 Report 接口，然后基于此接口扩展了两个实现： 第一种 Report 扩展是基于 Disruptor（https://github.com/LMAX-Exchange/disruptor） 高性能无锁循环队列的异步落地磁盘的日志打印。 第二种 Report 扩展是提供远程上报，能够将 SOFATracer 的链路数据模型汇报到 Zipkin 中做调用链路的展示。 当然，SOFATracer 也允许用户自定义上报功能，只需要在自己的工程代码中实现 Report 接口即可，下面是 Report 接口的定义： 123456789101112public interface Reporter &#123; // 上报到远程服务器的持久化类型 String REMOTE_REPORTER = "REMOTE_REPORTER"; // 组合类型 String COMPOSITE_REPORTER = "COMPOSITE_REPORTER"; // 获取 Reporter 实例类型 String getReporterType(); // 上报 span void report(SofaTracerSpan span); // 关闭上报 span 的能力 void close();&#125; SOFATracer Report 数据上报模型 上面提到 SOFATracer 的 Report 有两种机制，一种是落到磁盘，另外一种是上报到 zipkin。SOFATracer 中这两种方案并不是二选一的，而是可以同时使用多个实现。例如，我们希望上报数据到 zipkin，先引入 tracer-sofa-boot-starter 这个依赖，并进行相关 zipkin 的配置之后就可以将链路数据上报到 zipkin，如果没有引入依赖则不会上报。本节来分析下 SOFATracer 上报数据过程的具体逻辑。 上面这张图描述了数据上报的几种方式： 绿色部分，上报 zipkin：这里其实就是实现上报 zipkin 的一个回调，当进行 reportSpan 操作时，会执行一个invokeReportListeners ，这个方法就是通知所有实现了 SpanReportListener 接口的类执行回调方法，然后在这个回调方法中将 span 数据上报到 zipkin。 红色部分，输出到磁盘：SOFATracer 为了提供更好的扩展能力，将输出日志的 Report 细分为 client 和 server 两种；并在 Tracer 基类中提供 generateClientStatReporter 和 generateServerStatReporter 两个抽象方法，供不同的组件自己来实现一些特殊化的定制。 关于何时进行上报，其实这个在 Opentracing API 的规范中已经给出了明确的时机。在上面的介绍中提到，“Finish必须是 span 实例的最后一个被调用的方法”，当 finish 方法被调用时也就意味着一个 span 生命周期的结束，为了保证 span 数据的完整性和正确性，SOFATracer reportSpan 的逻辑就是在 finish 方法被调用时触发执行。 数据落地磁盘 SOFATracer 日志落盘是基于Disruptor高性能无锁循环队列实现的，提供了异步打印日志到本地磁盘的能力。 append : 追溯 Report，无论是 clientReport 还是 serverReport ，底层均依赖 DiskReporterImpl 的实现。DiskReporterImpl 是 SOFATracer 统筹处理日志落盘的类。clientReport 和 serverReport 的最终调用都会走到DiskReporterImpl 中的 digestReport 这个方法。digestReport 中会将当前 span append 到环形缓冲队列中，append 操作就是发布一个事件的过程。 consume：consume 是 Disruptor 中的对应的消费模型；SOFATracer 中这个消费者就是将 SofaTracerSpan 中的数据写到日志文件中的。 事件发布过程： 数据上报 zipkin 前面提到，上报 zipkin 的是通过 onSpanReport 这个回调函数完成的。tracer-sofa-boot-starter 这个依赖中提供了 SpanReportListener 接口实现 ZipkinSofaTracerSpanRemoteReporter 。而在 onSpanReport 这个回调函数中，又将具体上报委托给了 AsyncReporter 来处理。 123456789@Overridepublic void onSpanReport(SofaTracerSpan span) &#123; if (span == null) &#123; return; &#125; //convert Span zipkinSpan = convertToZipkinSpan(span); this.delegate.report(zipkinSpan);&#125; 构建 AsyncReporter 对象需要两个参数： sender： 数据发送器，SOFATracer 中，sender 的是通过 RestTemplate 以 http 方式 来与 zipkin 进行通信传输的。 url：Zipkin 默认的 Collector 使用 http 协议里收集 Trace 信息，客户端调用 /api/v1/spans 或 /api/v2/spans 来上报 tracer 信息。这里我们使用的是 Zipkin V2 的 API。 AsyncReporter 中实际构建的是 BoundedAsyncReporter 对象 ， 并且在构建一个异步报告器是，会根据messageTimeoutNanos 是否大于 0 来决定是否起一个守护线程 flushThread；flushThread 作用是一直循环调用 BoundedAsyncReporter 的 flush 方法，将内存中的 Span 信息上报给 Zipkin。具体细节这里不展开分析。 SOFATracer 和 Zipkin 模型转换原理 在上小节中贴出的小段代码中，除了构建 delegate 对象用于执行上报外；另一个关键就是 SOFATracer 的 Span 模型转换成 Zipkin Span 模型。SOFATracer 从 2.2.0 版本之后支持 Zipkin v2 的模型 ，对于 Zipkin v1 的模型不在提供支持。 Zipkin v2的模型 下面是 zipkin GitHub 上提供的 Zipkin v2 的模型的结构化数据 Demo。关于 Zipkin 的 Span 模型支持可以查看 Simplified span2 format #1499 12345678910111213141516171819202122&#123; "kind": "CLIENT", "traceId": "5af7183fb1d4cf5f", "parentId": "6b221d5bc9e6496c", "id": "352bff9a74ca9ad2", "name": "query", "timestamp": 1461750040359000, "duration": 5000, "localEndpoint": &#123; "serviceName": "zipkin-server", "ipv4": "172.19.0.3", "port": 9411 &#125;, "remoteEndpoint": &#123; "serviceName": "mysql", "ipv4": "172.19.0.2", "port": 3306 &#125;, "tags": &#123; "jdbc.query": "//....discard" &#125;&#125; Zipkin v2 的模型结构较为简洁，整体看起来并没有什么繁重，这种对于使用者来说是很友好的，方便理解。其实在Zipkin v1 模型时，其整个模型也是比较复杂的，zipkin 社区对于 Zipkin 数据模型的变更也有讨论，见 Zipkin v2 span model #939 ；像现在 v2 模型中的 tags，替换了原本 v1 中的 binaryAnnotations，binaryAnnotations 的存在是 v1 模型复杂的重要原因。详见 去除原因。 SofaTracerSpan 模型SofaTracerSpan 是基于 Opentracing 标准来的。但是 Opentracing 标准并没有规定一个 Span 模型必须有哪些属性。所以各个基于该标准的产品在于 Span 的模型上是不统一的，大多会基于其本身产生的场景带有一些特殊的属性。 12345678910111213141516171819202122232425&#123; "client":true, "server":false, "durationMicroseconds":775, "endTime":1536288243446, "logType":"httpclient-digest.log", "operationName":"GET", "logs":[ // ... ], "sofaTracer":&#123; "clientReporter":&#123;&#125;, "tracerTags":&#123;&#125;, "tracerType":"httpclient" &#125;, "sofaTracerSpanContext":&#123; // sofaTracerSpanContext info &#125;, "spanReferences":[], "startTime":1536288242671, "tagsWithBool":&#123;&#125;, "tagsWithNumber":&#123;&#125;, "tagsWithStr":&#123;&#125;, "thisAsParentWhenExceedLayer":&#123;&#125;&#125; SOFATracer 的 Span 模型相较于 Opentracing 规范模型和 Zipkin v2 的模型来说，记录的数据信息更加丰富，且在 Opentracing 规范的基础上扩展了一套自己的 API，可以让使用者能够更加方便的在自己的代码中来获取链路中的信息；在日志中展示更多的 span 信息，能够帮助我们去了解一些调用细节，在发生问题时，也提供了更多排查问题的依据信息。 模型转换对照为了使得 SOFATracer 的数据能够被 zipkin 解析，需要将 SOFATracer 的 Span 模型转换成 zipkin v2 的数据模型。 Zipkin v2 Span Model SOFATracer Span Model 备注 traceId traceId traceId id spanId spanId parentId parentId 父spanId name operationName span 名，用来描述当前span 的行为 duration - 当前span的时间跨度;这里通过span的（结束时间-开始时间）获取 timestamp timestamp 当前span的开始时间 localEndPoint operationName&amp;host&amp;logData 标明这个span的来源 remoteEndPoint - 被调用方的服务名和地址 tags bizBaggage &amp; tags 额外的用于描述span的信息 整体来看，Span 模型相似度是很高，但是实际上并不能直接将某些相同的字段直接进行值复制；这里有一个 案例：ISSUE#57 。 traceId 和 spanId 处理zipkin 在自己的模型里做了很多特殊的处理。比如 traceId 需满足16 或者 32 位，长度不够的会高位补 0；所以在使用 SOFATracer 时，日志中的 traceId 和上报到 zipkin 的 traceId 长度不一致是合理的。 关于 spanId，我们期望在 zipkin 中展示是以（0.1,0.1.1,…）这种形式来描述，能够直观的看到 span 之间的依赖关系。但是目前使用的 zipkin 模型并不能满足我们的需求，主要原因在于虽然 zipkin 在 v2 模型中虽然支持 string 类型的 id ，但是其长度限制是16位，对于 SOFATracer 来说，如果存在较长的链路调用，会导致层次丢失。另外，如果上报 zipkin 的 span 的 parentId 为 0，那么 zipkin 将会不进行设置；而 SOFATracer 的第一个 span 的 id 就是从 0 开始的，所以会导致链路构建失败，如果我们尝试通过改变起始 id 来改变，会对整个模型产生影响。经过验证测试，我们最终采用的方案是使用冲突较小的 FNV64 Hash 算法将 String 类型转换成 long 型来描述我们的 spanId。 SOFARPC 上报的数据处理在整个模型转换中，比较核心的就是如何兼容 SOFARPC 上报的数据。Zipkin 在构建链路数时，其基本的模型是 client-server-client-server-.. 这种模式；不会出现 a server calling a server 这种情况，也就是带有kind = server 的 span 的 父span 应该是 kind = client。 SOFARPC 对于一个 rpc span 上报了两个 span 信息，这两个 span 除了 kind 类型不同之外，其他的信息是一样的。当数据上报给 zipkin 之后，zipkin 通过自己的算法来构建依赖树时，会对上报的 SOFARPC 数据处理有问题。下图是没有适配 SOFARPC 生成的链路: 这里可以看出，从 mvc 到 rpc 之间的关系被‘切断’了。 造成上述问题的原因在于，SOFATracer 上报数据到 zipkin 时，在 v2 模型中，zipkin 会通过广度优先遍历来构建依赖树，实际上在展示 services 或者 dependencies 时，zipkin ui 中的展示会依赖 endpiont 中的 serviceName ；两个条件： SOFARPC 的 span 有两个（client&amp;server），但是这两个 span 具有相同的 spanId 和 parentId，span.kind 不同。 zipkin 在构建依赖树时，依赖于 endpiont 中的 serviceName。该 servieName 依赖于 idToNode（Node.TreeBuilder 中的属性，Map 结构，映射关系为 spanId -&gt; span）。 123Node&lt;V&gt; previous = idToNode.put(id, node);if (previous != null) node.setValue(mergeFunction.merge(previous.value, node.value)); 这里当前 node 为 rpc server 类型时，previous 返回结果不为 null，会执行 merge 操作，该 merge 操作的核心就是设置当前 rpc node 的 remoteEndpoint，值为 rpc client 的 localEndpoint。 这样会有一个问题，就是 RPC 的 client 和 server Span 在 Zipkin 模型中的会被合并成一个 span；这样就会导致 server -&gt; server 的情况，与 zipkin 的 client -&gt; server 链路模型有冲突。如下图（绿色为SOFATracer span，黄色为 zipkin span）： 通过分析 zipkin 的构建过程，适配 SOFARPC 上报数据时，SOFARPC server span 的 remoteEndpoint 不能依赖 SOFARPC client span 的 localEndpoint，而应该依赖 SOFARPC client parentSpan 的 localEndpoint。下图为 SOFARPC 适配之后的依赖关系图： 总结 本文从 OpenTracing 规范说起，对 OpenTracing 规范中的模型和行为进行了简单的描述。结合 OpenTracing 规范，介绍了蚂蚁金服 SOFATracer 分布式链路跟踪的模型实现。在此基础上，对 SOFATracer 的数据上报功能进行了详细的分析，包括基于 disruptor 实现的异步日志落盘和上报数据到zipkin；最后对 SOFATracer 和 Zipkin 模型转换原理进行了说明，并对 SOFARPC 模型数据的上报处理进行了解析。 相关文档链接 SOFATracer GitHub Zipkin 官网 Zipkin GitHub opentracing 规范 opentracing 官网 disruptor]]></content>
      <categories>
        <category>SOFA</category>
      </categories>
      <tags>
        <tag>OpenTracing</tag>
        <tag>链路跟踪</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看完这个不会配置 logback ，请你吃瓜！]]></title>
    <url>%2F2018%2F11%2F10%2Flogone%2F</url>
    <content type="text"><![CDATA[之前在 日志？聊一聊slf4j吧 这篇文章中聊了下slf4j。本文也从实际的例子出发，针对logback的日志配置进行学习。 logack 简介 logback 官网：https://logback.qos.ch/ 目前还没有看过日志类框架的源码，仅限于如何使用。所以就不说那些“空话”了。最直观的认知是： logback和log4j是一个人写的 springboot默认使用的日志框架是logback。 三个模块组成 logback-core logback-classic logback-access 其他的关于性能，关于内存占用，关于测试，关于文档详见源码及官网说明 logback-core 是其它模块的基础设施，其它模块基于它构建，显然，logback-core 提供了一些关键的通用机制。logback-classic 的地位和作用等同于 Log4J，它也被认为是 Log4J 的一个改进版，并且它实现了简单日志门面 SLF4J；而 logback-access 主要作为一个与 Servlet 容器交互的模块，比如说tomcat或者 jetty，提供一些与 HTTP 访问相关的功能。 配置文件详解这部分主要来学习下logback配置文件的一些配置项。 configuration先来看这张图，这个结构就是整个logback.xml配置文件的结构。 对应来看下配置文件： 1234567891011121314151617&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;property name="glmapper-name" value="glmapper-demo" /&gt; &lt;contextName&gt;$&#123;glmapper-name&#125;&lt;/contextName&gt; &lt;appender&gt; //xxxx &lt;/appender&gt; &lt;logger&gt; //xxxx &lt;/logger&gt; &lt;root&gt; //xxxx &lt;/root&gt; &lt;/configuration&gt; ps：想使用spring扩展profile支持，要以logback-spring.xml命名，其他如property需要改为springProperty scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 contextName每个logger都关联到logger上下文，默认上下文名称为“default”。但可以使用contextName标签设置成其他名字，用于区分不同应用程序的记录 property用来定义变量值的标签，property标签有两个属性，name和value；其中name的值是变量的名称，value的值时变量定义的值。通过property定义的值会被插入到logger上下文中。定义变量后，可以使“${name}”来使用变量。如上面的xml所示。 logger用来设置某一个包或者具体的某一个类的日志打印级别以及指定appender。 root根logger，也是一种logger，且只有一个level属性 appender负责写日志的组件，下面会细说 filterfilter其实是appender里面的子元素。它作为过滤器存在，执行一个过滤器会有返回DENY，NEUTRAL，ACCEPT三个枚举值中的一个。 DENY：日志将立即被抛弃不再经过其他过滤器 NEUTRAL：有序列表里的下个过滤器过接着处理日志 ACCEPT：日志会被立即处理，不再经过剩余过滤器 案例分析首先来配置一个非常简单的文件。这里申请下，我使用的是 logback-spring.xml。和 logback.xml 在properties上有略微差别。其他都一样。 工程：springboot+web 先来看下项目目录 properties中就是指定了日志的打印级别和日志的输出位置： 1234#设置应用的日志级别logging.level.com.glmapper.spring.boot=INFO#路径logging.path=./logs 通过控制台输出的loglogback-spring.xml的配置如下：123456789101112&lt;configuration&gt; &lt;!-- 默认的控制台日志输出，一般生产环境都是后台启动，这个没太大作用 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %-5level %logger&#123;80&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="STDOUT"/&gt; &lt;/root&gt;&lt;/configuration&gt; 打印日志的controller123456789101112private static final Logger LOGGER =LoggerFactory.getLogger(HelloController.class);@Autowiredprivate TestLogService testLogService;@GetMapping("/hello")public String hello()&#123; LOGGER.info("GLMAPPER-SERVICE:info"); LOGGER.error("GLMAPPER-SERVICE:error"); testLogService.printLogToSpecialPackage(); return "hello spring boot";&#125; 验证结果：123401:50:39.633 INFO com.glmapper.spring.boot.controller.HelloController- GLMAPPER-SERVICE:info01:50:39.633 ERROR com.glmapper.spring.boot.controller.HelloController- GLMAPPER-SERVICE:error 上面的就是通过控制台打印出来的，这个时候因为我们没有指定日志文件的输出，因为不会在工程目录下生产logs文件夹。 控制台不打印，直接输出到日志文件先来看下配置文件： 1234567891011121314151617181920212223242526272829303132333435&lt;configuration&gt; &lt;!-- 属性文件:在properties文件中找到对应的配置项 --&gt; &lt;springProperty scope="context" name="logging.path" source="logging.path"/&gt; &lt;springProperty scope="context" name="logging.level" source="logging.level.com.glmapper.spring.boot"/&gt; &lt;!-- 默认的控制台日志输出，一般生产环境都是后台启动，这个没太大作用 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %-5level %logger&#123;80&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="GLMAPPER-LOGGERONE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;append&gt;true&lt;/append&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt; &lt;/filter&gt; &lt;file&gt; $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log &lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="GLMAPPER-LOGGERONE"/&gt; &lt;/root&gt;&lt;/configuration&gt; 这里我们appender-ref指定的appender是GLMAPPER-LOGGERONE，因为之前没有名字为GLMAPPER-LOGGERONE的appender，所以要增加一个name为GLMAPPER-LOGGERONE的appender。 注意上面这个配置，我们是直接接将root的appender-ref直接指定到我们的GLMAPPER-LOGGERONE这个appender的。所以控制台中将只会打印出bannar之后就啥也不打印了，所有的启动信息都会被打印在日志文件glmapper-loggerone.log中。 但是实际上我们不希望我的业务日志中会包括这些启动信息。所以这个时候我们就需要通过logger标签来搞事情了。将上面的配置文件进行简单修改： 12345678&lt;logger name="com.glmapper.spring.boot.controller" level="$&#123;logging.level&#125;" additivity="false"&gt; &lt;appender-ref ref="GLMAPPER-LOGGERONE" /&gt;&lt;/logger&gt;&lt;root level="$&#123;logging.level&#125;"&gt; &lt;appender-ref ref="STDOUT"/&gt;&lt;/root&gt; 让root指向控制台输出；logger负责打印包com.glmapper.spring.boot.controller下的日志。 验证结果还是通过我们的测试controller来打印日志为例，但是这里不会在控制台出现日志信息了。期望的日志文件在./logs/glmapper-spring-boot/glmapper-loggerone.log。 logger和appender的关系上面两种是一个基本的配置方式，通过上面两个案例，我们先来了解下logger/appender/root之间的关系，然后再详细的说下logger和appender的配置细节。 在最前面介绍中提到，root是根logger,所以他两是一回事；只不过root中不能有name和additivity属性，是有一个level。 appender是一个日志打印的组件，这里组件里面定义了打印过滤的条件、打印输出方式、滚动策略、编码方式、打印格式等等。但是它仅仅是一个打印组件，如果我们不使用一个logger或者root的appender-ref指定某个具体的appender时，它就没有什么意义。 因此appender让我们的应用知道怎么打、打印到哪里、打印成什么样；而logger则是告诉应用哪些可以这么打。例如某个类下的日志可以使用这个appender打印或者某个包下的日志可以这么打印。 appender 配置详解这里以上面案例中的名为GLMAPPER-LOGGERONE的appender说明： 123456789101112131415161718&lt;appender name="GLMAPPER-LOGGERONE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;append&gt;true&lt;/append&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt; &lt;/filter&gt; &lt;file&gt; $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log &lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt; appender 有两个属性 name和class;name指定appender名称，class指定appender的全限定名。上面声明的是名为GLMAPPER-LOGGERONE，class为ch.qos.logback.core.rolling.RollingFileAppender的一个appender。 appender 的种类 ConsoleAppender：把日志添加到控制台 FileAppender：把日志添加到文件 RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。它是FileAppender的子类 append 子标签1&lt;append&gt;true&lt;/append&gt; 如果是 true，日志被追加到文件结尾，如果是false，清空现存文件，默认是true。 filter 子标签在简介中提到了filter；作用就是上面说的。可以为appender 添加一个或多个过滤器，可以用任意条件对日志进行过滤。appender 有多个过滤器时，按照配置顺序执行。 ThresholdFilter临界值过滤器，过滤掉低于指定临界值的日志。当日志级别等于或高于临界值时，过滤器返回NEUTRAL；当日志级别低于临界值时，日志会被拒绝。 123&lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;INFO&lt;/level&gt;&lt;/filter&gt; LevelFilter级别过滤器，根据日志级别进行过滤。如果日志级别等于配置级别，过滤器会根据onMath(用于配置符合过滤条件的操作) 和 onMismatch(用于配置不符合过滤条件的操作)接收或拒绝日志。 12345&lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; 关于NEUTRAL、ACCEPT、DENY 见上文简介中关于filter的介绍。 file 子标签file 标签用于指定被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。 123&lt;file&gt; $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log&lt;/file&gt; 这个表示当前appender将会将日志写入到${logging.path}/glmapper-spring-boot/glmapper-loggerone.log这个目录下。 rollingPolicy 子标签这个子标签用来描述滚动策略的。这个只有appender的class是RollingFileAppender时才需要配置。这个也会涉及文件的移动和重命名（a.log-&gt;a.log.2018.07.22）。 TimeBasedRollingPolicy最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。这个下面又包括了两个属性： FileNamePattern maxHistory 123456789&lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名:按天回滚 daily --&gt; &lt;FileNamePattern&gt; $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log.%d&#123;yyyy-MM-dd&#125; &lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;&lt;/rollingPolicy&gt; 上面的这段配置表明每天生成一个日志文件，保存30天的日志文件 FixedWindowRollingPolicy根据固定窗口算法重命名文件的滚动策略。 encoder 子标签对记录事件进行格式化。它干了两件事： 把日志信息转换成字节数组 把字节数组写入到输出流 12345&lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt;&lt;/encoder&gt; 目前encoder只有PatternLayoutEncoder一种类型。 定义一个只打印error级别日志的appcener1234567891011121314151617181920212223 &lt;!-- 错误日志 appender ： 按照每天生成日志文件 --&gt;&lt;appender name="ERROR-APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;append&gt;true&lt;/append&gt; &lt;!-- 过滤器，只记录 error 级别的日志 --&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;error&lt;/level&gt; &lt;/filter&gt; &lt;!-- 日志名称 --&gt; &lt;file&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-error.log&lt;/file&gt; &lt;!-- 每天生成一个日志文件，保存30天的日志文件 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名:按天回滚 daily --&gt; &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-error.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;!-- 编码 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt; 定义一个输出到控制台的appender123456&lt;!-- 默认的控制台日志输出，一般生产环境都是后台启动，这个没太大作用 --&gt;&lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %-5level %logger&#123;80&#125; - %msg%n&lt;/Pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; logger 配置详解1234&lt;logger name="com.glmapper.spring.boot.controller" level="$&#123;logging.level&#125;" additivity="false"&gt; &lt;appender-ref ref="GLMAPPER-LOGGERONE" /&gt;&lt;/logger&gt; 上面的这个配置文件描述的是：com.glmapper.spring.boot.controller这个包下的${logging.level}级别的日志将会使用GLMAPPER-LOGGERONE来打印。logger有三个属性和一个子标签： name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别（TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF），还有一个值INHERITED或者同义词NULL，代表强制执行上级的级别。如果没有设置此属性，那么当前logger将会继承上级的级别。 addtivity:用来描述是否向上级logger传递打印信息。默认是true。 appender-ref则是用来指定具体appender的。 不同日志隔离打印案例在前面的例子中我们有三种appender,一个是指定包约束的，一个是控制error级别的，一个是控制台的。然后这小节我们就来实现下不同日志打印到不同的log文件中。 根据包进行日志文件隔离这个例子里我们将com.glmapper.spring.boot.controller中的日志输出到glmapper-controller.log；将com.glmapper.spring.boot.service中的日志输出到glmapper-service.log。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!--打印日志到glmapper-service.log的appender--&gt;&lt;appender name="GLMAPPER-SERVICE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;append&gt;true&lt;/append&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt; &lt;/filter&gt; &lt;file&gt; $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-service.log &lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-service.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;!--打印日志到glmapper-controller.log的appender--&gt;&lt;appender name="GLMAPPER-CONTROLLER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;append&gt;true&lt;/append&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt; &lt;/filter&gt; &lt;file&gt; $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-controller.log &lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-controller.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;!--此logger约束将.controller包下的日志输出到GLMAPPER-CONTROLLER，错误日志输出到GERROR-APPENDE；GERROR-APPENDE见上面--&gt;&lt;logger name="com.glmapper.spring.boot.controller" level="$&#123;logging.level&#125;" additivity="false"&gt; &lt;appender-ref ref="GLMAPPER-CONTROLLER" /&gt; &lt;appender-ref ref="GERROR-APPENDER" /&gt;&lt;/logger&gt;&lt;!--此logger约束将.service包下的日志输出到GLMAPPER-SERVICE，错误日志输出到GERROR-APPENDE；GERROR-APPENDE见上面--&gt;&lt;logger name="com.glmapper.spring.boot.service" level="$&#123;logging.level&#125;" additivity="false"&gt; &lt;appender-ref ref="GLMAPPER-SERVICE" /&gt; &lt;appender-ref ref="GERROR-APPENDER" /&gt;&lt;/logger&gt; 来看运行结果 1、glmaper-controller 2、glmapper-service 3、glmapper-error 满足我们的预期，但是这里有个小问题。在info日志里出现了error,当然这是正常的。假如我们不想在info里面出现error怎么办呢？很简单，我们以APPENDER-SERVICE为例，将filter过滤器进行修改： 将下面的：123&lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;&lt;/filter&gt; 修改为： 1234567&lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;!-- 如果命中就禁止这条日志 --&gt; &lt;onMatch&gt;DENY&lt;/onMatch&gt; &lt;!-- 如果没有命中就使用这条规则 --&gt; &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt; &lt;/filter&gt; 这里同时要注意的是，在logger中level需要设置为info级别。 根据类进行日志文件隔离这个其实也是和上面那个差不过，只不过粒度更细一点，一般情况下比如说我们有个定时任务类需要单独来记录其日志信息，这样我们就可以考虑使用基于类维度来约束打印。 123456789101112131415161718192021222324252627&lt;!--特殊功能单独appender 例如调度类的日志--&gt;&lt;appender name="SCHEDULERTASKLOCK-APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;append&gt;true&lt;/append&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt; &lt;/filter&gt; &lt;file&gt;$&#123;logging.path&#125;/glmapper-spring-boot/scheduler-task-lock.log&lt;/file&gt; &lt;!-- 每天生成一个日志文件，保存30天的日志文件 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名:按天回滚 daily --&gt; &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/scheduler-task-lock.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;!-- 编码 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;!--这里指定到了具体的某一个类--&gt;&lt;logger name="com.glmapper.spring.boot.task.TestLogTask" level="$&#123;logging.level&#125;" additivity="true"&gt; &lt;appender-ref ref="SCHEDULERTASKLOCK-APPENDER" /&gt; &lt;appender-ref ref="ERROR-APPENDER" /&gt; &lt;/logger&gt; 最终TestLogTask中的日志将会被打印到这个自己独立的log文件中。如下所示： 根据自定义 logger 的 name 进行日志文件隔离logger的name除了类、包等约束之外，当然还可以这样来玩。。。 在进行案例之前，这里先把前面案例中logger声明的代码贴一下，以作对比,以TestLogTask类中的日志为例： 12private static final Logger LOGGER =LoggerFactory.getLogger(TestLogTask.class); 在getLogger中我们是将当前对象的class作为参数的，这个是为了打印时获取其全限定名的（见下面3-）。 12341-2018-07-21 11:15:42.003 [pool-1-thread-1] 2-INFO 3-com.glmapper.spring.boot.task.TestLogTask -4-com.glmapper.spring.boot.task:info 业务类定义我们同样是service包下定义一个类TestLogNameServiceImpl 1234567891011121314package com.glmapper.spring.boot.service;@Service("testLogNameService")public class TestLogNameServiceImpl implements TestLogNameService &#123; private static final Logger LOGGER = LoggerFactory.getLogger("GLMAPPER-TEST-LOG"); @Override public void print() &#123; LOGGER.info("GLMAPPER-TEST-LOG:this is special logger-----info"); LOGGER.error("GLMAPPER-TEST-LOG:this is special logger-------error"); &#125;&#125; appender和logger配置123456789101112131415161718192021222324252627&lt;appender name="ROOT-APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;append&gt;true&lt;/append&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt; &lt;/filter&gt; &lt;file&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-test.log&lt;/file&gt; &lt;!-- 每天生成一个日志文件，保存30天的日志文件 --&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名:按天回滚 daily --&gt; &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-test.log.%d&#123;yyyy-MM-dd&#125; &lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;!-- 编码 --&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt;&lt;/appender&gt;&lt;!--这里的name和业务类中的getLogger中的字符串是一样的--&gt;&lt;logger name="GLMAPPER-TEST-LOG" level="$&#123;logging.level&#125;" additivity="true"&gt; &lt;appender-ref ref="ROOT-APPENDER" /&gt; &lt;appender-ref ref="ERROR-APPENDER" /&gt; &lt;/logger&gt; 我们这个预期的是TestLogNameServiceImpl中的日志不打印到glmapper-service.log中，而是打印到glmapper-test.log中。 1、glmapper-test.log 2、glmapper-service.log 满足我们的预期。 如何使用logback打印mybatis的sql语句这个还是比较坑的。为什么。看下这个： 123&lt;settings&gt; &lt;setting name="logImpl" value="slf4j" /&gt;&lt;/settings&gt; 在mybatis-configration.xml中，我们通过这样一个配置项来关联到具体的日志组件。但是logImpl的实现中是没有logback的。那么怎么办呢？这里只能通过slf4j的方式桥接到logback。 然后在我们的logback-spring.xml中进行如下配置： 1234 &lt;!-- 将sql语句输出到具体的日志文件中 --&gt;&lt;logger name="com.alipay.sofa.cloudplatform.common.dao" level="$&#123;logging.sql.level&#125;" additivity="false"&gt; &lt;appender-ref ref="SQL-APPENDER"/&gt;&lt;/logger&gt; 这里有几个点需要注意的。首先是${logging.sql.level}这个必须是debug，这个是由mybatis本身实现决定的。而这里的name设定的com.alipay.sofa.cloudplatform.common.dao值就是我们dao接口的包路径。 网上看了一个比较典型的案例，这种方式只能输出到控制台，并不能将文件输出到日志文件；它是根据内部的一个实现机制偷了个懒。mybatis用logback日志不显示sql的解决办法。 总结本篇博客主要是整理最近工作中的一些日志配置积累，将每个细节进行总结一下，以作备忘。如果有时间的话会考虑看一个日志框架的源码。其实我觉得还是很有必要的，日志组件毕竟是需要进行日志文件落盘的，这个会涉及到许多的性能问题、缓冲区问题、队列问题、当然还有一些锁的问题、同步打印或者异步打印等问题。有兴趣的小伙伴可以看看，然后分享给我们。 后面准备写一写蚂蚁金服SOFABoot和SpringBoot的一些文章，如果有兴趣可以先看一波。 SOFABoot GitHub 传送门]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>logback</tag>
        <tag>slf4j</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SOFATracer 中 Disruptor 实践]]></title>
    <url>%2F2018%2F11%2F10%2Fsofatracerone%2F</url>
    <content type="text"><![CDATA[OpenTraceing 规范 OpenTracing语义标准 语义惯例 官方文档 SOFATracer 对 OpenTraceing 的实现 SOFATracer 就是根据 OpenTracing 规范 衍生出来的分布式 链路跟 踪的解决方案。 GitHub SOFATrcer 概念OpenTracing 标准中有三个重要的相互关联的类型，分别是Tracer, Span和 SpanContext。 【下面的概念说明过程中，如不做说明，所使用的案例代码均以SOFATracer中的实现为例。】 Tracer一个 trace 代表一个潜在的，分布式的，存在并行数据或并行执行轨迹（潜在的分布式、并行）的系统。一个trace可以认为是多个span的有向无环图（DAG）。 Tracer接口用来创建Span，以及处理如何处理Inject(serialize) 和 Extract (deserialize)，用于跨进程边界传递。 SOFATracer 中 SofaTracer这个类实现了 opentracing 的 Tracer 接口，并在此规范接口上做了一些扩展。看下Tracer 中声明的方法： 123456789101112public interface Tracer &#123; //启动一个新的span SpanBuilder buildSpan(String operationName); //将SpanContext上下文Inject（注入）到carrier &lt;C&gt; void inject(SpanContext spanContext, Format&lt;C&gt; format, C carrier); //将SpanContext上下文从carrier中Extract（提取） &lt;C&gt; SpanContext extract(Format&lt;C&gt; format, C carrier); interface SpanBuilder &#123; // 省略 &#125; &#125; 所以从接口定义来看，要实现一个Tracer，必须要实现其以下的几个能力： 启动一个新的spanSOFATracer 实现了 Tracer 中 buildSpan 方法： 1234@Overridepublic SpanBuilder buildSpan(String operationName) &#123; return new SofaTracerSpanBuilder(operationName);&#125; operationName :操作名称，字符串类型，表示由Span完成的工作 (例如，RPC方法名称、函数名称或一个较大的计算任务中的阶段的名称)。操作名称应该用泛化的字符串形式标识出一个Span实例。 何为泛化的字符串形式，比如现在有一个操作：获取用户 ；下面有几种标识方式： 1、/get 2、/get/user 3、/get/user/123 方式1过于抽象，方式3过于具体。方式2是正确的操作名。 将SpanContext上下文Inject（注入）到carrier12345678@Overridepublic &lt;C&gt; void inject(SpanContext spanContext, Format&lt;C&gt; format, C carrier) &#123; RegistryExtractorInjector&lt;C&gt; registryInjector = TracerFormatRegistry.getRegistry(format); if (registryInjector == null) &#123; throw new IllegalArgumentException("Unsupported injector format: " + format); &#125; registryInjector.inject((SofaTracerSpanContext) spanContext, carrier);&#125; SpanContext :实例 format（格式化）描述，一般会是一个字符串常量，但不做强制要求。通过此描述，通知Tracer实现，如何对SpanContext进行编码放入到carrier中。carrier，根据format确定。Tracer实现根据format声明的格式，将SpanContext序列化到carrier对象中。 RegistryExtractorInjector 见后面 将SpanContext上下文从carrier中Extract（提取）12345678@Overridepublic &lt;C&gt; SpanContext extract(Format&lt;C&gt; format, C carrier) &#123; RegistryExtractorInjector&lt;C&gt; registryExtractor = TracerFormatRegistry.getRegistry(format); if (registryExtractor == null) &#123; throw new IllegalArgumentException("Unsupported extractor format: " + format); &#125; return registryExtractor.extract(carrier);&#125; 格式描述符(format descriptor)(通常但不一定是字符串常量)，告诉Tracer的实现如何在载体对象中对SpanContext进行编码 载体(carrier)，其类型由格式描述符指定。Tracer的实现将根据格式描述对此载体对象中的SpanContext进行编码 返回一个SpanContext实例，可以使用这个SpanContext实例，通过Tracer创建新的Span。 Format从Tracer的注入和提取来看，format都是必须的。 Inject（注入）和Extract（提取）依赖于可扩展的format参数。format参数规定了另一个参数&quot;carrier&quot;的类型，同时约束了&quot;carrier&quot;中SpanContext是如何编码的。所有的Tracer实现，都必须支持下面的format。 Text Map: 基于字符串：字符串的map,对于key和value不约束字符集。 HTTP Headers: 适合作为HTTP头信息的，基于字符串：字符串的map。（RFC 7230.在工程实践中，如何处理HTTP头具有多样性，强烈建议tracer的使用者谨慎使用HTTP头的键值空间和转义符） Binary: 一个简单的二进制大对象，记录SpanContext的信息。 在上面的注入和提取代码中，有如下代码片段： 123456//注入RegistryExtractorInjector&lt;C&gt; registryInjector = TracerFormatRegistry.getRegistry(format);//提取RegistryExtractorInjector&lt;C&gt; registryExtractor = TracerFormatRegistry.getRegistry(format); 来通过TracerFormatRegistry这个类来来看下 SOFATracer 中的 Format 的具体实现。 X-B3在看Format之前，先了解下X-B3。 12Access-Control-Expose-Headers: X-B3-TraceId,X-B3-ParentSpanId,X-B3-SpanId HTTP请求时其span参数通过http headers来传递追踪信息；header中对应的key分别是: X-B3-TraceId: 64 encoded bits（id被encode为hex Strings） X-B3-SpanId : 64 encoded bits X-B3-ParentSpanId: 64 encoded bits X-B3-Sampled:(是否采样) Boolean (either “1” or “0”)（下面的调用是否进行采样） X-B3-Flags:a Long SOFATracer 中的 Format具体代码在 tracer-core -&gt; com.alipay.common.tracer.core.registy 包下: TextMapFormatter TextMapB3Formatter HttpHeadersFormatter HttpHeadersB3Formatter BinaryFormater BinaryFormater：这个的注入和提取实现没有编解码一说；本身就是基于二进制流的操作。 TextMapB3Formatter/TextMapFormatter 和 HttpHeadersB3Formatter/HttpHeadersFormatter 区别就在于编解码不同。HttpHeadersB3Formatter使用的是 URLDecoder.decode &amp;&amp; URLDecoder.encode ; TextMapB3Formatter 返回的是值本身（如果为空或者null则返回空字符串）。 TextMapFormatter和TextMapB3Formatter区别在于注入或者提取是使用的key不用。TextMapB3Formatter中使用的是 x-b3-{} 的字符串作为key。 Span一个span代表系统中具有开始时间和执行时长的逻辑运行单元。span之间通过嵌套或者顺序排列建立逻辑因果关系。当Span结束后(span.finish())，除了通过Span获取SpanContext外，下列其他所有方法都不允许被调用。 同样先来看下opentracing规范api 定义的 span 的定义及方法： 123456789101112131415161718public interface Span extends Closeable &#123; SpanContext context(); void finish(); void finish(long finishMicros); void close(); Span setTag(String key, String value); Span setTag(String key, boolean value); Span setTag(String key, Number value); Span log(Map&lt;String, ?&gt; fields); Span log(long timestampMicroseconds, Map&lt;String, ?&gt; fields); Span log(String event); Span log(long timestampMicroseconds, String event); Span setBaggageItem(String key, String value); String getBaggageItem(String key); Span setOperationName(String operationName); Span log(String eventName, /* @Nullable */ Object payload); Span log(long timestampMicroseconds, String eventName, /* @Nullable */ Object payload);&#125; 通过Span获取SpanContext12345//SOFATracerSpan@Overridepublic SpanContext context() &#123; return this.sofaTracerSpanContext;&#125; 返回值，Span构建时传入的SpanContext。这个返回值在Span结束后(span.finish())，依然可以使用。 复写操作名12345@Overridepublic Span setOperationName(String operationName) &#123; this.operationName = operationName; return this;&#125; operationName:新的操作名，覆盖构建Span时，传入的操作名。 结束Span123456789101112@Overridepublic void finish() &#123; this.finish(System.currentTimeMillis());&#125;@Overridepublic void finish(long endTime) &#123; this.setEndTime(endTime); //关键记录:report span this.sofaTracer.reportSpan(this); SpanExtensionFactory.logStoppedSpan(this);&#125; 有一个可选参数，如果指定完成时间则使用当前指定的时间；如果省略此参数，使用当前时间作为完成时间。finish方法中会将当前span进行report操作。 为Span设置tagTag是一个key:value格式的数据。key必须是String类型，value可以是字符串、布尔或者数字。 字符串类型的value 设置tag 1234567891011121314151617181920@Overridepublic Span setTag(String key, String value) &#123; if (StringUtils.isBlank(key) || StringUtils.isBlank(value)) &#123; return this; &#125; this.tagsWithStr.put(key, value); //注意:server 还是 client 在 OpenTracing 标准中是用 tags 标识的,所以在这里进行判断 if (isServer()) &#123; Reporter serverReporter = this.sofaTracer.getServerReporter(); if (serverReporter != null) &#123; this.setLogType(serverReporter.getReporterType()); &#125; &#125; else if (isClient()) &#123; Reporter clientReporter = this.sofaTracer.getClientReporter(); if (clientReporter != null) &#123; this.setLogType(clientReporter.getReporterType()); &#125; &#125; return this;&#125; 布尔类型的value 设置tag 1234public Span setTag(String key, boolean value) &#123; this.tagsWithBool.put(key, value); return this;&#125; 数字类型的value 设置tag 1234567public Span setTag(String key, Number number) &#123; if (number == null) &#123; return this; &#125; this.tagsWithNumber.put(key, number); return this;&#125; Log结构化数据1234567891011@Overridepublic Span log(long currentTime, Map&lt;String, ?&gt; map) &#123; AssertUtils.isTrue(currentTime &gt;= startTime, "current time must greater than start time"); this.logs.add(new LogData(currentTime, map)); return this;&#125;@Overridepublic Span log(Map&lt;String, ?&gt; map) &#123; return this.log(System.currentTimeMillis(), map);&#125; Map&lt;String, ?&gt; map : 键必须是字符串类型，值可以是任意类型 currentTime : 时间戳。如果指定时间戳，那么它必须在span的开始和结束时间之内。 设置一个baggage（随行数据）元素Baggage元素是一个键值对集合，将这些值设置给给定的Span，Span的SpanContext，以及所有和此Span有直接或者间接关系的本地Span。 也就是说，baggage元素随trace一起保持在带内传递。（译者注：带内传递，在这里指，随应用程序调用过程一起传递） Baggage元素为OpenTracing的实现全栈集成，提供了强大的功能 （例如：任意的应用程序数据，可以在移动端创建它，显然的，它会一直传递了系统最底层的存储系统。由于它如此强大的功能，他也会产生巨大的开销，请小心使用此特性。 再次强调，请谨慎使用此特性。每一个键值都会被拷贝到每一个本地和远程的下级相关的span中，因此，总体上，他会有明显的网络和CPU开销。 12345@Overridepublic Span setBaggageItem(String key, String value) &#123; this.sofaTracerSpanContext.setBizBaggageItem(key, value); return this;&#125; SofaTracerSpan 中的属性 sofaTracer : 当前 tracer spanReferences : 当前span的关系，ChildOf(引用) or FollowsFrom（跟随） tagsWithStr : String 类型的tag 集合 tagsWithBool : 布尔类型的tag集合 tagsWithNumber : 数值类型的tag集合 logs : log结构化数据列表，通过span.log（map）操作的map,均存储在logs中。 operationName：当前span的操作名 sofaTracerSpanContext：当前 spanContext startTime : 当前span 开始时间 endTime : 当前span 结束时间，在finish方法中传入。 logType : report时才有意义:摘要日志类型,日志能够正确打印的关键信息；当前 span 的日志类型,如:客户端为 rpc-client-digest.log,服务端为 rpc-server-digest.log parentSofaTracerSpan：父亲 span,当作为客户端结束并弹出线程上下文时,需要将父亲 span 再放入 SpanContextopentracing 中 SpanContext 接口中只有一个baggageItems方法，通过这个方法来遍历所有的baggage元素。 123public interface SpanContext &#123; Iterable&lt;Map.Entry&lt;String, String&gt;&gt; baggageItems();&#125; 相对于OpenTracing中其他的功能，SpanContext更多的是一个“概念”。也就是说，OpenTracing实现中，需要重点考虑，并提供一套自己的API。 OpenTracing的使用者仅仅需要，在创建span、向传输协议Inject（注入）和从传输协议中Extract（提取）时，使用SpanContext和references， OpenTracing要求，SpanContext是不可变的，目的是防止由于Span的结束和相互关系，造成的复杂生命周期问题。 Disruptor 简介 A High Performance Inter-Thread Messaging Library 高性能的线程间消息传递库 关于 Disruptor 的 一些原理分析可以参考：disruptor 案例先通过 Disruptor 的一个小例子来有个直观的认识；先看下它的构造函数： 1234567891011public Disruptor( final EventFactory&lt;T&gt; eventFactory, final int ringBufferSize, final ThreadFactory threadFactory, final ProducerType producerType, final WaitStrategy waitStrategy)&#123; this( RingBuffer.create(producerType, eventFactory, ringBufferSize, waitStrategy), new BasicExecutor(threadFactory));&#125; eventFactory : 在环形缓冲区中创建事件的 factory ringBufferSize:环形缓冲区的大小，必须是2的幂。 threadFactory：用于为处理器创建线程。 producerType：生成器类型以支持使用正确的sequencer和publisher创建RingBuffer；枚举类型，SINGLE、MULTI两个项。对应于 SingleProducerSequencer和MultiProducerSequencer两种Sequencer。 waitStrategy : 等待策略； 如果我们想构造一个disruptor,那么我们就需要上面的这些组件。从eventFactory来看，还需要一个具体的Event来作为消息事件的载体。【下面按照官方给的案例进行简单的修改作为示例】 消息事件 LongEvent ，能够被消费的数据载体123456789public class LongEvent &#123; private long value; public void set(long value) &#123; this.value = value; &#125; public long getValue() &#123; return value; &#125;&#125; 创建消息事件的factory123456public class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123; @Override public LongEvent newInstance() &#123; return new LongEvent(); &#125;&#125; ConsumerThreadFactory1234567public class ConsumerThreadFactory implements ThreadFactory &#123; private final AtomicInteger index = new AtomicInteger(1); @Override public Thread newThread(Runnable r) &#123; return new Thread(r, "disruptor-thread-" + index.getAndIncrement()); &#125;&#125; OK ，上面的这些可以满足创建一个disruptor了： 123456789101112131415private int ringBufferCapacity = 8;//消息事件生产FactoryLongEventFactory longEventFactory = new LongEventFactory();//执行事件处理器线程FactoryConsumerThreadFactory consumerThreadFactory = new ConsumerThreadFactory();//用于环形缓冲区的等待策略。WaitStrategy waitStrategy = new BlockingWaitStrategy();//构建disruptorDisruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;( longEventFactory, ringBufferCapacity, longEventThreadFactory, ProducerType.SINGLE, waitStrategy); 现在是已经有了 disruptor 了，然后通过：start 来启动： 12//启动 disruptor disruptor.start(); 到这里，已经构建了一个disruptor；但是目前怎么使用它来发布消息和消费消息呢？ 发布消息下面在 for 循环中 发布 5 条数据： 12345678910RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer();for (long l = 0; l &lt; 5; l++)&#123; long sequence = ringBuffer.next(); LongEvent event = ringBuffer.get(sequence); event.set(100+l); System.out.println("publish event :" + l); ringBuffer.publish(sequence); Thread.sleep(1000);&#125; 消息已经发布，下面需要设定当前disruptor的消费处理器。前面已经有个LongEvent 和 EventFactory ; 在disruptor中是通过 EventHandler 来进行消息消费的。 编写消费者代码1234567public class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123; @Override public void onEvent(LongEvent event, long sequence, boolean endOfBatch) throws Exception &#123; System.out.println("Event: " + event.getValue()+" -&gt; " + Thread.currentThread().getName()); Thread.sleep(2000); &#125;&#125; 将 eventHandler 设置到 disruptor 的处理链上 123//将处理事件的事件处理程序 -&gt; 消费事件的处理程序LongEventHandler longEventHandler = new LongEventHandler();disruptor.handleEventsWith(longEventHandler); 运行结果（这里）：123456789101112131415publish event :0Event: 0 -&gt; disruptor-thread-1--------------------------------&gt;publish event :1Event: 1 -&gt; disruptor-thread-1--------------------------------&gt;publish event :2Event: 2 -&gt; disruptor-thread-1--------------------------------&gt;publish event :3Event: 3 -&gt; disruptor-thread-1--------------------------------&gt;publish event :4Event: 4 -&gt; disruptor-thread-1--------------------------------&gt; 基本概念和原理Disruptor整个基于ringBuffer实现的生产者消费者模式的容器。主要属性 12345private final RingBuffer&lt;T&gt; ringBuffer;private final Executor executor;private final ConsumerRepository&lt;T&gt; consumerRepository = new ConsumerRepository&lt;&gt;();private final AtomicBoolean started = new AtomicBoolean(false);private ExceptionHandler&lt;? super T&gt; exceptionHandler = new ExceptionHandlerWrapper&lt;&gt;(); ringBuffer：内部持有一个 RingBuffer 对象，Disruptor 内部的事件发布都是依赖这个RingBuffer对象完成的。 executor：消费事件的线程池 consumerRepository：提供存储库机制，用于将EventHandler与EventProcessor关联起来 started : 用于标志当前Disruptor是否已经启动 exceptionHandler : 异常处理器，用于处理BatchEventProcessor事件周期中 uncaught exceptions 。 RingBuffer环形队列[实现上是一个数组]，可以类比为BlockingQueue之类的队列，ringBuffer的使用，使得内存被循环使用，减少了某些场景的内存分配回收扩容等耗时操作。 12public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt; E：在事件的交换或并行协调期间存储用于共享的数据的实现 -&gt; 消息事件 Sequencer RingBuffer 中 生产者的顶级父接口，其直接实现有SingleProducerSequencer和MultiProducerSequencer；对应 SINGLE、MULTI 两个枚举值。 EventHandler事件处置器，改接口用于对外扩展来实现具体的消费逻辑。如上面 demo 中的 LongEventHandler ; 1234//回调接口，用于处理&#123;@link RingBuffer&#125;中可用的事件public interface EventHandler&lt;T&gt; &#123; void onEvent(T event, long sequence, boolean endOfBatch) throws Exception;&#125; event : RingBuffer 已经发布的事件 sequence : 正在处理的事件 的序列号 endOfBatch : 用来标识否是来自 RingBuffer 的批次中的最后一个事件 SequenceBarrier消费者路障。规定了消费者如何向下走。事实上，该路障算是变向的锁。 12345678910111213final class ProcessingSequenceBarrier implements SequenceBarrier &#123; //当等待（探测）的需要不可用时，等待的策略 private final WaitStrategy waitStrategy; //依赖的其它Consumer的序号，这个用于依赖的消费的情况， //比如A、B两个消费者，只有A消费完，B才能消费。 private final Sequence dependentSequence; private volatile boolean alerted = false; //Ringbuffer的写入指针 private final Sequence cursorSequence; //RingBuffer对应的Sequencer private final Sequencer sequencer; //exclude method&#125; waitStrategy 决定了消费者采用何种等待策略。 WaitStrategy Strategy employed for making {@link EventProcessor}s wait on a cursor {@link Sequence}. EventProcessor 的等待策略；具体实现在 disruptor 中有8种， 这些等待策略不同的核心体现是在如何实现 waitFor 这个方法上。 EventProcessor事件处理器，实际上可以理解为消费者模型的框架，实现了线程Runnable的run方法，将循环判断等操作封在了里面。该接口有三个实现类: 1、BatchEventProcessor 12345678910public final class BatchEventProcessor&lt;T&gt; implements EventProcessor &#123; private final AtomicBoolean running = new AtomicBoolean(false); private ExceptionHandler&lt;? super T&gt; exceptionHandler = new FatalExceptionHandler(); private final DataProvider&lt;T&gt; dataProvider; private final SequenceBarrier sequenceBarrier; private final EventHandler&lt;? super T&gt; eventHandler; private final Sequence sequence = new Sequence( Sequencer.INITIAL_CURSOR_VALUE); private final TimeoutHandler timeoutHandler; //exclude method&#125; ExceptionHandler：异常处理器 DataProvider：数据来源，对应 RingBuffer EventHandler：处理 Event 的回调对象 SequenceBarrier：对应的序号屏障 TimeoutHandler：超时处理器，默认情况为空，如果要设置，只需要要将关联的EventHandler实现TimeOutHandler即可。 如果我们选择使用 EventHandler 的时候，默认使用的就是 BatchEventProcessor，它与EventHandler是一一对应，并且是单线程执行。 如果某个RingBuffer有多个BatchEventProcessor，那么就会每个BatchEventProcessor对应一个线程。 2、WorkProcessor 1234567891011121314151617public final class WorkProcessor&lt;T&gt; implements EventProcessor &#123; private final AtomicBoolean running = new AtomicBoolean(false); private final Sequence sequence = new Sequence(Sequencer.INITIAL_CURSOR_VALUE); private final RingBuffer&lt;T&gt; ringBuffer; private final SequenceBarrier sequenceBarrier; private final WorkHandler&lt;? super T&gt; workHandler; private final ExceptionHandler&lt;? super T&gt; exceptionHandler; private final Sequence workSequence; private final EventReleaser eventReleaser = new EventReleaser() &#123; @Override public void release() &#123; sequence.set(Long.MAX_VALUE); &#125; &#125;; private final TimeoutHandler timeoutHandler;&#125; 基本和 BatchEventProcessor 类似，不同在于，用于处理Event的回调对象是WorkHandler。 原理图 无消费者情况下，生产者保持生产，但是 remainingCapacity 保持不变在写demo的过程中，本来想通过不设定 消费者 来观察 RingBuffer 可用容量变化的。但是验证过程中，一直得不到预期的结果，(注：没有设置消费者，只有生产者)，先看结果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950publish event :0bufferSie:8remainingCapacity:8cursor:0--------------------------------&gt;publish event :1bufferSie:8remainingCapacity:8cursor:1--------------------------------&gt;publish event :2bufferSie:8remainingCapacity:8cursor:2--------------------------------&gt;publish event :3bufferSie:8remainingCapacity:8cursor:3--------------------------------&gt;publish event :4bufferSie:8remainingCapacity:8cursor:4--------------------------------&gt;publish event :5bufferSie:8remainingCapacity:8cursor:5--------------------------------&gt;publish event :6bufferSie:8remainingCapacity:8cursor:6--------------------------------&gt;publish event :7bufferSie:8remainingCapacity:8cursor:7--------------------------------&gt;publish event :8bufferSie:8remainingCapacity:8cursor:8--------------------------------&gt;publish event :9bufferSie:8remainingCapacity:8cursor:9--------------------------------&gt; 从结果来看，remainingCapacity 的值应该随着 发布的数量 递减的；但是实际上它并没有发生任何变化。 来看下ringBuffer.remainingCapacity() 这个方法： 123456789/** * Get the remaining capacity for this ringBuffer. * * @return The number of slots remaining. */public long remainingCapacity()&#123; return sequencer.remainingCapacity();&#125; 这里面又使用 sequencer.remainingCapacity()这个方法来计算的。上面的例子中使用的是ProducerType.SINGLE，那来看SingleProducerSequencer 这个里面remainingCapacity的实现。 1234567891011@Overridepublic long remainingCapacity()&#123; //上次申请完毕的序列值 long nextValue = this.nextValue; //计算当前已经消费到的序列值 long consumed = Util.getMinimumSequence(gatingSequences, nextValue); //当前生产到的序列值 long produced = nextValue; return getBufferSize() - (produced - consumed);&#125; 来解释下这段代码的含义： 假设当前 ringBuffer 的 bufferSize 是 8 ；上次申请到的序列号是 5，其实也就是说已经生产过占用的序列号是5；假设当前已经消费到的序列号是 3，那么剩余的容量为： 8-（5-2） = 5； 因为这里我们可以确定 bufferSize 和 produced 的值了，那么 remainingCapacity 的结果就取决于getMinimumSequence的计算结果了。 123456789public static long getMinimumSequence(final Sequence[] sequences, long minimum)&#123; for (int i = 0, n = sequences.length; i &lt; n; i++) &#123; long value = sequences[i].get(); minimum = Math.min(minimum, value); &#125; return minimum;&#125; 这个方法是从 Sequence 数组中获取最小序列 。如果sequences 为空，则返回 minimum。回到上一步，看下sequences这个数组是从哪里过来的，它的值在哪里设置的。 1long consumed = Util.getMinimumSequence(gatingSequences, nextValue); gatingSequences是 SingleProducerSequencer父类 AbstractSequencer 中的成员变量： 1protected volatile Sequence[] gatingSequences = new Sequence[0]; gatingSequences 是在下面这个方法里面来管理的。 12345678/** * @see Sequencer#addGatingSequences(Sequence...) */@Overridepublic final void addGatingSequences(Sequence... gatingSequences)&#123; SequenceGroups.addSequences(this, SEQUENCE_UPDATER, this, gatingSequences);&#125; 这个方法的调用栈向前追溯有这几个地方调用了： WorkerPool来管理多个消费者；hangdlerEventsWith 这个方法也是用来设置消费者的。但是在上面的测试案例中我们是想通过不设定消费者 只设定生成者 来观察 环形队列的占用情况，所以gatingSequences 会一直是空的，因此在计算时会把 produced 的值作为 minimum 返回。这样每次计算就相当于： 1return getBufferSize() - (produced - produced) === getBufferSize(); 也就验证了为何在不设定消费者的情况下，remainingCapacity 的值会一直保持不变。 SOFATracer 中 Disruptor 实践SOFATracer中，AsyncCommonDigestAppenderManager 对 disruptor 进行了封装，用于处理外部组件的Tracer摘要日志。该部分借助 AsyncCommonDigestAppenderManager 的源码来分析下SOFATracer如何使用disruptor的。 SOFATracer中使用了两种不同的事件模型，一种是SOFATracer内部使用的 StringEvent , 一种是 外部扩展使用的 SofaTacerSpanEvent。这里以 SofaTacerSpanEvent 这种事件模型来分析。StringEvent 消息事件模型对应的是 AsyncCommonAppenderManager 类封装的disruptor。 SofaTracerSpanEvent ( -&gt; LongEvent)定义消息事件模型，SofaTacerSpanEvent 和 前面 demo 中的 LongEvent 基本结构是一样的，主要是内部持有的消息数据不同，LongEvent 中是一个long类型的数据，SofaTacerSpanEvent中持有的是 SofaTracerSpan 。 123456789public class SofaTracerSpanEvent &#123; private volatile SofaTracerSpan sofaTracerSpan; public SofaTracerSpan getSofaTracerSpan() &#123; return sofaTracerSpan; &#125; public void setSofaTracerSpan(SofaTracerSpan sofaTracerSpan) &#123; this.sofaTracerSpan = sofaTracerSpan; &#125;&#125; Consumer ( -&gt; LongEventHandler)Consumer 是 AsyncCommonDigestAppenderManager 的内部类;实现了 EventHandler 接口，这个consumer就是作为消费者存在的。 在AsyncCommonAppenderManager中也有一个，这个地方个人觉得可以抽出去，这样可以使得AsyncCommonDigestAppenderManager/AsyncCommonAppenderManager的代码看起来更干净； 123456789101112131415161718192021222324252627282930313233343536373839private class Consumer implements EventHandler&lt;SofaTracerSpanEvent&gt; &#123; //日志类型集合，非该集合内的日志类型将不会被处理 protected Set&lt;String&gt; logTypes = Collections.synchronizedSet(new HashSet&lt;String&gt;()); @Override public void onEvent(SofaTracerSpanEvent event, long sequence, boolean endOfBatch) throws Exception &#123; // 拿到具体的消息数据 sofaTracerSpan SofaTracerSpan sofaTracerSpan = event.getSofaTracerSpan(); // 如果没有数据，则不做任何处理 if (sofaTracerSpan != null) &#123; try &#123; String logType = sofaTracerSpan.getLogType(); // 验证当前日志类型是否可以被当前consumer消费 if (logTypes.contains(logType)) &#123; // 获取编码类型 SpanEncoder encoder = contextEncoders.get(logType); //获取 appender TraceAppender appender = appenders.get(logType); // 对数据进行编码处理 String encodedStr = encoder.encode(sofaTracerSpan); if (appender instanceof LoadTestAwareAppender) &#123; ((LoadTestAwareAppender) appender).append(encodedStr, TracerUtils.isLoadTest(sofaTracerSpan)); &#125; else &#123; appender.append(encodedStr); &#125; // 刷新缓冲区，日志输出 appender.flush(); &#125; &#125; catch (Exception e) &#123; // 异常省略 &#125; &#125; &#125; public void addLogType(String logType) &#123; logTypes.add(logType); &#125; &#125; SofaTracerSpanEventFactory （-&gt; LongEventFactory）用于产生消息事件的 Factory 123456public class SofaTracerSpanEventFactory implements EventFactory&lt;SofaTracerSpanEvent&gt; &#123; @Override public SofaTracerSpanEvent newInstance() &#123; return new SofaTracerSpanEvent(); &#125;&#125; ConsumerThreadFactory (-&gt; LongEventThreadFactory )用来产生消费线程的 Factory。 123456789101112131415public class ConsumerThreadFactory implements ThreadFactory &#123; private String workName; public String getWorkName() &#123; return workName; &#125; public void setWorkName(String workName) &#123; this.workName = workName; &#125; @Override public Thread newThread(Runnable runnable) &#123; Thread worker = new Thread(runnable, "Tracer-AsyncConsumer-Thread-" + workName); worker.setDaemon(true); return worker; &#125;&#125; 构建disruptordisruptor 的构建是在 AsyncCommonDigestAppenderManager 的构造函数中完成的。 1234567891011121314151617181920212223242526272829303132333435363738394041public AsyncCommonDigestAppenderManager(int queueSize, int consumerNumber) &#123; // 使用这个计算来保证realQueueSize是2的次幂（返回当前 大于等于queueSize的最小的2的次幂数 ） int realQueueSize = 1 &lt;&lt; (32 - Integer.numberOfLeadingZeros(queueSize - 1)); //构建disruptor，使用的是 ProducerType.MULTI //等待策略是 BlockingWaitStrategy disruptor = new Disruptor&lt;SofaTracerSpanEvent&gt;(new SofaTracerSpanEventFactory(), realQueueSize, threadFactory, ProducerType.MULTI, new BlockingWaitStrategy()); //消费者列表 this.consumers = new ArrayList&lt;Consumer&gt;(consumerNumber); for (int i = 0; i &lt; consumerNumber; i++) &#123; Consumer consumer = new Consumer(); consumers.add(consumer); //设置异常处理程序 disruptor.setDefaultExceptionHandler(new ConsumerExceptionHandler()); //绑定消费者 disruptor.handleEventsWith(consumer); &#125; //是否允许丢弃，从配置文件获取 this.allowDiscard = Boolean.parseBoolean(SofaTracerConfiguration.getProperty( SofaTracerConfiguration.TRACER_ASYNC_APPENDER_ALLOW_DISCARD, DEFAULT_ALLOW_DISCARD)); if (allowDiscard) &#123; //是否记录丢失日志的数量 this.isOutDiscardNumber = Boolean.parseBoolean(SofaTracerConfiguration.getProperty( SofaTracerConfiguration.TRACER_ASYNC_APPENDER_IS_OUT_DISCARD_NUMBER, DEFAULT_IS_OUT_DISCARD_NUMBER)); //是否记录丢失日志的TraceId和RpcId this.isOutDiscardId = Boolean.parseBoolean(SofaTracerConfiguration.getProperty( SofaTracerConfiguration.TRACER_ASYNC_APPENDER_IS_OUT_DISCARD_ID, DEFAULT_IS_OUT_DISCARD_ID)); //丢失日志的数量达到该阈值进行一次日志输出 this.discardOutThreshold = Long.parseLong(SofaTracerConfiguration.getProperty( SofaTracerConfiguration.TRACER_ASYNC_APPENDER_DISCARD_OUT_THRESHOLD, DEFAULT_DISCARD_OUT_THRESHOLD)); if (isOutDiscardNumber) &#123; this.discardCount = new PaddedAtomicLong(0L); &#125; &#125;&#125; 启动 disruptordisruptor的启动委托给了AsyncCommonDigestAppenderManager 的start方法来执行。 1234public void start(final String workerName) &#123; this.threadFactory.setWorkName(workerName); this.ringBuffer = this.disruptor.start();&#125; 来看下，SOFATracer 中 具体是在哪里调用这个start 的： CommonTracerManager : 这个里面持有了AsyncCommonDigestAppenderManager 类的一个单例对象，并且是static 静态代码块中调用了start方法；这个用来输出普通日志。 SofaTracerDigestReporterAsyncManager：这里类里面也是持有了AsyncCommonDigestAppenderManager 类的一个单例对像，并且提供了getSofaTracerDigestReporterAsyncManager方法来获取该单例，在这个方法中调用了start方法；该对象用来输出摘要日志。 发布事件前面的demo中是通过一个for循环来发布事件的，在 SOFATracer 中 的事件发布无非就是当有Tracer日志需要输出时会触发发布，那么对应的就是日志的 append 操作，将日志 append 到环形缓冲区。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public boolean append(SofaTracerSpan sofaTracerSpan) &#123; long sequence = 0L; //是否允许丢弃 if (allowDiscard) &#123; try &#123; //允许丢弃就使用tryNext尝试申请序列，申请不到抛出异常 sequence = ringBuffer.tryNext(); &#125; catch (InsufficientCapacityException e) &#123; //是否输出丢失日志的TraceId和RpcId if (isOutDiscardId) &#123; SofaTracerSpanContext sofaTracerSpanContext = sofaTracerSpan .getSofaTracerSpanContext(); if (sofaTracerSpanContext != null) &#123; SynchronizingSelfLog.warn("discarded tracer: traceId[" + sofaTracerSpanContext.getTraceId() + "];spanId[" + sofaTracerSpanContext.getSpanId() + "]"); &#125; &#125; //是否输出丢失日志的数量 if ((isOutDiscardNumber) &amp;&amp; discardCount.incrementAndGet() == discardOutThreshold) &#123; discardCount.set(0); if (isOutDiscardNumber) &#123; SynchronizingSelfLog.warn("discarded " + discardOutThreshold + " logs"); &#125; &#125; return false; &#125; &#125; else &#123; // 不允许丢弃则使用next方法 sequence = ringBuffer.next(); &#125; try &#123; SofaTracerSpanEvent event = ringBuffer.get(sequence); event.setSofaTracerSpan(sofaTracerSpan); &#125; catch (Exception e) &#123; SynchronizingSelfLog.error("fail to add event"); return false; &#125; //发布 ringBuffer.publish(sequence); return true;&#125; SOFATracer 事件发布的调用逻辑： 追溯调用的流程，可以知道当前 span 调用 finish时或者 SOFATracer中调用reportSpan时 就相当于发布了一个消息事件。 小结本文对 SOFATracer 中使用 Disruptor 来进行日志输出的代码进行了简单的分析，更多内部细节原理可以自行看下SOFATracer的代码。SOFATracer 作为一种比较底层的中间件组件，在实际的业务开发中基本是无法感知的。但是作为技术来学习，还是有很多点可以挖一挖。 SOFATracer GitHub 传送门。 如果有小伙伴对中间件感兴趣，欢迎加入我们团队，欢迎来撩；对 SOFA 技术体系有兴趣的可以关注我们 ALIPAY SOFA 社区；附团队镇楼图。]]></content>
      <categories>
        <category>SOFA</category>
      </categories>
      <tags>
        <tag>SOFATracer</tag>
        <tag>Disruptor</tag>
        <tag>OpenTracing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊 RestTemplate]]></title>
    <url>%2F2018%2F11%2F10%2Fresttemplate1%2F</url>
    <content type="text"><![CDATA[最近这段时间用了下 RestTemplate 这个类，抽点时间总结下一些东西，希望对大家有所帮助。 从 3.0 版本开始，Spring 提供了 RestTemplate 作为用于访问 Rest 服务的客户端，RestTemplate 提供了多种便捷访问远程 Http 服务的方法，能够大大提高客户端的编写效率。 本篇文章将从 RestTemplate 提供的 API 入手，先来了解下 RestTemplate 的具体使用，然后再对其中涉及到的几个核心类进行分析，最后再来分析下 RestTemplate 执行的整个流程，篇幅比较长，建议先码为快！ 核心 API在平时的使用中，我们通常都是使用包装好的getForObject/getForEntity，postForObject/postForEntity/postForLocation，put以及delete。 get 请求处理getForEntity方法的返回值是一个ResponseEntity，ResponseEntity是Spring对HTTP请求响应的封装，包括了几个重要的元素，如响应码、contentType、contentLength、响应消息体等。 url：调用的服务的地址 responseType：返回的body类型 uriVariables：有两种形式: 可以用一个数字做占位符，最后是一个可变长度的参数，来一一替换前面的占位符 也可以前面使用name={name}这种形式，最后一个参数是一个map，map的key即为前边占位符的名字，map的value为参数值 responseType 测试案例定义的一个controller资源： 这里分别使用不同的 responseType 进行测试： 结果：12getForEntity(responseType=Map.class):&#123;glmapper=hello glmapper&#125;getForEntity(responseType=String.class):&#123;&quot;glmapper&quot;:&quot;hello glmapper&quot;&#125; uriVariables 测试案例先来看下非map方式的，两个controller，两种不同方式的参数获取（本质上是一样的） 使用占位符的方式： 使用 map 的方式： getForObjectgetForObject 函数实际上是对 getForEntity 函数的进一步封装，如果只关注返回的消息体的内容，对其他信息都不关注，那么就可以使用 getForObject。 这里调用就比getForEntity要简单一点了，可以直接拿到对象： getForObject 的几个重载方法和 getForEntity 基本是一样的。 post 请求处理在RestTemplate中，POST请求可以通过如下三个方法来发起：postForEntity，postForObject，postForLocation。 postForEntity 案例调用获取： 1postForEntity(URI url, @Nullable Object request, Class&lt;T&gt; responseType) 方法的第一参数表示要调用的服务的地址 方法的第二个参数表示上传的参数 方法的第三个参数表示返回的消息体的数据类型 postForObject 案例和 getForObject 相对应，只关注返回的消息体。 postForLocation 案例postForLocation也是提交新资源，提交成功之后，返回新资源的URI，postForLocation的参数和前面两种的参数基本一致，只不过该方法的返回值为Uri，这个只需要服务提供者返回一个Uri即可，该Uri表示新资源的位置。 这里有点坑，我们需要把这个uri添加到response的header中，不然后面拿到的是null。 exchangeexchange 方法和上述这些方法差别在于需要多一个请求类型的参数： AsyncRestTemplate 异步客户端RestTemplate的异步实现方式。所涉及到的API和RestTemplate基本一致。区别在于RestTemplate直接返回结果，而AsyncRestTemplate返回的是ListenableFuture。 RestTemplate 拦截器Spring提供了ClientHttpRequestInterceptor和AsyncClientHttpRequestInterceptor两个接口，分别可以对RestTemplate和AsyncRestTemplate发起的请求进行拦截，并在其被发送至服务端之前修改请求或是增强相应的信息。 ClientHttpRequestInterceptor 拦截 RestTemplate AsyncClientHttpRequestInterceptor 拦截AsyncRestTemplate 设置拦截器就是通过提供的 setInterceptors 设置即可： 自定义 ResponseErrorHandlerResponseErrorHandler 接口定义了当response发生错误时需要进行的操作。这里我们自定义一个CustomResponseErrorHandler，当返回的code不是200时，就表示执行出错了。 设置 ResponseErrorHandler： 执行结果： 处理流程下面来梳理下 RestTemplate 中请求处理的流程。下图中 XXXX 表示我们调用的 API 方法。大体流程就是：api 内部做一些请求相关的处理封装，然后交给 execute 方法执行，最后真正处理则是在 doExecute 方法中完成。 下面以 getForEntity 方法的执行过程来分析： getForEntity 方法： 基于给定响应类型，返回一个请求回调实现，准备请求。 基于给定响应类型，返回 ResponseEntity 的响应提取器。 execute 方法： 这个方法里面是对url进行urlencode编码处理的，统一转为URL。这里我们也可以手动把参数进行网络编码。 doExecute是请求真正处理的方法，这里来重点看下这个方法的执行过程： createRequest doWithRequest execute handleResponse 1、createRequest这个方法的作用就是创建一个 ClientHttpRequest 对象。RestTemplate集成了 HttpAccessor这个抽象类，创建ClientHttpRequest的过程就是在其父类HttpAccessor中通过默认的 ClientHttpRequestFactory 实现类 SimpleClientHttpRequestFactory 完成具体的请求创建。 1、创建 java.net.HttpURLConnection 对象 2、设置 connection，包括 connectTimeout、setDoInput 等。 3、bufferRequestBody 用于标志是否使用缓存流的形式，默认是 true。缺点是当发送大量数据时，比如 put/post，存在内存消耗严重。该值可以通过 SimpleClientHttpRequestFactory#setBufferRequestBody来修改。 不同版本的变更还是比较大的，大家在阅读源码时，还是从最新的代码来看。 2、doWithRequestRequestCallback 封装了请求体和请求头对象。这里会遍历所有的 HttpMessageConverter，解析成所有支持的MediaType，放在allSupportedMediaTypes中。 1request.getHeaders().setAccept(allSupportedMediaTypes); RestTemplate中对应了两个内部类的实现： AcceptHeaderRequestCallback.doWithRequest的处理。发送请求时，Http头部需要设置Accept字段，该字段表明了发送请求的这方接受的媒体类型（消息格式），也是响应端要返回的信息的媒体类型（消息格式）。根据postForEntity方法的第三个参数responseType，程序将选择适合的解析器XXXConverter，并依据该解析器找出所有支持的媒体类型。 HttpEntityRequestCallback.doWithRequest的处理。如果是POST请求并且消息体存在时，除了设置Accept字段，还可能需要设置Content-Type字段，该字段表明了所发送请求的媒体类型（消息格式），也是响应端接受的媒体类型（消息格式）。根据postForEntity方法的第二个参数request，程序将选择适合的解析器XXXConverter，将请求消息写入输出流。 3、execute这里会把请求头/体封装到connect，然后发送请求。跟踪 execute 方法执行，定位到SimpleBufferingClientHttpRequest#executeInternal方法： 这里是使用实例 SimpleBufferingClientHttpRequest 封装请求体和请求头。从代码中可以看到： delete 时通过前面设置的 DoOutput参数和是否可以设置输出流来判断是否需要发送请求体如果是 delete 请求，那么很明显 DoOutput = false，不会有封装请求体的过程，即不执行FileCopyUtils.copy(bufferedOutput, this.connection.getOutputStream())。 4、handleResponse最后就是 response 的解析了，从代码来看，主要还是 Error 的解析。这里的ErrorHandler我们前面也提到，可以通过实现 ResponseErrorHandler 来自定义 异常处理。 小结本篇先介绍了RestTemplate的API使用，挑了几个介绍了下，更多使用细节还是要针对不同的场景来决定。接着对拦截器，异步RestTemplate以及错误处理器做了简单的介绍并给出了案例。最后分析了下RestTemplate的执行流程，篇幅原因执行流程部分只是大概捋了捋，其中还是很多细节有时间再补充，这部分主要就是看底层是如何通信的，已经请求参数的传递等。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>web</tag>
        <tag>restful</tag>
        <tag>聊一聊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊 Spring 中的扩展机制(二) - NamespaceHandler]]></title>
    <url>%2F2018%2F11%2F10%2Fspringextentiontwo%2F</url>
    <content type="text"><![CDATA[前一篇 聊一聊 Spring 中的扩展机制（一） 中聊到了ApplicationListener、ApplicationContextAware、BeanFactoryAware三种机制。本篇将介绍 NamespaceHandler 的扩展使用。 相信很多小伙伴对于这几个类都不陌生，基本基于java实现的RPC框架都会使用，比如 Dubbo , SOFARpc 等。本文先从几个小demo入手，了解下基本的概念和编程流程，然后分析下 SOFARpc 中是如何使用的。 NamespaceHandlerNamespaceHandler 是 Spring 提供的 命名空间处理器。下面这张图中，除了乱入的本篇 demo 中涉及到的 BridgeNameSpaceHandler 之外，其他均为 Spring 自身提供的。因为这里我只引入了 bean 和 context 依赖，所以这也仅仅是一部分。图中我们常用的应该算是 AopNamespaceHandler。 我们使用基于xml的spring配置时，可能需要配置如&lt;aop:config /&gt;这样的标签，在配置这个标签之前，通常我们需要引入这个aop所在的命名空间： 1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd" /&gt; 关于AOP 可以了解下 聊一聊 AOP ：表现形式与基础概念，这里不过多解释，下面就按照 官方文档的流程 来写一个自定义xml，最终效果如下： 12345&lt;bridge:application id="bridgeTestApplication" name="bridgeTestApplication" version="1.0" organization="bridge.glmapper.com" owner="leishu@glmapper"/&gt; 1、定义 xsd 文件关于 xsd 文件的语法规则不在本篇范围之内，有兴趣的同学可以自行google。下面这个文件很简单，定义的element name 为application，对应于 bridge:application中的application。attribute就是上面效果展示中对应的几个属性名。 12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;xsd:schema xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:beans="http://www.springframework.org/schema/beans" xmlns:tool="http://www.springframework.org/schema/tool" xmlns="http://bridge.glmapper.com/schema/bridge" targetNamespace="http://bridge.glmapper.com/schema/bridge"&gt; &lt;xsd:import namespace="http://www.springframework.org/schema/beans"/&gt; &lt;xsd:complexType name="applicationType"&gt; &lt;xsd:attribute name="id" type="xsd:ID"/&gt; &lt;xsd:attribute name="name" type="xsd:string" use="required"/&gt; &lt;xsd:attribute name="version" type="xsd:string"/&gt; &lt;xsd:attribute name="owner" type="xsd:string"/&gt; &lt;xsd:attribute name="organization" type="xsd:string"/&gt; &lt;/xsd:complexType&gt; &lt;xsd:element name="application" type="applicationType"/&gt;&lt;/xsd:schema&gt; 2、编写 NamespaceHandler In addition to the schema, we need a NamespaceHandler that will parse all elements of this specific namespace Spring encounters while parsing configuration files. 用编写的这个 NamespaceHandler 来解析配置文件。 具体说来NamespaceHandler会根据schema和节点名找到某个BeanDefinitionParser，然后由BeanDefinitionParser完成具体的解析工作。 Spring提供了默认实现类NamespaceHandlerSupport和AbstractSingleBeanDefinitionParser，最简单的方式就是去继承这两个类。 这里通过继承 NamespaceHandlerSupport 这个抽象类来完成。 123456public class BridgeNamespaceHandler extends NamespaceHandlerSupport &#123; public void init() &#123; registerBeanDefinitionParser("application", new ApplicationBeanDefinitionParser()); &#125;&#125; 这里实际上只是注册了一个解析器，具体的 BeanDefinitionParser 才是将 XML元素映射到特定bean的。 3、编写 BeanDefinitionParser这里直接通过实现BeanDefinitionParser接口的方式定义我们的BeanDefinitionParser实现类。关于AbstractSingleBeanDefinitionParser 的使用在 SPFARpc 中会涉及到。 123456789101112131415161718192021222324252627public class ApplicationBeanDefinitionParser implements BeanDefinitionParser &#123; public BeanDefinition parse(Element element, ParserContext parserContext) &#123; //beanDefinition RootBeanDefinition beanDefinition = new RootBeanDefinition(); beanDefinition.setBeanClass(ApplicationConfig.class); beanDefinition.setLazyInit(false); //解析id String id = element.getAttribute("id"); beanDefinition.getPropertyValues().add("id", id); //解析name beanDefinition.getPropertyValues().add("name", element.getAttribute("name")); //解析version beanDefinition.getPropertyValues().add("version", element.getAttribute("version")); //owner beanDefinition.getPropertyValues().add("owner", element.getAttribute("owner")); //organization beanDefinition.getPropertyValues().add("organization", element.getAttribute("organization")); parserContext.getRegistry().registerBeanDefinition(id, beanDefinition); return beanDefinition; &#125;&#125; 这里我们需要了解的是开始解析自定义标签的时候，是通过BeanDefinitionParserDelegate-&gt;parseCustomElement方法来处理的，如下图所示： 通过ele元素拿到当前namespaceUri，也就是在xsd中定义的命名空间，接着委托给 DefaultNamespaceResolver 得到具体的handler（BridgenamspaceHandler） ,然后执行parse 解析。 4、配置 spring.handlers 和 spring.schmas1234http\://bridge.glmapper.com/schema/bridge=com.glmapper.extention.namespacehandler.BridgeNamespaceHandlerhttp\://bridge.glmapper.com/schema/bridge.xsd=META-INF/bridge.xsd 配置这个其实是为了让Spring在解析xml的时候能够感知到我们的自定义元素，我们需要把NamespaceHandler和xsd文件放到位于META-INF目录下的spring.handlers 和 spring.schmas文件中。这样就可以在spring配置文件中使用我们自定义的标签了。如下： 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:bridge="http://bridge.glmapper.com/schema/bridge" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://bridge.glmapper.com/schema/bridge http://bridge.glmapper.com/schema/bridge.xsd"&gt; &lt;bridge:application id="bridgeTestApplication" name="bridgeTestApplication" version="1.0" organization="bridge.glmapper.com" owner="leishu@glmapper"/&gt;&lt;/beans&gt; 验证下从容器中获取我们的bean： 123456789public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext("classpath:bean.xml"); ApplicationConfig applicationConfig = (ApplicationConfig) applicationContext.getBean("bridgeTestApplication"); System.out.println("applicationConfig = "+applicationConfig);&#125; 输出示例：1234567applicationConfig = ApplicationConfig &#123; id=bridgeTestApplication, name=&apos;bridgeTestApplication&apos;, version=&apos;1.0&apos;, owner=&apos;leishu@glmapper&apos;, organization=&apos;bridge.glmapper.com&apos;&#125; 整体来看，如果我们要实现自己的 xml 标签，仅需完成以下几步即可： 1、定义 xsd 文件 2、编写 NamespaceHandler 3、编写 BeanDefinitionParser 4、配置 spring.handlers 和 spring.schmas SOFARpc 中使用分析SOFARpc 中的 rpc.xsd 文件是集成在 sofaboot.xsd 文件中的，详细可见：sofa-boot xsd 文件这里不贴了，有点长 spring.handlers 和 spring.schmas先看下 spring.handlers 和 spring.schmas 配置： 12345678http\://sofastack.io/schema/sofaboot=com.alipay.sofa.infra.config.spring.namespace.handler.SofaBootNamespaceHandlerhttp\://sofastack.io/schema/sofaboot.xsd=META-INF/com/alipay/sofa/infra/config/spring/namespace/schema/sofaboot.xsdhttp\://sofastack.io/schema/rpc.xsd=META-INF/com/alipay/sofa/infra/config/spring/namespace/schema/rpc.xsd 从 spring.handlers找到 NamespaceHandler : SofaBootNamespaceHandler。 SofaBootNamespaceHandler源码如下，这里看出来，并不是像上面我们自己写的那种方式那样，会有一个 BeanDefinitionParser。这里其实设计的很巧妙，通过spi的方式来载入具体的BeanDefinitionParser。 12345678910111213141516171819202122public class SofaBootNamespaceHandler extends NamespaceHandlerSupport &#123; @Override public void init() &#123; ServiceLoader&lt;SofaBootTagNameSupport&gt; serviceLoaderSofaBoot = ServiceLoader.load(SofaBootTagNameSupport.class); //SOFABoot for (SofaBootTagNameSupport tagNameSupport : serviceLoaderSofaBoot) &#123; this.registerTagParser(tagNameSupport); &#125; &#125; private void registerTagParser(SofaBootTagNameSupport tagNameSupport) &#123; if (!(tagNameSupport instanceof BeanDefinitionParser)) &#123; // log return; &#125; String tagName = tagNameSupport.supportTagName(); registerBeanDefinitionParser(tagName, (BeanDefinitionParser) tagNameSupport); &#125;&#125; 这里可以看出有 ReferenceDefinitionParser 和 ServiceDefinitionParser 两个解析类，分别对应服务引用和服务暴露。 下面以ReferenceDefinitionParser为例，先看下它的类图： 解析工作都是在 AbstractContractDefinitionParser 类中完成， ReferenceDefinitionParser 自己只是做了一些特殊处理【jvm-first，jvm服务】。 小结本篇通过 NamespaceHandler 了解了如何去编写我们自定义的xml标签，从NamespaceHandler的角度可以很好的理解一些 RPC 框架中最基础的基于xml 方式的服务引用和暴露的实现思路。另外通过分析 SOFARpc ，也了解了在实际的工程组件中对于NamespaceHandler的扩展使用。 本文代码：glmapper-spring-extention]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>聊一聊</tag>
        <tag>spring 扩展机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聊一聊 Spring 中的扩展机制（一）]]></title>
    <url>%2F2018%2F11%2F10%2Fspringextentionone%2F</url>
    <content type="text"><![CDATA[之前 Spring 源码系列文章中大多是底层源码的分析，通过源码可以让我们能够清晰的了解 Spring 到底是什么，而不是停留于表面的认知。比如当我们要使用 @Autowired 注解时，可以拿到我们想要的 bean ,但是为什么可以是值得思考的。– 关于阅读源码 Spring源码的阅读结合日常的使用，可以帮助我们更好的掌握这个庞大的技术体系，实际的开发工作中有很多地方可以借鉴它的一些思想来帮助我们更好的实现自己的业务逻辑。本篇将以扩展点为切入点，来了解下在Spring生命周期中扩展Spring中的Bean功能。 ApplicationListener 扩展ApplicationListener 其实是 spring 事件通知机制中核心概念；在java的事件机制中，一般会有三个概念： event object : 事件对象 event source ：事件源，产生事件的地方 event listener ：监听事件并处理 ApplicationListener 继承自 java.util.EventListener ，提供了对于Spring中事件机制的扩展。 ApplicationListener 在实际的业务场景中使用的非常多，比如我一般喜欢在容器初始化完成之后来做一些资源载入或者一些组件的初始化。这里的容器指的就是Ioc容器，对应的事件是ContextRefreshedEvent 。 1234567891011@Componentpublic class StartApplicationListener implementsApplicationListener&lt;ContextRefreshedEvent&gt; &#123; @Override public void onApplicationEvent(ContextRefreshedEvent contextRefreshedEvent) &#123; //初始化资源文件 //初始化组件 如：cache &#125;&#125; 上面这段代码会在容器刷新完成之后来做一些事情。下面通过自定义事件来看看怎么使用，在看具体的demo之前，先来了解下一些关注点。 日常工作了，如果要使用 Spring 事件传播机制，我们需要关注的点有以下几点： 事件类，这个用来描述事件本身一些属性，一般继承ApplicationEvent 监听类，用来监听具体的事件并作出响应。需要实现 ApplicationListener 接口 事件发布类，需要通过这个类将时间发布出去，这样才能被监听者监听到，需要实现ApplicationContextAware接口。 将事件类和监听类交给Spring容器。 那么下面就按照这个思路来看下demo的具体实现。 事件类：UserRegisterEventUserRegisterEvent ，用户注册事件；这里作为事件对象，继承自 ApplicationEvent。 12345678910111213141516171819/** * @description: 用户注册事件 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class UserRegisterEvent extends ApplicationEvent &#123; public String name; public UserRegisterEvent(Object o) &#123; super(o); &#125; public UserRegisterEvent(Object o, String name) &#123; super(o); this.name=name; &#125;&#125; 事件发布类：UserService用户注册服务，这里需要在用户注册时将注册事件发布出去，所以通过实现ApplicationEventPublisherAware接口，使UserService具有事件发布能力。 ApplicationEventPublisherAware:发布事件，也就是把某个事件告诉的所有与这个事件相关的监听器。 123456789101112131415161718192021/** * @description: 用户注册服务，实现ApplicationEventPublisherAware接口 ，表明本身具有事件发布能力 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class UserService implements ApplicationEventPublisherAware &#123; private ApplicationEventPublisher applicationEventPublisher; public void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) &#123; this.applicationEventPublisher = applicationEventPublisher; &#125; public void register(String name) &#123; System.out.println("用户：" + name + " 已注册！"); applicationEventPublisher.publishEvent(new UserRegisterEvent(name)); &#125;&#125; 这里的UserService实际上是作为事件源存在的，通过register将用户注册事件传播出去。那么下面就是需要定义如何来监听这个事件，并且将事件进行消费处理掉，这里就是通过ApplicationListener来完成。 监听类：BonusServerListener当用户触发注册操作时，向积分服务发送消息，为用户初始化积分。 1234567891011121314/** * @description: BonusServerListener 积分处理，当用户注册时，给当前用户增加初始化积分 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class BonusServerListener implementsApplicationListener&lt;UserRegisterEvent&gt; &#123; public void onApplicationEvent(UserRegisterEvent event) &#123; System.out.println("积分服务接到通知，给 " + event.getSource() + " 增加积分..."); &#125;&#125; 注册到容器中123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;bean id="userService" class="com.glmapper.extention.UserService"/&gt; &lt;bean id="bonusServerListener" class="com.glmapper.extention.BonusServerListener"/&gt; &lt;/beans&gt; 客户端类12345678910111213141516/** * @description: 客户端类 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class MainTest &#123; public static void main(String[] args) &#123; ApplicationContext context =new ClassPathXmlApplicationContext("beans.xml"); UserService userService = (UserService) context.getBean("userService"); //注册事件触发 userService.register("glmapper"); &#125;&#125; 客户端类中，注册一个name为glmapper的用户，执行结果： 12用户：glmapper 已注册！积分服务接到通知，给 glmapper 增加积分... 现在来考虑另外一个问题，增加一个功能，用户注册之后给用户发一个邮件。这个其实就是增加一个监听类就可以，前提是这个监听者是监听当前事件的。 123456789101112/** * @description: 邮件服务监听器，当监听到用户的注册行为时， 给用户发送邮件通知 * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class EmailServerListener implementsApplicationListener&lt;UserRegisterEvent&gt; &#123; public void onApplicationEvent(UserRegisterEvent event) &#123; System.out.println("邮件服务接到通知，给 " + event.getSource() + " 发送邮件..."); 这里如果将UserRegisterEvent换成UserLoginEvent，那么邮件服务将不会有任何行为。 增加发送邮件监听类之后的执行结果：123用户：glmapper 已注册！邮件服务接到通知，给 glmapper 发送邮件...积分服务接到通知，给 glmapper 增加积分... Spring 的事件传播机制是基于观察者模式（Observer）实现的，它可以将 Spring Bean的改变定义为事件 ApplicationEvent，通过 ApplicationListener 监听 ApplicationEvent 事件，一旦Spring Bean 使用 ApplicationContext.publishEvent( ApplicationEvent event )发布事件后，Spring 容器会通知注册在 容器中所有 ApplicationListener 接口的实现类，最后 ApplicationListener 接口实现类判断是否处理刚发布出来的 ApplicationEvent 事件。 ApplicationContextAware 扩展ApplicationContextAware中只有一个setApplicationContext方法。实现了ApplicationContextAware接口的类，可以在该Bean被加载的过程中获取Spring的应用上下文ApplicationContext，通过ApplicationContext可以获取Spring容器内的很多信息。 这种一般在需要手动获取Bean的注入实例对象时会使用到。下面通过一个简单的demo来了解下。 GlmapperApplicationContext 持有ApplicationContext对象，通过实现 ApplicationContextAware接口来给ApplicationContext做赋值。12345678910111213141516171819/** * @description: GlmapperApplicationContext * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/29 */public class GlmapperApplicationContext implementsApplicationContextAware &#123; private ApplicationContext applicationContext; public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext=applicationContext; &#125; public ApplicationContext getApplicationContext()&#123; return applicationContext; &#125;&#125; 需要手动获取的bean: 1234567891011/** * @description: HelloService * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/29 */public class HelloService &#123; public void sayHello()&#123; System.out.println("Hello Glmapper"); &#125;&#125; 在配置文件中进行配置： 12345&lt;bean id="helloService"class="com.glmapper.extention.applicationcontextaware.HelloService"/&gt;&lt;bean id="glmapperApplicationContext"class="com.glmapper.extention.applicationcontextaware.GlmapperApplicationContext"/&gt; 客户端类调用： 12345678910111213141516171819202122public class MainTest &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); HelloService helloService = (HelloService) context.getBean("helloService"); helloService.sayHello(); //这里通过实现ApplicationContextAware接口的类来完成bean的获取 GlmapperApplicationContext glmapperApplicationContext = (GlmapperApplicationContext) context.getBean("glmapperApplicationContext"); ApplicationContext applicationContext = glmapperApplicationContext.getApplicationContext(); HelloService glmapperHelloService = (HelloService) applicationContext.getBean("helloService"); glmapperHelloService.sayHello(); &#125;&#125; BeanFactoryAware 扩展我们知道BeanFactory是整个Ioc容器最顶层的接口，它规定了容器的基本行为。实现BeanFactoryAware接口就表明当前类具体BeanFactory的能力。 BeanFactoryAware接口中只有一个setBeanFactory方法。实现了BeanFactoryAware接口的类，可以在该Bean被加载的过程中获取加载该Bean的BeanFactory，同时也可以获取这个BeanFactory中加载的其它Bean。 来想一个问题，我们为什么需要通过BeanFactory的getBean来获取Bean呢？Spring已经提供了很多便捷的注入方式，那么通过BeanFactory的getBean来获取Bean有什么好处呢？来看一个场景。 现在有一个HelloService，这个HelloService就是打招呼，我们需要通过不同的语言来实现打招呼，比如用中文，用英文。一般的做法是： 1234567891011121314151617public interface HelloService &#123; void sayHello();&#125;//英文打招呼实现public class GlmapperHelloServiceImpl implements HelloService &#123; public void sayHello() &#123; System.out.println("Hello Glmapper"); &#125;&#125;//中文打招呼实现public class LeishuHelloServiceImpl implements HelloService &#123; public void sayHello() &#123; System.out.println("你好，磊叔"); &#125;&#125; 客户端类来调用务必会出现下面的方式： 123456if (condition==&quot;英文&quot;)&#123; glmapperHelloService.sayHello();&#125;if (condition==&quot;中文&quot;)&#123; leishuHelloService.sayHello();&#125; 如果有一天，老板说我们要做国际化，要实现全球所有的语言来问候。你是说好的，还是控制不住要动手呢？ 那么有没有什么方式可以动态的去决定我的客户端类到底去调用哪一种语言实现，而不是用过if-else方式来罗列呢？是的，对于这些需要动态的去获取对象的场景，BeanFactoryAware就可以很好的搞定。OK，来看代码改造： 引入BeanFactoryAware： 123456789101112131415161718192021222324252627282930/** * @description: 实现BeanFactoryAware ，让当前bean本身具有 BeanFactory 的能力 * * 实现 BeanFactoηAware 接口的 bean 可以直接访问 Spring 容器，被容器创建以后， * 它会拥有一个指向 Spring 容器的引用，可以利用该bean根据传入参数动态获取被spring工厂加载的bean * * @email: &lt;a href="glmapper_2018@163.com"&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/29 */public class GlmapperBeanFactory implements BeanFactoryAware &#123; private BeanFactory beanFactory; public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; this.beanFactory=beanFactory; &#125; /** * 提供一个execute 方法来实现不同业务实现类的调度器方案。 * @param beanName */ public void execute(String beanName)&#123; HelloService helloService=(HelloService) beanFactory.getBean(beanName); helloService.sayHello(); &#125;&#125; 这里为了逻辑方便理解，再加入一个HelloFacade 类,这个类的作用就是持有一个BeanFactoryAware的实例对象，然后通过HelloFacade实例对象的方法来屏蔽底层BeanFactoryAware实例的实现细节。 12345678910public class HelloFacade &#123; private GlmapperBeanFactory glmapperBeanFactory; //调用glmapperBeanFactory的execute方法 public void sayHello(String beanName)&#123; glmapperBeanFactory.execute(beanName); &#125; public void setGlmapperBeanFactory(GlmapperBeanFactory beanFactory)&#123; this.glmapperBeanFactory = beanFactory; &#125;&#125; 客户端类 1234567891011121314151617181920212223public class MainTest &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext("beans.xml"); HelloFacade helloFacade = (HelloFacade) context.getBean("helloFacade"); GlmapperBeanFactory glmapperBeanFactory = (GlmapperBeanFactory) context.getBean("glmapperBeanFactory"); //这里其实可以不通过set方法注入到helloFacade中， //可以在helloFacade中通过autowired //注入；这里在使用main方法来执行验证，所以就手动set进入了 helloFacade.setGlmapperBeanFactory(glmapperBeanFactory); //这个只需要传入不同HelloService的实现类的beanName， //就可以执行不同的业务逻辑 helloFacade.sayHello("glmapperHelloService"); helloFacade.sayHello("leishuHelloService"); &#125;&#125; 可以看到在调用者（客户端）类中，只需要通过一个beanName就可以实现不同实现类的切换，而不是通过一堆if-else来判断。另外有的小伙伴可能会说，程序怎么知道用哪个beanName呢？其实这个也很简单，这个参数我们可以通过一些途径来拼接得到，比如使用一个prefix用来指定语言，prefix+HelloService就可以确定唯一的beanName。 小结本来想着在一篇文章里面把扩展点都写一下的，但是实在太长了。后面差不多还有两篇。本系列中所有的demo可以在github获取，也欢迎小伙伴把能够想到的扩展点pr过来。 glmapper-spring-extention]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>聊一聊</tag>
        <tag>spring 事件机制</tag>
        <tag>spring 扩展机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[：SpringBoot 集成 SpringSession]]></title>
    <url>%2F2018%2F11%2F10%2Fspringsessionone%2F</url>
    <content type="text"><![CDATA[springSession是 spring 旗下的一个项目，把 servlet 容器实现的 httpSession替换为springSession，专注于解决session管理问题。可简单快速且无缝的集成到我们的应用中。本文通过一个案例，使用SpringBoot来集成 SpringSession，并且使用Redis作为存储来实践下SpringSession 的使用。 环境准备因为需要使用Redis作为底层Session的存储介质，实现分布式session，因此需要安装Redis。 Redis 安装1、从官网下载最新版的Redis 2、解压 1tar zxvf redis-5.0.0.tar.gz 3、编译测试 1sudo make test 4、编译安装 1sudo make install 5、安装问题 如果您之前安装过，重复安装且没有卸载干净的话，会报下面的错 12make[1]: *** [test] Error 1 make: *** [test] Error 2 解决这个错误，执行下面的语句即可： 123make distclean make make test 正确安装姿势如下： 6、启动Redis在您的Redis安装目录下，有 redis-server ，执行该脚本命令： OK，到这里，Redis的安装工作完毕。 SpringBoot 工程准备这里我们直接通过Idea来构建我们的SpringBoot工程。 1File-&gt;New-&gt;Project : Spring Initializr OK，SpringBoot 工程准备完毕，这里选择创建的是一个Web工程。 集成集成主要是依赖引入，这里需要redis和session的依赖 依赖引入123456789101112&lt;dependencies&gt; &lt;!--redis 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--sessions 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置application.properties123456789#服务端口server.port=8080#redi主机地址spring.redis.host=localhost#redis服务端口spring.redis.port=6379# spring session使用存储类型，spirngboot默认就是使用redis方式，如果不想用可以填none。spring.session.store-type=redis 在启动类中加入@EnableRedisHttpSession 注解1234567@SpringBootApplication@EnableRedisHttpSessionpublic class SpringBootSessionApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootSessionApplication.class, args); &#125;&#125; 测试先来编写一个Controller 123456789101112131415161718192021222324252627/** * SessionController * * @author: glmapper@leishu * @since: 18/11/3 下午3:16 * @version 1.0 **/@Controller@RequestMapping(value = "/")public class SessionController &#123; @ResponseBody @RequestMapping(value = "/session") public Map&lt;String, Object&gt; getSession(HttpServletRequest request) &#123; request.getSession().setAttribute("userName", "glmapper"); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("sessionId", request.getSession().getId()); return map; &#125; @ResponseBody @RequestMapping(value = "/get") public String get(HttpServletRequest request) &#123; String userName = (String) request.getSession().getAttribute("userName"); return userName; &#125;&#125; 测试结果启动SpringBoot 工程；然后浏览器中输入地址 http://localhost:8080/session； 这里对应执行的是我们上面Controller中的第一个方法getSession，这个方法向session中设置了一个值。 下面我们执行：http://localhost:8080/get 这里是从session中取值: 到此，SpringBoot 整合 SpringSession 的过程就完成了。这里我们只是引入了依赖，然后做了简单的配置，那么我们的请求是如何被 SpringSession 处理的呢？从我们一贯的认知来看，对于基于Servlet规范的容器（SpringBoot 使用的是嵌入式Tomcat）的应用，请求最先被处理的是Filter。我们在基于Spring+SpringMvc这套技术栈开发时,如果我们需要做权限管理，通过会基于Filter或者拦截器。但是这里貌似我们什么也没做，但是请求确实被SpringSession处理了。OK，我们来扒一扒。 SpringSession 是如何处理请求的？上面这张截图想必大家都不陌生，是SpringBoot的启动日志；上图红色框内的是当前应用注册是Filter信息，从这里可以看到有个和 session 有关的Filter：sessionRepositoryFilter；这个bean对应的类是： 12org.springframework.boot.autoconfigure.session.SessionRepositoryFilterConfiguration.ConditionalOnBean=org.springframework.session.web.http.SessionRepositoryFilter 在这里找到了 这里涉及到SpringBoot的自动配置，从spring-boot-autoconfig包下加载spring-autoconfigure-metadata.properties 配置文件，然后获取所有支持自动配置的信息；SpringSession 也在其中。关于如何加载并且注册不在本文的范畴之内，我们继续来分析SpringSession的处理过程。 SpringSession 的处理过程从上面SpringBoot的启动过程我们找到了处理session的Filter，然后知道了它是通过自动配置的方式被注册到当前的容器并且来处理请求。123@Order(SessionRepositoryFilter.DEFAULT_ORDER)public class SessionRepositoryFilter&lt;S extends Session&gt; extends OncePerRequestFilter &#123; 从SessionRepositoryFilter的定义来看： 1、使用了Order，并且配置了一个很小的值（Integer.MIN_VALUE + 50），以此来确保session的Filter在Filter链中被优先执行。 2、集成了OncePerRequestFilter，确保在一次请求只通过一次filter，而不需要重复执行 为什么 session 的 Filter 要被优先执行呢？因为我们的请求被包装了，如果SessionRepositoryFilter不优先处理请求，可能会导致后续的请求行为不一致，这里涉及到 springSession无缝替换应用服务器的request的原理： 1.自定义个Filter，实现doFilter方法 2.继承 HttpServletRequestWrapper 、HttpServletResponseWrapper 类，重写getSession等相关方法(在这些方法里调用相关的 session存储容器操作类)。 3.自定义request和response类；并把它们分别传递到过滤器链 4.把该filter配置到过滤器链的第一个位置上 OK，了解了这些背景，我们来跟踪下整个处理流程。 1、断点到 doFilterInternal 从这里可以看到request和response类被包装了。 2、断点到 getSession这里是从Redis中拿我们session数据的地方 先从我们当前servlet容器中去拿，如果拿到则直接返回 去Redis中取 这里会有一个缓存处理，并非是每次都到Reids中去查一次，避免一次与Reids的交互。 如果缓存当前应用容器缓存中有，则直接返回当前被缓存的session 如果没有，则从请求中获取sessionId，并且根据当前sessionId去Reids中查找session数据 更新缓存session，sessionId,requestedSessionCached等数据状态 如果Redis中有，则更新session相关信息并返回 如果Reids中没有找到，则根据 create 来判断是否创建新的session。 断点到 readCookieValuesSpringSession提供了两种保存和传递SessionId的方式，一种是基于Cookie的，一种是基于Header的。SpringSession中默认使用的是基于Cookie的方式。readCookieValues 就是实现如何从Cookie中获取sessionId的。 这个过程其实很简单，先是从request中获取当前请求携带的所以的Cookie信息，然后将匹配到的 cookieName 为 “SESSION” 的Cookie进行解析。 断点到 RedisOperationsSessionRepository -&gt; getSession这里是从Redis中取session数据的地方 根据sessionId从 Redis中取到 entries 数据 构建 RedisSession 并返回 断点到 commitSessioncommitSession作用是通过HttpSessionIdResolver 将sessionId写到response，并且进行持久化。 这里的 session 其实是已经更新过状态的，比如重新设置了 session 的过期时间等。session 提交实际上就意味着当前请求已经处理完毕了。 小结本文先介绍了如何使用 SpringBoot 集成 SpringSession，并且以 Redis 作为存储。然后简单分析了 SpringSession 的处理过程，本文对 SpringSession 的原理部分没有进行深入分析，下一篇分析下SpringSession的原理。]]></content>
      <categories>
        <category>spring</category>
        <category>session</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>session</tag>
      </tags>
  </entry>
</search>
