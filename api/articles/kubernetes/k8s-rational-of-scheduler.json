{"title":"k8s-rational-of-scheduler","uid":"278b3ce51ecfe81c1855a9665e3a6c3d","slug":"kubernetes/k8s-rational-of-scheduler","date":"2025-02-15T06:47:46.000Z","updated":"2025-02-15T06:51:23.414Z","comments":true,"path":"api/articles/kubernetes/k8s-rational-of-scheduler.json","keywords":"宋国磊, glmapper, 卫恒, 分享, 开源","cover":[],"content":"<p>k8s scheduler 的主要职责是为新创建的 pod 寻找一个最合适的 node 节点, 然后进行 bind node 绑定, 后面 kubelet 才会监听到并创建真正的 pod。</p>\n<span id=\"more\"></span>\n<h1 id=\"整体介绍\"><a href=\"#整体介绍\" class=\"headerlink\" title=\"整体介绍\"></a>整体介绍</h1><ul>\n<li>Kubernetes 资源调度是指将 Pod 放置到合适的节点上，以便节点上的 Kubelet 能够运行这些 Pod。</li>\n<li>调度器通过 Kubernetes 的监测机制来发现集群中新创建且尚未被调度到节点上的 Pod。</li>\n<li>kube-scheduler 是 Kubernetes 集群的默认调度器，负责选择最佳节点来运行新创建的或尚未调度的 Pod。</li>\n<li>调度器在做调度决定时需要考虑的因素包括：资源请求、硬件&#x2F;软件&#x2F;策略限制、亲和性和反亲和性要求、数据局部性、负载间的干扰等。</li>\n<li>调度流程包括两个主要步骤：过滤（预选）和打分（优选）。过滤阶段会将所有满足 Pod 调度需求的节点选出来，打分阶段则会为这些节点进行打分并选择得分最高的节点。</li>\n<li>调度框架（scheduler framework）是面向 Kubernetes 调度器的一种插件架构，允许大多数调度功能以插件的形式实现，同时使调度核心保持简单且可维护。</li>\n</ul>\n<p><font style=\"color:rgb(34, 34, 34);\">一个完整且可运行的 Kubernetes 集群所需的各种组件如下图所示</font></p>\n<p><img src=\"https://vspicgo.oss-cn-shanghai.aliyuncs.com/typora/1733907341689-2a220732-1783-4780-8203-a270abe1f0c4.png\"></p>\n<h1 id=\"POD-的创建流程\"><a href=\"#POD-的创建流程\" class=\"headerlink\" title=\"POD 的创建流程\"></a>POD 的创建流程</h1><p><font style=\"color:rgb(0, 0, 0);\">pod  创建流程涉及上上述集群各组件之间的协作，大致的时序图如下图所示</font></p>\n<p><img src=\"https://vspicgo.oss-cn-shanghai.aliyuncs.com/typora/1733907477851-b235df71-1a7f-4638-8ace-0fde78956fc6.png\"></p>\n<p><strong>流程说明：</strong></p>\n<ol>\n<li><font style=\"color:rgb(1, 1, 1);\">用户向 Kubernetes API server 发送创建（create&#x2F;apply）指令。</font></li>\n<li><font style=\"color:rgb(1, 1, 1);\">Apiserver 接收到配置文件，进行校验后，将配置数据存储到 etcd 中。</font></li>\n<li><font style=\"color:rgb(1, 1, 1);\">Controller-manager 监听 Apiserver 的变化，检测到有新的 Pod 对象时，控制器创建 Pod 并将其状态设为 Pending。</font></li>\n<li><strong><font style=\"color:rgb(0, 0, 0);\">Scheduler 也通过监听 Apiserver 的变化，发现有新的、尚未分配节点的 Pod。根据预选策略和优选策略，选择一个最适合的 Node 来运行新的 Pod。</font></strong></li>\n<li><font style=\"color:rgb(1, 1, 1);\">Pod 被调度到对应的 Node 后，该 Node 上的 kubelet 组件则开始根据 Pod 配置文件，拉镜像、启动 app、就绪探针探测。</font></li>\n<li><font style=\"color:rgb(1, 1, 1);\">Kubelet 向 Apiserver  上报状态为 Reday， Apiserver 写入到 etcd 中。</font></li>\n</ol>\n<h1 id=\"Kube-Scheduler-调度流程\"><a href=\"#Kube-Scheduler-调度流程\" class=\"headerlink\" title=\"Kube Scheduler 调度流程\"></a>Kube Scheduler 调度流程</h1><p><img src=\"https://vspicgo.oss-cn-shanghai.aliyuncs.com/typora/1733887284841-bee19c5f-38c7-47bf-af3f-79dd25cf51b0.jpeg\" alt=\"画板\"></p>\n<p>上图中，scheduleOne 下面对应的框中，调度器主要经过 3 个步骤来寻找合适的 node：</p>\n<ul>\n<li>predicates(预选)：<font style=\"color:rgb(31, 35, 40);\">从集群的所有节点中根据调度算法筛选出所有可以运行该 pod 的节点集合</font></li>\n<li>priorites(优选)：<font style=\"color:rgb(31, 35, 40);\">按照算法对预选出来的节点进行打分，找到分值最高的节点作为调度节点</font></li>\n<li>bind(绑定)：将 pod 的 spec.NodeName 赋值为最优节点</li>\n</ul>\n<p><strong>流程说明：</strong></p>\n<ul>\n<li><font style=\"color:rgb(31, 35, 40);\">1、默认调度器根据给定的参数启动。</font></li>\n<li><font style=\"color:rgb(31, 35, 40);\">2、监听 API Server，将 </font><code>spec.nodeName</code><font style=\"color:rgb(31, 35, 40);\"> 为空的 Pod 放入其内部的调度队列中。从调度队列中取出一个 Pod，并开始标准的调度流程。</font></li>\n<li><font style=\"color:rgb(31, 35, 40);\">3、调度器从 Pod 的 API 规范中获取“硬性要求”（例如 CPU&#x2F;内存请求、nodeSelector&#x2F;nodeAffinity 等）。然后进入预选阶段（Predicates Phase），在此阶段计算出满足这些要求的节点候选列表。</font></li>\n<li><font style=\"color:rgb(31, 35, 40);\">4、从 Pod 的 API 规范中获取“软性要求”，并应用一些默认的软性“策略”（例如 Pod 更倾向于密集部署或在节点间分散部署）。</font></li>\n<li>5、最后调度器会为每个候选节点打分，并选择得分最高的节点作为最终的“赢家”；然后通过向 API Server 发送绑定（bind）请求，将 Pod 绑定到选定的节点上。</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>上述设计在批调度器上就不是一定的，批调度器因为要支持gang scheduler，即比如一个 job 包含 5 个 pod，至少 3 个 pod 启动才可以正常工作，此时就不能一个 pod 一个pod 判断，批调度器会采用 session 的方式，一个 session 对当前的 pod node 状态 的”定格“，一次性为当前 session内所有未调度的 pod 确定 node。开源社区的 volcano 就是批调度的实现方案之一)</p></blockquote>\n<h2 id=\"三个队列\"><a href=\"#三个队列\" class=\"headerlink\" title=\"三个队列\"></a>三个队列</h2><p><img src=\"https://vspicgo.oss-cn-shanghai.aliyuncs.com/typora/1733887814166-daf038a5-fef9-4f9f-8f53-a078053eb2bf.png\"></p>\n<h3 id=\"1-Active-队列\"><a href=\"#1-Active-队列\" class=\"headerlink\" title=\"1. Active 队列\"></a>1. Active 队列</h3><p>存放等待被调度的 Pod。内部实现是一个 <code>Heap</code> 堆结构，按照优先级从高到低排序，堆顶的 Pod 优先级最高，新创建的 Pod (.spec.nodeName 属性为空) 都会加入到这个队列中。在每个调度周期中，调度器会从该队列中取出 Pod 并进行调度，如果调度失败了 (例如因为资源不足)，Pod 就会被加入到 UnSchedulable 队列中。 如果 Pod 被成功调度，其会从队列中被删除。</p>\n<h3 id=\"2-UnSchedulable-队列\"><a href=\"#2-UnSchedulable-队列\" class=\"headerlink\" title=\"2. UnSchedulable 队列\"></a>2. UnSchedulable 队列</h3><p>存放无法被调度的 Pod。</p>\n<h3 id=\"3-Backoff-队列\"><a href=\"#3-Backoff-队列\" class=\"headerlink\" title=\"3. Backoff 队列\"></a>3. Backoff 队列</h3><p>存放等待重试的 Pod，之所以单独设置一个队列，是为了避免处于等待状态的 Pod 不断重试，给调度器带来不必要的负载。内部实现是一个 <code>Heap</code> 堆结构，按照重试等待时间从低到高排序，堆顶的 Pod 等待时间最少。单个 Pod 的的重试次数越多，该 Pod 重新进入 Active 队列所需要的时间就越长 (几乎所有重试机制都是这么设计的)。</p>\n<p>重试算法采用的是 指数退避机制，默认情况下最小为 1 秒，最大为 10 秒，例如，重试 3 次的 Pod 下一次的重试等待时间为 2^3 &#x3D; 8 秒。 为了避免 Pod 经常调度失败而频繁进入等待队列，应该配置合理的退避时间基数，降低系统负载。</p>\n<p>此外，调度队列机制有两个在后台运行的 goroutine, 负责定期刷新 将 Pod 加入到 Active 队列，当某些事件 (例如节点添加或更新、现有 Pod 被删除等) 触发时， 调度程序会将 UnSchedulable 队列或 Backoff 队列中的 Pod 移动到 Active 队列，做好重新调度前的准备工作。</p>\n<h2 id=\"调度策略\"><a href=\"#调度策略\" class=\"headerlink\" title=\"调度策略\"></a>调度策略</h2><p><font style=\"color:rgb(34, 34, 34);\">在 Kubernetes v1.23 版本之前，可以使用调度策略来指定 </font><strong><font style=\"color:rgb(34, 34, 34);\">predicates</font></strong><font style=\"color:rgb(34, 34, 34);\"> 和 </font><strong><font style=\"color:rgb(34, 34, 34);\">priorities</font></strong><font style=\"color:rgb(34, 34, 34);\"> 进程。 例如，可以通过运行 </font><code>kube-scheduler --policy-config-file &lt;filename&gt;</code><font style=\"color:rgb(34, 34, 34);\"> 或者 </font><code>kube-scheduler --policy-configmap &lt;ConfigMap&gt;</code><font style=\"color:rgb(34, 34, 34);\"> 设置调度策略。</font></p>\n<p><font style=\"color:rgb(34, 34, 34);\"></font></p>\n<p><font style=\"color:rgb(34, 34, 34);\">但是从 Kubernetes v1.23 版本开始，不再支持这种调度策略。 同样地也不支持相关的 </font><code>policy-config-file</code><font style=\"color:rgb(34, 34, 34);\">、</font><code>policy-configmap</code><font style=\"color:rgb(34, 34, 34);\">、</font><code>policy-configmap-namespace</code><font style=\"color:rgb(34, 34, 34);\"> 和 </font><code>use-legacy-policy-config</code><font style=\"color:rgb(34, 34, 34);\"> 标志。 你可以通过使用调度配置来实现类似的行为。</font></p>\n<h3 id=\"默认的-Predicates-和-Priorities\"><a href=\"#默认的-Predicates-和-Priorities\" class=\"headerlink\" title=\"默认的  Predicates 和 Priorities\"></a>默认的  Predicates 和 Priorities</h3><figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Used as the default set of predicates if Policy was specified, but predicates was nil.</span></span><br><span class=\"line\">DefaultPredicates: sets.NewString(</span><br><span class=\"line\">    <span class=\"comment\">// 检查给定的 Zone 限制前提下，如果在此主机中部署 Pod 是否存在卷冲突。</span></span><br><span class=\"line\">    NoVolumeZoneConflictPred, </span><br><span class=\"line\">    <span class=\"comment\">// （过时）确保已挂载的 EBS 存储卷不超过设置的最大值。</span></span><br><span class=\"line\">    MaxEBSVolumeCountPred,</span><br><span class=\"line\">    <span class=\"comment\">// （过时）确保已挂载的 GCE 存储卷不超过设置的最大值。</span></span><br><span class=\"line\">    MaxGCEPDVolumeCountPred,</span><br><span class=\"line\">    <span class=\"comment\">// （过时）确保已挂载的 Azure 存储卷不超过设置的最大值。</span></span><br><span class=\"line\">    MaxAzureDiskVolumeCountPred,</span><br><span class=\"line\">    <span class=\"comment\">// 检查 Node 的 Volume 数量是否超过最大值</span></span><br><span class=\"line\">    MaxCSIVolumeCountPred,</span><br><span class=\"line\">    <span class=\"comment\">// 检查 Pod 和其他 Pod 是否符合亲和性规则。</span></span><br><span class=\"line\">    MatchInterPodAffinityPred,</span><br><span class=\"line\">    <span class=\"comment\">// 检查挂载的卷和已经存在的卷是否有冲突。</span></span><br><span class=\"line\">    NoDiskConflictPred,</span><br><span class=\"line\">    <span class=\"comment\">// 检查资源是否充足，包含 HostName 检查、PodFitsHostPorts 主机端口是否被占用、</span></span><br><span class=\"line\">    <span class=\"comment\">// MatchNodeSelector 节点、PodFitsResources Pod 依赖的资源配额是否满足。</span></span><br><span class=\"line\">    GeneralPred,</span><br><span class=\"line\">    <span class=\"comment\">// 确保 Pod 定义的 tolerates 能接纳 Node 定义的 taints。</span></span><br><span class=\"line\">    PodToleratesNodeTaintsPred,</span><br><span class=\"line\">    <span class=\"comment\">// 检查该 Node 的 PV 是否满足 PVC。</span></span><br><span class=\"line\">    CheckVolumeBindingPred,</span><br><span class=\"line\">    <span class=\"comment\">// Node 是否可调度。</span></span><br><span class=\"line\">    CheckNodeUnschedulablePred,</span><br><span class=\"line\">    <span class=\"comment\">// Node 是否满足拓扑传播限制。</span></span><br><span class=\"line\">    EvenPodsSpreadPred,</span><br><span class=\"line\">),</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Used as the default set of predicates if Policy was specified, but priorities was nil.</span></span><br><span class=\"line\">DefaultPriorities: <span class=\"keyword\">map</span>[<span class=\"type\">string</span>]<span class=\"type\">int64</span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 按 Service 和 Replicaset 归属计算 Node 上分布最少的同类 Pod 数量，得分计算：数量越少得分越高</span></span><br><span class=\"line\">    SelectorSpreadPriority:      <span class=\"number\">1</span>,</span><br><span class=\"line\">    <span class=\"comment\">// Pod 亲和性选择策略，类似 NodeAffinityPriority，</span></span><br><span class=\"line\">    InterPodAffinityPriority:    <span class=\"number\">1</span>,</span><br><span class=\"line\">    <span class=\"comment\">// 计算 Pods 需要的 CPU 和内存在当前节点可用资源的百分比，具有最小百分比的节点就是最优</span></span><br><span class=\"line\">    <span class=\"comment\">// 得分计算公式：cpu((capacity – sum(requested)) * 10 / capacity) + memory((capacity – sum(requested)) * 10 / capacity) / 2</span></span><br><span class=\"line\">    LeastRequestedPriority:      <span class=\"number\">1</span>,</span><br><span class=\"line\">    <span class=\"comment\">// 节点上各项资源（CPU、内存）使用率最均衡的为最优</span></span><br><span class=\"line\">    <span class=\"comment\">// 得分计算公式：10 – abs(totalCpu/cpuNodeCapacity-totalMemory/memoryNodeCapacity)*10</span></span><br><span class=\"line\">    BalancedResourceAllocation:  <span class=\"number\">1</span>,</span><br><span class=\"line\">    <span class=\"comment\">//  根据 Node 的 annotation: scheduler.alpha.kubernetes.io/preferAvoidPods 进行调度</span></span><br><span class=\"line\">    NodePreferAvoidPodsPriority: <span class=\"number\">10000</span>,</span><br><span class=\"line\">    <span class=\"comment\">// 节点亲和性选择策略，提供两种选择器支持：</span></span><br><span class=\"line\">    <span class=\"comment\">// 1、requiredDuringSchedulingIgnoredDuringExecution（保证所选的主机必须满足所有Pod对主机的规则要求）</span></span><br><span class=\"line\">    <span class=\"comment\">// 2、preferresDuringSchedulingIgnoredDuringExecution（调度器会尽量但不保证满足 NodeSelector 的所有要求）</span></span><br><span class=\"line\">    NodeAffinityPriority:        <span class=\"number\">1</span>,</span><br><span class=\"line\">    <span class=\"comment\">//  类似于 Predicates 策略中的 PodToleratesNodeTaints，优先调度到标记了 Taint 的节点。</span></span><br><span class=\"line\">    TaintTolerationPriority:     <span class=\"number\">1</span>,</span><br><span class=\"line\">    <span class=\"comment\">// 根据主机上是否已具备 Pod 运行的环境来打分，得分计算：不存在所需镜像，返回0分，存在镜像，镜像越大得分越高。</span></span><br><span class=\"line\">    ImageLocalityPriority:       <span class=\"number\">1</span>,</span><br><span class=\"line\">    <span class=\"comment\">//  满足拓扑传递限制的 Pod 的个数计算得分</span></span><br><span class=\"line\">    EvenPodsSpreadPriority:      <span class=\"number\">2</span>,</span><br><span class=\"line\">&#125;,</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"通过调度器配置选择\"><a href=\"#通过调度器配置选择\" class=\"headerlink\" title=\"通过调度器配置选择\"></a>通过调度器配置选择</h3><p>通过调度配置文件，你可以配置 kube-scheduler 在不同阶段的调度行为。 每个阶段都在一个<strong>扩展点</strong>中公开。** 调度插件通过实现一个或多个扩展点，来提供调度行为**。这种方式本质上是基于 scheduler-framework 机制来实现的。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p> scheduler-framework 是面向 Kubernetes 调度器的一种插件架构， 它由一组直接编译到调度程序中的“插件” API 组成。cheduler-framework 定义了一些扩展点。调度器插件注册后在一个或多个扩展点处被调用， 这些插件中的一些可以改变调度决策。每次调度一个 Pod 的尝试都分为两个阶段，即 <strong>调度周期和绑定周期</strong>。</p></blockquote>\n<p>下图是 Scheduler-Framework 的扩展点</p>\n<p><img src=\"https://vspicgo.oss-cn-shanghai.aliyuncs.com/typora/1733905742576-a32fb6f2-9bf8-4887-a02f-889e4645cc48.png\"></p>\n<ul>\n<li>扩展点</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>扩展点</strong></th>\n<th><strong>描述</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>queueSort</td>\n<td>这些插件对调度队列中的悬决的 Pod 排序。 一次只能启用一个队列排序插件。</td>\n</tr>\n<tr>\n<td>preFilter</td>\n<td>这些插件用于在过滤之前预处理或检查 Pod 或集群的信息。 它们可以将 Pod 标记为不可调度。</td>\n</tr>\n<tr>\n<td>filter</td>\n<td>这些插件相当于调度策略中的断言（Predicates），用于过滤不能运行 Pod 的节点。 过滤器的调用顺序是可配置的。 如果没有一个节点通过所有过滤器的筛选，Pod 将会被标记为不可调度。</td>\n</tr>\n<tr>\n<td>postFilter</td>\n<td>当无法为 Pod 找到可用节点时，按照这些插件的配置顺序调用他们。 如果任何 <code>postFilter</code> 插件将 Pod 标记为可调度，则不会调用其余插件。</td>\n</tr>\n<tr>\n<td>preScore</td>\n<td>这是一个信息扩展点，可用于预打分工作。</td>\n</tr>\n<tr>\n<td>score</td>\n<td>这些插件给通过筛选阶段的节点打分。调度器会选择得分最高的节点。</td>\n</tr>\n<tr>\n<td>reserve</td>\n<td>这是一个信息扩展点，当资源已经预留给 Pod 时，会通知插件。 这些插件还实现了 <code>Unreserve</code> 接口，在 <code>Reserve</code> 期间或之后出现故障时调用。</td>\n</tr>\n<tr>\n<td>permit</td>\n<td>这些插件可以阻止或延迟 Pod 绑定。</td>\n</tr>\n<tr>\n<td>preBind</td>\n<td>这些插件在 Pod 绑定节点之前执行。</td>\n</tr>\n<tr>\n<td>bind</td>\n<td>这个插件将 Pod 与节点绑定。<code>bind</code> 插件是按顺序调用的，只要有一个插件完成了绑定， 其余插件都会跳过。<code>bind</code> 插件至少需要一个。</td>\n</tr>\n<tr>\n<td>postBind</td>\n<td>这是一个信息扩展点，在 Pod 绑定了节点之后调用。</td>\n</tr>\n<tr>\n<td>multiPoint</td>\n<td>这是一个仅配置字段，允许同时为所有适用的扩展点启用或禁用插件。</td>\n</tr>\n</tbody></table>\n<ul>\n<li>调度插件</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong>插件</strong></th>\n<th><strong>描述</strong></th>\n<th><strong>扩展点实现</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ImageLocality</td>\n<td>选择已经存在 Pod 运行所需容器镜像的节点</td>\n<td>score</td>\n</tr>\n<tr>\n<td>TaintToleration</td>\n<td>实现了 <a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/taint-and-toleration/\">污点和容忍</a></td>\n<td><code>filter</code>、<code>preScore</code>、<code>score</code></td>\n</tr>\n<tr>\n<td>NodeName</td>\n<td>检查 Pod 指定的节点名称与当前节点是否匹配</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>NodePorts</td>\n<td>检查 Pod 请求的端口在节点上是否可用</td>\n<td><code>preFilter</code>、<code>filter</code></td>\n</tr>\n<tr>\n<td>NodeAffinity</td>\n<td>实现了 <a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector\">节点选择器</a> 和<a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\">节点亲和性</a></td>\n<td><code>filter</code>、<code>score</code></td>\n</tr>\n<tr>\n<td>PodTopologySpread</td>\n<td>实现了 <a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/topology-spread-constraints/\">Pod 拓扑分布</a></td>\n<td><code>preFilter</code>、<code>filter</code>、<code>preScore</code>、<code>score</code></td>\n</tr>\n<tr>\n<td>NodeUnschedulable</td>\n<td>过滤 <code>.spec.unschedulable</code> 值为 true 的节点</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>NodeResourcesFit</td>\n<td>检查节点是否拥有 Pod 请求的所有资源。 得分可以使用以下三种策略之一：<code>LeastAllocated</code>（默认）、<code>MostAllocated</code> 和 <code>RequestedToCapacityRatio</code></td>\n<td><code>preFilter</code>、<code>filter</code>、<code>score</code></td>\n</tr>\n<tr>\n<td>NodeResourcesBalancedAllocation</td>\n<td>调度 Pod 时，选择资源使用更为均衡的节点</td>\n<td>score</td>\n</tr>\n<tr>\n<td>VolumeBinding</td>\n<td>检查节点是否有请求的卷，或是否可以绑定请求的<a href=\"https://kubernetes.io/zh-cn/docs/concepts/storage/volumes/\">卷</a></td>\n<td><code>preFilter</code>、<code>filter</code>、<code>reserve</code>、<code>preBind</code> 和 <code>score</code></td>\n</tr>\n<tr>\n<td>VolumeRestrictions</td>\n<td>检查挂载到节点上的卷是否满足卷提供程序的限制</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>VolumeZone</td>\n<td>检查请求的卷是否在任何区域都满足</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>NodeVolumeLimits</td>\n<td>检查该节点是否满足 CSI 卷限制</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>EBSLimits</td>\n<td>检查节点是否满足 AWS EBS 卷限制</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>GCEPDLimits</td>\n<td>检查该节点是否满足 GCP-PD 卷限制</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>AzureDiskLimits</td>\n<td>检查该节点是否满足 Azure 卷限制</td>\n<td>filter</td>\n</tr>\n<tr>\n<td>InterPodAffinity</td>\n<td>实现 <a href=\"https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\">Pod 间亲和性与反亲和性</a></td>\n<td><code>preFilter</code>、<code>filter</code>、<code>preScore</code>、<code>score</code></td>\n</tr>\n<tr>\n<td>PrioritySort</td>\n<td>默认的基于优先级的排序</td>\n<td>queueSort</td>\n</tr>\n<tr>\n<td>DefaultBinder</td>\n<td>默认的绑定机制</td>\n<td>bind</td>\n</tr>\n<tr>\n<td>DefaultPreemption</td>\n<td>默认的抢占机制</td>\n<td>postFilter</td>\n</tr>\n</tbody></table>\n","feature":true,"text":"k8s scheduler 的主要职责是为新创建的 pod 寻找一个最合适的 node 节点, 然后进行 bind node 绑定, 后面 kubelet 才会...","permalink":"/post/kubernetes/k8s-rational-of-scheduler","photos":[],"count_time":{"symbolsCount":"7.4k","symbolsTime":"7 mins."},"categories":[{"name":"kubernetes","slug":"kubernetes","count":3,"path":"api/categories/kubernetes.json"}],"tags":[{"name":"kubernetes","slug":"kubernetes","count":4,"path":"api/tags/kubernetes.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">整体介绍</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#POD-%E7%9A%84%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">POD 的创建流程</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Kube-Scheduler-%E8%B0%83%E5%BA%A6%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">Kube Scheduler 调度流程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%89%E4%B8%AA%E9%98%9F%E5%88%97\"><span class=\"toc-text\">三个队列</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-Active-%E9%98%9F%E5%88%97\"><span class=\"toc-text\">1. Active 队列</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-UnSchedulable-%E9%98%9F%E5%88%97\"><span class=\"toc-text\">2. UnSchedulable 队列</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-Backoff-%E9%98%9F%E5%88%97\"><span class=\"toc-text\">3. Backoff 队列</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5\"><span class=\"toc-text\">调度策略</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%BB%98%E8%AE%A4%E7%9A%84-Predicates-%E5%92%8C-Priorities\"><span class=\"toc-text\">默认的  Predicates 和 Priorities</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%80%9A%E8%BF%87%E8%B0%83%E5%BA%A6%E5%99%A8%E9%85%8D%E7%BD%AE%E9%80%89%E6%8B%A9\"><span class=\"toc-text\">通过调度器配置选择</span></a></li></ol></li></ol></li></ol>","author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}},"mapped":true,"hidden":false,"prev_post":{"title":"K8S Pod 中共享内存不足问题","uid":"0e025b15fb575a54a8fc4bbc222e5a27","slug":"kubernetes/k8s-sharing-memory-insufficient","date":"2025-02-15T06:48:51.000Z","updated":"2025-02-15T06:51:26.813Z","comments":true,"path":"api/articles/kubernetes/k8s-sharing-memory-insufficient.json","keywords":"宋国磊, glmapper, 卫恒, 分享, 开源","cover":null,"text":"报错信息大致如下： RuntimeError: Insufficient shared memory available. Required: 45298483...","permalink":"/post/kubernetes/k8s-sharing-memory-insufficient","photos":[],"count_time":{"symbolsCount":"3.7k","symbolsTime":"3 mins."},"categories":[{"name":"kubernetes","slug":"kubernetes","count":3,"path":"api/categories/kubernetes.json"}],"tags":[{"name":"kubernetes","slug":"kubernetes","count":4,"path":"api/tags/kubernetes.json"}],"author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}},"feature":true},"next_post":{"title":"k8s-create-api-token","uid":"373effae7edac83d76a746199917db9b","slug":"kubernetes/k8s-create-api-token","date":"2025-02-15T06:47:08.000Z","updated":"2025-02-15T06:51:10.641Z","comments":true,"path":"api/articles/kubernetes/k8s-create-api-token.json","keywords":"宋国磊, glmapper, 卫恒, 分享, 开源","cover":null,"text":"在 Kubernetes 中，可以通过创建一个服务账户（ServiceAccount）并为其生成一个 token 来访问 Kubernetes API Serv...","permalink":"/post/kubernetes/k8s-create-api-token","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"kubernetes","slug":"kubernetes","count":3,"path":"api/categories/kubernetes.json"}],"tags":[{"name":"kubernetes","slug":"kubernetes","count":4,"path":"api/tags/kubernetes.json"}],"author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}},"feature":true}}