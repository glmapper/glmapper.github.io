{"title":"SpringBoot 实践系列-Kafka简介&集成SpringBoot","uid":"f94d5062192ef9da77e7f3024a117b4b","slug":"springboot/springboot-series-kafka-introduction","date":"2019-03-07T09:58:54.000Z","updated":"2024-07-05T04:09:05.829Z","comments":true,"path":"api/articles/springboot/springboot-series-kafka-introduction.json","keywords":null,"cover":[],"content":"<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p> 近期在做 SOFA 与 SpringCloud 的集成，希望通过一系列的 DEMO 工程去帮助大家更好的使用 SOFA 和 SpringCloud；同时也希望大家一起来参与共建和 star。</p>\n<p>GitHub传送门：<a href=\"https://github.com/alipay/spring-cloud-sofastack-samples/issues/1\">spring-cloud-sofastack-samples</a></p></blockquote>\n<h2 id=\"Kafka-简介\"><a href=\"#Kafka-简介\" class=\"headerlink\" title=\"Kafka 简介\"></a>Kafka 简介</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>官方网站：<a href=\"https://kafka.apache.org/\">https://kafka.apache.org/</a></p></blockquote>\n<p><img src=\"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka.jpg\" alt=\"img\"></p>\n<span id=\"more\"></span>\n\n<h3 id=\"功能提供\"><a href=\"#功能提供\" class=\"headerlink\" title=\"功能提供\"></a>功能提供</h3><p>Apache Kafka™ 是 一个分布式数据流平台，从官方文档的解释来看，其职能大体如下：</p>\n<ul>\n<li>Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system。发布和订阅数据流，与消息队列或企业级消息系统很像。</li>\n<li>Store streams of records in a fault-tolerant durable way。具有很强容灾性的存储数据流</li>\n<li>Process streams of records as they occur。及时的处理数据流。</li>\n</ul>\n<p>作为一个后端司机，大多数情况下都是把 Kafka 作为一个分布式消息队列来使用的，分布式消息队列可以提供应用解耦、流量消峰、消息分发等功能，已经是大型互联网服务架构不可缺少的基础设置了。</p>\n<h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><h4 id=\"topic-和-partition\"><a href=\"#topic-和-partition\" class=\"headerlink\" title=\"topic 和 partition\"></a>topic 和 partition</h4><p>Kafka 对数据提供的核心抽象，topic 是发布的数据流的类别或名称。topic 在 Kafka 中，支持多订阅者； 也就是说，topic 可以有零个、一个或多个消费者订阅写到相应 topic 的数据。对应每一个 topic，Kafka 集群会维护像一个如下这样的分区的日志：<br><img src=\"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka-topic.jpg\" alt=\"img\"><br>每个 Partition 都是一个有序的、不可变的并且不断被附加的记录序列，也就是一个结构化提交日志（commit log）。为了保证唯一标性识 Partition 中的每个数据记录，Partition 中的记录每个都会被分配一个叫做偏移（offset）顺序的ID号。通过一个可配置的保留期，Kafka 集群会保留所有被发布的数据，不管它们是不是已经被消费者处理。例如，如果保留期设置为两天，则在发布记录后的两天内，数据都可以被消费，之后它将被丢弃以释放空间。 Kafka 的性能是不为因为数据量大小而受影响的，因此长时间存储数据并不成问题。</p>\n<p><img src=\"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka-producers.jpg\" alt=\"img\"><br>事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置，这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。 例如，消费者可以重置为较旧的偏移量以重新处理来自过去的数据，或者跳过之前的记录，并从“现在”开始消费。 这种特征的组合意味着 Kafka 消费者非常轻量级，随意的开启和关闭并不会对其他的消费者有大的影响。</p>\n<p>日志中的 Partition 有几个目的：</p>\n<ul>\n<li>保证日志的扩展性，topic 的大小不受单个服务器大小的限制。每个单独的 Partition 大小必须小于托管它的服务器磁盘大小，但 topic 可能有很多 Partition，因此它可以处理任意数量的海量数据。</li>\n<li>作为并行处理的单位 (<a href=\"https://www.zhihu.com/question/28925721/answer/139861200\">知乎-Partition</a>：Kafka可以将主题划分为多个分区（Partition），会根据分区规则选择把消息存储到哪个分区中，只要如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，多个订阅者可以从一个或者多个分区中同时消费数据，以支撑海量数据处理能力)</li>\n</ul>\n<h4 id=\"kafka中的topic为什么要进行分区\"><a href=\"#kafka中的topic为什么要进行分区\" class=\"headerlink\" title=\"kafka中的topic为什么要进行分区\"></a>kafka中的topic为什么要进行分区</h4><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>原贴：<a href=\"https://www.zhihu.com/question/28925721\">kafka中的topic为什么要进行分区</a> ，由于不能转载，此处不摘抄原文~</p></blockquote>\n<h4 id=\"生产者\"><a href=\"#生产者\" class=\"headerlink\" title=\"生产者\"></a>生产者</h4><p>生产者将数据发布到他们选择的 topic ， 生产者负责选择要吧数据分配给 topic 中哪个 Partition。这可以通过循环方式（round-robin）简单地平衡负载，或者可以根据某些语义进行分区（例如基于数据中的某些关键字）来完成。</p>\n<h4 id=\"消费者\"><a href=\"#消费者\" class=\"headerlink\" title=\"消费者\"></a>消费者</h4><p>消费者们使用消费群组(<em>consumer group</em> )名称来标注自己，几个消费者共享一个 group，每一个发布到 topic 的数据会被传递到每个消费群组(<em>consumer group</em> )中的一个消费者实例。 消费者实例可以在不同的进程中或不同的机器上。</p>\n<p>如果所有的消费者实例具有相同的 consumer group，则记录将在所有的消费者实例上有效地负载平衡</p>\n<p>如果所有的消费者实例都有不同的 consumer group，那么每个记录将被广播给所有的消费者进程，每个数据都发到了所有的消费者。<br><img src=\"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka-consume-group.jpge\" alt=\"img\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>上图解释源自<a href=\"http://ifeve.com/kafka-introduction/\">《Kafka 官方文档》 介绍</a>：</p>\n<p>如上图，一个两个服务器节点的Kafka集群， 托管着4个分区(P0-P3)，分为两个消费者群. 消费者群A有2个消费者实例，消费者群B有4个. 然而，更常见的是，我们发现主题具有少量的消费者群，每个消费者群代表一个“逻辑订户”。每个组由许多消费者实例组成，保证可扩展性和容错能力。这可以说是“发布-订阅”语义，但用户是一组消费者而不是单个进程。 在Kafka中实现消费的方式，是通过将日志中的分区均分到消费者实例上，以便每个实例在任何时间都是“相应大小的一块”分区的唯一消费者。维护消费者组成员资格的过程，由卡夫卡协议动态处理。 如果新的实例加入组，他们将从组中的其他成员接管一些分区; 如果一个实例消失，其分区将被分发到剩余的实例。 Kafka仅提供单个<em>分区内</em>的记录的顺序，而不是主题中的不同分区之间的总顺序。 每个分区排序结合按键分区，足以满足大多数应用程序的需求。 但是，如果您需要使用总顺序，则可以通过仅具有一个分区的主题来实现，尽管这仅意味着每个消费者组只有一个消费者进程。</p></blockquote>\n<h3 id=\"Kafka-作为消息系统\"><a href=\"#Kafka-作为消息系统\" class=\"headerlink\" title=\"Kafka 作为消息系统\"></a>Kafka 作为消息系统</h3><p>消息系统传统上有两种模式: <a href=\"http://en.wikipedia.org/wiki/Message_queue\">队列</a>和<a href=\"http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern\">发布-订阅</a>。 </p>\n<ul>\n<li>队列模式中，消费者池可以从服务器读取，每条记录只会被某一个消费者消费<ul>\n<li>允许在多个消费者实例上分配数据处理，但是一旦数据被消费之后，数据就没有了</li>\n</ul>\n</li>\n<li>发布订阅模式中，记录将广播给所有消费者<ul>\n<li>允许将数据广播到多个进程，但无法缩放和扩容，因为每个消息都发送给每个订阅用户</li>\n</ul>\n</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>本篇只介绍 Kafka 作为消息队列的一些基本概念，更多介绍请参考<a href=\"https://kafka.apache.org/intro\">官方文档</a>。</p></blockquote>\n<h2 id=\"Kafka-安装\"><a href=\"#Kafka-安装\" class=\"headerlink\" title=\"Kafka 安装\"></a>Kafka 安装</h2><p>这里来看下如何安装 kafka，下载地址：<a href=\"https://kafka.apache.org/downloads%E3%80%82%E6%9C%AC%E7%AF%87%E4%BD%BF%E7%94%A8%E7%9A%84%E7%89%88%E6%9C%AC%E6%98%AF\">https://kafka.apache.org/downloads。本篇使用的版本是</a> <strong>kafka_2.12-1.1.1</strong>。</p>\n<ul>\n<li><p>获取包文件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; wget http://mirrors.shu.edu.cn/apache/kafka/1.1.1/kafka_2.12-1.1.1.tgz</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>解压压缩包</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; tar -zxvf kafka_2.12-1.1.1.tgz</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>修改配置文件</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; cd kafka_2.12-1.1.1/config</span><br><span class=\"line\">&gt; vim server.properties</span><br></pre></td></tr></table></figure>\n\n<p>我这里主要修改项包括以下几个：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># The id of the broker. This must be set to a unique integer for each broker.</span><br><span class=\"line\">broker.id=0</span><br><span class=\"line\"></span><br><span class=\"line\">listeners=PLAINTEXT://192.168.0.1:9092</span><br><span class=\"line\"></span><br><span class=\"line\">advertised.listeners=PLAINTEXT://192.168.0.1:9092</span><br><span class=\"line\"># zookeeper 地址，可以多个</span><br><span class=\"line\">zookeeper.connect=192.168.0.6:2181</span><br></pre></td></tr></table></figure>\n\n<p>  Kafka 服务启动需要依赖 Zookeeper ，所以在配置文件中需要指定 Zookeeper 集群地址。Kafka 自己的安装包中解压之后是包括 Zookeeper 的，可以通过以下的方式来启动一个单节点 Zookeeper 实例：</p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; sh zookeeper-server-start.sh -daemon config/zookeeper.properties</span><br></pre></td></tr></table></figure>\n\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>这里我是指定了之前部署的一台ZK机器，所以可以直接将ZK地址指到已部署好的地址。Zookeeper 安装可以参考： <a href=\"http://www.glmapper.com/2019/03/04/zk-on-linux/\">Linux 下安装 Zookeeper</a> </p></blockquote>\n<p>  通过上述操作，下面就可以直接来启动Kafka 服务了：</p>\n  <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; sh kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"SpringBoot-集成-Kafka\"><a href=\"#SpringBoot-集成-Kafka\" class=\"headerlink\" title=\"SpringBoot 集成 Kafka\"></a>SpringBoot 集成 Kafka</h2><h3 id=\"构建一个简单的-Kafka-Producer-工具依赖\"><a href=\"#构建一个简单的-Kafka-Producer-工具依赖\" class=\"headerlink\" title=\"构建一个简单的 Kafka Producer 工具依赖\"></a>构建一个简单的 Kafka Producer 工具依赖</h3><ul>\n<li>依赖引入</li>\n</ul>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.kafka<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-kafka<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.3.5.RELEASE<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span><span class=\"comment\">&lt;!--$NO-MVN-MAN-VER$--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>producer</li>\n</ul>\n<p>为了可以把 Kafka 封装已提供给其他模块使用，大家可以将 Kafka 的生产端工具类使用 SpringBoot 的自动配置机制进行包装，如下：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">KafkaProducerAutoConfiguration</span> &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Autowired</span></span><br><span class=\"line\">    <span class=\"keyword\">private</span> KafkaTemplate&lt;String, String&gt; kafkaTemplate;</span><br><span class=\"line\">    <span class=\"meta\">@Bean</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> KafkaSender <span class=\"title function_\">kafkaSender</span><span class=\"params\">()</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"keyword\">new</span> <span class=\"title class_\">KafkaSender</span>(kafkaTemplate);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>KafkaSender</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">KafkaSender</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">private</span> KafkaTemplate&lt;String, String&gt; kafkaTemplate;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"title function_\">KafkaSender</span><span class=\"params\">(KafkaTemplate&lt;String, String&gt; kafkaTemplate)</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">this</span>.kafkaTemplate = kafkaTemplate;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * send message</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">sendMessage</span><span class=\"params\">(String topic, String message)</span> &#123;</span><br><span class=\"line\">        kafkaTemplate.send(topic, message);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>自动配置</li>\n</ul>\n<figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">org.springframework.boot.autoconfigure.EnableAutoConfiguration</span>=<span class=\"string\">\\</span></span><br><span class=\"line\"><span class=\"string\">io.sofastack.cloud.core.kafka.configuration.KafkaProducerAutoConfiguration</span></span><br></pre></td></tr></table></figure>\n\n<p>工程模块如下：<br>image-20190306151759441.png<br><img src=\"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka-demo-one.jpg\"></p>\n<h3 id=\"案例测试\"><a href=\"#案例测试\" class=\"headerlink\" title=\"案例测试\"></a>案例测试</h3><p>在测试工程中引入依赖，这个依赖就是上面工程打包来的：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>io.sofastack.cloud<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>sofastack-cloud-core-kafka<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>在 resources 目录下新建 application.properties 配置文件<figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#============== kafka ===================</span></span><br><span class=\"line\"><span class=\"comment\"># 指定kafka 代理地址，可以多个,这里的192.168.0.1是上面Kafka 启动配置文件中对应的</span></span><br><span class=\"line\"><span class=\"comment\"># 注：网上一些帖子中说 Kafka 这里的配置只能是主机名，不支持 ip，没有验证过，</span></span><br><span class=\"line\"><span class=\"comment\"># 如果您在验证时出现问题，可以尝试本机绑定下 host</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.bootstrap-servers</span>= <span class=\"string\">192.168.0.1:9092</span></span><br><span class=\"line\"><span class=\"comment\">#=============== provider  =======================</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.producer.retries</span>=<span class=\"string\">0</span></span><br><span class=\"line\"><span class=\"comment\"># 每次批量发送消息的数量</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.producer.batch-size</span>=<span class=\"string\">16384</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.producer.buffer-memory</span>=<span class=\"string\">33554432</span></span><br><span class=\"line\"><span class=\"comment\"># 指定消息key和消息体的编解码方式</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.producer.key-serializer</span>=<span class=\"string\">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.producer.value-serializer</span>=<span class=\"string\">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class=\"line\"><span class=\"comment\">#=============== consumer  =======================</span></span><br><span class=\"line\"><span class=\"comment\"># 指定默认消费者group id</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.consumer.group-id</span>=<span class=\"string\">test-consumer-group</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.consumer.auto-offset-reset</span>=<span class=\"string\">earliest</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.consumer.enable-auto-commit</span>=<span class=\"string\">true</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.consumer.auto-commit-interval</span>=<span class=\"string\">100ms</span></span><br><span class=\"line\"><span class=\"comment\"># 指定消息key和消息体的编解码方式</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.consumer.key-deserializer</span>=<span class=\"string\">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.consumer.value-deserializer</span>=<span class=\"string\">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class=\"line\"><span class=\"attr\">spring.application.name</span>=<span class=\"string\">kafka-test</span></span><br><span class=\"line\"><span class=\"attr\">logging.path</span>=<span class=\"string\">./logs</span></span><br></pre></td></tr></table></figure></li>\n<li>启动类中模拟发送消息</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@SpringBootApplication</span></span><br><span class=\"line\"><span class=\"meta\">@PropertySource(&quot;classpath:application-kafka.properties&quot;)</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">ProviderApplication</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">main</span><span class=\"params\">(String[] args)</span> &#123;</span><br><span class=\"line\">        <span class=\"type\">ConfigurableApplicationContext</span> <span class=\"variable\">run</span> <span class=\"operator\">=</span> SpringApplication.run(ProviderApplication.class, args);</span><br><span class=\"line\">        <span class=\"comment\">// 这里通过容器获取，正常使用情况下，可以直接使用 Autowired 注入</span></span><br><span class=\"line\">        <span class=\"type\">KafkaSender</span> <span class=\"variable\">bean</span> <span class=\"operator\">=</span> run.getBean(KafkaSender.class);</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">0</span>; i &lt; <span class=\"number\">3</span>; i++) &#123;</span><br><span class=\"line\">            <span class=\"comment\">//调用消息发送类中的消息发送方法</span></span><br><span class=\"line\">            bean.sendMessage(KafkaContants.TRADE_TOPIC, <span class=\"string\">&quot;send a test message&quot;</span>);</span><br><span class=\"line\">            <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">                Thread.sleep(<span class=\"number\">3000</span>);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">catch</span> (InterruptedException e) &#123;</span><br><span class=\"line\">                e.printStackTrace();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>编写消费者，在 SpringBoot 工程中，消费者实现非常简单</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Component</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">KafkaReceiver</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 配置监听的主体，groupId 和配置文件中的保持一致</span></span><br><span class=\"line\">    <span class=\"meta\">@KafkaListener(topics = &#123; KafkaContants.TRADE_TOPIC &#125;, groupId = &quot;test-consumer-group&quot;)</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">listen</span><span class=\"params\">(ConsumerRecord&lt;?, ?&gt; record)</span> &#123;</span><br><span class=\"line\">        Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value());</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (kafkaMessage.isPresent()) &#123;</span><br><span class=\"line\">            <span class=\"type\">Object</span> <span class=\"variable\">message</span> <span class=\"operator\">=</span> kafkaMessage.get();</span><br><span class=\"line\">            System.out.println(message);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>启动工程后，可以在控制台看下消费者打印的信息：<br><img src=\"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka-demo-two.jpg\"><br>这里保持应用正常运行，再通过服务端来手动发送消息，看下是当前消费者能够正确监听到对应的 topic 并消费。\t</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; sh kafka-console-producer.sh --broker-list 192.168.0.1:9092 --topic trading</span><br></pre></td></tr></table></figure>\n<p>执行上述命令之后，命令行将会等待输入，这里输入先后输入 glmapper 和 sofa :<br><img src=\"hhttps://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka-demo-three.jpg\"><br>然后再看下应用程序控制台输入结果如下：<br>image-20190306153452565.png<br><img src=\"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/bootkafka/boot-kafka-demo-four.jpg\"></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li><a href=\"http://kafka.apache.org/intro\">Introduction</a></li>\n<li><a href=\"http://ifeve.com/kafka-introduction/#more-32041\">《Kafka 官方文档》介绍</a></li>\n</ul>\n","text":" 近期在做 SOFA 与 SpringCloud 的集成，希望通过一系列的 DEMO 工程去帮助大家更好的使用 SOFA 和 SpringCloud；同时也希望...","permalink":"/post/springboot/springboot-series-kafka-introduction","photos":[],"count_time":{"symbolsCount":"7.8k","symbolsTime":"7 mins."},"categories":[{"name":"SpringBoot","slug":"SpringBoot","count":17,"path":"api/categories/SpringBoot.json"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","count":17,"path":"api/tags/SpringBoot.json"},{"name":"Kafka","slug":"Kafka","count":1,"path":"api/tags/Kafka.json"},{"name":"消息","slug":"消息","count":2,"path":"api/tags/消息.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Kafka-%E7%AE%80%E4%BB%8B\"><span class=\"toc-text\">Kafka 简介</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8A%9F%E8%83%BD%E6%8F%90%E4%BE%9B\"><span class=\"toc-text\">功能提供</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5\"><span class=\"toc-text\">基本概念</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#topic-%E5%92%8C-partition\"><span class=\"toc-text\">topic 和 partition</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#kafka%E4%B8%AD%E7%9A%84topic%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%88%86%E5%8C%BA\"><span class=\"toc-text\">kafka中的topic为什么要进行分区</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%94%9F%E4%BA%A7%E8%80%85\"><span class=\"toc-text\">生产者</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%B6%88%E8%B4%B9%E8%80%85\"><span class=\"toc-text\">消费者</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Kafka-%E4%BD%9C%E4%B8%BA%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F\"><span class=\"toc-text\">Kafka 作为消息系统</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Kafka-%E5%AE%89%E8%A3%85\"><span class=\"toc-text\">Kafka 安装</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#SpringBoot-%E9%9B%86%E6%88%90-Kafka\"><span class=\"toc-text\">SpringBoot 集成 Kafka</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84-Kafka-Producer-%E5%B7%A5%E5%85%B7%E4%BE%9D%E8%B5%96\"><span class=\"toc-text\">构建一个简单的 Kafka Producer 工具依赖</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A1%88%E4%BE%8B%E6%B5%8B%E8%AF%95\"><span class=\"toc-text\">案例测试</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E8%80%83\"><span class=\"toc-text\">参考</span></a></li></ol>","author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}},"mapped":true,"hidden":false,"prev_post":{"title":"SpringBoot 源码系列-事件机制详解","uid":"7b12c81b8791d99dc46d122cdc93aac5","slug":"springboot/springboot-series-event","date":"2019-04-13T09:53:12.000Z","updated":"2024-07-05T04:09:05.828Z","comments":true,"path":"api/articles/springboot/springboot-series-event.json","keywords":null,"cover":[],"text":"在这篇文章中聊一聊 Spring 中的扩展机制（一）中对Spring中的事件机制进行了分析。那么对于 SpringBoot 来说，它在 Spring 的基础上又...","permalink":"/post/springboot/springboot-series-event","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"SpringBoot","slug":"SpringBoot","count":17,"path":"api/categories/SpringBoot.json"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","count":17,"path":"api/tags/SpringBoot.json"},{"name":"event","slug":"event","count":1,"path":"api/tags/event.json"},{"name":"事件机制","slug":"事件机制","count":1,"path":"api/tags/事件机制.json"}],"author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}}},"next_post":{"title":"SpringCloud-版本及组件概述","uid":"f93d64595e35ae0269b6922a4bbacf9d","slug":"springcloud/spring-cloud-summary","date":"2018-12-31T15:38:38.000Z","updated":"2024-07-05T04:09:05.839Z","comments":true,"path":"api/articles/springcloud/spring-cloud-summary.json","keywords":null,"cover":null,"text":" 本系列基于Spring Cloud **Finchley SR2 & SOFABoot 3.0.0 Spring Cloud 为开发人员提供了快速构建分布式系...","permalink":"/post/springcloud/spring-cloud-summary","photos":[],"count_time":{"symbolsCount":"4.8k","symbolsTime":"4 mins."},"categories":[{"name":"SpringCloud","slug":"SpringCloud","count":14,"path":"api/categories/SpringCloud.json"}],"tags":[{"name":"config","slug":"config","count":6,"path":"api/tags/config.json"},{"name":"gateway","slug":"gateway","count":2,"path":"api/tags/gateway.json"},{"name":"netflix","slug":"netflix","count":1,"path":"api/tags/netflix.json"}],"author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}}}}