{"title":"浅析 SOFA 注册中心数据同步","uid":"2c6664cf4370278f829998c803443e3c","slug":"sofa/sofa-registry-sync-data","date":"2022-09-12T02:58:30.000Z","updated":"2024-07-05T04:09:05.801Z","comments":true,"path":"api/articles/sofa/sofa-registry-sync-data.json","keywords":"宋国磊, glmapper, 卫恒, 分享, 开源","cover":[],"content":"<p>本篇主要对 SOFARegistry 的数据同步模块进行解析，对于注册中心的概念以及 SOFARegistry 的基础架构不做过多阐述，相关介绍可以见<a href=\"%5Bhttps://www.sofastack.tech/blog/sofa-registry-introduction/%5D(https://www.sofastack.tech/blog/sofa-registry-introduction/)\">海量数据下的注册中心 - SOFARegistry 架构介绍</a> 这篇文章。</p>\n<span id=\"more\"></span>\n\n<p>本文主要写作思路大致分为下面 2 个部分：第一部分借助 SOFARegistry 中的角色分类来说明哪些角色之间会进行数据同步，第二部分对数据同步的具体实现进行解析。</p>\n<h2 id=\"SOFARegistry-的角色分类\"><a href=\"#SOFARegistry-的角色分类\" class=\"headerlink\" title=\"SOFARegistry 的角色分类\"></a>SOFARegistry 的角色分类</h2><p><img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/97432566c0794124b2a4f602f7165fcb~tplv-k3u1fbpfcp-zoom-1.image\" alt=\"image.png\"><br />如上图，SOFARegistry 包含 4 个角色：</p>\n<table>\n<thead>\n<tr>\n<th>角色</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Client</td>\n<td>提供应用接入服务注册中心的基本 API 能力，应用系统通过依赖客户端 JAR 包，通过编程方式调用服务注册中心的服务订阅和服务发布能力。</td>\n</tr>\n<tr>\n<td>SessionServer</td>\n<td>会话服务器，负责接受 Client 的服务发布和服务订阅请求，并作为一个中间层将写操作转发 DataServer 层。SessionServer 这一层可随业务机器数的规模的增长而扩容。</td>\n</tr>\n<tr>\n<td>DataServer</td>\n<td>数据服务器，负责存储具体的服务数据，数据按 dataInfoId 进行一致性 Hash 分片存储，支持多副本备份，保证数据高可用。这一层可随服务数据量的规模的增长而扩容。</td>\n</tr>\n<tr>\n<td>MetaServer</td>\n<td>元数据服务器，负责维护集群 SessionServer 和 DataServer 的一致列表，作为 SOFARegistry 集群内部的地址发现服务，在 SessionServer 或 DataServer 节点变更时可以通知到整个集群。</td>\n</tr>\n</tbody></table>\n<p>在这 4 个角色中，MetaServer 作为元数据服务器本身不处理实际的业务数据，仅负责维护集群 SessionServer 和 DataServer 的一致列表，不涉及数据同步问题；Client 与 SessionServer 之间的核心动作是订阅和发布，从广义上来说，属于用户侧客户端与 SOFARegistry 集群的数据同步，可以见：<a href=\"https://github.com/sofastack/sofa-registry/issues/195\">https://github.com/sofastack/sofa-registry/issues/195</a>，因此不在本文讨论范畴之内。</p>\n<p>SessionServer 作为会话服务，它主要解决海量客户端连接问题，其次是缓存客户端发布的所有 pub 数据；session 本身不持久化服务数据，而是将数据转写到 DataServer。DataServer 存储服务数据是按照 dataInfoId 进行一致性 Hash 分片存储的，支持多副本备份，保证数据高可用。</p>\n<p>从 SessionServer 和 DataServer 的功能分析中可以得出：</p>\n<ul>\n<li>SessionServer 缓存的服务数据需要与 DataServer 存储的服务数据保持一致</li>\n</ul>\n<p><img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c8d9dac32fa4455e81ca7b6e51c0e6d6~tplv-k3u1fbpfcp-zoom-1.image\" alt=\"image.png\"></p>\n<ul>\n<li>DataServer 支持多副本来保证高可用，因此 DataServer 多副本之间需要保持服务数据一致。</li>\n</ul>\n<p><img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/dea43352cdfa477bb33fd62b2269b315~tplv-k3u1fbpfcp-zoom-1.image\" alt=\"image.png\"></p>\n<p>SOFARegistry 中对于上述两个对于数据一致性保证就是通过数据同步机制来实现的。</p>\n<h2 id=\"数据同步的具体实现\"><a href=\"#数据同步的具体实现\" class=\"headerlink\" title=\"数据同步的具体实现\"></a>数据同步的具体实现</h2><p>下面主要介绍数据同步的实现细节，主要包括 SessionServer 和 DataServer 之间的数据同步 和 DataServer 多副本之间的数据同步两块。</p>\n<h3 id=\"SessionServer-和-DataServer-之间的数据同步\"><a href=\"#SessionServer-和-DataServer-之间的数据同步\" class=\"headerlink\" title=\"SessionServer 和 DataServer 之间的数据同步\"></a>SessionServer 和 DataServer 之间的数据同步</h3><p>SessionServer 和 DataServer 之间的数据同步，是基于推拉结合的机制</p>\n<ul>\n<li>推：DataServer 在数据有变化时，会主动通知 SessionServer，SessionServer 检查确认需要更新（对比 version） 后主动向 DataServer 获取数据。</li>\n<li>拉：除了上述的 DataServer 主动推以外，SessionServer 每隔一定的时间间隔，会主动向 DataServer 查询所有 dataInfoId 的 version 信息，然后再与 SessionServer 内存的 version 作比较，若发现 version 有变化，则主动向 DataServer 获取数据。这个“拉”的逻辑，主要是对“推”的一个补充，若在“推”的过程有错漏的情况可以在这个时候及时弥补。</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>关于推和拉两种模式检查的 version 有一些差异，可以详见下面 <strong>推模式下的数据同步</strong> 和 **拉模式下的数据同步 **中的具体介绍</p></blockquote>\n<h4 id=\"推模式下的数据同步流程\"><a href=\"#推模式下的数据同步流程\" class=\"headerlink\" title=\"推模式下的数据同步流程\"></a>推模式下的数据同步流程</h4><p>推模式是通过 SyncingWatchDog 这个守护线程不断 loop 执行来实现数据变更检查和通知发起的。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 这里遍历所有的 slot</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (SlotState slotState : slotTableStates.slotStates.values()) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        sync(slotState, syncSessionIntervalMs, syncLeaderIntervalMs, slotTableEpoch);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (Throwable e) &#123;</span><br><span class=\"line\">        SYNC_ERROR_LOGGER.error(</span><br><span class=\"line\">                <span class=\"string\">&quot;[syncCommit]failed to do sync slot &#123;&#125;, migrated=&#123;&#125;&quot;</span>,</span><br><span class=\"line\">                slotState.slot,</span><br><span class=\"line\">                slotState.migrated,</span><br><span class=\"line\">                e);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>按 slot 分组汇总数据版本。data 与每个 session 的连接都对应一个 SyncSessionTask，SyncSessionTask 负责执行同步数据的任务，核心同步逻辑在 <code>com.alipay.sofa.registry.server.data.slot.SlotDiffSyncer#sync</code>方法中完成，大致流程如下面时序图所示：<br /><img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/682a94a812d644f19f6bb67300075450~tplv-k3u1fbpfcp-zoom-1.image\" alt=\"image.png\"><br />这上图圈红部分的逻辑第四步，根据 dataInfoId diff 更新 data 内存数据，这里仅处理了被移除的 dataInfoId，对于新增和更新的没有做任务处理，而是通过后面的第 5 -7 步来完成；这么做的主要原因在于避免产生空推送导致一些危险情况发生。</p>\n<p>第 5 步中，比较的是所有变更 dataInfoId  的 pub version，具体比较逻辑参考后面 <a href=\"%5Bhttps://www.yuque.com/sofatracerlab/kylae1/arip14/edit#LT5Yn%5D(https://www.yuque.com/sofatracerlab/kylae1/arip14/edit#LT5Yn)\">diffPublisher</a> 小节中的介绍。</p>\n<h5 id=\"数据变更的事件通知处理\"><a href=\"#数据变更的事件通知处理\" class=\"headerlink\" title=\"数据变更的事件通知处理\"></a>数据变更的事件通知处理</h5><p><img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b6a672d68c0d496cad49db1f1c01901a~tplv-k3u1fbpfcp-zoom-1.image\"></p>\n<p>数据变更事件会被收集在 DataChangeEventCenter 的 dataCenter2Changes 缓存中，然后由一个守护线程 ChangeMerger 负责从 dataCenter2Changes 缓存中不断的读取，这些被捞到的事件源会被组装成 ChangeNotifier 任务，提交给一个单独的线程池(notifyExecutor)处理，整个过程全部是异步的。</p>\n<h4 id=\"拉模式下的数据同步流程\"><a href=\"#拉模式下的数据同步流程\" class=\"headerlink\" title=\"拉模式下的数据同步流程\"></a>拉模式下的数据同步流程</h4><p>拉模式下，由 SessionServer 负责发起，<code>com.alipay.sofa.registry.server.session.registry.SessionRegistry.VersionWatchDog</code>默认情况下每 5 秒扫描一次版本数据，如果版本有发生变更，则主动进行拉取一次，流程大致如下：<br /><img src=\"https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eaeca1574ad44bdd975442a23f7d67d5~tplv-k3u1fbpfcp-zoom-1.image\" alt=\"image.png\"></p>\n<p>需要注意的是，拉模式对推送流程的补充，这里的 version 是每个 sub 的 lastPushedVersion， 而 推模式的version 是 pub 的数据的 version。关于 lastPushedVersion 的获取可以参考 <code>com.alipay.sofa.registry.server.session.store.SessionInterests#selectSubscribers</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">store.forEach((String dataInfoId, Map&lt;String, Subscriber&gt; subs) -&gt; &#123;</span><br><span class=\"line\">   <span class=\"comment\">// ...</span></span><br><span class=\"line\">  <span class=\"type\">long</span> <span class=\"variable\">maxVersion</span> <span class=\"operator\">=</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">  <span class=\"keyword\">for</span> (Subscriber sub : subs.values()) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// ...</span></span><br><span class=\"line\">    <span class=\"comment\">// 获取当前 sub 的 pushVersion</span></span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"type\">long</span> <span class=\"variable\">pushVersion</span> <span class=\"operator\">=</span> sub.getPushedVersion(dataCenter);</span><br><span class=\"line\">    <span class=\"comment\">// 如果 pushVersion 比最大(最新)版本大，则将当前  pushVersion 作为最新版本推送版本</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (maxVersion &lt; pushVersion) &#123;</span><br><span class=\"line\">      maxVersion = pushVersion;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  versions.put(dataInfoId, <span class=\"keyword\">new</span> <span class=\"title class_\">DatumVersion</span>(maxVersion));</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"DataServer-多副本之间的数据同步\"><a href=\"#DataServer-多副本之间的数据同步\" class=\"headerlink\" title=\"DataServer 多副本之间的数据同步\"></a>DataServer 多副本之间的数据同步</h3><p>主要是 slot对应的 data 的 follower 定期和 leader 进行数据同步，其同步逻辑与 SessionServer 和 DataServer 之间的数据同步逻辑差异不大；发起方式也是一样的；data 判断如果当前节点不是 leader，就会进行与 leader 之间的数据同步。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (localIsLeader(slot)) &#123;</span><br><span class=\"line\">   <span class=\"comment\">// 如果当前是 leader，则执行 session 同步或者 migrating</span></span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 如果当前不是 leader，则和 leader 同步数据</span></span><br><span class=\"line\">    syncLeader(slotState, syncLeaderIntervalMs, slotTableEpoch);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>篇幅原因，这部分不展开讨论。</p></blockquote>\n<h3 id=\"增量同步-diff-计算逻辑分析\"><a href=\"#增量同步-diff-计算逻辑分析\" class=\"headerlink\" title=\"增量同步 diff 计算逻辑分析\"></a>增量同步 diff 计算逻辑分析</h3><p>不管是 SessionServer 和 DataServer 之间的同步，还是 DataServer 多副本之间的同步，都是基于增量 diff 同步的，不会一次性同步全量数据。本节对增量同步 diff 计算逻辑进行简单分析，核心代码在 <code>com.alipay.sofa.registry.common.model.slot.DataSlotDiffUtils</code>（建议阅读这部分代码时直接结合代码中的测试用例来看）；主要包括计算 digest 和 publishers 两个。</p>\n<h4 id=\"diffDigest\"><a href=\"#diffDigest\" class=\"headerlink\" title=\"diffDigest\"></a>diffDigest</h4><p><code>DataSlotDiffUtils#diffDigest</code> 方法接收两个参数</p>\n<ul>\n<li>targetDigestMap 可以理解为目标数据</li>\n<li>sourceDigestMap 可以理解为基线数据</li>\n</ul>\n<p>核心计算逻辑如下代码分析<br /></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 遍历 sourceDigestMap 元素</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (Map.Entry&lt;String, DatumDigest&gt; e : sourceDigestMap.entrySet()) &#123;</span><br><span class=\"line\">  <span class=\"comment\">// dataInfoId</span></span><br><span class=\"line\">  <span class=\"keyword\">final</span> <span class=\"type\">String</span> <span class=\"variable\">dataInfoId</span> <span class=\"operator\">=</span> e.getKey();</span><br><span class=\"line\">  <span class=\"comment\">// 从 目标数据 集中根据 dataInfoId 获取数据摘要</span></span><br><span class=\"line\">  <span class=\"type\">DatumDigest</span> <span class=\"variable\">targetDigest</span> <span class=\"operator\">=</span> targetDigestMap.get(dataInfoId);</span><br><span class=\"line\">  <span class=\"comment\">// 如果目标数据集中没有当前 dataInfoId 对应的数据摘要，</span></span><br><span class=\"line\">  <span class=\"comment\">// 则将当前 dataInfoId 作为新增项</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (targetDigest == <span class=\"literal\">null</span>) &#123;</span><br><span class=\"line\">    adds.add(dataInfoId);</span><br><span class=\"line\">    <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  <span class=\"comment\">// 如果目标数据集中有当前 dataInfoId 对应的数据摘要，</span></span><br><span class=\"line\">  <span class=\"comment\">// 但是数据摘要不同，则将当前 dataInfoId 作为待更新项</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (!targetDigest.equals(e.getValue())) &#123;</span><br><span class=\"line\">    updates.add(dataInfoId);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 如果目标数据集中的 dataInfoId 不再基线数据集中时，</span></span><br><span class=\"line\"><span class=\"comment\">// 则将当前 dataInfoId 作为待移除项。</span></span><br><span class=\"line\">List&lt;String&gt; removes = <span class=\"keyword\">new</span> <span class=\"title class_\">ArrayList</span>&lt;&gt;();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (String dataInfoId : targetDigestMap.keySet()) &#123;</span><br><span class=\"line\">  <span class=\"keyword\">if</span> (!sourceDigestMap.containsKey(dataInfoId)) &#123;</span><br><span class=\"line\">    removes.add(dataInfoId);</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>那么根据上述 diff 计算逻辑，这里有如下几种场景（假设基线数据集数据中 dataInfoId 为 a 和 b）</p>\n<ul>\n<li>目标数据集为空：返回 dataInfoId 为 a 和 b 两项作为新增项</li>\n<li>目标数据集与基线数据集相等，新增项、待更新项与待移除项均为空</li>\n<li>目标数据集中包括 a,b,c 三个 dataInfoId，则返回 c 作为待移除项</li>\n<li>目标数据集中包括 a 和 c 两个 dataInfoId，则返回 c 作为待移除项，b 作为新增项</li>\n</ul>\n<h4 id=\"diffPublisher\"><a href=\"#diffPublisher\" class=\"headerlink\" title=\"diffPublisher\"></a>diffPublisher</h4><p>diffPublisher 与 diffDigest 计算稍有不同，diffPublisher 接收三个参数，除了目标数据集和基线数据集之外，还有一个 publisherMaxNum（默认 400），用于限制每次处理的数据个数；这里同样给出核心代码解释：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 遍历所有目标数据集</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (DatumSummary summary : targetDatumSummaries) &#123;</span><br><span class=\"line\">      <span class=\"comment\">// 拿到 dataInfoId</span></span><br><span class=\"line\">      <span class=\"keyword\">final</span> <span class=\"type\">String</span> <span class=\"variable\">dataInfoId</span> <span class=\"operator\">=</span> summary.getDataInfoId();</span><br><span class=\"line\">      <span class=\"comment\">// 看基线数据集中是否包括当前 dataInfoId 对应的 Publisher 数据</span></span><br><span class=\"line\">      Map&lt;String, Publisher&gt; publisherMap = sourcePublishers.get(dataInfoId);</span><br><span class=\"line\">      <span class=\"comment\">// 这里表示 dataInfoId 移除被移除了，不需要做任何处理</span></span><br><span class=\"line\">      <span class=\"keyword\">if</span> (publisherMap == <span class=\"literal\">null</span>) &#123; <span class=\"keyword\">continue</span>; &#125;</span><br><span class=\"line\">      </span><br><span class=\"line\">      Set&lt;String&gt; registerIds = summary.getPublisherVersions().keySet();</span><br><span class=\"line\">      <span class=\"comment\">// 遍历 registerIds</span></span><br><span class=\"line\">      <span class=\"keyword\">for</span> (String registerId : registerIds) &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 如果基线数据集中不包括此 registerId，则将当前 registerId 加入待移除列表中</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!publisherMap.containsKey(registerId)) &#123;</span><br><span class=\"line\">          List&lt;String&gt; list = removedPublishers.computeIfAbsent(dataInfoId, k -&gt; <span class=\"keyword\">new</span> <span class=\"title class_\">ArrayList</span>&lt;&gt;());</span><br><span class=\"line\">          list.add(registerId);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      List&lt;Publisher&gt; publishers = <span class=\"keyword\">new</span> <span class=\"title class_\">ArrayList</span>&lt;&gt;();</span><br><span class=\"line\">      Map&lt;String, RegisterVersion&gt; versions = summary.getPublisherVersions();</span><br><span class=\"line\">      <span class=\"comment\">// 遍历版本</span></span><br><span class=\"line\">      <span class=\"keyword\">for</span> (Map.Entry&lt;String, Publisher&gt; p : publisherMap.entrySet()) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> <span class=\"type\">String</span> <span class=\"variable\">registerId</span> <span class=\"operator\">=</span> p.getKey();</span><br><span class=\"line\">        <span class=\"comment\">// 如果目标数据集当前 dataInfoId 的 registerIds 集中不包括基线的</span></span><br><span class=\"line\">        <span class=\"comment\">// 则作为更新项</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!versions.containsKey(registerId)) &#123;</span><br><span class=\"line\">          publishers.add(p.getValue());</span><br><span class=\"line\">          <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 如果当前 registerId 版本相同，则不做处理</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p.getValue().registerVersion().equals(versions.get(registerId))) &#123;</span><br><span class=\"line\">          <span class=\"comment\">// the same</span></span><br><span class=\"line\">          <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"comment\">// 不相等，则作为更新项</span></span><br><span class=\"line\">        publishers.add(p.getValue());</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里同样分析几种场景（下面只的是更新 dataInfoId 对应的 publisher，registerId 与 publisher是 一一对应）：</p>\n<ul>\n<li>目标数据集与基线数据集相同，且数据没有超过 publisherMaxNum，返回的待更新和待移除均为空，且没有剩余未处理数据</li>\n<li>需要移除的情况：基线中不包括目标数据集 dataInfoId 的 registerId （移除的是 registerId，不是 dataInfoId）</li>\n<li>需要更新的情况：<ul>\n<li>目标数据集中存在基线数据集不存在的 registerId</li>\n<li>目标数据集和基线数据集存在的 registerId 的版本不同</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>本文主要介绍了 SOFARegistry 中数据同步模块；首先从 SOFARegistry 角色分类阐述不同角色之间存在的数据同步问题，针对其中 SessionServer 与 DataServer 数据同步 和 DataServer 多副本之间数据同步进行了展开分析；在 SessionServer 与 DataServer 数据同步分析中，着重分析了推和拉两种场景下数据同步的整体流程；最后对 SOFARegistry 中数据增加的 diff 计算逻辑进行了介绍，并结合相关核心代码描述了具体的场景。</p>\n<p>整体来看，SOFARegistry 数据同步上的处理上有一些点值得我们学习：</p>\n<ul>\n<li>SOFARegistry 基于 ap，在一致性上是满足最终一致性；在实际的同步逻辑处理上，结合事件机制，基本都是异步化完成的，从而弱化了数据同步对于核心流程的影响。</li>\n<li>在拉模式和数据变更通知两个部分，内部采用了类似生产-消费模型，一方面是对于生产和消费逻辑的解耦，从代码上更独立；再者通过缓存或者队列来消除生产和消费速度不同而相互阻塞的问题。</li>\n<li>拉模式对推模式的补充；我们知道推模式是 server -&gt; client，发生在数据变更时，如果出现一些异常，导致某条 server -&gt; client 链路推送失败，则会导致不同 client 持有的数据不一致的情况；拉模式的补充，使得 client 可以主动去完成对于数据一致性的检查。</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>最后，感谢大家的阅读，文中如有错误，请指出；也欢迎大家关注 sofastack 社区。原文链接：<a href=\"https://mp.weixin.qq.com/s/UqsFzSuxuOfdVGJUGEid8g?from=timeline&isappinstalled=0&scene=2&clicktime=1657013852&enterid=1657013852\">https://mp.weixin.qq.com/s/UqsFzSuxuOfdVGJUGEid8g?from=timeline&amp;isappinstalled=0&amp;scene=2&amp;clicktime=1657013852&amp;enterid=1657013852</a></p></blockquote>\n","text":"本篇主要对 SOFARegistry 的数据同步模块进行解析，对于注册中心的概念以及 SOFARegistry 的基础架构不做过多阐述，相关介绍可以见海量数据下...","permalink":"/post/sofa/sofa-registry-sync-data","photos":[],"count_time":{"symbolsCount":"8.6k","symbolsTime":"8 mins."},"categories":[{"name":"SOFA","slug":"SOFA","count":9,"path":"api/categories/SOFA.json"}],"tags":[{"name":"注册中心","slug":"注册中心","count":1,"path":"api/tags/注册中心.json"},{"name":"分布式","slug":"分布式","count":6,"path":"api/tags/分布式.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#SOFARegistry-%E7%9A%84%E8%A7%92%E8%89%B2%E5%88%86%E7%B1%BB\"><span class=\"toc-text\">SOFARegistry 的角色分类</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">数据同步的具体实现</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#SessionServer-%E5%92%8C-DataServer-%E4%B9%8B%E9%97%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5\"><span class=\"toc-text\">SessionServer 和 DataServer 之间的数据同步</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%8E%A8%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">推模式下的数据同步流程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%8F%98%E6%9B%B4%E7%9A%84%E4%BA%8B%E4%BB%B6%E9%80%9A%E7%9F%A5%E5%A4%84%E7%90%86\"><span class=\"toc-text\">数据变更的事件通知处理</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%8B%89%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">拉模式下的数据同步流程</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#DataServer-%E5%A4%9A%E5%89%AF%E6%9C%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5\"><span class=\"toc-text\">DataServer 多副本之间的数据同步</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5-diff-%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E5%88%86%E6%9E%90\"><span class=\"toc-text\">增量同步 diff 计算逻辑分析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#diffDigest\"><span class=\"toc-text\">diffDigest</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#diffPublisher\"><span class=\"toc-text\">diffPublisher</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">总结</span></a></li></ol>","author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}},"mapped":true,"hidden":false,"prev_post":{"title":"ab 测试","uid":"c87a3afb2738074b526bbfc99d4f6216","slug":"tests/test-benchmark-ab","date":"2022-09-22T13:26:42.000Z","updated":"2024-07-05T04:09:05.844Z","comments":true,"path":"api/articles/tests/test-benchmark-ab.json","keywords":"宋国磊, glmapper, 卫恒, 分享, 开源","cover":null,"text":"Apache Benchmark Tool ab is a tool for benchmarking your Apache Hypertext Transf...","permalink":"/post/tests/test-benchmark-ab","photos":[],"count_time":{"symbolsCount":"10k","symbolsTime":"9 mins."},"categories":[{"name":"test","slug":"test","count":5,"path":"api/categories/test.json"}],"tags":[{"name":"test","slug":"test","count":5,"path":"api/tags/test.json"},{"name":"ab test","slug":"ab-test","count":1,"path":"api/tags/ab-test.json"}],"author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}}},"next_post":{"title":"你知道 @Async 是怎么让方法异步执行的吗？","uid":"3784314f76c771adae1123b249748729","slug":"springboot/spring-boot-async-anno","date":"2022-09-12T01:05:44.000Z","updated":"2024-07-05T04:09:05.826Z","comments":true,"path":"api/articles/springboot/spring-boot-async-anno.json","keywords":"宋国磊, glmapper, 卫恒, 分享, 开源","cover":null,"text":"在阅读本文之前，你可以通过 Creating Asynchronous Methods 指导来体验下创建异步方法的使用方式。 为什么要写这篇文章，本质上对于这些...","permalink":"/post/springboot/spring-boot-async-anno","photos":[],"count_time":{"symbolsCount":"8.2k","symbolsTime":"7 mins."},"categories":[{"name":"SpringBoot","slug":"SpringBoot","count":17,"path":"api/categories/SpringBoot.json"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","count":17,"path":"api/tags/SpringBoot.json"}],"author":{"name":"glmapper","slug":"blog-author","avatar":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/favicon.ico","link":"/","description":"开放，开源，分享，共享","socials":{"github":"https://github.com/glmapper","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/2412872703","zhihu":"","csdn":"","juejin":"https://juejin.cn/user/3227821827961806","customs":{"sofastack":{"icon":"https://glmapper-blog.oss-cn-hangzhou.aliyuncs.com/common/sofastack.svg","link":"https://www.sofastack.tech/"}}}}}}