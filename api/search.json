[{"id":"112cbc38ea4b5162ae16f2ac3f23f8d7","title":"CentOS 7 编译和部署 ZLMediaKit","content":"官方建议是在 Ubuntu 上去编译 ZLMediaKit；条件有限，我们的场景用的是 CentOS 7.9，所以就参考着官方文档的 QuickStart: https://github.com/ZLMediaKit/ZLMediaKit/wiki/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B 和网上各位大神的博客以及 ChatGPT 帮忙下完成了在 CentOS 7 编译和部署 ZLMediaKit 的工作。在此整理以备后续查阅，也分享给其他需要的工程师。\n\n\n\n\n\n\n\n\n\n整体还行，踩坑主要是 make 过程中缺少的乱七八糟依赖；总耗时大约 2 小时。\n\n基本构建工具cmake构建工具 cmake 版本要求 &gt;3.1.3：\n12# cmake --versioncmake version 3.15.5\n\n\n卸载之前的 cmake：yum erase cmake\nyum install -y wget （已安装过可跳过）\nwget https://github.com/Kitware/CMake/releases/download/v3.15.5/cmake-3.15.5.tar.gz(如果下载不了，直接去 github 上下载包，自行上传)\ntar -zxvf cmake-3.15.5.tar.gz\ncd cmake-3.15.5\n.&#x2F;bootstrap &amp;&amp; make -j4 &amp;&amp; sudo make install\nln -s &#x2F;usr&#x2F;local&#x2F;bin&#x2F;cmake &#x2F;usr&#x2F;bin&#x2F;\n\nopenssl我系统默认带的 openssl 是 1.0.2k-fips 版本\n12# openssl version OpenSSL 1.0.2k-fips  26 Jan 2017\n\n看了很多网上资料，ZLMediaKit 编译依赖的 openssl 版本要 &gt; 1.1.，否则回出现如下类似报错\n\n1、libssl.so.1.1: cannot open shared object file: No such file or directory\n2、[ZLMediaKit]error: ‘X509_up_ref’ was not declared in this scope\n3、openssl 未找到, rtmp 将不支持 flash 播放器\n\n123CMake Warning at CMakeLists.txt:412 (message):  openssl 未找到, rtmp 将不支持 flash 播放器,  https/wss/rtsps/rtmps/webrtc 也将失效\n\n\n\n这里升级到 1.1.1\n\n先备份\n12mv /usr/bin/openssl /usr/bin/openssl.bakmv /usr/include/openssl /usr/include/openssl.bak\n\n下载  wget https://www.openssl.org/source/openssl-1.1.1k.tar.gz\n\ntar -zxvf openssl-1.1.1k.tar.gz\n\ncd openssl-1.1.1k\n\n.&#x2F;config shared –openssldir&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl\n\nmake &amp;&amp; make install\n\n\n编译完成后，使用 openssl version 来查看一下当前 openssl 版本号时，你会发现还是 1.0.2，所以这里需要做一些额外的配置工作\n1234ln -s /usr/local/openssl/bin/openssl /usr/bin/opensslln -s /usr/local/openssl/include/openssl /usr/include/opensslecho “/usr/local/openssl/lib” &gt;&gt; /etc/ld.so.confldconfig -v\n\n查看(PS：如果有一些奇怪的提示或者报错，可以重载当前窗口再进入试试)\n12# openssl version OpenSSL 1.1.1k  25 Mar 2021\n\n\n\nlibsrtp2这个不安装，编译时会出现如下告警\n1[ZLMediaKit]srtp 未找到, WebRTC 相关功能打开失败\n\n\n下载 https://github.com/cisco/libsrtp/releases\n解压 tar -zxvf libsrtp-2.3.0.tar.gz \ncd libsrtp-2.3.0\n.&#x2F;configure –enable-openssl –with-openssl-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;openssl\nsudo  make -j8 &amp;&amp; sudo make install\n\n编译之前准备避免踩坑，在编译之前先处理好一些环境问题，比如我在编译时，因为 openssl 已经安装过了，并且版本正确；但是可能是连接器无法找到 openssl 中的相关初始化函数，导致我出现如下错误信息：\n12345/data/tools/ZLMediaKit/3rdpart/ZLToolKit/src/Util/SSLBox.cpp:48: undefined reference to OPENSSL_init_ssl&#x27;/data/tools/ZLMediaKit/3rdpart/ZLToolKit/src/Util/SSLBox.cpp:49: undefined reference to OPENSSL_init_ssl&#x27;/data/tools/ZLMediaKit/3rdpart/ZLToolKit/src/Util/SSLBox.cpp:50: undefined reference to OPENSSL_init_crypto&#x27;/data/tools/ZLMediaKit/3rdpart/ZLToolKit/src/Util/SSLBox.cpp:51: undefined reference to OPENSSL_init_crypto&#x27;/data/tools/ZLMediaKit/3rdpart/ZLToolKit/src/Util/SSLBox.cpp:52: undefined reference to OPENSSL_init_crypto&#x27;\n\n\n\n123456789101112131415../../../release/linux/Debug/libmk_api.so: undefined reference to HMAC_CTX_reset&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to X509_get0_pubkey&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to OPENSSL_init_crypto&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to OPENSSL_init_ssl&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to TLS_server_method&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to SSL_is_init_finished&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to HMAC_CTX_free&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to SSL_CTX_set_options&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to X509_getm_notBefore&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to EVP_PKEY_up_ref&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to TLS_client_method&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to X509_up_ref&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to HMAC_CTX_new&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to X509_getm_notAfter&#x27;../../../release/linux/Debug/libmk_api.so: undefined reference to DTLS_set_timer_cb&#x27;\n\nGPT 给出的解决方案包括\n确认 OpenSSL 库和符号确保 OpenSSL 库文件确实存在，并且包含 OPENSSL_init_ssl 和 OPENSSL_init_crypto 符号。你可以使用 nm 工具检查 OpenSSL 库文件中的符号：\n12nm /usr/local/openssl/lib/libssl.so | grep OPENSSL_init_sslnm /usr/local/openssl/lib/libssl.so | grep OPENSSL_init_crypto\n\n手动指定 OpenSSL 路径CMakeLists.txt\n123find_package(OpenSSL REQUIRED PATHS /usr/local/openssl /usr/include/openssl)target_link_libraries(your_target /usr/local/openssl/lib/libssl.a /usr/local/openssl/lib/libcrypto.a)\n\n编译时指定在编译时设置 LDFLAGS 和 CXXFLAGS 环境变量，确保链接器能够找到 OpenSSL 库：\n12export LDFLAGS=&quot;-L/usr/local/openssl/lib&quot;export CXXFLAGS=&quot;-I/usr/local/openssl/include&quot;\n\n我是通过编译时指定的方式构建成功的。\n编译12345678# 国内用户推荐从同步镜像网站gitee下载 git clone --depth 1 https://gitee.com/xia-chu/ZLMediaKit &amp;&amp; cd ZLMediaKit# 千万不要忘记执行这句命令,官方文档强调git submodule update --initmkdir build &amp;&amp; cd build# macOS 下可能需要这样指定 openss 路径：cmake .. -DOPENSSL_ROOT_DIR=/usr/local/Cellar/openssl/1.0.2j/cmake .. &amp;&amp; make -j4\n\n成功编译后日志大致如下(/data/tools/ZLMediaKit/build 是我的路径)：\n123456789make[2]: Leaving directory `/data/tools/ZLMediaKit/build&#x27;[100%] Built target test_rtpmake[2]: Leaving directory `/data/tools/ZLMediaKit/build&#x27;[100%] Built target api_tester_pushermake[2]: Leaving directory `/data/tools/ZLMediaKit/build&#x27;[100%] Built target test_wsServermake[2]: Leaving directory `/data/tools/ZLMediaKit/build&#x27;[100%] Built target test_servermake[1]: Leaving directory `/data/tools/ZLMediaKit/build&#x27;\n\n启动1234567# 挪到 /opt/ZLMediaKit 下mkdir -p /opt/ZLMediaKit下mv ../release/linux/Debug/* /opt/ZLMediaKit/ &amp;&amp; cd /opt/ZLMediaKit/# 备份配置文件cp config.ini config.ini.template# 修改 mediaServerId= &#123;your_server_id&#125;vim config.ini\n\n通过 -h 可以了解启动参数 ./MediaServer -h\n12345678910111213141516171819202122232025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: H2642025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: H2652025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: JPEG2025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: mpeg4-generic2025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: opus2025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: PCMA2025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: PCMU2025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: L162025-02-14 17:35:29.340 I [MediaServer] [809550-MediaServer] Factory.cpp:35 registerPlugin | Load codec: MP3  -h  --help       无参  默认:null                         选填  打印此信息  -d  --daemon     无参  默认:null                         选填  是否以Daemon方式启动  -l  --level      有参  默认:1                            选填  日志等级,LTrace~LError(0~4)  -m  --max_day    有参  默认:7                            选填  日志最多保存天数  -c  --config     有参  默认:/opt/ZLMediaKit/config.ini   选填  配置文件路径  -s  --ssl        有参  默认:/opt/ZLMediaKit/default.pem  选填  ssl证书文件或文件夹,支持p12/pem类型  -t  --threads    有参  默认:32                           选填  启动事件触发线程数      --affinity   有参  默认:1                            选填  是否启动cpu亲和性设置  -v  --version    无参  默认:null                         选填  显示版本号      --log-slice  有参  默认:100                          选填  最大保存日志切片个数      --log-size   有参  默认:256                          选填  单个日志切片最大容量,单位MB      --log-dir    有参  默认:/opt/ZLMediaKit/log/         选填  日志保存文件夹路径2025-02-14 17:35:29.342 I [MediaServer] [809550-MediaServer] logger.cpp:91 ~Logger | \n\n以守护进程模式启动 ./MediaServer -d &amp;\n安装 Ffmpeg先安装 epel-release\n1yum install epel-release\n\n安装 nux 存储库\n12rpm -v --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.rorpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm\n\n安装 ffmpeg\n1yum install ffmpeg ffmpeg-devel\n\n最后测试下\n12345678910111213# ffmpeg -versionffmpeg version 2.8.15 Copyright (c) 2000-2018 the FFmpeg developersbuilt with gcc 4.8.5 (GCC) 20150623 (Red Hat 4.8.5-36)configuration: --prefix=/usr --bindir=/usr/bin --datadir=/usr/share/ffmpeg --incdir=/usr/include/ffmpeg --libdir=/usr/lib64 --mandir=/usr/share/man --arch=x86_64 --optflags=&#x27;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic&#x27; --extra-ldflags=&#x27;-Wl,-z,relro &#x27; --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libvo-amrwbenc --enable-version3 --enable-bzlib --disable-crystalhd --enable-gnutls --enable-ladspa --enable-libass --enable-libcdio --enable-libdc1394 --enable-libfdk-aac --enable-nonfree --disable-indev=jack --enable-libfreetype --enable-libgsm --enable-libmp3lame --enable-openal --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-libschroedinger --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libvorbis --enable-libv4l2 --enable-libx264 --enable-libx265 --enable-libxvid --enable-x11grab --enable-avfilter --enable-avresample --enable-postproc --enable-pthreads --disable-static --enable-shared --enable-gpl --disable-debug --disable-stripping --shlibdir=/usr/lib64 --enable-runtime-cpudetectlibavutil      54. 31.100 / 54. 31.100libavcodec     56. 60.100 / 56. 60.100libavformat    56. 40.101 / 56. 40.101libavdevice    56.  4.100 / 56.  4.100libavfilter     5. 40.101 /  5. 40.101libavresample   2.  1.  0 /  2.  1.  0libswscale      3.  1.101 /  3.  1.101libswresample   1.  2.101 /  1.  2.101libpostproc    53.  3.100 / 53.  3.100\n\n","slug":"middleware/middleware-zkmediakit-deploy-record","date":"2025-02-15T05:48:05.000Z","categories_index":"Middleware","tags_index":"ZLMediaKit","author_index":"glmapper"},{"id":"b66d839268b41dec0c2b4caf81d61b35","title":"神经网络浅讲：从神经元到深度学习","content":"\n\n\n\n\n\n\n\n\n本篇是笔者最近在学习机器学习时阅读到的一篇文章，刚好和笔者最近在阅读《深度学习革命》这本书里的内容有较多的重叠之处，结合来看，个人认为它比较清楚的帮我捋顺了一些机器学习领域发展的时间线和一些关键技术概念。此外因为作者提到可以转发，因此在公众号转发以便于个人收藏阅读，也期望分享给相关对此方向感兴趣的同学。我保留了原文的标题，对于其中的一些内容做了适当的修改、删除和补充，以便更符合公众号读者的阅读习惯。当然如果你期望转发本篇，请也同时备注原文链接。原文：https://www.cnblogs.com/subconscious/p/5058741.html\n神经网络是一门重要的机器学习技术。它是目前最为火热的研究方向–深度学习的基础。学习神经网络不仅可以让你掌握一门强大的机器学习方法，同时也可以更好地帮助你理解深度学习技术。本文以一种简单的，循序的方式讲解神经网络。适合对神经网络了解不多的同学。本文对阅读没有一定的前提要求，但是懂一些机器学习基础会更好地帮助理解本文神经网络是一种模拟人脑的神经网络以期能够实现类人工智能的机器学习技术。人脑中的神经网络是一个非常复杂的组织。成人的大脑中估计有1000亿个神经元之多。\n\n那么机器学习中的神经网络是如何实现这种模拟的，并且达到一个惊人的良好效果的？通过本文，你可以了解到这些问题的答案，同时还能知道神经网络的历史，以及如何较好地学习它。由于本文较长，为方便读者，可以收藏转发保存。\n一. 前言让我们来看一个经典的神经网络。这是一个包含三个层次的神经网络。红色的是输入层，绿色的是输出层，紫色的是中间层（也叫隐藏层）。输入层有3个输入单元，隐藏层有4个单元，输出层有2个单元。后文中，我们统一使用这种颜色来表达神经网络的结构。\n\n在开始介绍前，有一些知识可以先记在心里：\n\n1、设计一个神经网络时，输入层与输出层的节点数往往是固定的，中间层则可以自由指定；\n2、神经网络结构图中的拓扑与箭头代表着预测过程时数据的流向，跟训练时的数据流有一定的区别；\n3、结构图里的关键不是圆圈（代表“神经元”），而是连接线（代表“神经元”之间的连接）。每个连接线对应一个不同的权重（其值称为权值），这是需要训练得到的。\n\n除了从左到右的形式表达的结构图，还有一种常见的表达形式是从下到上来表示一个神经网络。这时候，输入层在图的最下方。输出层则在图的最上方，如下图：\n\n\n\n\n\n\n\n\n\n\n从左到右的表达形式以 Andrew Ng 和 LeCun 的文献使用较多，Caffe 里使用的则是从下到上的表达。在本文中使用 Andrew Ng 代表的从左到右的表达形式。下面从简单的神经元开始说起，一步一步介绍神经网络复杂结构的形成。\n二. 神经元1、引子对于神经元的研究由来已久，1904 年生物学家就已经知晓了神经元的组成结构。一个神经元通常具有多个树突，主要用来接受传入信息；而轴突只有一条，轴突尾端有许多轴突末梢可以给其他多个神经元传递信息轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置在生物学上叫做“突触”。人脑中的神经元形状可以用下图做简单的说明：\n\n1943年，心理学家 McCulloch 和数学家 Pitts 参考了生物神经元的结构，发表了抽象的神经元模型 MP。在下文中，我们会具体介绍神经元模型。\n  \n图5 Warren McCulloch（左）和 Walter Pitts（右） \n2、结构神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。下图是一个典型的神经元模型：包含有3个输入，1个输出，以及2个计算功能。注意中间的箭头线。这些线称为“连接”。每个上有一个“权值”。\n\n 连接是神经元中最重要的东西，每一个连接上都有一个权重。一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。我们使用a来表示输入，用w来表示权值。一个表示连接的有向箭头可以这样理解：在初端，传递的信号大小仍然是a，端中间有加权参数w，经过这个加权后的信号会变成a*w，因此在连接的末端，信号的大小就变成了a*w。\n在其他绘图模型里，有向箭头可能表示的是值的不变传递。而在神经元模型里，每个有向箭头表示的是值的加权传递。\n\n 如果我们将神经元图中的所有变量用符号表示，并且写出输出的计算公式的话，就是下图。\n\n可见z是在输入和权值的线性加权和叠加了一个 函数g 的值。在MP模型里，函数 g 是 sgn 函数，也就是取符号函数。这个函数当输入大于 0 时，输出 1，否则输出 0。\n下面对神经元模型的图进行一些扩展。首先将sum函数与sgn函数合并到一个圆圈里，代表神经元的内部计算。其次，把输入a与输出z写到连接线的左上方，便于后面画复杂的网络。最后说明，一个神经元可以引出多个代表输出的有向箭头，但值都是一样的。神经元可以看作一个计算与存储单元。计算是神经元对其的输入进行计算功能。存储是神经元会暂存计算结果，并传递到下一层。\n\n当我们用“神经元”组成网络以后，描述网络中的某个“神经元”时，我们更多地会用“单元”（unit）来指代。同时由于神经网络的表现形式是一个有向图(DAG)，有时也会用“节点”（node）来表达同样的意思。 \n3、效果神经元模型的使用可以这样理解：\n\n\n\n\n\n\n\n\n\n我们有一个数据，称之为 样本。样本有四个属性，其中三个属性已知，一个属性未知。我们需要做的就是通过三个已知属性预测未知属性。具体办法就是使用神经元的公式进行计算。三个已知属性的值是 a1，a2，a3，未知属性的值是 z。z 可以通过公式计算出来。\n这里，已知的属性称之为特征，未知的属性称之为目标。假设特征与目标之间确实是线性关系，并且我们已经得到表示这个关系的权值 w1，w2，w3。那么，我们就可以通过神经元模型预测新样本的目标。\n4、影响1943 年发布的MP模型，虽然简单，但已经建立了神经网络大厦的地基。但是，MP模型中，权重的值都是预先设置的，因此不能学习。1949 年心理学家 Hebb 提出了 Hebb 学习率，认为人脑神经细胞的突触（也就是连接）上的强度上可以变化的。于是计算科学家们开始考虑用调整权值的方法来让机器学习。这为后面的学习算法奠定了基础。\n\n尽管神经元模型与Hebb学习律都已诞生，但限于当时的计算机能力，直到接近 10 年后，第一个真正意义的神经网络才诞生。\n三. 单层神经网络（感知器）1、引子1958年，计算科学家 Rosenblatt 提出了由两层神经元组成的神经网络。他给它起了一个名字–“感知器”（Perceptron）（有的文献翻译成“感知机”，下文统一用“感知器”来指代）。感知器是当时首个可以学习的人工神经网络。Rosenblatt 现场演示了其学习识别简单图像的过程，在当时的社会引起了轰动。人们认为已经发现了智能的奥秘，许多学者和科研机构纷纷投入到神经网络的研究中。美国军方大力资助了神经网络的研究，并认为神经网络比“原子弹工程”更重要。这段时间直到 1969 年才结束，这个时期可以看作神经网络的第一次高潮。\n\n2、结构在原来 MP 模型的“输入”位置添加神经元节点，标志其为“输入单元”。其余不变，于是我们就有了下图：从本图开始，我们将权值 w1, w2, w3 写到“连接线”的中间。\n\n在“感知器”中，有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算。\n我们把需要计算的层次称之为“计算层”，并把拥有一个计算层的网络称之为“单层神经网络”。有一些文献会按照网络拥有的层数来命名，例如把“感知器”称为两层神经网络。但在本文里，我们根据计算层的数量来命名。\n假如我们要预测的目标不再是一个值，而是一个向量，例如[2,3]。那么可以在输出层再增加一个“输出单元”。下图显示了带有两个输出单元的单层神经网络，其中输出单元z1的计算公式如下图。\n\n可以看到，z1的计算跟原先的z并没有区别。我们已知一个神经元的输出可以向多个神经元传递，因此z2的计算公式如下图。\n\n可以看到，z2的计算中除了三个新的权值：w4，w5，w6以外，其他与z1是一样的。整个网络的输出如下图。\n\n目前的表达公式有一点不让人满意的就是：w4，w5，w6 是后来加的，很难表现出跟原先的w1，w2，w3的关系。因此我们改用二维的下标，用 wxy 来表达一个权值。下标中的 x 代表后一层神经元的序号，而 y 代表前一层神经元的序号（序号的顺序从上到下）。例如，w1,2代表后一层的第1个神经元与前一层的第2个神经元的连接的权值（这种标记方式参照了Andrew Ng的课件）。根据以上方法标记，我们有了下图。\n\n 如果我们仔细看输出的计算公式，会发现这两个公式就是线性代数方程组。因此可以用矩阵乘法来表达这两个公式。例如，输入的变量是[a1，a2，a3]T（代表由a1，a2，a3 组成的列向量），用向量 a 来表示。方程的左边是[z1，z2]T，用向量 z 来表示。系数则是矩阵W（2行3列的矩阵，排列形式与公式中的一样）。于是，输出公式可以改写成：\n\n\n\n\n\n\n\n\n\ng(W * a) &#x3D; z\n 这个公式就是神经网络中从前一层计算后一层的矩阵运算。\n3、效果与神经元模型不同，感知器中的权值是通过训练得到的。因此，根据以前的知识我们知道，感知器类似一个逻辑回归模型，可以做线性分类任务。我们可以用决策分界来形象的表达分类的效果。决策分界就是在二维的数据平面中划出一条直线，当数据的维度是三维的时候，就是划出一个平面，当数据的维度是N维时，就是划出一个N-1维的超平面。下图显示了在二维平面中划出决策分界的效果，也就是感知器的分类效果。\n\n4、影响感知器只能做简单的线性分类任务。但是当时的人们热情太过于高涨，并没有人清醒的认识到这点。于是，当人工智能领域的巨擘 Minsky 指出这点时，事态就发生了变化。Minsky 在1969年出版了一本叫《Perceptron》的书，里面用详细的数学证明了感知器的弱点，尤其是感知器对 XOR（异或）这样的简单分类任务都无法解决。\nMinsky 认为，如果将计算层增加到两层，计算量则过大，而且没有有效的学习算法。所以，他认为研究更深层的网络是没有价值的。（本文成文后一个月，即2016年1月，Minsky在美国去世。谨在本文中纪念这位著名的计算机研究专家与大拿。）\n  \n由于 Minsky 的巨大影响力以及书中呈现的悲观态度，让很多学者和实验室纷纷放弃了神经网络的研究。神经网络的研究陷入了冰河期。这个时期又被称为AI winter。接近10年以后，对于两层神经网络的研究才带来神经网络的复苏。\n四. 两层神经网络（多层感知器）1、引子两层神经网络是本文的重点，因为正是在这时候，神经网络开始了大范围的推广与使用。Minsky 说过单层神经网络无法解决异或问题，但是当增加一个计算层以后，两层神经网络不仅可以解决异或问题，而且具有非常好的非线性分类效果。不过两层神经网络的计算是一个问题，没有一个较好的解法。\n1986 年，Rumelhar 和 Hinton 等人提出了反向传播（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。目前，大量的教授神经网络的教材，都是重点介绍两层（带一个隐藏层）神经网络的内容。这时候的 Hinton 还很年轻，30 年以后，正是他重新定义了神经网络，带来了神经网络复苏的又一春。\n    \n2、结构两层神经网络除了包含一个输入层，一个输出层以外，还增加了一个中间层。此时，中间层和输出层都是计算层。我们扩展上节的单层神经网络，在右边新加一个层次（只含有一个节点）。现在，我们的权值矩阵增加到了两个，我们用上标来区分不同层次之间的变量。\n例如ax(y)代表第 y 层的第 x 个节点。z1，z2 变成了a1(2)，a2(2)。下图给出了a1(2)，a2(2)的计算公式。\n\n计算最终输出z的方式是利用了中间层的a1(2)，a2(2)和第二个权值矩阵计算得到的，如下图。\n\n假设我们的预测目标是一个向量，那么与前面类似，只需要在“输出层”再增加节点即可。我们使用向量和矩阵来表示层次中的变量。a(1)，a(2)，z 是网络中传输的向量数据。W(1)和W(2)是网络的矩阵参数。如下图。\n\n使用矩阵运算来表达整个计算公式的话如下：\ng(W(1) * a(1)) =a(2)\n\ng(W(2) * a(2)) = z\n\n \n\n由此可见，使用矩阵运算来表达是很简洁的，而且也不会受到节点数增多的影响（无论有多少节点参与运算，乘法两端都只有一个变量）。因此神经网络的教程中大量使用矩阵运算来描述。\n\n\n\n\n\n\n\n\n\n需要说明的是，至今为止，我们对神经网络的结构图的讨论中都没有提到偏置节点（bias unit）。事实上，这些节点是默认存在的。它本质上是一个只含有存储功能，且存储值永远为1的单元。在神经网络的每个层次中，除了输出层以外，都会含有这样一个偏置单元。正如线性回归模型与逻辑回归模型中的一样。\n偏置单元与后一层的所有节点都有连接，我们设这些参数值为向量 b，称之为偏置。如下图。\n\n可以看出，偏置节点很好认，因为其没有输入（前一层中没有箭头指向它）。有些神经网络的结构图中会把偏置节点明显画出来，有些不会。一般情况下，我们都不会明确画出偏置节点。 在考虑了偏置以后的一个神经网络的矩阵运算如下：\ng(W(1) * a(1) + b(1)) =a(2)\n\n g(W(2) * a(2) + b(2)) = z\n\n需要说明的是，在两层神经网络中，我们不再使用sgn函数作为函数g，而是使用平滑函数sigmoid作为函数g。我们把函数g也称作激活函数（active function）。事实上，神经网络的本质就是通过参数与激活函数来拟合特征与目标之间的真实函数关系。初学者可能认为画神经网络的结构图是为了在程序中实现这些圆圈与线，但在一个神经网络的程序中，既没有“线”这个对象，也没有“单元”这个对象，实现一个神经网络最需要的是 线性代数库。\n3、效果\n\n\n\n\n\n\n\n\n 与单层神经网络不同。理论证明，两层神经网络可以无限逼近任意连续函数。\n这是什么意思呢？也就是说，面对复杂的非线性分类任务，两层（带一个隐藏层）神经网络可以分类的很好。下面就是一个例子（此两图来自colah 的博客http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/），红色的线与蓝色的线代表数据。而红色区域和蓝色区域代表由神经网络划开的区域，两者的分界线就是**决策分界**。\n\n　　\n可以看到，这个两层神经网络的决策分界是非常平滑的曲线，而且分类的很好。有趣的是，前面已经学到过，单层网络只能做线性分类任务。而两层神经网络中的后一层也是线性分类层，应该只能做线性分类任务。为什么两个线性分类任务结合就可以做非线性分类任务？我们可以把输出层的决策分界单独拿出来看一下：\n\n可以看到，输出层的决策分界仍然是直线。关键就是，从输入层到隐藏层时，数据发生了空间变换。也就是说，两层神经网络中，隐藏层对原始的数据进行了一个空间变换，使其可以被线性分类，然后输出层的决策分界划出了一个线性分类分界线，对其进行分类。这样就导出了两层神经网络可以做非线性分类的关键–隐藏层。联想到我们一开始推导出的矩阵公式，我们知道，矩阵和向量相乘，本质上就是对向量的坐标空间进行一个变换。因此，隐藏层的参数矩阵的作用就是使得数据的原始坐标空间从线性不可分，转换成了线性可分。\n两层神经网络通过两层的线性模型模拟了数据内真实的非线性函数。因此，多层的神经网络的本质就是复杂函数拟合。\n下面来讨论一下隐藏层的节点数设计。在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。因此，“自由”把握在设计者的手中。但是，节点数设置的多少，却会影响到整个模型的效果。如何决定这个自由层的节点数呢？目前业界没有完善的理论来指导这个决策。一般是根据经验来设置。较好的方法就是预先设定几个可选值，通过切换这几个值来看整个模型的预测效果，选择效果最好的值作为最终选择。这种方法又叫做 Grid Search（网格搜索）。了解了两层神经网络的结构以后，我们就可以看懂其它类似的结构图。例如EasyPR字符识别网络架构（下图）。\n\nEasyPR 使用了字符的图像去进行字符文字的识别。输入是 120 维的向量，输出是要预测的文字类别，共有 65 类。根据实验，我们测试了一些隐藏层数目，发现当值为 40 时，整个网络在测试集上的效果较好，因此选择网络的最终结构就是120，40，65。\n4、训练在 Rosenblat 提出的感知器模型中，模型中的参数可以被训练，但是使用的方法较为简单，并没有使用目前机器学习中通用的方法，这导致其扩展性与适用性非常有限。从两层神经网络开始，神经网络的研究人员开始使用机器学习相关的技术进行神经网络的训练。例如用大量的数据（1000-10000左右），使用算法进行优化等等，从而使得模型训练可以获得性能与数据利用上的双重优势。机器学习模型训练的目的，就是使得参数尽可能的与真实的模型逼近。具体做法是这样的：\n首先给所有参数赋上随机值。我们使用这些随机生成的参数值，来预测训练数据中的样本。样本的预测目标为yp，真实目标为y。那么，定义一个值 loss，计算公式如下:\nloss = (yp - y)2\n\n \n\n这个值称之为 损失（loss），我们的目标就是使对所有训练数据的损失和尽可能的小。\n如果将先前的神经网络预测的矩阵公式带入到yp中（因为有z&#x3D;yp），那么我们可以把损失写为关于参数（parameter）的函数，这个函数称之为 损失函数（loss function）。下面的问题就是求：如何优化参数，能够让损失函数的值最小。\n此时这个问题就被转化为一个优化问题。一个常用方法就是高等数学中的求导，但是这里的问题由于参数不止一个，求导后计算导数等于0的运算量很大，所以一般来说解决这个优化问题使用的是 梯度下降 算法。梯度下降算法每次计算参数在当前的梯度，然后让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时截止。一般这个时候，所有的参数恰好达到使损失函数达到一个最低值的状态。\n在神经网络模型中，由于结构复杂，每次计算梯度的代价很大。因此还需要使用 反向传播 算法。反向传播算法是利用了神经网络的结构进行的计算。不一次计算所有参数的梯度，而是从后往前。首先计算输出层的梯度，然后是第二个参数矩阵的梯度，接着是中间层的梯度，再然后是第一个参数矩阵的梯度，最后是输入层的梯度。计算结束以后，所要的两个参数矩阵的梯度就都有了。反向传播算法可以直观的理解为下图。梯度的计算从后往前，一层层反向传播，前缀E 代表着相对导数的意思。\n\n反向传播算法的启示是数学中的 链式法则。在此需要说明的是，尽管早期神经网络的研究人员努力从生物学中得到启发，但从BP算法开始，研究者们更多地从数学上寻求问题的最优解。不再盲目模拟人脑网络是神经网络研究走向成熟的标志。正如科学家们可以从鸟类的飞行中得到启发，但没有必要一定要完全模拟鸟类的飞行方式，也能制造可以飞天的飞机。\n优化问题只是训练中的一个部分。机器学习问题之所以称为学习问题，而不是优化问题，就是因为它不仅要求数据在训练集上求得一个较小的误差，在测试集上也要表现好。因为模型最终是要部署到没有见过训练数据的真实场景。提升模型在测试集上的预测效果的主题叫做 泛化（generalization），相关方法被称作正则化（regularization），神经网络中常用的泛化技术有 权重衰减 等。\n5、影响两层神经网络在多个地方的应用说明了其效用与价值。10 年前困扰神经网络界的异或问题被轻松解决。神经网络在这个时候，已经可以发力于语音识别，图像识别，自动驾驶等多个领域。历史总是惊人的相似，神经网络的学者们再次登上了《纽约时报》的专访。人们认为神经网络可以解决许多问题。就连娱乐界都开始受到了影响，当年的《终结者》电影中的阿诺都赶时髦地说一句：我的 CPU 是一个神经网络处理器，一个会学习的计算机。\n但是神经网络仍然存在若干的问题：尽管使用了BP算法，一次神经网络的训练仍然耗时太久，而且困扰训练优化的一个问题就是局部最优解问题，这使得神经网络的优化较为困难。同时，隐藏层的节点数需要调参，这使得使用不太方便，工程和研究人员对此多有抱怨。\n90 年代中期，由Vapnik等人发明的 SVM（Support Vector Machines，支持向量机）算法诞生，很快就在若干个方面体现出了对比神经网络的优势：无需调参；高效；全局最优解。基于以上种种理由，SVM 迅速打败了神经网络算法成为主流。\n\n神经网络的研究再次陷入了冰河期。当时，只要你的论文中包含神经网络相关的字眼，非常容易被会议和期刊拒收，研究界那时对神经网络的不待见可想而知。\n五、多层神经网络（深度学习）1、引子\n\n\n\n\n\n\n\n\n在被人摒弃的 10 年中，有几个学者仍然在坚持研究。这其中的棋手就是加拿大多伦多大学的 Geoffery Hinton 教授。\n2006 年，Hinton 在《Science》和相关期刊上发表了论文，首次提出了“深度信念网络”的概念。与传统的训练方式不同，“深度信念网络”有一个“预训练”（pre-training）的过程，这可以方便的让神经网络中的权值找到一个接近最优解的值，之后再使用“微调”(fine-tuning)技术来对整个网络进行优化训练。这两个技术的运用大幅度减少了训练多层神经网络的时间。他给多层神经网络相关的学习方法赋予了一个新名词–“深度学习”。\n很快，深度学习在语音识别领域暂露头角。接着，2012 年，深度学习技术又在图像识别领域大展拳脚。Hinton 与他的学生在 ImageNet 竞赛中，用多层的卷积神经网络成功地对包含一千类别的一百万张图片进行了训练，取得了分类错误率  15% 的好成绩，这个成绩比第二名高了近 11 个百分点，充分证明了多层神经网络识别效果的优越性。在这之后，关于深度神经网络的研究与应用不断涌现。\n\n2、结构我们延续两层神经网络的方式来设计一个多层神经网络。在两层神经网络的输出层后面，继续添加层次。原来的输出层变成中间层，新加的层次成为新的输出层。所以可以得到下图。\n\n依照这样的方式不断添加，我们可以得到更多层的多层神经网络。公式推导的话其实跟两层神经网络类似，使用矩阵运算的话就仅仅是加一个公式而已。在已知输入a(1)，参数W(1)，W(2)，W(3) 的情况下，输出 z 的推导公式如下：\ng(W(1) * a(1)) =a(2)\n\ng(W(2) * a(2)) =a(3)\n\ng(W(3) * a(3)) = z \n\n \n\n多层神经网络中，输出也是按照一层一层的方式来计算。从最外面的层开始，算出所有单元的值以后，再继续计算更深一层。只有当前层所有单元的值都计算完毕以后，才会算下一层。有点像计算向前不断推进的感觉。所以这个过程叫做“正向传播”。下面讨论一下多层神经网络中的参数。\n首先我们看第一张图，可以看出W(1)中有6个参数，W(2)中有4个参数，W(3)中有6个参数，所以整个神经网络中的参数有16个（这里我们不考虑偏置节点，下同）。\n 假设我们将中间层的节点数做一下调整。第一个中间层改为3个单元，第二个中间层改为4个单元。经过调整以后，整个网络的参数变成了33个。\n \n虽然层数保持不变，但是第二个神经网络的参数数量却是第一个神经网络的接近两倍之多，从而带来了更好的表示（represention）能力。表示能力是多层神经网络的一个重要性质。在参数一致的情况下，我们也可以获得一个“更深”的网络。\n \n上图的网络中，虽然参数数量仍然是 33，但却有 4 个中间层，是原来层数的接近两倍。这意味着一样的参数数量，可以用更深的层次去表达。\n3、效果\n\n\n\n\n\n\n\n\n与两层神经网络不同，多层神经网络中的层数增加了很多。增加更多的层次有什么好处？更深入的表示特征，以及更强的函数模拟能力。\n更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的抽象表示更深入。在神经网络中，每一层神经元学习到的是前一层神经元值的更抽象的表示。例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。\n关于逐层特征学习的例子，可以参考下图。\n \n更强的函数模拟能力是由于随着层数的增加，整个网络的参数就越多。而神经网络其实本质就是模拟特征与目标之间的真实关系函数的方法，更多的参数意味着其模拟的函数可以更加的复杂，可以有更多的 容量（capcity）去拟合真正的关系。\n通过研究发现，在参数数量一样的情况下，更深的网络往往具有比浅层的网络更好的识别效率。这点也在 ImageNet 的多次大赛中得到了证实。从 2012 年起，每年获得 ImageNet 冠军的深度神经网络的层数逐年增加，2015 年最好的方法 GoogleNet 是一个多达 22 层的神经网络。\n在最新一届的 ImageNet 大赛上，目前拿到最好成绩的MSRA团队的方法使用的更是一个深达152层的网络！关于这个方法更多的信息有兴趣的可以查阅ImageNet网站。\n4、训练在单层神经网络时，我们使用的激活函数是sgn函数。到了两层神经网络时，我们使用的最多的是sigmoid函数。而到了多层神经网络时，通过一系列的研究发现，ReLU函数在训练多层神经网络时，更容易收敛，并且预测性能更好。因此，目前在深度学习中，最流行的非线性函数是ReLU函数。ReLU函数不是传统的非线性函数，而是分段线性函数。其表达式非常简单，就是y&#x3D;max(x,0)。简而言之，在 x 大于0，输出就是输入，而在 x 小于 0 时，输出就保持为 0。这种函数的设计启发来自于生物神经元对于激励的线性响应，以及当低于某个阈值后就不再响应的模拟。\n在多层神经网络中，训练的主题仍然是优化和泛化。当使用足够强的计算芯片（例如 GPU 图形加速卡）时，梯度下降算法以及反向传播算法在多层神经网络中的训练中仍然工作的很好。目前学术界主要的研究既在于开发新的算法，也在于对这两个算法进行不断的优化，例如，增加了一种带动量因子（momentum）的梯度下降算法。　\n在深度学习中，泛化技术变的比以往更加的重要。这主要是因为神经网络的层数增加了，参数也增加了，表示能力大幅度增强，很容易出现 过拟合现象。因此正则化技术就显得十分重要。目前，Dropout 技术，以及数据扩容（Data-Augmentation）技术是目前使用的最多的正则化技术。\n5、影响目前，深度神经网络在人工智能界占据统治地位。但凡有关人工智能的产业报道，必然离不开深度学习。神经网络界当下的四位引领者除了前文所说的 Ng，Hinton 以外，还有 CNN 的发明人 Yann Lecun（法国人，杨立坤），以及《Deep Learning》的作者 Bengio。\n前段时间一直对人工智能持谨慎态度的马斯克，搞了一个 OpenAI项目http://news.cnblogs.com/n/534878/，邀请 Bengio 作为高级顾问。马斯克认为，人工智能技术不应该掌握在大公司如 Google，Facebook 的手里，更应该作为一种开放技术，让所有人都可以参与研究。\n  \n多层神经网络的研究仍在进行中。现在最为火热的研究技术包括 RNN，LSTM 等（目前是更大规模参数模型的天下了），研究方向则是图像理解方面（现在有很多，图像理解也是多模态 LLM 中必不可少的组成 ）。图像理解技术是给计算机一幅图片，让它用语言来表达这幅图片的意思。ImageNet 竞赛也在不断召开，有更多的方法涌现出来，刷新以往的正确率。\n六、回顾1、影响回顾一下神经网络发展的历程，神经网络的发展历史曲折荡漾，既有被人捧上天的时刻，也有摔落在街头无人问津的时段，中间经历了数次大起大落。从单层神经网络（感知器）开始，到包含一个隐藏层的两层神经网络，再到多层的深度神经网络，一共有三次兴起过程。详见下图。\n \n上图中的顶点与谷底可以看作神经网络发展的高峰与低谷，图中的横轴是时间，以年为单位。纵轴是一个神经网络影响力的示意表示。如果把 1949 年 Hebb 模型提出到 1958 年的感知机诞生这个 10 年视为落下（没有兴起）的话，那么神经网络算是经历了“三起三落”这样一个过程。俗话说，天将降大任于斯人也，必先苦其心志，劳其筋骨。经历过如此多波折的神经网络能够在现阶段取得成功也可以被看做是磨砺的积累吧。\n历史最大的好处是可以给现在做参考。科学的研究呈现螺旋形上升的过程，不可能一帆风顺。同时，这也给现在过分热衷深度学习与人工智能的人敲响警钟，因为这不是第一次人们因为神经网络而疯狂了。1958 年到 1969 年，以及 1985 年到 1995，这两个十年间人们对于神经网络以及人工智能的期待并不现在低，可结果如何大家也能看的很清楚。\n因此，冷静才是对待目前深度学习热潮的最好办法。如果因为深度学习火热，或者可以有“钱景”就一窝蜂的涌入，那么最终的受害人只能是自己。神经网络界已经两次有被人们捧上天了的境况，相信也对于捧得越高，摔得越惨这句话深有体会。因此，神经网络界的学者也必须给这股热潮浇上一盆水，不要让媒体以及投资家们过分的高看这门技术。很有可能，三十年河东，三十年河西，在几年后，神经网络就再次陷入谷底。根据上图的历史曲线图，这是很有可能的。\n2、效果\n\n\n\n\n\n\n\n\n下面说一下神经网络为什么能这么火热？简而言之，就是其学习效果的强大。随着神经网络的发展，其表示性能越来越强。\n从单层神经网络，到两层神经网络，再到多层神经网络，下图说明了，随着网络层数的增加，以及激活函数的调整，神经网络所能拟合的决策分界平面的能力。\n \n可以看出，随着层数增加，其非线性分界拟合能力不断增强。图中的分界线并不代表真实训练出的效果，更多的是示意效果。神经网络的研究与应用之所以能够不断地火热发展下去，与其强大的函数拟合能力是分不开关系的。\n3、外因当然，光有强大的内在能力，并不一定能成功。一个成功的技术与方法，不仅需要内因的作用，还需要时势与环境的配合。神经网络的发展背后的外在原因可以被总结为：更强的计算性能，更多的数据，以及更好的训练方法。只有满足这些条件时，神经网络的函数拟合能力才能得已体现，见下图。\n \n之所以在单层神经网络年代，Rosenblat 无法制作一个双层分类器，就在于当时的计算性能不足，Minsky 也以此来打压神经网络。但是 Minsky 没有料到，仅仅10 年以后，计算机 CPU 的快速发展已经使得我们可以做两层神经网络的训练，并且还有快速的学习算法BP。\n但是在两层神经网络快速流行的年代。更高层的神经网络由于计算性能的问题，以及一些计算方法的问题，其优势无法得到体现。直到 2012 年，研究人员发现，用于高性能计算的图形加速卡（GPU）可以极佳地匹配神经网络训练所需要的要求：高并行性，高存储，没有太多的控制需求，配合预训练等算法，神经网络才得以大放光彩。\n互联网时代，大量的数据被收集整理，更好的训练方法不断被发现。所有这一切都满足了多层神经网络发挥能力的条件。\n\n\n\n\n\n\n\n\n\n“时势造英雄”，正如Hinton在2006年的论文里说道的\n“**… provided that computers were fast enough, data sets were big enough, and the initial weights were close enough to a good solution. All three conditions are now satisfied.**”，\n 外在条件的满足也是神经网络从神经元得以发展到目前的深度神经网络的重要因素。除此以外，一门技术的发扬没有“伯乐”也是不行的。在神经网络漫长的历史中，正是由于许多研究人员的锲而不舍，不断钻研，才能有了现在的成就。前期的 Rosenblat，Rumelhart 没有见证到神经网络如今的流行与地位。但是在那个时代，他们为神经网络的发展所打下的基础，却会永远流传下去，不会退色。\n参考文献　　1.Neural Networks\n　　2.Andrew Ng Neural Networks \n　　3.神经网络简史\n　　4.中科院 史忠植 神经网络 讲义\n　　5.深度学习 胡晓林\n","slug":"llm/shenduxuexi-shenjingwangluo","date":"2024-12-25T09:46:44.000Z","categories_index":"LLM","tags_index":"neural network,marchine learning","author_index":"glmapper"},{"id":"7bb9924a7e1cee47f31fec8a03bac95f","title":"OTeL & Micrometer 在 Spring Boot 中的应用与分析","content":"之前在 聊聊 SpringBoot3 的 Micrometer Tracing 这篇文章中我介绍了 SpringBoot3 使用 Micrometer Tracing 来作为分布式链路组件的来龙去脉，在那篇文章中也提及了 SpringBoot  在 可观测性部分官方默认使用的是 Micrometer 来实现。\n实际上，在可观测性部分，OpenTelemetry  正在往大一统的方向不断前进，SpringBoot 即时默认使用 Micrometer 来补充其在可观测性上的板块，但是社区也从未停止过对于 SpringBoot 集成 OpenTelemetry 讨论；SpringBoot 实际上先是在 tracing 上完成了对于 OTEL tracing 的桥接，但是对于 metrics 却迟了一些动作，可以从这里看到关于 SpringBoot 对于可观测性的计划 Observability Planning。关于 OpenTelemetry support in Spring 的讨论，在这个 issue 中有比较详细的记录 Consolidate OpenTelemetry support in Spring。\n在本篇文章中，我将向您介绍如何使用 OpenTelemetry Java agent 来捕获 SpringBoot Metrics。并希望通过本篇来了解 Micrometer metrics 以及 OpenTelemetry metrics 在指标收集中的差异以及两种报文协议的区别。\n环境及前置步骤准备\n环境\n\n\n\n\n项目\n版本\n\n\n\nmacOS\n14.4\n\n\njdk\n21\n\n\nSpringboot\n3.2.3\n\n\n\n基本依赖\n\n12345678910111213&lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;      &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;  &lt;/dependency&gt;\n\n这里仅提供了最基本的 web 工程的依赖，你可以在 idea 或者 start.spring.io 来初始化一个测试工程。\n基于 Micrometer metrics 的指标收集基于前面的环境和前置步骤，搭建一个简单的 SpringBoot 样例工程。前面提到，SpringBoot 默认使用 micrometer 来实现指标的收集，下面在依赖中添加基于 Prometheus 协议的 registry 来暴露 micrometer 指标。\n12345&lt;!--注意这里使用的是 micrometer-registry-prometheus，在后面将会替换成 otlp 的--&gt;&lt;dependency&gt;  &lt;groupId&gt;io.micrometer&lt;/groupId&gt;  &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt;\n\n在 配置文件中配置暴露 prometheus endpoint。\n1management.endpoints.web.exposure.include=prometheus\n\n启动应用之后，可以通过 http://localhost:8080/actuator/prometheus 来查看默认的一些指标信息。关于指标信息的解释可以查阅 springboot 官方文档 Metrics。这里我添加一个默认的自定义指标 hello.total 来统计调用 &#x2F;hello 接口的次数，以便于后面来区分不同协议中的表现，代码如下：\n1234567891011121314@RestControllerpublic class HelloController &#123;    private final MeterRegistry registry;    public HelloController(MeterRegistry registry) &#123;        this.registry = registry;    &#125;    @RequestMapping(&quot;hello&quot;)    public String hello() &#123;        this.registry.counter(&quot;hello.total&quot;).increment();        return &quot;hello glmapper&quot;;    &#125;&#125;\n\n请求此接口之后得到的指标信息如下：\n1234➜  ~ curl -i http://localhost:8080/actuator/prometheus | grep hello_total# HELP hello_total# TYPE hello_total counterhello_total 1.0\n\n\n\n到这里，初步完成相关的准备工作，这里提供出去的 &#x2F;actuator&#x2F;prometheus 实际上就是我们常规生产环境中对外暴露的监控数据获取的 endpoint，以便于 promethus 来拉取指标数据，这里不在赘述。\n使用 OpenTelemetry Collector 来抓取  &#x2F;actuator&#x2F;prometheus 数据首先，需要部署一个  OpenTelemetry Collector ，这里可以根据官方文档来部署，https://opentelemetry.io/docs/collector/installation/。我这里是从 GitHub 下载的可执行文件安装的，可以根据你的操作系统来选择具体的可执行文件下载。然后根据官方文档的配置来创建一个 config.yaml 文件，用于指定相应的 receivers 和 exporters，下面是参考官方文档创建的配置文件：\n1234567891011121314151617181920receivers:  prometheus:    config:      scrape_configs:        - job_name: &quot;springboot-otel-guides&quot;          scrape_interval: 5s # 采集的时间间隔          metrics_path: &#x27;/actuator/prometheus&#x27; #采集的目标服务对外提供的 metric endpoint path          static_configs:            - targets: [&quot;localhost:8080&quot;] #采集的目标服务地址exporters:  prometheus:    endpoint: &quot;localhost:8889&quot; #收集器对外暴露访问的地址，这里仅配置了 prometheus 的 exportersservice:  pipelines:    metrics:      receivers: [prometheus]  # 使用 prometheus 协议，对应上面的 receivers#prometheus      processors: [batch]      exporters: [prometheus] # 对应上面 exporters#prometheus\n\n启动 OTEL Collector\n1./otelcol --config=config.yaml\n\n启动日志大致如下：\n12345678910Downloads ./otelcol-contrib_0.96.0_darwin_arm64/otelcol-contrib --config=config.yaml2024-03-21T15:58:26.162+0800\tinfo\tservice@v0.96.0/telemetry.go:55\tSetting up own telemetry...2024-03-21T15:58:26.162+0800\tinfo\tservice@v0.96.0/telemetry.go:97\tServing metrics\t&#123;&quot;address&quot;: &quot;:8888&quot;, &quot;level&quot;: &quot;Basic&quot;&#125;2024-03-21T15:58:26.162+0800\tinfo\tservice@v0.96.0/service.go:143\tStarting otelcol-contrib...\t&#123;&quot;Version&quot;: &quot;0.96.0&quot;, &quot;NumCPU&quot;: 8&#125;2024-03-21T15:58:26.162+0800\tinfo\textensions/extensions.go:34\tStarting extensions...2024-03-21T15:58:26.163+0800\tinfo\tprometheusreceiver@v0.96.0/metrics_receiver.go:240\tStarting discovery manager\t&#123;&quot;kind&quot;: &quot;receiver&quot;, &quot;name&quot;: &quot;prometheus&quot;, &quot;data_type&quot;: &quot;metrics&quot;&#125;2024-03-21T15:58:26.164+0800\tinfo\tprometheusreceiver@v0.96.0/metrics_receiver.go:231\tScrape job added\t&#123;&quot;kind&quot;: &quot;receiver&quot;, &quot;name&quot;: &quot;prometheus&quot;, &quot;data_type&quot;: &quot;metrics&quot;, &quot;jobName&quot;: &quot;springboot-otel-guides&quot;&#125;2024-03-21T15:58:26.164+0800\tinfo\tservice@v0.96.0/service.go:169\tEverything is ready. Begin running and processing data.2024-03-21T15:58:26.164+0800\twarn\tlocalhostgate/featuregate.go:63\tThe default endpoints for all servers in components will change to use localhost instead of 0.0.0.0 in a future version. Use the feature gate to preview the new default.\t&#123;&quot;feature gate ID&quot;: &quot;component.UseLocalHostAsDefaultHost&quot;&#125;2024-03-21T15:58:26.164+0800\tinfo\tprometheusreceiver@v0.96.0/metrics_receiver.go:282\tStarting scrape manager\t&#123;&quot;kind&quot;: &quot;receiver&quot;, &quot;name&quot;: &quot;prometheus&quot;, &quot;data_type&quot;: &quot;metrics&quot;&#125;\n\n通过 http://localhost:8889/metrics 访问，查看之前自定义的 hello_total\n1234➜  ~ curl -i http://localhost:8889/metrics | grep hello_total# HELP hello_total# TYPE hello_total counterhello_total&#123;instance=&quot;localhost:8080&quot;,job=&quot;springboot-otel-guides&quot;&#125; 1\n\n这里我仅是将 Micrometer 采集的指标数据（本质上使用的是 PromethusMeterRegistry，而不是 Micrometer 默认的 SimpleMeterRegistry）通过 promethus 协议同步到 OpenTelemetry Collector。下面来将 Micrometer 采集的方式换成 OpenTelemetry Java Agent  方式采集。\n使用 OpenTelemetry Java Agent 代替 Micrometer前面我配置了 OpenTelemetry Collector 来抓取 Micrometer 采集的数据，这小节会使用 OpenTelemetry Java Agent 代替 Micrometer 来收集指标，使用 OpenTelemetry Line Protocol (otlp) 协议来提供指标数据给 OpenTelemetry Collector。\n\n1、首先将前面的 config.yaml  配置文件修改使用 otlp 协议\n\n12345678910111213141516receivers:  otlp:    protocols:      grpc:      http:exporters:  prometheus:    endpoint: &quot;localhost:8889&quot; # 还是适用 prometheus 对外暴露数据service:  pipelines:    metrics:      receivers: [otlp] # 这里使用 otlp 协议      processors: [batch]      exporters: [prometheus]\n\n\n2、下载  OpenTelemetry Java Agent\n\n从  github 上下载  agent，地址：https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases；默认情况下，代理中的指标是禁用的，这里可以通过设置环境变量来启用 OTEL_METRICS_EXPORTER=otlp。\n12export OTEL_METRICS_EXPORTER=otlpjava -javaagent:opentelemetry-javaagent.jar  -jar target/springboot-otel-guides-0.0.1-SNAPSHOT.jar\n\n\n3、移除关于 promethus 的配置和依赖\n\n12345678# application.properties 中移除management.endpoints.web.exposure.include=prometheus# pom.xml 中移除&lt;dependency&gt;    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;    &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;\n\n重新启动 OTEL Collector 和 应用程序之后，再次访问 &#x2F;hello，然后查看指标信息\n1234➜  ~ curl -i http://localhost:8889/metrics | grep hello_total# HELP hello_total# TYPE hello_total counterhello_total&#123;job=&quot;springboot-otel-guides&quot;&#125; 1 #指标的表现形式和之前不同\n\n\n\n前面两种，我使用了两种不同的采集方式(PromethusMeterRegistry 和 OpenTelemetryMeterRegistry) 和 两种不同的 receivers 方式将指标信息采集到 OpenTelemetry Collector 中。在这篇文章中提到的指标差异问题，在我的测试过程中其实体现不是很明显，从源码调试中捕获到的信息是，Micrometer 的 Metrics.globalRegistry 中，除了opentelemetry-javaagent 中的OpenTelemetryMeterRegistry 之外，还有 Micrometer 自己的 SimpleMeterRegistry，但是实际情况看起来是 runtime 使用了 OpenTelemetryMeterRegistry 而不是 SimpleMeterRegistry，这也就和文章中提及的可能注册”错误的 MeterRegistry 实例” 的条件没有成立。\n实际上，SpringBoot 已经默认集成了 otlp exporters，其基本具备和 promethus 同样的接入方式。下面的案例中，将会去除 agent，直接使用 otlp registry。\nSpringBoot 使用 otlp registry因为在前面的步骤中已经移除了 promethus 相关的依赖和配置，应用服务通过集成 agent 来采集指标数据，在下面的测试中，将会移除 agent，然后引入新的依赖，使得能够使用 otlp 协议来发布指标数据。\n\n引入 micrometer-registry-otlp 和 opentelemetry-exporter-otlp 依赖\n\n1234567891011&lt;dependency&gt;     &lt;groupId&gt;io.micrometer&lt;/groupId&gt;     &lt;artifactId&gt;micrometer-registry-otlp&lt;/artifactId&gt;     &lt;version&gt;1.12.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;     &lt;artifactId&gt;opentelemetry-exporter-otlp&lt;/artifactId&gt;     &lt;version&gt;1.36.0&lt;/version&gt; &lt;/dependency&gt;\n\n\n配置  management.otlp.metrics.export.ur\n\n1management.otlp.metrics.export.url=http://localhost:4318/v1/metrics\n\n\n修改 OpenTelemetry Collector 配置\n\n123456789101112131415161718receivers:  otlp:    protocols: # otlp 对应的两种协议方式      grpc:        endpoint: localhost:4317      http:        endpoint: localhost:4318exporters:  debug:    verbosity: detailed  file:    path: /Users/glmapper/Downloads/metrics-otlp.json # 为了方便查看，这里我将指标信息直接 export 到文件中  service:  pipelines:    metrics:      receivers: [otlp] # 使用 otlp      exporters: [file] # 使用 file\n\n\n\n\n\n\n\n\n\n\nPS：OtlpMeterRegistry 中默认使用了 http 协议，并通过 http://localhost:4318/v1/metrics 接口向 OpenTelemetry Collector  POST 指标数据。\n重新启动 OpenTelemetry Collector 和应用服务程序，下面是访问 &#x2F;hello 之后，采集到的自定义指标数据如下：\n1234567891011121314&#123;    &quot;name&quot;: &quot;hello.total&quot;,    &quot;sum&quot;: &#123;        &quot;dataPoints&quot;: [            &#123;                &quot;startTimeUnixNano&quot;: &quot;1711090372507000000&quot;,                &quot;timeUnixNano&quot;: &quot;1711090415605000000&quot;,                &quot;asDouble&quot;: 1            &#125;        ],        &quot;aggregationTemporality&quot;: 2,        &quot;isMonotonic&quot;: true    &#125;&#125;,\n\n从这里数据结构看，与前面使用 promethus 协议的指标数据结构差异是非常大的 \n123# HELP hello_total # TYPE hello_total counterhello_total&#123;job=&quot;springboot-otel-guides&quot;&#125; 2\n\n\n\n这里我把 两种协议版本的数据样例格式提供一下，以便于需要的同学自行查看\n\notlp v1.1.0 版本的数据格式，其内部通过 opentelemetry/proto/resource/v1/metrics.proto 来描述\nprometheus 指标数据格式，其内部通过 io.prometheus.client.Collector.MetricFamilySamples 来描述\n\n从源码角度分析 prometheus 和 otlp 协议的指标收集这里主要以 micrometer 来看，围绕 micrometer-registry-otlp 和 micrometer-registry-prometheus 两个依赖实现的 MeterRegistry 指标收集代码来分析。MeterRegistry 作为 Micrometer 提供的指标管理的顶层抽象类，其除了提供一组共不同厂商扩展的抽象方法（如 newCounter等）之外，主要核心能力是内部通过维护一个 CHM 类型的 meterMap 来统一管理 Meter 数据。 micrometer-registry-otlp 和 micrometer-registry-prometheus  两个包中最核心的也就是对于 MeterRegistry 抽象类的子类扩展实现。从指标数据的透出方式来看， micrometer-registry-otlp  是通过一个定时任务线程池来主动将指标数据 report 给 OpenTelemeter Collector，而  micrometer-registry-prometheus   则是提供一个对外访问的 endpoint 以供收集器来拉取指标数据。\nprometheus#PrometheusMeterRegistryprometheus 的实现 SpringBoot 对外提供的 endpoint 对应的类是 PrometheusScrapeEndpoint，其数据是从它内部持有的 collectorRegistry 对象获取，CollectorRegistry负责维护当前系统中所有的Collector实例。 HTTPServer在接收到HTTP请求之后，会从 CollectorRegistry 中拿到所有的Collector实例，并调用其collect()方法获取所有样本，最后格式化为 Prometheus 的标准输出。CollectorRegistry 是 prometheus 客户端提供的能力。同样持有 CollectorRegistry 还有 PrometheusMeterRegistry，前面提到在 micrometer 中所有的指标数据是存在 meterMap 中的，但是在创建 Meter 时，PrometheusMeterRegistry 也会将 Meter 通过 applyToCollector 方法同步到 CollectorRegistry，这样就实现了 prometheus 和 micrometer 对于指标数据的链接。\n\notlp#OtlpMeterRegistry这里主要分析下 OtlpMeterRegistry 的 push 模型，OtlpMeterRegistry 实现了 micrometer PushMeterRegistry 类，其内部提供了 publish 方法的实现，OtlpMeterRegistry#publish 实现了 meter 到 OpenTelemetry 的具体逻辑。\n\n当流量进入之后，经过 &#x2F;hello 接口中的自定义埋点代码，此时 meterRegistry 的注入实例为 OtlpMeterRegistry；但是实际上 OtlpMeterRegistry 对于 meter 数据并没有像 prometheus 那样还提供了内部自己模型的桥接逻辑 ，OtlpMeterRegistry 数据的管理是完全依托于 MeterRegistry 的。\n从架构角度分析 OpenTelemetry Collector 数据流向这里包括前面实例中的几种场景，首先是 OpenTelemetry Collector pull 应用服务 prometheus endpoint 吐出的数据，otlp collector 使用的是 receiver 和 expose 使用的是 prometheus 协议。\n\n第二个是使用 OpenTelemetry Java instrumentation agent 收集指标的数据流向\n\n最后是使用  micrometer-registry-otlp  方式，它使用的是类似于 micrometer-registry-prometheus  通过业务系统中通过代码打点的方式采集的，但是上报方式是和 agent 上报是一致的，这里就不单独提供数据流程示意图了。\n总结本文主要是研究 SpringBoot 如何集成 metrics ，文章中提供了机遇 micrometer 和 agent 两种指标采集的形式；基于 micrometer 的方式又细分了基于 prometheus 协议和 otlp 协议两种方式。并且在使用 Otel collector 作为指标数据的中间组件，并提供了相应的实示例代码和示意图。希望通过本文能够帮助大家使用和理解 Springboot 中对于 micrometer 和 otlp 收集指标数据的基本流程和原理。\n","slug":"middleware/middleware-micrometer-otel","date":"2024-09-09T07:44:30.000Z","categories_index":"Middleware","tags_index":"Metrics,OTLP","author_index":"glmapper"},{"id":"f39ea97e417100cd6078bb8210dec4a8","title":"Dubbo Metrics 基本原理及扩展 OTLP 协议","content":"\n\n\n\n\n\n\n\n\n关于 dubbo metrics 的使用可以参考dubbo-metrics 和  可观测性 Metrics Proposal 两篇文档。\ndubbo 的 metrics 目前是基于 micrometer 实现，这里关于整体的代码结构与工作流程官方文档中阐述的比较清楚，本篇文档主要是补充官方文档之外的更多代码实现细节上的内容，以及简要阐述如何将 metrics 通过 OTLP 协议对外暴露的实现思路。\n理解 MetricsEvent、MetricsListener、MetricsCollector 和 MetricsDispatcherdubbo metrics 数据收集主要入口是 provider 端的 MetricsClusterFilter 和 consumer 端的 MetricsFilter 两个 Filter 扩展。metrics 数据的流转是通过 个事件总线进行的异步化处理，以降低埋点这种非核心代码的耦合度，从而有效的降低指标埋点所带来的性能消耗。\nMetricsEventMetricsEvent 抽象类，在 Dubbo 的度量系统中主要用于封装和处理度量事件；TimeCounterEvent 在 Dubbo 的度量系统中用于标记某些类型的事件，并允许自动记录开始和结束时间，提供时间对 TimePair，它提供了一种灵活的方式来处理和记录度量事件的时间信息。下图是 MetricsEvent 的类图结构：\n\n\nMetricsEvent：\n存储度量事件的源对象，即 ApplicationModel 实例。这个实例包含了应用的所有信息，如服务、模块、实例等。 \n提供了一种机制来附加额外的信息到度量事件中。这些信息可以通过 attachments 字段来存储和获取\n提供了一个 MetricsDispatcher 实例，用于分发度量事件。\n提供了一种方式来检查度量事件的可用性。如果度量事件不可用，那么它将不会被分发\n提供了一个 TypeWrapper 实例，用于确定度量事件的类型。\n提供了一种方式来自定义度量事件在被发布后的行为，这可以通过覆盖 customAfterPost 方法来实现。\n\n\nTimeCounterEvent ：\n继承了 MetricsEvent 类的所有功能，如存储度量事件的源对象，附加额外的信息到度量事件中，分发度量事件等。 \n提供了一个 TimePair 实例，用于记录事件的开始和结束时间。这个实例在类的构造函数中通过 TimePair.start() 方法创建\n提供了一个 getTimePair 方法，用于获取记录的时间对\n\n\n\n其他的诸如 MetadataEvent 等均属于某特定场景的子类事件，读者可以自行查看。\nMetricsListenerMetricsListener 定义了一个度量事件监听器应该具备的基本行为，其内部提供一个 onEvent 方法，用于度量事件发生时被调用。MetricsLifeListener 在 MetricsListener 基础上扩展了事件的两个生命周期方法 ：onEventFinish 和 onEventError，这两个方法分别在一个度量事件完成和出错时被调用。\nMetricsListener 子类扩展出了两个部分，一块是 xxxListener ，一块是 xxxCollector。可以参考下面两张图所示：\n\nMetricsListener\n\n\n\nMetricsCollector\n\n\n从类图结构和代码分析来看，指标数据的采集最终会由 MetricsCollector 来完成，MetricsCollector 依托 MetricsListener 监听 Dubbo 服务的调用事件，收集各种指标数据。实际上在阅读代码的过程中发现，当 MetricsEventBus 接收到发布的信息时，首先是将信息转发到所有 MetricsCollector 中，如下图所示：\n\n对于 CombMetricsCollector 的实现（上面 4 种均是），它们又会调用自己创建的 MetricsEventMulticaster 再次转发消息，到具体指标的监听器，然后这些监听器就会根据自己的逻辑修改 Collector 中的指标计数。\nMetricsDispatcherMetricsDispatcher 本质上就是一个简单的度量事件发布器，它实现了 MetricsEventMulticaster 接口。这个类的主要职责是管理度量事件的监听器，并在度量事件发生时通知这些监听器。其父类 SimpleMetricsEventMulticaster 中维护了一个 listeners 列表用于存储所有的度量事件监听器，这套设计应该是有参考 spring 的事件机制实现的。\n\n\n\n\n\n\n\n\n\n在 MetricsDispatcher 的构造方法中，会通过 dubbo 自身的 SPI 机制将框架默认的一些 MetricsCollector 添加到 listeners 列表中。\n实际上，这里的 MetricsDispatcher 并不是单纯只有一个 MetricsDispatcher，而是一组。\n\n它们均继承自 SimpleMetricsEventMulticaster，因此它们都具有注册监听、转发事件的能力；每个 SubDispatcher 会绑定一个 Collector ，以 DefaultSubDispatcher 为例\n\nDefaultSubDispatcher主要负责注册核心RPC调用次数指标，包括：\n\n请求次数 （METRIC_REQUESTS）\n请求成功次数（METRIC_REQUESTS_SUCCEED）\n请求失败次数（METRIC_REQUEST_BUSINESS_FAILED）\n\n这三个指标在内部实现上会映射成三个 MetricsCat，MetricsCat 是一个封装类，它包含了 MetricsKey 的行为，保存了键的完整内容（MetricsPlaceValue），对应的收集器（CombMetricsCollector），以及键级别的事件监听器（AbstractMetricsKeyListener），它将这些组合在一起，提供了一种灵活的方式来处理度量事件，借用官方文档中的描述就是：为特定指标生产指标监听器的工厂。\n理解 MetricsReporter这部分主要是指标上报相关的核心设计。MetricsReporter 是将 Metrics 信息暴露给外部系统，dubbo 中默认提供了两种指标报告器 DefaultMetricsReporter 和 PrometheusMetricsReporter，如下图所示：\n\n每个 MetricsReporter 都对应一个 MetricsReporterFactory，这里就是简单工厂模式的实现。\n\n下面分析下 MetricsReporter 初始化的逻辑。\ninitMetricsReporter 初始化逻辑解析 在应用的初始化和启动过程中（具体代码参考：org.apache.dubbo.config.deploy.DefaultApplicationDeployer），通过 initMetricsReporter 方法来完成，下面摘取和 MetricsReporter 相关的部分代码：\n1234567891011121314151617181920212223// 通过 SPI 机制获取 MetricsReporterFactoryMetricsReporterFactory metricsReporterFactory =                getExtensionLoader(MetricsReporterFactory.class).getAdaptiveExtension();MetricsReporter metricsReporter = null;try &#123;  \t// 通过 MetricsReporterFactory 创建 MetricsReporter    metricsReporter = metricsReporterFactory.createMetricsReporter(metricsConfig.toUrl());&#125; catch (IllegalStateException e) &#123;    // 省略&#125;// MetricsReporter 初始化metricsReporter.init();applicationModel.getBeanFactory().registerBean(metricsReporter);// 如果当前不是使用默认协议，则也将默认的 MetricsReporter 创建出来// 实际上目前仅提供了 default 和 prometheus 两种协议实现方式if (!PROTOCOL_DEFAULT.equals(metricsConfig.getProtocol())) &#123;    DefaultMetricsReporterFactory defaultMetricsReporterFactory =            new DefaultMetricsReporterFactory(applicationModel);    MetricsReporter defaultMetricsReporter =            defaultMetricsReporterFactory.createMetricsReporter(metricsConfig.toUrl());    defaultMetricsReporter.init();    applicationModel.getBeanFactory().registerBean(defaultMetricsReporter);&#125;\n\n\n\n\n\n\n\n\n\n\nDubbo 在 metrics 部分的设计使用了非常多的 SPI 扩展能力，包括 MetricsReporterFactory、MetricsCollector 等等，dubbo 作为一个通信框架，使用基于 SPI 而不是  AutoConfiguration （springboot 中的机制），应该也是不期望框架本身过度耦合 Springboot。\n基于事件驱动的埋点逻辑链路Dubbo 指标采集的整体设计思路基于事件驱动编程思想，其大体的事件处理链路如下（参考官方提供）：\n\n上面这张图，笔者一开始在分析的过程中其实有不少问题；从消息总线到指标转发器，再到指标转发器&#x2F;收集器，最后到指标监听器，事件的流转和二次发布理解起来还是有一些成本在的；在 debug 过程中，结合下面线程堆栈，自下而上，第一次事件发布，消费者是在收集器；第二次事件发布，消费者是监听器，最后再由收集器转存到 BaseStatComposite 中去。\n\n因此这里对上图进行补充，将存储和 export&amp;reporter 也放进来，形成一个完整的结构图\n\n扩展 OTLP 协议笔者在 架构解析系列-OTeL &amp; Micrometer 在 Spring Boot 中的应用与分析 这篇文中分析了 springboot 中对于 OTeL &amp; Micrometer 的使用分析，springboot 提供的 埋点机制和 dubbo 中提供的是一样的，底层都是基于 Micrometer api，上层协议透出主要是依赖于 Micrometer 提供的不同sdk，主流的就是 prometheus 和 otlp。在 dubbo 社区的 这个提案 issue 中，已经提供了一些思路，笔者基于 dubbo 3.2.x 版本进行了初步的集成和测试，目前已经提交社区进行讨论，期待进一步的沟通和 approve。\n\n\n\n\n\n\n\n\n\n因为 prometheus 和 otlp 使用的是两种不同的数据推送方式，prometheus 使用的是 pull 的方式，即提供一个 endpoint 出去（PushGateway 也是基于 push）；而 otlp 的实现则是通过 push 的方式。在推送的数据量中，prometheus 协议一次性推送了全量数据，otlp 则是按批推送。\n总结本篇的出发点是这个提案 issue，期望通过洞悉 dubbo 埋点的内部实现来找到 otlp 协议吐出的切入点。整体看来，dubbo 的 metrics 的实现逻辑还是比较清晰的，而且官方文档中对于 metrics 部分的源码分析也非常详细。笔者在参阅了官方文档和结合自己理解以及逐步 debug 逻辑，也基本摸清了dubbo 的实现逻辑，本篇作为学习备忘记录下来，也分享给更多的同学。\n","slug":"middleware/middleware-dubbo-metrics","date":"2024-09-09T07:43:22.000Z","categories_index":"Middleware","tags_index":"Dubbo,Metrics,OTLP","author_index":"glmapper"},{"id":"75a9f38981cbb37e9f3b4b30830b22d2","title":"浅谈 JAVA 中的垃圾回收机制","content":"在现代编程语言中，垃圾回收机制（Garbage Collection）扮演着至关重要的角色，尤其在 Java 语言中更是如此。Java 作为一门广泛应用于企业级开发的编程语言，通过自动化的内存管理，极大地简化了开发者的工作。然而，垃圾回收机制的复杂性也带来了许多挑战和性能优化的需求。本文将深入探讨 Java 中的垃圾回收机制，从基础原理到具体收集器的工作方式，再到如何进行垃圾回收调优，帮助开发者更好地理解和应用这一关键技术。\n\n\nGC 要解决的问题本质是什么这里没有必要再和各位读者讨论什么是垃圾以及什么是垃圾回收；也相信绝大多数的 Java 开发者也都多少背过一些面试的八股文，比如如何识别垃圾 ？当你提到引用计数法的时候，可能面试官已经预测到你要说 可达性分析法 了。不过这里笔者还是将 Oracle Java 官方文档关于 GC 的一段描述放在这里：\n\n\n\n\n\n\n\n\n\nAutomatic garbage collection is the process of looking at heap memory, identifying which objects are in use and which are not, and deleting the unused objects. An in use object, or a referenced object, means that some part of your program still maintains a pointer to that object. An unused object, or unreferenced object, is no longer referenced by any part of your program. So the memory used by an unreferenced object can be reclaimed.\n自动垃圾收集是查看堆内存、识别哪些对象正在使用、哪些未使用，并删除未使用的对象的过程。正在使用的对象或引用的对象意味着程序的某些部分仍然维护着指向该对象的指针。程序的任何部分都不再引用未使用的对象或未引用的对象。因此，未被引用的对象所使用的内存可以被回收。\n从这段描述中，可以这样理解：GC 的作用是收集无效的对象（未使用的对象或未引用的对象），进而释放掉这些无效对象所占用的内存空间。那换个思路：如果物理内存空间是无限大的，那么是不是可以不需要去关注这些无效的对象？这显然是理论上的可能性。因此 GC 要解决的问题的本质是 因内存资源的稀缺性带来的如保障有足够空间来分配对象、保障不会因过多无效对象影响计算机缓存结构的访问效率以及硬件成本等问题。\n另外，不得不提一下，GC 技术并不是 Java 所特有的，也不是 Java 语言开发者所提出的。GC 技术早在 Java 语言问世前 30 多年就已经发展和成熟起来了， Java 语言所做的不过是把这项神奇的技术带到了广大程序员身边而已。笔者查阅了相关资料，1960 年前后诞生于 MIT 的 Lisp 语言是第一种高度依赖于动态内存分配技术的语言， Lisp 中几乎所有数据都以“表”的形式出现，而“表”所占用的空间则是在堆中动态分配得到的。 Lisp 语言先天就具有的动态内存管理特性，这也就意味着要求 Lisp 语言的设计者必须解决堆中每一个内存块的自动释放问题，这也就直接促使了 GC  技术初始雏形。\n好了，到这里，我想先抛出这篇文章所要阐述的第一个问题，即不管是 Java 还是 Lisp 语言都提及的动态内存分配技术，那么为什么动态内存分配技术必须要使用 GC 机制来兜底呢？\n内存分配机制这里简单回顾一下内存分配的主要方式。我们知道，大多数主流的语言或运行环境都支持三种最基本的内存分配方式，它们分别是：\n\n静态分配（ Static Allocation ）：在程序编译时确定内存的分配和大小，并且在程序整个生命周期内这部分内存不会改变。静态分配就像你在家中固定安装的一个书架，用来存放特定数量的书籍。这个书架的大小和位置在你安装好之后就不会再改变。\n\n自动分配（ Automatic Allocation ）：由编译器在函数调用时自动分配和释放内存。通常用于函数内部的局部变量，内存分配在函数调用时进行，在函数返回时释放。如：你在家中进行烹饪时，临时使用一个菜板切菜。使用完后，你会立即清洗并收好，菜板的使用是临时的，且与烹饪过程直接相关。\n\n动态分配（ Dynamic Allocation ）：在程序运行时根据需要动态分配内存，并且需要显式地释放内存。通常使用内存管理函数如 malloc、free 等。如：你在家中举办派对，根据派对人数临时租用桌椅。派对结束后，你需要联系租赁公司将桌椅归还。这种情况下，桌椅的数量和使用时间都是灵活的。\n\n\n静态分配和自动分配不需要垃圾回收（GC）的原因在于其内存生命周期固定且由编译器自动管理。静态分配在程序启动时确定，内存始终有效，直到程序结束；自动分配用于函数内部的局部变量，函数调用时分配，结束时自动释放。这两种分配方式内存管理简单且确定，不存在内存泄漏或悬挂指针问题，因此自然而安就无需 GC 介入。而动态分配是在运行时进行内存分配，通常这些内存分配的动作是在代码中通过 malloc/free、new/delete 等关键字进行申请和释放。\n这就取决于编写代码的程序员的技术能力，还有就是对于代码整体的掌控能力；如果处理不当，则可能会引发下面的一些问题：\n\n内存泄漏：当程序员分配内存但忘记释放内存时，就会发生这种情况。随着系统运行时间的拉长，这些未释放的内存块会慢慢累积，导致可用内存逐渐减少，最终可能会使应用程序或系统崩溃。\n悬空指针：仍在使用或稍后将使用的内存会过早释放，访问此类内存空间可能会导致未定义的行为，从而导致应用程序崩溃或不可预知的结果。\n双重释放：程序员试图取消分配已释放空间的问题，可能会损坏内存并导致不稳定的行为。\n\n为了省去上述手动内存管理的麻烦，大佬们钻研开发出了 GC ，即如果把内存管理交给计算机，程序员就不用去主动释放内存了。在手动内存管理中，程序员要判断哪些是不用的内存空间（垃圾）和时刻留意内存空间的寿命。通过引入 GC 机制来解决程序员在手动内存管理上所带来的一系列问题，从而大大减轻程序员的负担和编程的复杂度，让程序员告别繁琐的内存管理，把精力集中在更本质的编程工作上。这就是动态内存分配技术需要使用 GC 机制来兜底的原因。\nJAVA 中的 GC 机制前面介绍了GC 要解决的问题本质是什么以及动态内存分配和GC 的关系，本小节主要来看看 JAVA 中的 GC 机制。Java 中垃圾回收由 Java 虚拟机 （JVM） 负责。要了解 Java 中的垃圾回收工作原理，首先必须了解 Java 内存模型的结构。\n\nJava 的内存管理实际上就是对象的管理，其中包括对象的分配和释放，而对象的分配一般是在堆上，因此 GC 的主要工作区域是堆。\n关于可达性分析和三色标记法这里主要是讨论 JVM 判断对象存活的算法，常见的是引用计数法和可达性分析算法\n\n引用计数法：给对象添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；计数器为 0 的对象就是不可能再被使用的对象。这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。\n可达性分析算法：这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。\n\n当前主流的 JVM 实现中，已经摒弃了引用计数法，主要以可达性分析算法的实现为主，但是基本的可达性分析算法也同样存在问题，主要是 STW 时间长。\n可达性分析的整个过程都需要 STW，以避免对象的状态发生改变，这就导致GC停顿时长很长，大大影响应用的整体性能。为了解决上面这些问题，就引入了三色标记算法。\n三色标记算法（Tricolor Marking Algorithm）是一种基于可达性分析的垃圾回收算法。它将对象状态分为三种：白色、灰色、黑色，其中：\n\n白色（White）：表示对象未被访问过，即还未进行可达性分析。\n\n灰色（Gray）：表示对象已被访问过，但其引用的对象尚未进行可达性分析。\n\n黑色（Black）：表示对象已被访问过，并且其引用的对象也已进行了可达性分析。\n\n\n同时将标记过程可以分为三个阶段：初始标记（Initial Marking）、并发标记（Concurrent Marking）和重新标记（Remark）。三个标记阶段中，初始标记和重新标记是需要 STW ，而并发标记是不需要 STW。其中最耗时的其实就是并发标记的这个阶段，因为这个阶段需要遍历整个对象树，而三色标记把这个阶段做到了和应用线程并发执行，也就大大降低了 GC 的停顿时长。\n分代 GC 的基本过程目前 Java 中主要使用的分代垃圾回收机制，即使是 G1 以 region 概念进行的分区管理方式，也仍旧保留了分代的概念。这里主要依据是分代假说理论。\n\n\n\n\n\n\n\n\n\n分代假说主要思想：在大多数情况下，大部分对象的生命周期很短暂，而少部分对象的生命周期较长。\n基于分代假说，GC 算法通常会针对不同代使用不同的策略。例如，年轻代常使用复制算法（Copying Algorithm）或标记-复制算法（Mark-Compact Algorithm）进行垃圾回收，而老年代则可能使用标记-清除算法（Mark and Sweep Algorithm）或标记-整理算法（Mark-Compact Algorithm）。这种分代的思想是基于实践观察和优化策略而提出的，旨在通过不同的策略和算法，针对对象的生命周期特点，提高垃圾回收的效率和性能。下面是分代垃圾回收的基本过程。\n\n1、任何新对象都会被分配到 eden 空间，两个 survior 空间一开始都是空的。\n\n\n\n2、当 eden 空间填满时，将触发 minor GC。\n\n\n\n3、引用的对象将移动到第一个 survior 空间。清除 eden 空间时，将删除未引用的对象。\n\n\n\n4、在下一个minor  GC 中，eden 空间也会发生同样的事情。删除未引用的对象，并将引用的对象移动到 survior 空间。但是，在这种情况下，它们被移动到第二个 survior 空间 （S1）。此外，第一个 survior 空间 （S0） 上最后一个 minor GC 中的对象的年龄会递增并移动到 S1。将所有幸存的对象移动到 S1 后，S0 和 eden 都会被清除。此时在 survior 空间中有不同年龄的对象。\n\n\n\n5、在下一个minor GC 中，重复相同的过程。然而，这一次，survior 空间发生了变化。引用的对象将移动到 S0。幸存的对象已经老化。Eden 和 S1 被清除。\n\n\n\n6、在 minor GC 之后，当老化对象达到某个年龄阈值时，它们将从年轻一代提升到老一代。\n\n\n\n7、随着 minor GC 的继续发生，对象将继续被提升到老年代空间。\n\n\n\n8、最终，将对老年代进行 major GC 处理，以清理和压缩该空间。\n\n\nGC 调优的目标是什么？最后笔者希望和各位读者来探讨下 GC 调优的目标。在过往的经历中，或者面试者提供的简历中，关于 GC 调优的问题背景差不多可以归结如下几类：\n\n系统运行时出现了 OOM\n尖刺问题\n其他非堆区问题的 GC ，如 metaspace 不够，栈溢出等\n\n确实，这些问题有的会导致我们在线业务受损，有的则可能直接导致系统崩溃。我们的调优往往基于这些已经发生的现象进行的调整，因为 GC 调优本身就没有标准的范式，它取决于你的软硬件环境、你的业务属性、你的流量分布情况等等。这里笔者就引出本小节希望探讨的另一个话题—-调优的目的是什么？\n这个问题很简单，一句话就是保障系统可用性，这个是终极目标；再细一点则是在有限的内存资源条件下，通过 GC 调优使得系统能够稳定长期运行。那再细一点呢？\n笔者认为， GC 调优的目标是更合理的使用堆内存空间，尽量减少应该 GC 带来的业务影响；进一步展开就是：在有限的内存资源限定的条件下，通过 GC 调优来提高应用程序或系统对请求的数据做出响应的速度（响应能力）以及最大化应用程序在特定时间段内的工作量（吞吐量），以使得系统能够以一种较优的姿态保持稳定长期运行。\nGC 调优的一些基本思路从前一小节可以知道，在进行 GC 调优时，我们的目标是优化内存资源使用、提升响应速度、增加吞吐量，并确保系统能够稳定长期运行。为了实现这些目标，我们需要关注和调整一些关键因素，包括堆大小、吞吐量、停顿时间。\n![GC 性能指标三角形](&#x2F;Users&#x2F;glmapper&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20240626145258548.png)\n内存资源（堆内存空间）堆内存空间是 GC 调优的基础，合理设置堆大小能够平衡内存使用和 GC 频率，避免内存不足或过度分配带来的性能问题。在实际的应用中，一般会关注初始堆大小（-Xms）和最大堆大小（-Xmx），通过这两个参数可以控制应用程序在启动和运行期间的内存使用；如果你的系统对响应性能要求比较高，可以将这两个值设置为相同，以避免动态调整带来的开销和性能波动。如果是 G1，除了调整堆大小之外，region size 可能也是一个值得关注的因素。\n响应速度提升应用的响应速度，从调优过程角度则是要降低 GC 带来的延迟，而这个延迟主要取决于GC 产生的停顿时间。这里可以考虑选择响应时间优先的GC 算法，如 G1;G1 中提出了一种模型叫做 Pause Prediction Model （停顿预测模型），与 CMS 最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数-XX:MaxGCPauseMillis 指定一个G1收集过程目标停顿时间（默认值200ms，不是硬性条件，只是期望值）。G1根据这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。 停顿预测模型是以衰减标准偏差为理论基础实现的：\n12345//  share/vm/gc_implementation/g1/g1CollectorPolicy.hppdouble get_new_prediction(TruncatedSeq* seq) &#123;    return MAX2(seq-&gt;davg() + sigma() * seq-&gt;dsd(),                seq-&gt;davg() * confidence_factor(seq-&gt;num()));&#125;\n\n\n\n\n\n\n\n\n\n\n这里不展开，有兴趣的读者可以自行研究一下 Pause Prediction Model 。\n吞吐量吞吐量指的是应用在单位时间内能够处理的任务数量，优化吞吐量可以提升系统的整体效率。这里的吞吐量指的是 CPU 用于运行用户代码的时间与CPU 总消耗时间的比值，即\n\n\n\n\n\n\n\n\n\n吞吐量 &#x3D; 运行用户代码时间&#x2F;（运行用户代码时间+ 垃圾收集时间）。\n比如如果应用程序总运行时间为100秒，其中90秒用于处理业务逻辑，10秒用于垃圾回收，那么吞吐量为90%（90秒 &#x2F; 100秒）。\n当我们说 GC 吞吐量优先时，意味着我们的目标是最大化应用程序的有效工作时间，最小化垃圾回收带来的开销；一般情况下吞吐量优先的场景主要是批处理系统或者后台服务，这类服务更关注整体处理能力而非单次操作的响应时间。如果你的系统关注吞吐量，可以选择并行 GC 或者其他高吞吐量的 GC 算法，如 Parallel GC。在 GC 参数的调整上，可以 增大年轻代大小，通过增加年轻代（-Xmn）的大小，减少对象晋升到老年代的频率，降低 Full GC 的次数；此外还可以 调整并行 GC 线程数，通过增加并行 GC 的线程数来提高并行垃圾回收的效率。\nJVM GC 机制的发展展望这张图是 2019 年时 JAVA 版本的使用情况分布，还是以 JAVA 8 为主。\n\n下面这张图是 State of Java 2023 中关于 JAVA 目前版本使用情况的统计，从这张图可以看出，版本任你发，我用Java 8 的声音可能会慢慢的消失在历史的长河中。\n\n从 2019 年到 2023 年，短短几年的时间，越来越多的用户选择了更好版本的 LTS 版本，这也意味着高版本中提供的各种语言特性或者机制（包括 GC）能够给用户带去更多的收益价值。从官方纰漏的 报告 中指出，从  JDK 8 到 JDK 18，经历了 10 个版本，Java 垃圾回收也经历了十次进化，包括了 2000+ 个增强功能。从这些演进中可以基本的出的结论是，Java 一直在为寻求更低的延迟、更高效的内存利用和更大的吞吐而努力；这不是三者平衡和折中的过程，而是将 GC 性能指标三角形的张力扩大的过程。\n总结本文主要针对 JAVA 中的垃圾回收机制进行了探讨，和其他文章不同的是，笔者没有将关注点放在某一个垃圾回收算法上，也不是针对某一个具体垃圾收集器进行展开；笔者期望从一个更加宏观的角度去解释什么需要 GC 以及 GC 的目标是什么。此外本文也对 GC 的基本过程、调优思路以及 GC 的未来发展进行了阐述，期望读者可以更加全面的理解 GC 机制。\n参考\nhttps://blogs.oracle.com/javamagazine/post/java-garbage-collectors-evolution\nhttps://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html\nhttps://www.azul.com/wp-content/uploads/final-2023-state-of-java-report.pdf\n《垃圾回收的算法与实现》– 中村成洋 相川光\n\n","slug":"jvm/jvm-gc-total-summary","date":"2024-07-01T02:59:14.000Z","categories_index":"jvm","tags_index":"gc,jvm","author_index":"glmapper"},{"id":"815e5fe8003f703e73f556f106d850e3","title":"win 10 部署 langchain-chatchat gpu 版","content":"基于 ChatGLM 等大语言模型与 Langchain 等应用框架实现，开源、可离线部署的检索增强生成(RAG)大模型知识库项目。\n\n本地环境\n品牌：戴尔 optiplex 7000\n操作系统：win11  家庭版 x64\n处理器：12th Gen Intel(R) Core(TM) i9-12900 2.4 GHz\n显卡：RTX 3060  12g\n\nnvidia-smi  查看 GPU 信息如下：\n123456789101112131415161718192021222324252627282930Fri Jan  5 14:38:11 2024+---------------------------------------------------------------------------------------+| NVIDIA-SMI 536.19                 Driver Version: 536.19       CUDA Version: 12.2     ||-----------------------------------------+----------------------+----------------------+| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. ||                                         |                      |               MIG M. ||=========================================+======================+======================||   0  NVIDIA GeForce RTX 3060      WDDM  | 00000000:01:00.0  On |                  N/A ||  0%   35C    P8               7W / 170W |  12063MiB / 12288MiB |      7%      Default ||                                         |                      |                  N/A |+-----------------------------------------+----------------------+----------------------++---------------------------------------------------------------------------------------+| Processes:                                                                            ||  GPU   GI   CI        PID   Type   Process name                            GPU Memory ||        ID   ID                                                             Usage      ||=======================================================================================||    0   N/A  N/A      6788    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      ||    0   N/A  N/A      6940    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      ||    0   N/A  N/A      7876    C+G   C:\\Windows\\explorer.exe                   N/A      ||    0   N/A  N/A      8816    C+G   ...on\\120.0.2210.91\\msedgewebview2.exe    N/A      ||    0   N/A  N/A      8988    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      ||    0   N/A  N/A      9124    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      ||    0   N/A  N/A     15560    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      ||    0   N/A  N/A     16528    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      ||    0   N/A  N/A     17260      C   ...\\anaconda3\\envs\\Chatchat\\python.exe    N/A      ||    0   N/A  N/A     21584    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |+---------------------------------------------------------------------------------------+\n\n\n\n软件环境安装Python 版本使用的是官方 wiki 中建议的版本区别： 3.11.5\nAnaconda 安装Anaconda 用于管理 python 虚拟环境。Conda 是一个开源的包管理系统和环境管理系统，主要用于数据科学、机器学习和科学计算等领域。它是 Anaconda 发行版的一部分，也可以作为 Miniconda 的一部分单独安装。Conda可以帮助用户轻松地安装、管理和更新软件包、库和依赖项，而无需担心不同软件包之间的冲突。它还允许用户创建、管理和切换不同的虚拟环境，使得在同一台机器上同时进行多个项目开发变得更加便捷。Conda也提供了对Python和非Python软件包的支持，这使得它成为一个广泛使用的工具，不仅局限于Python生态系统。\n\n下载地址：https://www.anaconda.com/download\n\n版本  23.11.0\n\n\n按安装指引默认安装即可，安装完测试：\n12~ conda -V~ conda 23.11.0\n\n\n\ncuda 安装CUDA（Compute Unified Device Architecture）是由NVIDIA开发的并行计算平台和应用程序编程接口（API）。它允许开发人员使用C&#x2F;C++、Python等编程语言来利用NVIDIA GPU的并行计算能力。CUDA使开发人员能够在GPU上编写高性能的通用并行程序，用于加速科学计算、深度学习、图形渲染和其他需要大量并行计算的领域。通过CUDA，开发人员可以利用GPU的大量计算核心并行处理数据，加快计算速度。\ncuda 所有版本归档地址：https://developer.nvidia.com/cuda-toolkit-archive，可以在这里下载需要的版本；在上述 nvidia-smi  查看的 GPU 信息看到，我本机支持的 cuda 版本最高是 12.2。\npytorch 安装PyTorch是一个开源的机器学习库，专注于深度学习任务。它由Facebook的人工智能研究团队开发并维护，提供了丰富的工具和接口，用于构建和训练神经网络模型。\n安装时可以在这里 https://download.pytorch.org/whl/torch_stable.html 下载。根据需要按照不同操作系统、是否是gpu 环境等找对应的版本即可。\n\ngpu 版本安装\n123456# torchpip install https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl # torchaudiopip install https://download.pytorch.org/whl/cu121/torchaudio-2.1.2%2Bcu121-cp310-cp310-win_amd64.whl  # torchvisionpip install https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-win_amd64.whl\n\ncpu 版本安装（这里用了清华源）\n\n\n1pip install torch torchvision torchaudio --index-url https://download.pytorch.org/wh1/cull8 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n\n环境测试创建 python 运行虚拟环境打开 Anaconda Prompt 终端命令行工具，使用 conda 创建 python 运行虚拟环境\n123456789101112(base) ~ conda create -n Chatchat python=3.11.5 (base) ~ done(base) ~ #(base) ~ # To activate this environment, use(base) ~ #(base) ~ #     $ conda activate Chatchat(base) ~ #(base) ~ # To deactivate an active environment, use(base) ~ #(base) ~ #     $ conda deactivate(base) ~ conda activate Chatchat  # 激活虚拟环境(Chatchat) ~ \n\n\n\n测试 pytorch12345678910111213(Chatchat) ~ pythonPython 3.11.5 # 省略 .... &gt;&gt;&gt; import torch&gt;&gt;&gt; torch.cuda.is_available()False&gt;&gt;&gt; x = torch.rand(5, 3)&gt;&gt;&gt; print(x)tensor([[0.8827, 0.8297, 0.5390],        [0.4590, 0.8473, 0.4074],        [0.4045, 0.0082, 0.4121],        [0.7649, 0.3901, 0.1535],        [0.5408, 0.8168, 0.8615]])&gt;&gt;&gt;\n\nLangchain-Chatchat 下载本文是基于 常规模式本地部署方案 进行部署的。代码拉取 &amp; 安装依赖\n12345678910111213# 拉取仓库$ git clone --recursive https://github.com/chatchat-space/Langchain-Chatchat.git# 进入目录$ cd Langchain-Chatchat# 安装全部依赖$ pip install -r requirements.txt# 默认依赖包括基本运行环境（FAISS向量库）。以下是可选依赖：- 如果要使用 milvus/pg_vector 等向量库，请将 requirements.txt 中相应依赖取消注释再安装。- 如果要开启 OCR GPU 加速，请安装 rapidocr_paddle[gpu]- 如果要使用在线 API 模型，请安装对用的 SDK\n\n在执行安装依赖时遇到 https://github.com/chatchat-space/Langchain-Chatchat/issues/2533 这个问题，采用 issue 中提的方式，使用 conda 进行安装的。这里可以先将 requirements.txt 中的 jq 依赖先注释调\n12# rapidocr_paddle[gpu]&gt;=1.3.0.post5 # gpu accelleration for ocr of pdf and image files# jq&gt;=1.6.0 # for .json and .jsonl files. suggest `conda install jq` on windows\n\n然后再执行 pip install -r requirements.txt，然后再使用 conda install jq 安装 jq。\n\n\n\n\n\n\n\n\n\nPs: 笔者之前没有做过 python 开发，最大体验是，一直在装各种包….\n此外，为方便用户 API 与 webui 分离运行，可单独根据运行需求安装依赖包。\n\n如果只需运行 API，可执行：\n12$ pip install -r requirements_api.txt# 默认依赖包括基本运行环境（FAISS向量库）。如果要使用 milvus/pg_vector 等向量库，请将 requirements.txt 中相应依赖取消注释再安装。\n\n如果只需运行 WebUI，可执行：\n1$ pip install -r requirements_webui.txt\n\n其他建议直接参考官方 wiki 即可，如果有问题先查官方 issue。\n模型下载安装官方手册，下载两个模型：m3e-base 内置模型和 chatglm2-6b-int4 模型。额，实际上  https://huggingface.co/moka-ai/m3e-base 和 https://huggingface.co/THUDM/chatglm2-6b 通过 git 直接 拉是拉不下来的，最后是在 files and versions 下手动下载的。chatglm2-6b 也是一样。即使下载了 lfs 也是不行的，可能打开方式不对？\n配置修改和文件修改批量修改配置文件名针对 Langchain-Chatchat，批量复制 configs 目录下所有的配置文件，去掉 example 后缀：\n1python copy_config_example.py\n\n截图如下：\n\n修改 model_config.py 文件\n修改 m3e-base 的模型本地路径\n123# &quot;m3e-base&quot;: &quot;moka-ai/m3e-base&quot;,# 修改为本地的 路径&quot;m3e-base&quot;: &quot;D:\\\\llm\\\\m3e-base&quot;,\n\n修改 chatglm2-6b-int4 模型本地路径\n12345678&quot;llm_model&quot;: &#123;        # 以下部分模型并未完全测试，仅根据 fastchat和vllm模型的模型列表推定支持        &quot;chatglm-6b&quot;: &quot;THUDM/chatglm-6b&quot;,        &quot;chatglm2-6b&quot;: &quot;THUDM/chatglm2-6b&quot;,        # &quot;chatglm2-6b-int4&quot;: &quot;THUDM/chatglm2-6b-int4&quot;,        &quot;chatglm2-6b-int4&quot;: &quot;D:\\\\llm\\\\chatglm2-6b&quot;,         &quot;chatglm2-6b-32k&quot;: &quot;THUDM/chatglm2-6b-32k&quot;,        # ...\n\n修改LLM模型为chatglm2-6b-int4\n12# LLM 名称 ,修改为 chatglm2-6bLLM_MODEL = &quot;chatglm2-6b\n\n修改 LLM_DEVICE 运行设备，看使用cpu、cuda（带GPU）或mps( mac本）\n123456# 选用的 Embedding 名称EMBEDDING_MODEL = &quot;m3e-base&quot; # 可以尝试最新的嵌入式sota模型：bge-large-zh-v1.5# Embedding 模型运行设备。设为&quot;auto&quot;会自动检测，也可手动设定为&quot;cuda&quot;,&quot;mps&quot;,&quot;cpu&quot;其中之一。EMBEDDING_DEVICE = &quot;auto&quot;# LLM 名称LLM_MODEL = &quot;chatglm2-6b&quot;\n\n修改 server_config.py12# 各服务器默认绑定 host。如改为&quot;0.0.0.0&quot;需要修改下方所有XX_SERVER的hostDEFAULT_BIND_HOST = “127.0.0.1&quot;\n\n部署知识库初始化\n创建过知识库，可以先执行以下命令创建或更新数据库表，如果可以正常运行，则无需再重建知识库。\n1python init_database.py --create-tables\n\n如果是第一次运行本项目，知识库尚未建立，或者之前使用的是低于最新master分支版本的框架，或者配置文件中的知识库类型、嵌入模型发生变化，或者之前的向量库没有开启 normalize_L2，需要以下命令初始化或重建知识库：\n1python init_database.py --recreate-vs\n\n\n\n\n\n\n\n\n\n\n这里因为前面安装依赖时一直出现 jq 报错问题，导致很多依赖没有安装成功，在执行数据库初始化时报了一堆依赖找不到，也是一个个 install 的，😭….\n启动项目1python startup.py -a\n\n执行日志大致如下：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788==============================Langchain-Chatchat Configuration==============================操作系统：Windows-10-10.0.22000-SP0.python版本：3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]项目版本：v0.2.9langchain版本：0.0.353. fastchat版本：0.2.34当前使用的分词器：ChineseRecursiveTextSplitter当前启动的LLM模型：[&#x27;chatglm2-6b&#x27;] @ cuda&#123;&#x27;device&#x27;: &#x27;cuda&#x27;, &#x27;host&#x27;: &#x27;127.0.0.1&#x27;, &#x27;infer_turbo&#x27;: False, &#x27;model_path&#x27;: &#x27;D:\\\\llm\\\\chatglm3-6b&#x27;, &#x27;model_path_exists&#x27;: True, &#x27;port&#x27;: 20002&#125;当前Embbedings模型： m3e-base @ cuda==============================Langchain-Chatchat Configuration==============================2024-01-05 14:17:15,651 - startup.py[line:651] - INFO: 正在启动服务：2024-01-05 14:17:15,651 - startup.py[line:652] - INFO: 如需查看 llm_api 日志，请前往 D:\\llm\\Langchain-Chatchat\\logs2024-01-05 14:17:20 | ERROR | stderr | INFO:     Started server process [16928]2024-01-05 14:17:20 | ERROR | stderr | INFO:     Waiting for application startup.2024-01-05 14:17:20 | ERROR | stderr | INFO:     Application startup complete.2024-01-05 14:17:20 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:20000 (Press CTRL+C to quit)2024-01-05 14:17:21 | INFO | model_worker | Loading the model [&#x27;chatglm2-6b&#x27;] on worker 2ed3839d ...Loading checkpoint shards:   0%|                                                                                                                                           | 0/7 [00:00&lt;?, ?it/s]Loading checkpoint shards:  14%|██████████████████▋                                                                                                                | 1/7 [01:05&lt;06:31, 65.24s/it]Loading checkpoint shards:  29%|█████████████████████████████████████▍                                                                                             | 2/7 [01:41&lt;04:00, 48.07s/it]Loading checkpoint shards:  43%|████████████████████████████████████████████████████████▏                                                                          | 3/7 [01:41&lt;01:45, 26.36s/it]Loading checkpoint shards:  57%|██████████████████████████████████████████████████████████████████████████▊                                                        | 4/7 [01:42&lt;00:48, 16.14s/it]Loading checkpoint shards:  71%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 5/7 [01:42&lt;00:21, 10.51s/it]Loading checkpoint shards:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 6/7 [02:13&lt;00:17, 17.35s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [02:50&lt;00:00, 23.71s/it]Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [02:50&lt;00:00, 24.32s/it]2024-01-05 14:20:11 | ERROR | stderr |2024-01-05 14:20:16 | INFO | model_worker | Register to controllerINFO:     Started server process [7956]INFO:     Waiting for application startup.INFO:     Application startup complete.INFO:     Uvicorn running on http://127.0.0.1:7861 (Press CTRL+C to quit)==============================Langchain-Chatchat Configuration==============================操作系统：Windows-10-10.0.22000-SP0.python版本：3.10.11 | packaged by Anaconda, Inc. | (main, May 16 2023, 00:55:32) [MSC v.1916 64 bit (AMD64)]项目版本：v0.2.9langchain版本：0.0.353. fastchat版本：0.2.34当前使用的分词器：ChineseRecursiveTextSplitter当前启动的LLM模型：[&#x27;chatglm2-6b&#x27;] @ cuda&#123;&#x27;device&#x27;: &#x27;cuda&#x27;, &#x27;host&#x27;: &#x27;127.0.0.1&#x27;, &#x27;infer_turbo&#x27;: False, &#x27;model_path&#x27;: &#x27;D:\\\\llm\\\\chatglm3-6b&#x27;, &#x27;model_path_exists&#x27;: True, &#x27;port&#x27;: 20002&#125;当前Embbedings模型： m3e-base @ cuda服务端运行信息：    OpenAI API Server: http://127.0.0.1:20000/v1    Chatchat  API  Server: http://127.0.0.1:7861    Chatchat WEBUI Server: http://127.0.0.1:8501==============================Langchain-Chatchat Configuration==============================      Welcome to Streamlit!      If you’d like to receive helpful onboarding emails, news, offers, promotions,      and the occasional swag, please enter your email address below. Otherwise,      leave this field blank.      Email:  2024-01-05 14:24:24 | INFO | stdout | INFO:     127.0.0.1:63380 - &quot;GET /v1 HTTP/1.1&quot; 404 Not FoundINFO:     127.0.0.1:63456 - &quot;GET / HTTP/1.1&quot; 307 Temporary RedirectINFO:     127.0.0.1:63456 - &quot;GET /docs HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63456 - &quot;GET /swagger-ui.css HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63457 - &quot;GET /swagger-ui-bundle.js HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63457 - &quot;GET /openapi.json HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63456 - &quot;GET /favicon.png HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63645 - &quot;GET /docs HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63645 - &quot;GET /swagger-ui.css HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63646 - &quot;GET /swagger-ui-bundle.js HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63646 - &quot;GET /openapi.json HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63646 - &quot;GET /favicon.png HTTP/1.1&quot; 200 OKINFO:     127.0.0.1:63744 - &quot;POST /chat/chat HTTP/1.1&quot; 200 OK\n\n\n\n运行效果如下：\n\n总结作为一个连门都没入的 java 工程师，前后花了差不多 1 天多时间；主要坑就是 Could not build wheels for jq, which is required to install pyproject.toml-based projects 这个报错让我纠结了很久；官方 issue 关于这个问题也有不少社区反馈：https://github.com/chatchat-space/Langchain-Chatchat/issues?q=jq。另外还是对于官方文档中给的 wiki 看的太粗，也导致在某些点上浪费了一些时间。\n通过此次部署，首先是对于大模型本地部署的流程有了一些基本印象和思路；对于如 conda、cuda、pytorch 等相关框架及工具有一些初步认识，还是有一些收获的。\n参考\nhttps://blog.csdn.net/xqdd/article/details/134247532\nhttps://github.com/chatchat-space/Langchain-Chatchat/wiki/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2#%E5%B8%B8%E8%A7%84%E6%A8%A1%E5%BC%8F%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88\n\n","slug":"llm/langchain-chatchat-deploy","date":"2024-01-05T09:32:34.000Z","categories_index":"LLM","tags_index":"langchain","author_index":"glmapper"},{"id":"b4c75674b257351f24efe8fa873c5818","title":"聊一聊 Spring Data JPA 中的那些日常实践","content":"一直以来，团队在使用 ORM 框架上都是比较随意的，一开始是鼓励大家使用 mybatis，主要是期望团队同学可以自己写写 SQL，不至于写 SQL 手生；但是从实际工作中来看，我们并不会涉及到很多非常复杂的 SQL 语句，这就导致了大家会消耗相当部分的精力在写一些重复性并且没有什么技术难度的 SQL，对于基于数据库驱动的业务来说，当业务涉及到的表结构越多时，这种问题就越突出。于是我在项目的脚手架中就提供了 mybatis 和 jpa 两种访问数据库的方式，但是在随后的一段时间中发现，团队在使用 jpa 来操作数据库上的代码提交几乎为0，而有相当部分的同学则是引入了 mybatis-plus。\n\n\n对于这个现象，我没有做过多的干预和询问，但从个人使用体验来说，我觉得可能有两个方面的原因：\n\n1、mybatis&#x2F;mybatis-plus 相较于 JPA 来说更灵活，它是国内开发者发起的，网上资源多，且都是中文。\n2、JPA 对于一些复杂操作用起来很别扭，网上关于 JPA 的高级用法文档很少且比较凌乱，官网上的介绍也很简单。\n\n也大概看了下网上关于 JPA 和 mybatis&#x2F;mybatis-plus 家族的区别以及对比文章（推荐知乎这篇：SpringBoot开发使用Mybatis还是Spring Data JPA??，也都各有各的支持者。本篇文档不对比优劣，仅基于自己的项目实践，梳理了关于 JPA 的一些使用方式，这些使用方式主要是针对其默认 CrudRepository 在诸如分页、复合条件查询等方面不足的一些实践使用。\n关于 Spring Data 中的 RepositoryRepositoryRepository 概念是 Spring Data 中的，源码中关于这个接口的注释写的比较清楚，它是一个标记接口，类似与 Java 中的 Serializable 接口差不多含义。那放在 Spring Data 中来解释那就是用于交互数据仓库的接口。它介于业务层和数据层之间，将两者隔离开来，在它不同的实现内部封装了数据查询和存储的逻辑。\nCentral repository marker interface. Captures the domain type to manage as well as the domain type&#39;s id type. General purpose is to hold type information as well as being able to discover interfaces that extend this one during classpath scanning for easy Spring bean creation.\nRepository 和 DAODAO 是传统 MVC 中 Model 的关键角色，全称是 Data Access Object。DAO 直接负责数据库的存取工作，乍一看两者非常类似，但从架构设计上讲两者有着本质的区别：\n\nRepository 蕴含着真正的 oo 概念，即一个数据仓库角色，负责所有对象的持久化管理。\nDAO 没有摆脱数据的影子，仍然停留在数据操作的层面上。\n\nRepository 是相对对象而言，DAO 则是相对数据库而言，虽然可能是同一个东西 ，但侧重点不同。\nSpring Data JPASpring Data JPA 作为 Spring Data 的子集项目，其扩展了 Repository 接口，并提供了一组便于操作数据库的子类。如下图所示：\n\n\n\n\n\n\n\n\n\n\nPS: KV-Repository主要是对接 Nosql 部分，这里也放出来提供对比视图\n三种 Repository上面这张图我们主要关注的是 CrudRepository、PagingAndSortingRepository 和 JpaRepository。\n\nCrudRepository：提供最基本的 CRUD 操作。\nPagingAndSortingRepository：在 CrudRepository 的基础上，提供排序和分页能力。\nJpaRepository：在 PagingAndSortingRepository 的基础上，进一步提供了查询列表、批量删除、强制同步以及 Example 查询等能力。\n\n在我们项目中，目前是基于 CrudRepository 接口的，因此大多数情况下，对于基本的分页查询能力从 CrudRepository 的视角是不可感知的，亦或是有同学关注到了这一点，但是对比于 mybaitis-plus 来说，缺少了一些吸引力。\nExample 构建动态查询Example 构建查询主要是基于 QueryByExampleExecutor 接口，QueryByExampleExecutor 接口提供了一组方法，其入参为 Example 对象，通常情况下，可以通过 Example 提供的静态方法结合 ExampleMatcher 来构建 Example。在使用上，根据官方文档的描述来看：\n\nNo support for nested or grouped property constraints, such as firstname = ?0 or (firstname = ?1 and lastname = ?2)，不支持嵌套或分组的属性约束\nOnly supports starts&#x2F;contains&#x2F;ends&#x2F;regex matching for strings and exact matching for other property types，只支持字符串 start&#x2F;contains&#x2F;ends&#x2F;regex 匹配和其他属性类型的精确匹配。\n\n下面给出两个常用的基本示例。\n\nOpenTalkUserRepository\n123public interface OpenTalkUserRepository extends CrudRepository&lt;OpenTalkUserEntity,Long&gt;, QueryByExampleExecutor&lt;OpenTalkUserEntity&gt; &#123;&#125;\n\n按照指定列精确查询\n1234567891011121314/** * 按多条件精确匹配查询 */@Testpublic void test_base_dynamic_query_fixed() &#123;    // 构建实体类需要动态查询的条件，按照 sourceFrom 和 verified 进行指定条件值匹配查询    OpenTalkUserEntity user = new OpenTalkUserEntity();    user.setSourceFrom(&quot;qq&quot;);    user.setVerified(&quot;1&quot;);    // 注意: 这个 Example 对象是 spring data 的 &#123; @link: org.springframework.data.domain.Example&#125;    Example&lt;OpenTalkUserEntity&gt; example = Example.of(user);    List&lt;OpenTalkUserEntity&gt; list = (List&lt;OpenTalkUserEntity&gt;) repository.findAll(example);    Assert.assertTrue(list.size() &gt; 0);&#125;\n\n按照指定列模糊查询\n12345678910111213141516171819 /** * 按指定字段条件模糊匹配查询 */@Testpublic void test_base_dynamic_query_like() &#123;    OpenTalkUserEntity user = new OpenTalkUserEntity();    user.setEmail(&quot;qq&quot;);    // 创建一个新的匹配器，默认情况下，probe 中所有的非空属性都匹配。即所有的属性条件用 and 连接    // matchingAny: probe 中所有的非空属性匹配一个即可。即所有的属性条件用or连接    // matchingAll:  probe 中所有的非空属性都匹配。即所有的属性条件用and连接    // probe 表示含有对应字段的实例对象    ExampleMatcher matcher = ExampleMatcher.matching();    // 查询 email 中包括  qq 的记录    // 这里指定列名， GenericPropertyMatcher 为 contains    matcher = matcher.withMatcher(&quot;email&quot;, ExampleMatcher.GenericPropertyMatchers.contains());    Example&lt;OpenTalkUserEntity&gt; example = Example.of(user, matcher);    List&lt;OpenTalkUserEntity&gt; list = (List&lt;OpenTalkUserEntity&gt;) repository.findAll(example);  Assert.assertTrue(list.size() &gt; 0);&#125;\n\nGenericPropertyMatcher 包括以下几种类型：\n\n\n\n类型\n解释\n\n\n\nignoreCase\n忽略大小写\n\n\ncaseSensitive\n大小敏感\n\n\ncontains\n包含 xx        同 “like %xx%”\n\n\nendsWith\n以 xx 结尾   同 “like %xx”\n\n\nstartsWith\n以 xx 开始   同 “like xx%”\n\n\nexact\n精确匹配\n\n\nstoreDefaultMatching\n默认规则，效果和 EXACT 相同\n\n\nregex\n正则匹配\n\n\n\n复杂组合查询\n12345678910111213141516171819202122 /** * 组合查询，忽略指定列、忽略 null 值、忽略 大小写等 */@Testpublic void test_base_dynamic_multi_condition_query() &#123;    OpenTalkUserEntity user = new OpenTalkUserEntity();    user.setEmail(&quot;qq&quot;);    user.setId(17L);    ExampleMatcher matcher = ExampleMatcher.matching();    // 查询 email 中包括 qq 的记录    matcher = matcher.withMatcher(&quot;email&quot;, ExampleMatcher.GenericPropertyMatchers.contains());    // 忽略主键，所以这里对于上面设置 id = 17 这个条件是无用的，返回结构中会包括 id = 17 的记录    matcher = matcher.withIgnorePaths(&quot;id&quot;);    // 忽略 null 值    matcher = matcher.withIgnoreNullValues();    // 忽略 大小写    matcher = matcher.withIgnoreCase();    Example&lt;OpenTalkUserEntity&gt; example = Example.of(user, matcher);    List&lt;OpenTalkUserEntity&gt; list = (List&lt;OpenTalkUserEntity&gt;) repository.findAll(example);    System.out.println(JSONObject.toJSONString(list));    Assert.assertTrue(list.size() &gt; 0);&#125;\n\nSpecification 构建动态查询Example 只能针对字符串进行条件设置，那如果希望对所有类型支持，可以使用 Specification。Specification 需要继承 JpaSpecificationExecutor 接口。和 Example 的 QueryByExampleExecutor 类型，JpaSpecificationExecutor 也同样提供了一组方法，其入参是 Specification。Specification 中几个概念：\n\nRoot：查询哪个表（关联查询） &#x3D;  from\nCriteriaQuery：查询哪些字段，排序是什么 &#x3D;组合(order by . where )\nCriteriaBuilder：条件之间是什么关系，如何生成一个查询条件，每一个查询条件都是什么类型（&gt; between in…) &#x3D; where\nPredicate（Expression）： 每一条查询条件的详细描述\n\n\n\n下面给出 Specification 的使用示例。\n\n组合条件查询\n12345678910111213141516@Testpublic void test_specification() &#123;    Specification&lt;OpenTalkUserEntity&gt; spec = (root, query, criteriaBuilder) -&gt; &#123;        Path&lt;Integer&gt; type = root.get(&quot;verified&quot;);        // verified == &quot;1&quot;        Predicate verifiedPredicate = criteriaBuilder.equal(type, &quot;1&quot;);\t    // email like &quot;%qq%&quot;        Path&lt;String&gt; email = root.get(&quot;email&quot;);        Predicate emailPredicate = criteriaBuilder.like(email, &quot;%qq%&quot;);        // and 条件 verified == &quot;1&quot; and email like &quot;%qq%&quot;        Predicate predicate = criteriaBuilder.and(verifiedPredicate, emailPredicate);        return predicate;    &#125;;    List&lt;OpenTalkUserEntity&gt; list = this.repository.findAll(spec);    System.out.println(JSONObject.toJSONString(list));&#125;\n\n使用 Spring Data JPA 的一些实践分页查询需要注意的是，不管是 Specification 还是 Example，查询的起始页都是 0，而不是 1。\n\n使用 Specification 的分页查询\n1234567891011121314151617181920212223@Testpublic void test_specification_combine_page() &#123;    Specification&lt;OpenTalkUserEntity&gt; spec = (root, query, criteriaBuilder) -&gt; &#123;        Path&lt;Integer&gt; type = root.get(&quot;verified&quot;);        // verified == &quot;1&quot;        Predicate verifiedPredicate = criteriaBuilder.equal(type, &quot;1&quot;);        Path&lt;String&gt; email = root.get(&quot;email&quot;);        // email like &quot;%qq%&quot;        Predicate emailPredicate = criteriaBuilder.like(email, &quot;%qq%&quot;);        // and 条件 verified == &quot;1&quot; and email like &quot;%qq%&quot;        Predicate predicate = criteriaBuilder.and(verifiedPredicate, emailPredicate);        return predicate;    &#125;;    Sort sort = Sort.by(Sort.Direction.DESC, &quot;createTime&quot;);    // 注意这里的起始页为 0    PageRequest pageRequest = PageRequest.of(0, 10, sort);    Page&lt;OpenTalkUserEntity&gt; all = this.repository.findAll(spec, pageRequest);    long total = all.getTotalElements();    List&lt;OpenTalkUserEntity&gt; content = all.getContent();    System.out.println(JSONObject.toJSONString(content));    Assert.assertTrue(total &gt; 0);&#125;\n\n使用 Example 的分页查询\n123456789101112131415@Testpublic void test_example_combine_page() &#123;    // 构建实体类需要动态查询的条件，按照 sourceFrom 和 verified 进行指定条件值匹配查询    OpenTalkUserEntity user = new OpenTalkUserEntity();    user.setSourceFrom(&quot;qq&quot;);    user.setVerified(&quot;1&quot;);    // 注意: 这个 Example 对象是 spring data 的 &#123; @link: org.springframework.data.domain.Example&#125;    Example&lt;OpenTalkUserEntity&gt; example = Example.of(user);    Sort sort = Sort.by(Sort.Direction.DESC, &quot;createTime&quot;);    // 注意这里的起始页为 0    PageRequest pageRequest = PageRequest.of(0, 10, sort);    Page&lt;OpenTalkUserEntity&gt; result = repository.findAll(example, pageRequest);    System.out.println(JSONObject.toJSONString(result.getContent()));    Assert.assertTrue(result.getTotalElements() &gt; 0);&#125;\n\n返回固定列数据\n1、定义模型，这里须使用 @lombok.Value 注解\n123456@Valuepublic class SimpleOpenTalkUserModel implements Serializable &#123;    private String email;    private String verified;    private String sourceFrom;&#125;\n\n2、自定义查询方法\n123456789/**   * 用户返回指定列的数据   *   * @param email   * @param tClass   * @param &lt;T&gt;   * @return   */  &lt;T&gt; Optional&lt;T&gt; findCustomByEmail(String email, Class&lt;T&gt; tClass);\n\n3、查询数据\n12345@Testpublic void test_custom_model() &#123;    Optional&lt;SimpleOpenTalkUserModel&gt; optional = this.repository.findCustomByEmail(&quot;test15@qq.com&quot;, SimpleOpenTalkUserModel.class);    System.out.println(optional.get());&#125;\n\n使用 SQL还是按照上面那个返回自定义对象，这里使用注解的方式来查询\n123456789/**    * 使用注解    *    * @param email    * @return    */   @Query(value = &quot;select new com.gl.guides.jpa.entity.SimpleOpenTalkUserModel(user.email ,user.verified,    user.sourceFrom) from OpenTalkUserEntity user where user.email = ?1&quot;)   SimpleOpenTalkUserModel findCustomByEmail(String email);\n\n注意，这里不能使用 nativeQuery = true ，并且 SimpleOpenTalkUserModel 需要提供全参的构造函数。\n关联查询正常的复杂关联查询，完全可以通过使用 nativeQuery = true ，然后编写原生的 SQL 来实现即可。这里不再赘述。\n总结实际上，Spring Data JPA 可以整的花活是非常多的；上面提到的几种案例对于绝大多数业务场景应该是满足的。JPA 提供的封装屏蔽了底层的复杂逻辑，在一定程度上可能会造成性能上的影响，但是对于中小型项目，并且在数据体量不是很大的情况下，JPA 是个不错的选择。\n\n\n\n\n\n\n\n\n\nPS: JPA 对于自定义方法，如上面的 findCustomByEmail ，刚开始 debug 起来有点摸不到头脑；但是对于 Java 开发者来说，总归绕不过代理这个东西，顺藤摸瓜就找到了。下面补一张图备忘，以便于后续研究其源码时使用。\n此代码片段位于 org.springframework.data.jpa.repository.query.JpaQueryExecution 类中\n\n参考\nhttps://segmentfault.com/a/1190000012346333\nhttps://zhuanlan.zhihu.com/p/565770887\nhttps://www.zhihu.com/question/316458408\nhttps://spring.io/projects/spring-data\nhttps://spring.io/projects/spring-data-jpa\nhttps://tuonioooo-notebook.gitbook.io/application-framework/jpapian/spring-data-jpa-quan-mian-jie-xi\n\n","slug":"springboot/spring-boot-data-jpa-practice","date":"2023-11-27T14:58:52.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,JPA","author_index":"glmapper"},{"id":"13684172933510c4dbfa702cdfb990b7","title":"Linux 服务器端口不可访问问题排查","content":"问题描述项目中使用的服务器是物理机，使用 centos 7.6 版本的操作系统， 4 个千兆网口，上架时间 23 年 8  月份。部署在内网机房，并且在内网机房分配的固定IP 是 172.87.7.249，并在机器上部署了 docker，\n\n\n大概在 10 月中旬左右，这台机器出现访问时好是坏的问题；前期出现时一直以为是机房调整网络环境导致，短暂性的不可访问没有实际影响业务，所以就没太关注。但是从 10 月底开始，机器开始频繁性出现不可访问的问题，开始接入排查。\n同机房同机柜还有其他 3 台服务器，ip 地址分别为 172.87.7.246，172.87.7.247，172.87.7.248。在 172.87.7.249 出现频繁性不可访问的同时，在办公网环境其他 3 台机器访问均无影响，并在当在办公网通过 ssh 登录 172.87.7.249 提示 Connection refused 时，通过其他三台机器的任何一台  ssh 登录 172.87.7.249，却可以登录。\n总结下现象：\n\n1、172.87.7.246，172.87.7.247，172.87.7.248，172.87.7.249 同处一个机房，一个机柜，连接的也是同一个核心交换机，同一个网关。\n2、办公网环境访问 172.87.7.249，前期偶发性时好时坏，后期频繁不可访问，间歇性可访问。\n3、办公网环境访问 172.87.7.248/247/246，正常。\n4、172.87.7.248/247/246 访问 172.87.7.249 前期正常，后期短暂间歇性不可访问，但大多数情况下是可以访问的。\n5、172.87.7.249 能 ping 通\n\n\n\n\n\n\n\n\n\n\n看到这里，对于熟悉网络的大神应该能猜到个八九不离十的原因了，但是对于研发工程师来说，网络问题一直都是技术上的疼点。\n下面就从研发视角来看下排查过程。\n排查过程防火墙配置一般情况下，IP 能 ping 通，端口无法访问，99% 的原因都是出在防火墙；\n\n1、先通过 systemctl status firewalld 查看防火墙状态，可以看到防火墙正常开启\n12345678910111213[root@localhost ~]# systemctl status firewalld● firewalld.service - firewalld - dynamic firewall daemon   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)   Active: active (running) since 二 2023-11-21 00:29:44 CST; 3 days ago     Docs: man:firewalld(1) Main PID: 63661 (firewalld)    Tasks: 2   Memory: 26.0M   CGroup: /system.slice/firewalld.service           └─63661 /usr/bin/python2 -Es /usr/sbin/firewalld --nofork --nopid11月 21 00:29:44 172-87-7-249.brainerd.net systemd[1]: Starting firewalld - dynamic firewall daemon...11月 21 00:29:44 172-87-7-249.brainerd.net systemd[1]: Started firewalld - dynamic firewall daemon.\n\n\n\n2、通过 firewall-cmd --list-ports 查看端口开发策略，22 端口正常的\n12[root@localhost ~]# firewall-cmd --list-ports22/tcp 80/tcp 9080/tcp\n\n​\t\t一般情况下，默认 zone 是 public；\n\n3、这里为了避免可能是 zone 策略问题，也看了下 zone 和出网网卡的对应\n1234567[root@localhost ~]# firewall-cmd --get-active-zonespublic  interfaces: enp61s0f0[root@localhost ~]#[root@localhost ~]# firewall-cmd --get-zone-of-interface=enp61s0f0public[root@localhost ~]#\n\n这里也没问题，同时为了避免环境差异，对比了其他三台机器，配置策略都是一样的。\n\n\n进程是否 OK之前在使用 onlyoffic 时遇到的一个问题，在宿主机上通过 docker 启动 onlyoffic，启动完成之后通过 docker ps  查看镜像运行状态是正常的，通过 netstat 查看端口对应的进程也存在（宿主机的），但是也是端口无法访问；当时问题是因为镜像容器内部的 nginx 进程没有被拉起导致的，就是宿主机的端口正常，但是映射到容器内部的端口对应的进程不存在。\n为了避免重复踩坑，也涨了记性查了下进程\n1234[root@localhost ~]# ps -ef | grep sshdroot      93164 171028  0 14:02 ?        00:00:00 sshd: root@pts/0root      96871  93211  0 14:18 pts/0    00:00:00 grep --color=auto sshdroot     171028      1  0 11月13 ?      00:00:00 /usr/sbin/sshd -D\n\nsshd 进程也是正常的。实际上到这里从研发视角的排查基本就到头了，但是这些都是正常的，问题依然存在。\n是否和 docker 有关在排查完防火墙和进程之后，把目标瞄向了 docker 容器了，这里的依据是：\n\n1、执行 systemctl status firewalld 时，有一条告警\n1WARNING: COMMAND_FAILED: &#x27;/usr/sbin/iptables -w10 -D FORWARD -i docker0 -o d\n\n2、执行 firewall-cmd --get-zones 时，提示\n1block dmz docker drop external home internal nm-shared public trusted work\n\n实际上这两个问题从排查来看，并不是前述问题的原因，但是这两个提示把我们排查的方向带的有点偏。首先是第一个告警，这个问题是因为 dockerd 启动时，参数 –iptables 默认为 true，表示允许修改 iptables 路由表；当时排查时，我是直接将 docker stop 掉了，因此排除了这个因素，如果需要修改docker iptables ，可以在 /etc/docker/daemon.json 这个文件修改。\n关于第二个，这里稍微介绍下；firewalled 有两个基础概念，分别是 zone 和 service，每个 zone 里面有不同的 iptables 规则，默认一共有 9 个 zone，而 Centos7 默认的 zone 为 public：\n\ndrop（丢弃）：任何接收的网络数据包都被抛弃，没有任何回复。仅能有发送出去的网络连接。\n\nblock（限制）：任何接收的网络连接都被IPv4的icmp-host-prohibited信息和IPv6的icmp-adm-prohibited信息所拒绝。\n\npublic（公共）：在公共区域使用，不能相信网络内的其他计算机不会对你的计算机造成危害，只能接收经过选取的连接\n\nexternal（外部）：特别是为路由器启用了伪装功能的外部网。你不能信任来自网络的其他计算，不能相信它们不会对你的计算机造成危害，只能接收经过选择的连接。\n\ndmz（非军事区）：用于你的非军事区内的计算机，此区域内可公开访问，可以有限地进入你的内部网络，仅仅接收经过选择的连接。\n\nwork（工作）：用于工作区。你可以基本相信网络内的其它计算机不会危害你的计算机。仅仅接收经过选择的连接。\n\nhome（家庭）：用于家庭网络。你可以基本信任网络内的其它计算机不会危害你的计算机。仅仅接收经过选择的连接。\n\ninternal（内部）：用于内部网络。你可以基本上信任网络内的其它计算机不会威胁你的计算机，仅仅接收经过选择的连接。\n\ntrusted（信任）：可接收所有的网络连接\n\ndocker: 这个当我们在机器上启动 dockerd 时，docker 自己会默认创建一个 zone。\n\n\n根据前面防火墙部分的排查，我们的规则是在 public zone 的，是正常的。\nIP 冲突在排查完上面几种情况之后，已经开始怀疑是不是硬件问题导致的。并且联系和厂商和机房网管从机房防火墙层面开始排查，但是结论都是正常。这个问题和两位小伙伴闲聊提了下，他们猜测的点中包括了上面的几种情况，此外还提到一个点就是可能是 IP 冲突。\n实际上一开始关于 IP 冲突，第一直觉就是不大可能，因为机房里面的机器都是固定分配的，而且不同单位分配的地址也是按段分配，所以不大可能出现 IP 冲突。DHCP\n但是在排除上述可以排查的所有问题之后，我又把排查思路转义回到了这个问题上，并开始测试。这里使用的工具是 arp-scan。\n执行：sudo arp-scan -I eno1 -l （eno1 是我使用的测试机器的网卡标识）\n\n\n可以看到，确实存在两个相同的 IP，并且有一台通过 mac 地址对比是我们的机器。通过 arping 也可以看到能够收到两台设备返回的数据包。\n\n那至此基本是明确是因为 IP 冲突导致的。一开始因为当前 IP 绑定了一些上下游服务，不大想改我们的 ip，于是就尝试从 mac 地址来找设备，但是没能实现。如果你的环境允许，你可以先是通过 https://mac.bmcx.com/ 查了下当前冲突的那个 mac 地址对应的设备类型和厂商来缩小人工排查范围。\n最后再回头来盘一下 IP 冲突的问题，因为之前提到，机房内的设备 IP 都是固定分配的，那为什么会存在 IP 冲突呢？这只能是我们当前环境是如此的糟糕，当找网管要了办公区及机房 IP 段分配标准时发现，机房的 IP 和办公区域的 IP 分段规则是有重合的。比如机房的 172.87.7.xxx 在办公网环境也会存在，并且是基于 DHCP 协议自动分配 IP 的。\n总结本篇主要记录了一次 Linux 服务端口访问不通问题的排查过程，涉及到了 Linux 防火墙、进程&#x2F;端口、Docker 以及 arp-scan 等方向和工具。事实证明，大多数问题并不是那么复杂，在没有足够的知识积累的情况下，总归是要花这些成本去弥补自己知识欠缺的。最后想说的就是，一个耗费相当大精力排查的问题，不一定是复杂的问题，往往这个问题的产生原因是相关简单的。\n","slug":"linux/linux-port-deny-access","date":"2023-11-27T14:57:01.000Z","categories_index":"Linux","tags_index":"linux,arping","author_index":"glmapper"},{"id":"b6cc4bb37be33d0751cb992f744131af","title":"Nginx 转发 404 问题的排查和思考","content":"\n\n\n\n\n\n\n\n\n本篇文章原自当前业务遇到的一个实际问题，因为受到所在网络环境的因素影响，所以整体排查下来耗费了很大精力，记录一下。\n项目背景项目是 toG 项目，部署的网络环境是一个大的内网环境（又具体分为内网和内网互联网区），项目涉及到小程序、前端、后端（又包括 JAVA 和 GO 两个项目）的部署。整体的部署拓扑图大致如下：\n\n\n\n\n\n\n\n\n\n\n\n虚拟 IP 映射：大多数内网如何需要暴露对外访问，会在出口的核心路由上配置一个虚拟的 IP 作为对外的统一访问入口。比如你的内网地址及端口是 10.13.3.177:8080，则通过虚拟 IP 映射的地址及端口可能是：10.31.31.253:8080。\n在这个业务流程程，访问路径是：公网（小程序前台）-&gt; 内网互联网区【10.31.1.142(nginx + 小程序后台)】 -&gt; 【10.31.31.253 -&gt; 10.13.3.177(nginx+后端)】 -&gt; 【10.233.1.2 -&gt; 172.13.7.249(nginx+后端)】。其中 10.13.3.177 和 172.13.7.249 是两台虚拟机，虚拟机上部署了nginx 和 后端服务。\n\n\n\n\n\n\n\n\n\nPS：上述所有的 IP 均已做过处理，非正式 IP。\n问题访问步骤及问题节点：\n\n1、小程序访小程序后台服务\n2、小程序后台服务发起调用到 10.31.31.253（这里实际上是 10.31.1.142 要调用 10.233.1.2 的服务，因为 10.31.1.142 不能直接访问 10.233.1.2，所以借用 10.31.31.253 来实现一层转发逻辑）。\n\n这里会涉及到两个转发，\n\n10.31.31.253 对应的 10.13.3.177 这台机器上的 nginx 需要将 10.31.1.142 的请求转发给 10.233.1.2\n10.233.1.2 对应的 nginx 需要将请求到当前机器的后台服务上\n\n在转发时通过 10.31.31.253 调用 10.233.1.2 时出现 404，10.233.1.2 调用本机后端服务时也出现 404；还有一个 502 是 10.31.1.142 访问 10.31.31.253 出现的。下面是分析问题的大体过程和解决办法。\n因端口映射导致的访问 502 问题前面提到 10.31.31.253 和 10.233.1.2 均是 虚拟 IP ，10.31.31.253:8805 端口映射到虚拟机 10.13.3.177  上的端口是 18805，10.13.3.177 上 nginx 配置的监听端口是 18805，所以 10.31.1.142 在访问的第一跳是 10.31.31.253:8805，但在实际排查中发现， 10.31.1.142 访问的是 10.31.31.253:18805，所以出现 502 问题。\n\n\n\n\n\n\n\n\n\n状态码 502 表示 HTTP 协议中的 “Bad Gateway”，通常用于表示服务器作为网关或代理时遇到了问题。这个错误通常会在一个服务器作为中介时，无法从另一个服务器获取有效响应以满足客户端请求时出现。\nproxy_pass 转发 url 丢弃路径导致的 404 问题根据前面的背景，实际上两个 404 问题均是因为这个原因导致。10.31.1.142 发起的请求是 10.31.31.253:8805/miniapp/user/case, nginx access.log 的日志如下：\n123&quot;POST /miniapp/user/case HTTP/1.1&quot; 404 153 &quot;-&quot; &quot;Java/1.8.0_351&quot;&quot;POST /miniapp/user/case HTTP/1.1&quot; 404 153 &quot;-&quot; &quot;Java/1.8.0_351&quot;&quot;POST /miniapp/user/case HTTP/1.1&quot; 404 153 &quot;-&quot; &quot;Java/1.8.0_351&quot;\n\n因为这个请求不是 10.31.31.253 对应的 10.13.3.177 这台机器上的服务处理，而是直接转发给 10.233.1.2 对应的 172.13.7.249 机器的，因此这里出现 404，因为是转发到 172.13.7.249 时没有找到相应的资源。查看 249 机器上的 nginx 访问日志\n123&quot;POST /user/case HTTP/1.0&quot; 404 153 &quot;-&quot; &quot;Java/1.8.0_351&quot;&quot;POST /user/case HTTP/1.0&quot; 404 153 &quot;-&quot; &quot;Java/1.8.0_351&quot;&quot;POST /user/case HTTP/1.0&quot; 404 153 &quot;-&quot; &quot;Java/1.8.0_351&quot;\n\n可以看到， 249 这台机器上的请求变成了 &#x2F;user&#x2F;case，丢失了 &#x2F;miniapp 这个 prefix，10.13.3.177 机器的 nginx 配置如下：\n1234location /miniapp/ &#123;    // 主要是这里    proxy_pass http://10.31.31.253:8805/;&#125;\n\n关于这个问题，解决方案大致有如下几种（来源各种技术文章）：\n\n1、修改代理配置：将匹配以 &#x2F;miniapp 开头的所有请求，并将它们代理到 10.31.31.253:8805，保持请求 URI 不变。\n\n123location /miniapp &#123;    proxy_pass http://10.31.31.253:8805;&#125;\n\n\n2、使用正则表达式捕获和重写 URI：捕获以 &#x2F;miniapp 开头的请求，并将 &#x2F;miniapp 后面的部分传递给后端服务器。\n\n123location ~ ^/miniapp(/.*)$ &#123;    proxy_pass http://10.31.31.253$1;&#125;\n\n\n3、rewrite 重写：使用 rewrite 指令将 &#x2F;miniapp 后面的部分提取出来，然后将其传递给后端服务器\n\n1234location /miniapp/ &#123;    rewrite ^/miniapp(/.*)$ $1 break;    proxy_pass http://10.31.31.253;&#125;\n\n\n4、保留 location 前缀：就是将 location 前缀保留在 proxy_pass 的后面\n\n123location /miniapp/ &#123;    proxy_pass http://10.31.31.253:8805/miniapp/;&#125;\n\n经测试，方案 1 和 方案 4 是可以解决 404 问题的。其中方案 4 是有病治病的逻辑，转发丢弃则就加上。这两个问题对于了解 nginx proxy_pass 配置的同学来说应该一眼就可以看到问题所在，但是 **大多数时候，我们会忽略那些看起来并不是很显眼的东西，比如 /**。\nproxy_pass 配置以 &#x2F; 结尾和不以 &#x2F; 结尾的区别\n以 &#x2F; 结尾的proxy_pass配置\n\n123location /miniapp/ &#123;    proxy_pass http://10.31.31.253:8805/;&#125;\n\n这种配置方式以斜杠 / 结尾，意味着 Nginx 会将原始请求的 URI 与 proxy_pass 后面的 URI 拼接在一起，并将最终的请求发送到后端服务器。例如，如果原始请求是 http:&#x2F;&#x2F;10.31.1.142&#x2F;miniapp&#x2F;user&#x2F;case，那么 Nginx会将它代理到 http://10.31.31.253:8805/user/case。\n\n不以 &#x2F; 结尾的proxy_pass配置\n\n123location /miniapp/ &#123;    proxy_pass http://10.31.31.253:8805;&#125;\n\n这种配置方式没有斜杠 &#x2F; 结尾，意味着 Nginx 会将原始请求的 URI 原封不动地传递给后端服务器。例如，如果原始请求是 http://10.31.1.142/miniapp/user/case，那么 Nginx 会将它代理到http://10.31.31.253:8805/miniapp/user/case。\n所以说，如果你希望将请求映射到后端服务器的根目录，则可以使用以斜杠 / 结尾的配置。如果你希望保持URI不变，可以使用不以 / 结尾的配置。\n关于 proxy_pass 以及 location网上关于这两个介绍的文章非常多，本篇不做过多的阐述。\n\nproxy_pass 指令用于定义 Nginx 的 反向代理 功能。它指定了将客户端请求代理到的后端服务器的地址，关于反向代理和负载均衡可以参考我之前写过的一篇文章：nginx反向代理和负载均衡策略实战案例；\nlocation 指令用于匹配客户端请求的 URI，然后定义如何处理这些请求，推荐阅读：彻底弄懂 Nginx location 匹配。\n\n小结问题其实不是很复杂，主要还是对于 nginx 的一些配置作用不大清楚，另外就是在实际排查过程中，因为链路和网络环境问题走了很多弯路；但是如果把这些信息梳理清楚了，就会拨云见日；问题就在那里，复杂的是过程。\n","slug":"middleware/middleware-nginx-proxy-pass","date":"2023-09-13T01:04:07.000Z","categories_index":"Middleware","tags_index":"nginx,反向代理,负载均衡","author_index":"glmapper"},{"id":"ddb33e3231bb937dcbd835cfc8516ae1","title":"如何编写测试用例","content":"代码质量管理是软件开发过程中的关键组成部分，比如我们常说的代码规范、代码可读性、单元测试和测试覆盖率等，对于研发人员来说单元测试和测试覆盖率是保障自己所编写代码的质量的重要手段；好的用例可以帮助研发人员确保代码质量和稳定性、减少维护成本、提高开发效率以及促进团队合作。之前看过一篇关于 OceanBase 质量之道的文章，文章中提到的工程理念就把测试作为非常重要的组成部分，是和研发同样重要的组成部分；也听过内部的同学说过，OB 最核心的是用例。\n\n\n\n\n\n\n\n\n\n\n\nOceanBase工程理念：经过多年的摸索，OceanBase团队打造了独特的工程文化。测试和开发同时进行，功能测试不再是一个独立分开的过程，而是融入到开发环节，从源端控制引入bug的概率。资深测试人员的精力主要放在难度较大的bug的发现，测试体系建设和相关技术钻研、测试自动化实施。我们建立了一套高效的代码准入流程，防范了许多初级的问题，提升了团队整体的研发效率。\n由此可见，测试用例对于项目的重要性。从实际的工作中，也会发现大多数的同学对于如何编写测试用例其实是比较模糊的，在以项目交付为核心思路的工程实践中，测试用例往往只占整个工程周期相当小的一部分，更多时候是依赖测试团队进行功能测试，属于纯黑盒测试。那么这种测试对于业务常规流程可以起到一定的作用，但是对于一些边界问题其实很难 cover 住；另外，基于黑盒模式的功能性测试对于研发团队本身来说，除了拿到准入的测试报告之外，并无其他帮助，当研发需要对代码进行重构或者升级某部分组件时，没有用例的保障，则会将风险直接带到线上环境去。\n常见的测试方式在既往的工作团队中，关于测试方式，包括我自己在内，在没系统了解过测试理论之前，对于各种测试方式也是模棱两可；因为测试方式的种类实在是多又杂。下面是梳理的常见的测试方式，按照不同的维度进行了分类。\n\n\n\n分类维度\n测试方式\n说明\n\n\n\n测试目标\n功能测试\n验证系统是否按照规格说明的功能需求进行操作和响应。\n\n\n\n性能测试\n评估系统在不同负载条件下的性能表现。\n\n\n\n安全性测试\n发现系统的安全漏洞和弱点，以确保系统不容易受到攻击。\n\n\n\n回归测试\n确保在对系统进行修改后，没有引入新的错误或破坏已有功能。\n\n\n\n可用性测试\n评估系统的用户界面和用户体验。\n\n\n\n兼容性测试\n验证系统在不同浏览器、操作系统和设备上的兼容性。\n\n\n测试层次\n单元测试\n验证单个代码单元（通常是函数、方法、类等）的正确性。\n\n\n\n组件测试\n验证单个软件组件的功能性和正确性。\n\n\n\n集成测试\n验证不同组件、模块或服务之间的接口和协同工作。\n\n\n\n系统测试\n验证整个系统是否按照需求规格正常运行。\n\n\n\n验收测试\n由最终用户或客户进行的测试，以验证系统是否满足其需求和期望。\n\n\n测试方法\n手动测试\n测试人员手动执行测试用例，模拟用户的操作。\n\n\n\n自动化测试\n使用自动化测试工具和脚本来执行测试用例，提高测试效率和一致性。\n\n\n\n白盒测试\n关注内部代码逻辑，通常由开发人员执行。\n\n\n\n黑盒测试\n关注输入和输出，不关心内部代码逻辑。\n\n\n\n灰盒测试\n结合了白盒测试和黑盒测试的特点。\n\n\n执行时机\n静态测试\n在代码编写之前或编译之后执行，包括静态代码分析、代码审查等。\n\n\n\n动态测试\n在运行时执行，包括各种类型的功能测试、性能测试等。\n\n\n测试对象\n功能测试\n测试系统的功能性。\n\n\n\n非功能测试\n测试系统的非功能性特征，如性能、安全性、可用性等。\n\n\n\n白盒测试\n测试代码的内部逻辑和结构。\n\n\n\n黑盒测试\n测试系统的输入和输出，不考虑内部实现。\n\n\n每种测试方式都有其独特的目标和方法，可以在软件开发生命周期的不同阶段进行。不同的测试方式在不同的测试维度分类下会有一些重叠，这是正常的，但是他们的关注点是一致的。\n在本篇文章中，主要更偏向于研发侧，所以从测试层次角度来看，更多的是关注单元测试(UT)、组件测试(CT)以及集成测试(IT)。总体来说，UT 关注代码单元的正确性，CT关注组件的功能性，IT关注不同组件的集成和协同工作。这些测试层次通常是渐进的，从UT开始，然后是CT，最后是IT。不同的测试方式在软件测试策略中起着不同的作用，这些测试手段的目的就是共同确保软件在各个层次上的质量和稳定性。\n\n\n\n\n\n\n\n\n\n下面会通过一个具体的例子来阐述不同的测试方式，主要是针对单元测试、组件测试和集成测试；项目基于 Spingboot 2.4.12 版本，使用 Junit4 和 Mockito 两种测试工具包。\nUT、CT 和 IT在具体看案例之前，先把几个测试工具跑出来，做个简单了解。\n测试工具下面的案例中主要涉及到的测试工具和框架包括：spring-boot-starter-test、junit4和Mockito。\nspring-boot-starter-test\n\n\n\n\n\n\n\n\n官方文档：https://docs.spring.io/spring-boot/docs/1.5.7.RELEASE/reference/html/boot-features-testing.html \nspring-boot-starter-test 是 Spring Boot 提供的一个用于测试的依赖库，它简化了 Spring Boot 应用程序的测试过程，提供了许多有用的工具和类，帮助开发人员编写高效、可靠的单元测试和集成测试。就目前而言，JAVA 技术栈的项目是绕不开 Spring 这套体系的，而绝大多数情况下，在 spring 或者 springBoot 项目中，我们需要依赖 spring 容器刷新之后去测试相应的逻辑，spring-boot-starter-test 就是做这个事情的。\n12345&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;  &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\njunit4JUnit 4 是一个用于 Java 编程语言的单元测试框架。目前版本是 JUnit 5，目前我们项目中使用的是 JUnit4。以下是 JUnit 4 中一些常用的特性和概念：\n\n注解驱动的测试：JUnit 4使用注解来标记测试方法，以指定哪些方法应该被运行为测试。常见的测试注解包括 @Test 用于标记测试方法、@Before 用于标记在每个测试方法之前运行的方法、@After 用于标记在每个测试方法之后运行的方法等。对于全局资源的初始化和释放可以通过 @BeforeClass 和 @AfterClass 来搞定。\n测试套件：JUnit 4允许你将多个测试类组合在一起，形成一个测试套件，然后可以一次运行所有测试类。这对于组织和管理测试非常有用。\n断言：JUnit 4提供了一系列的断言方法，用于验证测试中的条件是否为真。如果条件不满足，断言将引发测试失败。常见的断言方法包括 assertEquals、assertTrue、assertFalse、assertNull、assertNotNull 等。\n运行器（Runners）：JUnit 4引入了运行器的概念，允许你扩展测试的执行方式。JUnit 4提供了一些内置的运行器，例如 BlockJUnit4ClassRunner 用于普通的 JUnit 测试类，还有一些用于特定用途的运行器，如 Parameterized 用于参数化测试。目前在 springboot 中，使用了 SpringRunner 其实也是 BlockJUnit4ClassRunner 的子类。\n\n关于 Junit 的运行机制可以参考我之前写的一篇文章：你知道 Junit 是怎么跑的吗？\nMockitoMockito 是一个用于模拟对象的框架，用于创建和配置模拟对象，以模拟外部依赖。Mockito 的主要焦点是模拟外部依赖，以便在单元测试中隔离被测试的代码，并确保它与外部依赖正确交互。和 JUnit 4 的区别在于，JUnit 4  是一个单元测试框架，用于编写和运行测试用例，JUnit 4 的主要焦点是定义和执行测试，以及管理测试生命周期。关于 Mockito 的运行机制可以参考我之前写的一篇文章：聊一聊 Mockito\n单元测试（UT）在前面的测试分类中，单元测试主要是验证单个代码单元（通常是函数、方法、类等）的正确性；在实际的项目中，单元测试主要是对于一个封装好的工具类的测试。如在 DateUtil 工具类中有一个方法：\n1234567public static String getDate(Date date, String pattern) &#123;    if (null == date) &#123;        return null;    &#125;    SimpleDateFormat sdf = new SimpleDateFormat(pattern);    return sdf.format(date);&#125;\n\n右击选中方法，goto -&gt; test，也可以通过相应的快捷键直接创建当前选中方法的测试用例。相应的测试代码如下：\n12345678public class DateUtilTest &#123;    @Test    public void test_getDate() &#123;        int dateYear = DateUtil.getDateYear(new Date());        String yyyy = DateUtil.getDate(new Date(), &quot;YYYY&quot;);        Assert.assertEquals(String.valueOf(dateYear), yyyy);    &#125;&#125;\n\n这里覆盖了正常的情况，对于传入 date 为 null 的分支并未覆盖到；所以对于强调覆盖率必须满足一定阈值的情况(之前的一个项目中，在 CI 流程中会对当前提供的代码覆盖率进行严格把控，比如行覆盖率比如达到 75% 才能被 merge)，则对于不同分支逻辑也需要提供对应的用例。\n123456// 当date 为 null 时，期望返回 null@Testpublic void test_getDate_when_date_null_thenReturn_null() &#123;    String result = DateUtil.getDate(null, &quot;YYYY&quot;);    Assert.assertEquals(null, result);&#125;\n组件测试（CT）&#x2F;集成测试（IT）我们目前基于 SpringBoot test 的测试，大体可以归类于组件测试；这种情况只需要针对当前服务自己的组件进行设计用例；对于可能涉及到的上下游依赖，一般可以通过 mock 的方式来绕过，从而使得当前应用的用例 focus 在自己的业务逻辑上。\n使用 mock 代替实际请求场景描述：UserCaseService 中有个 getUserCaseList 方法，通过传入一个 UserCaseRequest 参数，然后去另一个服务拉取当前用户的事件列表；代码如下：\n123456789public Response&lt;CaseResponse&gt; getUserCaseList(UserCaseRequest request) &#123;    Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();    param.put(&quot;phone&quot;,request.getPhone());    param.put(&quot;pageNo&quot;,request.getPageNo());    param.put(&quot;pageSize&quot;,request.getPageSize());    JSONObject result = HttpUtils.useHHMApi(&quot;/miniapp/user/case&quot;, param);    Response&lt;CaseResponse&gt; response = result.toJavaObject(result, Response.class);    return response;&#125;\n\n在 HttpUtils 中，底层是对 RestTemplate 的封装：\n1234567891011public static JSONObject request(String url, Map&lt;String, Object&gt; headers, Map&lt;String, Object&gt; param) &#123;HttpHeaders head = new HttpHeaders();if (!ObjectUtils.isNull(headers)) &#123;    for (String h : headers.keySet()) &#123;        head.add(h, String.valueOf(headers.get(h)));    &#125;&#125;// HttpUtils.useHHMApi 底层实际发起拉取数据的地方String entity = restTemplate.postForObject(url, new HttpEntity&lt;Map&gt;(param, head), String.class);return JSONObject.parseObject(entity);&#125;\n\n在上面那段代码中，会具体发送 http 请求到另一个服务去拉取数据。对于这种场景：\n\n1、需要保障用例不会受到对方服务的影响都能顺利执行。\n2、关注的是 getUserCaseList 这个方法本身的逻辑（这里举例，代码做了相应的简化）\n\n因此，和实际运行的逻辑不同在于，在编写测试用例时，对于底层发起的 http 调用其实不是主要关注的，可以基于约定好的成功&#x2F;失败的数据报文结构，通过 mock 的方式来代替实际 http 请求发送。\n123456789101112@Testpublic void test_getUserCaseList() &#123;    // 提供 mock 条件    Mockito.when(restTemplate.postForObject(Mockito.any(String.class), Mockito.any(HttpEntity.class), Mockito.any(Class.class))).thenReturn(MockData.mockMiniAppUserCaseResponseData(true));    UserCaseRequest request = new UserCaseRequest();    request.setPhone(&quot;15215608668&quot;);    request.setPageNo(1);    request.setPageSize(10);    Response&lt;UserCaseResponse&gt; response = naturalService.getUserCaseList(request);    Assert.assertEquals(&quot;200&quot;, response.getCode());&#125;\n\n通过这种形式，则可以有效屏蔽因为三方服务对于我们自己当前用例的影响（核心的还是要关注在自己的业务逻辑上）；\n\n\n\n\n\n\n\n\n\n准备条件可以在 @Before 中体现@Beforepublic void before() {    RestTemplate restTemplate &#x3D; Mockito.mock(RestTemplate.class);    HttpUtils.setRestTemplate(restTemplate);}\nSpringBootTest 说明在 test_getUserCaseList 中，naturalService 是一个spring bean，因此执行此用例我们需要依赖 spring 容器环境。\n123456789@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT,                 classes = ServerApplication.class)@RunWith(SpringRunner.class)public class UserCaseTest &#123;    @Autowired    private NaturalService naturalService;    // your test case &#125;\n\n@SpringBootTest 在官文档中被描述用于 integration testing 使用的注解，其目的是用于启动一个 ApplicationContext，达到在无需部署应用程序或连接到其他基础设施即可执行集成测试。已上面的代码为例，其中：\n\nwebEnvironment 用于描述运行环境，主要包括以下几种类型：\n\n\n\n类型\n描述\n\n\n\nMOCK\n这个选项不启动真正的 Web 服务器，而是使用模拟的 Servlet 上下文来运行测试。这意味着你的应用程序的 Web 层（控制器、过滤器等）将在一个模拟的环境中运行，不会实际处理 HTTP 请求和响应。这种环境适用于单元测试和切片测试，通常用于测试应用程序的业务逻辑。\n\n\nRANDOM_PORT\n这个选项会启动一个嵌入式的 Web 服务器，并随机选择一个可用的端口。测试将通过实际的 HTTP 请求和响应与应用程序的 Web 层交互。这种环境适用于端到端测试，可以测试整个 Web 栈，包括控制器、服务、数据访问等。\n\n\nDEFINED_PORT\n这个选项也会启动嵌入式的 Web 服务器，但它会使用一个预定义的端口号。你可以通过 server.port 配置属性来指定端口号。与 WebEnvironment.RANDOM_PORT 不同，这个选项的端口号是固定的。这对于需要在已知端口上运行测试的情况很有用。\n\n\nNONE\n这个选项完全不启动 Web 服务器。它用于纯粹的单元测试，不涉及任何 Web 层的逻辑。在这种环境中，通常只测试应用程序的业务逻辑和服务层，不测试与 HTTP 请求和响应相关的内容。\n\n\n\nclasses 属性用于指定要加载的配置类，这些配置类将用于初始化 Spring Boot 应用程序上下文。通过 classes 属性，可以控制在测试中加载的 Spring Bean 配置，以适应不同的测试需求。在上述案例中，ServerApplication.class 是当前项目的启动类，表示在测试中加载整个应用程序上下文。\n\n@RunWith 用于指定测试运行器（Runner），JUnit 4 默认运行器是 BlockJUnit4ClassRunner ，在 Spring 中对应的是 BlockJUnit4ClassRunner 的子类 SpringJUnit4ClassRunner，而上述代码中的 SpringRunner 和  SpringJUnit4ClassRunner 是一样的，从 SpringRunner 类的源码注释中可以看到，SpringRunner是 SpringJUnit4ClassRunner 的别名(SpringRunner is an alias for the SpringJUnit4ClassRunner)。\n\n\n使用 H2 内存数据库来代替实际库在编写用例时，大多数情况下，我们需要依赖数据库的数据进行场景描述；但是一般情况下，即使是测试库，用于作为测试用例的依赖也是不合适的。因此在实践过程中，一般会使用 H2 来代替实际使用的类似 Mysql 数据库来进行测试，实现数据层面的环境隔离。使用 H2 作为测试用例依赖数据库也比较简答，在 pom 中引入如下 H2 的依赖。然后在测试时指定对应 H2 的配置文件代替 Mysql 的配置文件即可。制定配置参考下一小节。\n12345&lt;dependency&gt;  &lt;groupId&gt;com.h2database&lt;/groupId&gt;  &lt;artifactId&gt;h2&lt;/artifactId&gt;  &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n使用指定的测试配置文件如前面提到，如何我们期望测试用例的环境和实际的环境隔离，则可以使用一个单独的配置文件来描述。比如使用 H2 代替实际的数据库。\n\n测试配置文件 application-test.yaml\n12345678spring:  # 使用 H2 作为数据源  datasource:    url: jdbc:h2:mem:customdb    driverClassName: org.h2.Driver    username: root    password: password# 省略其他配置\n\n指定配置文件\n12345678910@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT,                 classes = ServerApplication.class)@RunWith(SpringRunner.class)@PropertySource(value = &#123;&quot;classpath:application-test.yaml&quot;&#125;)public class UserCaseTest &#123;    @Autowired    private NaturalService naturalService;    // your test case &#125;\n\n做好测试资源的清理做好测试资源清理是一个好用例具备的基本前提；如何两个研发同事需要依赖某一个表的数据进行用例设计，如果每个人都没有做好自己用例的资源清理，则在实际的用例执行过程中则会出现用例之间的相互干扰。另外，如过对于一些团队，没有使用 H2 来代替实际的测试库，那么在用例不断执行的过程中，会给测试库产生相当于的测试脏数据。基于上面两个前提，所以我们在设计用例时，特别是涉及到数据或者状态变更的场景时，一定要做好相应的资源清理。如：用户注册的场景逻辑：\n1234567891011@Testpublic void test_register()&#123;    UserDto userDto = new UserDto();    userDto.setPhone(&quot;test number&quot;);    userDto.setName(&quot;test&quot;);    userDto.setNickName(&quot;test&quot;);    userDto.setPassword(&quot;test pwd&quot;);    // 注册用户    bool success = userService.register(userDto);    Assert.assertTrue(success);&#125;\n在上面这段用例，可能会出现的情况：\n\n如果用户表中没有做基于名字或者手机号的唯一性校验，则在我们的表中可能会出现很多 name 为 test 的用户。（每执行一次，则产生一条记录）\n如果用户表做了唯一性约束，那么当第一次执行完之后，第二次执行时则可能会报错，当前用例会执行失败。\n\n所以，在优化这个用例时，就可以将用例执行完之后的数据清除掉。具体做法有两种：\n\n1、在当前用例中执行，比如通过 try finally，在 finally 块中执行删除插入的数据\n2、在 @After 中执行删除插入的数据（@After 注解描述的方法，会在每个用例执行完之后执行，通过用于做资源清理）\n\n小结本篇主要针对如何编写测试用例进行了简单的介绍；包括场景的测试方式分类、测试工具；并通过几个小的测试用例对单元测试、组件测试和集成测试做了分析。最后针对日常研发中，如何做好测试编写和如何做好测试资源释放给了目前主流方案的建议和使用说明。\n","slug":"tests/test-about-write-test","date":"2023-09-08T09:15:51.000Z","categories_index":"test","tags_index":"test,junit","author_index":"glmapper"},{"id":"abbcd011f0be9dc628ed542e40f49896","title":"Linux nohup 命令","content":"nohup 表示不挂断地运行命令，是 no hangup 的缩写，语法格式如下：\n1nohup Command [ Arg ... ] [　&amp; ]\n\nnohup 命令运行由 Command参数和任何相关的 Arg参数指定的命令，忽略所有挂断（SIGHUP）信号。\nnohup放在命令的开头，表示不挂起（no hang up），也即，关闭终端或者退出某个账号，进程也继续保持运行状态，一般配合&amp;符号一起使用。如 nohup command &amp;。\n\n\n\nman nohup123456789101112131415161718192021222324252627282930313233343536NOHUP(1)                                                                                                                                                                  User Commands                                                                                                                                                                 NOHUP(1)NAME       nohup - run a command immune to hangups, with output to a non-ttySYNOPSIS       nohup COMMAND [ARG]...       nohup OPTIONDESCRIPTION       Run COMMAND, ignoring hangup signals.       --help display this help and exit       --version              output version information and exit       If standard input is a terminal, redirect it from /dev/null.  If standard output is a terminal, append output to &#x27;nohup.out&#x27; if possible, &#x27;$HOME/nohup.out&#x27; otherwise.  If standard error is a terminal, redirect it to standard output.  To save output to FILE, use &#x27;nohup COMMAND &gt; FILE&#x27;.       NOTE: your shell may have its own version of nohup, which usually supersedes the version described here.  Please refer to your shell&#x27;s documentation for details about the options it supports.       GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt; Report nohup translation bugs to &lt;http://translationproject.org/team/&gt;AUTHOR       Written by Jim Meyering.COPYRIGHT       Copyright © 2013 Free Software Foundation, Inc.  License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;.       This is free software: you are free to change and redistribute it.  There is NO WARRANTY, to the extent permitted by law.SEE ALSO       The full documentation for nohup is maintained as a Texinfo manual.  If the info and nohup programs are properly installed at your site, the command              info coreutils &#x27;nohup invocation&#x27;       should give you access to the complete manual.\n\n通过上面 man nohup 可以了解到：\n\n如果不将 nohup 命令的输出重定向，输出将附加到当前目录的 nohup.out 文件中。\n如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME&#x2F;nohup.out 文件中。\n\nnohup 重定向输出主要是针对常见的如：2&gt;&amp;1、/dev/null 等参数的解释。下表是各字符的含义解释：\n\n\n\n项\n描述\n\n\n\n&#x2F;dev&#x2F;null\n表示空设备文件\n\n\n0\nstdin 标准输入\n\n\n1\nstdout 标准输出\n\n\n2\nstderr 标准错误\n\n\n&gt; file\n将标准输出输出到file中，也就相当于 1&gt;file;\n\n\n2 &gt; error\n将错误输出到error文件中\n\n\n2&gt;&amp;1\n将错误重定向到标准输出上\n\n\n2&gt;&amp;1 &gt;file\n将错误输出到终端，标准输出重定向到文件file，等同于 &gt; file 2&gt;&amp;1\n\n\n有一点需要注意，对于 &gt; file 和 &gt;&gt; file\n\n&gt; 表示的是定向输出到文件，如果文件不存在，就创建文件；如果文件存在，就将其清空；一般我们备份清理日志文件的时候，就是这种方法：先备份日志，再用&gt;，将日志文件清空（文件大小变成0字节）；\n&gt;&gt; 表示的是将输出内容追加到目标文件中。如果文件不存在，就创建文件；如果文件存在，则将新的内容追加到那个文件的末尾，该文件中的原有内容不受影响。\n\n&amp; 符号&amp; 放在命令到结尾，表示后台运行，防止终端一直被某个进程占用，这样终端可以执行别到任务，配合 &gt;file 2&gt;&amp;1 可以将 log 保存到某个文件中，但如果终端关闭，则进程也停止运行。如 command &gt; file.log 2&gt;&amp;1 &amp; 。\n使用\n在控制台输出日志\n1nohup java -jar $GLMAPPER_APP_NAME.jar  &amp;\n\n不输出控制台日志\n1nohup java -jar $GLMAPPER_APP_NAME.jar  &gt;/dev/null 2&gt;&amp;1 &amp;\n\n一般情况下，我们的服务都是有配置指定的日志输出路径的，比如 java 中使用 logback 作为日志组件，在 logback-spring.xml 配置文件中指定了日志目录，那么这种情况下，我们就可以不需要将日志输出到控制台，则使用第二种方式就比较合理。\n对于有些服务如果启动后将日志输出到控制台，然后默认产生一个 nohup.out 文件，随着服务运行时间变长，nohup.out 文件可能会非常大；如果期望在不停服务的情况下清空 nohup.out 文件，则可以通过以下几种方式来完成\n\ncp &#x2F;dev&#x2F;null nohup.out\ncat &#x2F;dev&#x2F;null &gt; nohup.out\necho “” &gt; nohup.out\n\n最后还是建议配置日志路径，不要使用默认路径将日志输出。\n","slug":"linux/linux-no-hangup","date":"2023-08-15T02:12:22.000Z","categories_index":"Linux","tags_index":"linux,nohup","author_index":"glmapper"},{"id":"9d6bba182f887ce7358e9129a5f246bb","title":"基于 CentOS 7.6 + Samba 搭建文件服务器","content":"出于产品、解决方案同事的诉求，需要搭建一个用于共享文件的平台，因此基于 Samba 搭建了一个共享文件服务器，这里记录一下，以便用于后续维护参阅。\n\n\n\n\n\n\n\n\n\n Samba 是 SMB&#x2F;CIFS 网络文件共享协议的免费开放源重新实现，该协议允许最终用户访问文件，打印机和其他共享资源。\n\n\n环境\nCentOS 7.6\nSamba 4.10.16\n能够访问互联网环境\n\n安装 Samba执行安装\n1sudo yum install samba samba-client\n\n安装完成后，开机启动，并且启用服务：\n12sudo systemctl start smb.service sudo systemctl enable smb.service\n\nsmb  服务提供文件共享和打印服务，并侦听 TCP 端口 139 和 445。nmb服务向客户端提供基于 IP 命名服务的 NetBIOS，并侦听 UDP 端口137。\n配置防火墙执行如下命令，允许 samba 服务访问\n1234[root@localhost ~]# firewall-cmd --permanent --zone=public --add-service=sambasuccess[root@localhost ~]# firewall-cmd --zone=public --add-service=sambasuccess\n\n创建Samba用户和目录结构在确定文件或者用户目录之前要看下磁盘的空间情况\n12345678/dev/mapper/centos-root   50G  1.4G   49G    3% /devtmpfs                 3.9G     0  3.9G    0% /devtmpfs                    3.9G     0  3.9G    0% /dev/shmtmpfs                    3.9G   17M  3.9G    1% /runtmpfs                    3.9G     0  3.9G    0% /sys/fs/cgroup/dev/vda1               1014M  146M  869M   15% /boot/dev/mapper/centos-home  142G   33M  142G    1% /hometmpfs                    783M     0  783M    0% /run/user/0\n\n我的系统在 &#x2F;home 分配的空间最大，因此这里将所有 Samba 目录和数据都放在 &#x2F;home 空间下；新建一个 &#x2F;home&#x2F;samba\n1mkdir /home/samba\t\t\n\n创建一个名为sambashare的新组。然后，我们将所有 Samba 用户添加到该组中。\n1sudo groupadd sambashare\n\n将/home/samba目录组所有权设置为sambashare：\n1do chgrp sambashare /home/samba\n\n\n\nSamba 使用 Linux 用户和组权限系统，但它具有与标准 Linux 身份验证分开的身份验证机制。下面将使用标准的 Linux useradd工具创建用户，然后使用smbpasswd实用程序设置用户密码。\n创建 Samba 用户创建名为glmapper的新用户，命令如下：\n1sudo useradd -M -d /home/samba/glmapper -s /usr/sbin/nologin -G sambashare glmapper\n\n\n\nuseradd选项的含义如下：\n\n-M 不创建用户的主目录。(将手动创建此目录)\n-d /home/samba/glmapper  将用户的主目录设置为/home/samba/glmapper。\n-s /usr/sbin/nologin  禁止该用户访问 shell。\n-G sambashare  将用户添加到sambashare组。\n\n创建用户的主目录，并将目录所有权设置为用户 glmapper 和组 sambashare：\n12sudo mkdir /home/samba/glmappersudo chown glmapper:sambashare /home/samba/glmapper\n\n\n\n以下命令将 setgid 位添加到/home/samba/glmapper目录，以便该目录中的新创建文件将继承父目录的组。这样，无论哪个用户创建一个新文件，该文件都将具有sambashare的组所有者。例如，如果您未将目录的权限设置为2770，并且sadmin用户创建了一个新文件，则用户glmapper将无法读取&#x2F;写入该文件。 165]\n1sudo chmod 2770 /home/samba/glmapper\n\n设置用户密码将glmapper用户帐户添加到 Samba 数据库：\n1234567891011#系统将提示输入并确认用户密码。sudo smbpasswd -a glmapper#输入成功之后New SMB password:Retype new SMB password:Added user glmapper.# 启用 glmapper 账户，成功会显示 Enabled user glmapper.sudo smbpasswd -e josh   \n\n如果再需要创建其他用户，流程就是和创建 glmapper 的流程是一样的了。\n创建 用户和组 sadminsadmin 组的所有成员将具有管理权限，如果期望其他用户也具备管理权限，则可以将用户加入到 sadmin 这个组中。创建管理用户：\n1sudo useradd -M -d /home/samba/users -s /usr/sbin/nologin -G sambashare sadmin\n\n上面的命令还创建了一个组sadmin，并将用户添加到sadmin和sambashare组中。\n设置密码并启用用户：\n1234# 设置密码sudo smbpasswd -a sadmin# 启用账户sudo smbpasswd -e sadmin\n\n创建Users共享目录\n1234# 创建目录mkdir /home/samba/users# 将目录所有权设置为用户 sadmin 和组 sambashare：sudo chown sadmin:sambashare /home/samba/users\n\n所有身份验证的用户都可以访问此目录。以下命令配置对/home/samba/users目录中sambashare组成员的写&#x2F;读访问：\n1sudo chmod 2770 /home/samba/users\n\n\n\n配置 Samba 共享编辑 Samba 配置文件 vi /etc/samba/smb.conf ，并将下面的配置添加到配置文件中\n123456789101112131415[users]  # 登录时将使用的共享名称    path = /home/samba/users   # 分享的目录路径    browseable = yes # 是否应在可用共享列表中列出该共享。设置为no，其他用户将看不到共享。    read only = no   # valid users 列表中指定的用户是否能够写入此共享    force create mode = 0660    # 设置此共享中新创建文件的权限。    force directory mode = 2770 # 设置此共享中新创建目录的权限。    valid users = @sambashare @sadmin # 允许访问共享的用户和组的列表。组以@符号为前缀。[glmapper]    path = /home/samba/glmapper    browseable = no    read only = no    force create mode = 0660    force directory mode = 2770    valid users = glmapper @sadmin\n\n\n\n配置完成后，重新启动 Samba 服务\n12sudo systemctl restart smb.servicesudo systemctl restart nmb.service\n\n使用 win 配置连接到 Samba 共享下面是使用 Windows File Explore 访问共享的步骤：\n\n1、打开文件管理器，右击 “此电脑”\n2、选择 “添加一个网络位置”，然后点击下一步\n3、在 “Internet 或者网络地址” 中，输入 Samba 共享的地址 \\\\192.168.1.136\\glmapper (192.168.1.136 是我的主机 IP，glmapper 是我的共享目录)\n4、单机下一步，这里会提示你输入登录凭证（然后输入前面创建用户所设置的用户名和密码即可）\n5、下一步… 完成\n\n至此就可以在本地磁盘看到映射的服务器了。\n问题在配置完成之后，可以正常连接到文件服务器，并且也可以看到相应的目录，但是当我创建文件时，提示没有权限。从前面的用户&#x2F;组授权来看，完全是没有问题的。最后咨询了下 IT 部门的同事，猜测可能是 SELinux  禁止网络上对 Samba 服务器上的共享目录进行写操作导致；尝试执行 setenforce 0 之后无写权限的问题解决了。\n\n\n\n\n\n\n\n\n\nSELinux 的作用：\n\n1、通过对进程和文件资源采用 MAC 控制方式，为 Linux 系统提供了改进的安全性；\n2、赋予了主体最小的访问特权，最大限度地减小系统中服务进程可访问的资源，可以防止主体对其他用户或进程产生不利的影响；\n3、每个进程都有自己的运行区域，各进程仅运行在自己的域内，无法访问其他进程和文件；\n4、SELinux 能最大程序上限制 Linux 系统中的恶意代码活动。\n\nsetenforce  设置\n\n1  设置 SELinux  成为 enforcing 模式\n0  设置 SELinux  成为 permissive 模式\n\n","slug":"tools/tool-samba-file-server","date":"2023-05-31T02:00:35.000Z","categories_index":"工具","tags_index":"tool,samba","author_index":"glmapper"},{"id":"c71afb276dbf15777a4f23717015b86c","title":"使用 ngrok 解决测试时外部系统无法访问本地网络问题","content":"问题日常开发中有一些场景会有这样的诉求，就是外部系统 callback 回调本系统，但是本系统没有提供外部访问的 IP 或者域名；比如微信公众号测试号开发，就需要填写一个 URL，这个 URL 是开发者用来接收微信消息和事件的接口 URL，那如果这个 URL 是本地的，微信服务器肯定是无法访问的。\n对于这种情况，如果你本地机器可以提供公网访问的能力，那自然是没有问题的；如果不行，可能就需要考虑买一些云服务器来测试，但是这种测试肯定是没有直接本地测试（包括 debug）来的直接。\n\n\n还有一种办法就是通过 映射端口 把本地端口映射到外网，这个可以借助一些工具，比如 ngrok.\nngrokngrok 的使用非常简单，分分钟上手； 下载安装包 -&gt; 解压 -&gt; 打开终端。。\n\n\n\n\n\n\n\n\n\n可以通过此链接进行下载 ngrok 下载官网。这里下载需要账号，支持 github 和 google 三方来授权登录，如果你有这些三方账号，可以直接通过三方账号进行登录即可。\n登录之后，你可以在下图中的位置找到你自己的 token\n然后通过如下指令配置 token\n1./ngrok authtoken xxxx\n\n最后就是做端口映射，比如你的本地服务端口是 8080\n1./ngrok http 8080\n启动之后就会有个域名，如下图\n这样你可以可以将 https://4644-183-162-254-123.ngrok-free.app 作为你的外部网络访问的域名入口了。这里需要注意一点 https://9d15-183-162-254-123.ngrok-free.app 不需要再带端口了，因为这个链接映射的就是 http://localhost:8080。\n","slug":"tools/tool-ngrok","date":"2023-04-26T02:21:59.000Z","categories_index":"工具","tags_index":"tool,ngrok","author_index":"glmapper"},{"id":"792d93df9e83310cd9b49667bfb8f9ca","title":"聊一聊 Linux 的起源和发展","content":"最近在系统性重新整理下关于 linux 的一些知识。linux 对于所有的开发工程师来说都不算是陌生的东西，但往往在面对它时，却又显得那么生疏。关于生疏，对于出入门的同学来说，其过多发行版和指令已经够吃一壶的了。这篇文章主要是看看 linux 自身的一些故事。\n计算机主机实际上就是一堆硬件，为了更好的、有效率的控制这些硬件资源，于是乎就有了操作系统。操作系统除了负责控制这些硬件资源的分配，还具备提供计算机运行所需的一些基本功能，比如网络功能。当然，如果仅有这些是不够的，对于用户来说，直接面向的并不是硬件或者操作系统，而是软件。因此，操作系统也会为了让工程师更容易开发软件，也提供了一整组系统调用接口；这也是 Unix 或者 Linux 最原始的初心和核心。\n\n\n从 CTSS 到 Multies早期的计算机并不像如今这样普及，并且当时的计算机操作系统仍然比较简单，只能支持单用户、单任务和少量用户之间的数据共享，其主要用于军事、高科技研究以及学术单位，其存在的问题就是\n\n不好用\n速度慢\n操作接口不友好\n输入输出单一\n程序编写困难\n\n随着硬件与操作系统的改良，可以使用键盘来进行输入。但是对于一个普通的学校来说，大多数情况下都是只有一台主机，那么这种情况下就会大家都在等着轮换住使用这个主机。于是在 1960年初，麻省理工学院开发了 CTSS（Compatible Time-Sharing System 兼容分时调度系统），其目的是可以让大型主机通过提供数个终端机以连线进入主机（即使是现在这种路子还在一些企业中使用，就是常见的瘦客户端模式），CTSS  这玩意可以说是近代操作系统的始祖。\nCTSS 解决了多个使用者在某一时间内分别使用 CPU的资源（实际上就是 CPU 在内个工作者工作之间进行切换）；但是其问题在于，这些终端机仅具备输入输出的功能，不具备任何运算或者软件安装的能力，并且一台主机所能支持的终端数的数量也是有限的（差不多 30 个）。\n于是在 1965 年，由麻省理工学院、贝尔实验室和通用电气公司共同发起了 Multies 计划：让大型主机可以达成提供 300 个以上的终端机连线的目标。到 1969年，由于计划进度落后，加上资金短缺，Bell 宣布退出。不过 Multies 系统最终还是由剩下的两家合作完成了，不过此时已经没法在“一石激起千层浪“了。Multies 计划的结果没有给业界带来多大的影响，不过在这个过程中也着实培养了许多优秀的人才，这些人也在后续的 Linux 的演进中起到了非常重要的作用，比如 Ken Thompson。\nCTSS 和 Multics 的出现，为后来操作系统的发展奠定了基础，它们的分时段、分层结构、多用户和多任务等特性，成为了后来操作系统开发的重要范本和参考。虽然 Multics 的发展遭遇了失败，但它的设计思想和技术，对后来的操作系统和计算机科学领域产生了深远的影响。\nKen Thompson 是 Bell 的人，在Bell 退出之后，这哥们也没闲着，他出于自身的需求，花了一个月的时间，基于 DEC PDP-7 计算机，使用 Assemble 语言写出了一组核心程序，同时包括了一些核心工具程序，以及一个小小的文件系统，没错，这就是 unix 的原型，在当时这个系统还没有被称为 unix，而是 unics(相对于 Mutlies 的复杂而言)。下面是 unics 这个文件系统中的两个重要的概念：\n\n所有的程序或者系统设备都是文件\n不管是使用建构编辑器还是附属文件，编写程序的目标都应该是有效地完成既定的任务\n\n\n\n\n\n\n\n\n\n\n在软件开发中，建构编辑器和附属文件是两种不同的工具，它们都可以帮助程序员有效地编写代码。建构编辑器（如Visual Studio、Eclipse等）通常包括代码编辑器、编译器和调试器等工具，可以提高程序员的生产力和效率。附属文件则是一些额外的文件，例如配置文件、库文件和资源文件，它们为程序提供了一些必要的附加信息和功能。\n不过话说回来，你知道前面提到的 Ken Thompson 的 “自身需求” 是什么吗？—玩游戏….，不过这哥们不仅是玩，为了玩，还贡献了一些代码来改进游戏，包括优化游戏的性能和改进用户界面等方面，当然最重要的是他写的那个 unics 系统。\nunix 的诞生上面提到，Ken Tompson 为了玩游戏，搞出了一个叫 unics 系统；由于 unics 系统的易用性，使得在贝尔实验室内部广为流传，并且也进行了数度改版。但是因为 Unics 本来是以 Assmeble 语言写成的，可移植性太差，加上当时的计算机机器架构都不太相同，所以每次要安装到不同的机器都得要重新编写 Assmeble 语言，很不方便。这时另一个大神就出现了，他叫 Dennis Ritchie。为了解决可移植性，可读性以及可维护性问题，Ritchie 先是创建了 C 语言（起初是B 语言，但是 B 编译的核心性能不好，所以创建了 C 语言），又基于 C 语言重写了 unics 的核心，这也标志着 unix 的正式诞生。\n重要的Unix分支–BSD的诞生BSD（Berkeley Software Distribution）是一个 Unix 操作系统的分支，其起源可以追溯到20世纪70年代。在当时，AT&amp;T的Unix操作系统被广泛用于大型计算机，但是它的源代码并未公开，因此开发者无法自由地修改和分发它。\n为了解决这个问题，加州大学伯克利分校的计算机科学系（主要是 Bill Joy，没错，这哥们就是 sun 的创始人）开始开发自己的Unix操作系统，即BSD。由于该系统是在AT&amp;T的Unix系统的基础上开发的，因此它继承了许多Unix系统的基本特性，并添加了许多新的功能和工具，例如vi编辑器和BSD套接字（socket）API等。\nBSD系统的发展得到了广泛的支持和贡献，成为了Unix操作系统的重要分支之一。BSD操作系统的开放源代码和社区参与模式也为其他类Unix操作系统的开发提供了范例和灵感，例如Linux操作系统的开发就受到了BSD的影响。\n值得注意的是，由于历史原因和版权问题，BSD系统在1994年被划分为两个主要的分支，即FreeBSD和OpenBSD。这两个分支各自拥有自己的开发团队和社区，但它们都继承了BSD系统的传统和哲学，继续为Unix操作系统的发展做出贡献。\nSystem-VSystem V 最初由 AT&amp;T 开发并发布于 1983 年，相对于早期的 Unix 版本，System V 引入了许多新的特性和功能，包括 TCP&#x2F;IP 协议栈、虚拟内存、可靠信号机制、动态链接等。System V还提供了许多标准的系统调用和库，这些标准在 Unix 系统之间得到了广泛的共享和兼容。\n在System V发布后不久，许多Unix厂商开始将它作为他们的主要操作系统版本，并在其基础上进行了许多改进和定制，例如IBM的AIX、HP 的 HP-UX、Sun 的 Solaris 等。\n由于 Unix 的高度可移植性与强大的性能，加上当时并没有版权的纠纷， 所以让很多商业公司开始了Unix操作系统的发展，例如AT&amp;T自家的System V、IBM的AIX以及HP与DEC等公司， 都有推出自家的主机搭配自己的Unix操作系统。随之而来的一个问题是，早期生产计算机硬件的公司之间并没有所谓的“协定“，这就导致了每一个计算机硬件公司生产的硬件不兼容，所以每个公司又都设计了符合自己硬件的 unix 系统。\nSystem V 的另一个重要的特点是可以支持x86架构的个人计算机系统，也就是说 System V 可以在个人计算机上面安装与运行了。System V  兴起也使得AT&amp;T 在商业版权上有了新的念头，在 1979 年发行的第七版 Unix 中，特别提到了 “不可对学生提供源代码”的严格限制！这也造成Unix业界之间的紧张气氛，并且也引爆了很多的商业纠纷。\n\n\n\n\n\n\n\n\n\n目前被称为纯种的 Unix 指的就是 System V 以及 BSD 这两套\nMinixSystem V 在1979年的版权声明中，影响最大是学校教 Unix 核心源代码相关知识的教授，这里面就包括了 Andrew Tanenbaum。\n1979年 的Unix第七版可以在Intel的x86架构上面进行移植， 那么是否意味着可以将Unix改写并移植到x86上面了呢？在这个想法上， Tanenbaum教授于是乎自己动手写了Minix这个Unix Like的核心程序！ 在撰写的过程中，为了避免版权纠纷，Tanenbaum 完全不看Unix核心源代码！ 并且强调他的Minix必须能够与Unix相容才行！Tanenbaum在1984年开始撰写核心程序， 到了1986年终于完成。Minix算是一个小型 Unix 操作系统，其主要目的是教学和研究。Minix 的代码是开源的，它吸引了许多程序员的关注和参与，其中就包括了后来的 Linux 开发者林纳斯·托瓦兹（Linus Torvalds）。\nLinux1991 年，林纳斯·托瓦兹在 Minix 的基础上，开发出了 Linux 操作系统。Linux 的开发目标是提供一个完全开源、免费、可定制的操作系统，使得更多人可以参与其中的开发和使用。Linux 借鉴了 Unix 和 Minix 的许多设计思想和技术，如文件系统、Shell 命令解释器、分时段系统、网络功能等，但也有许多创新，如内核模块化设计、虚拟文件系统等。\n随着时间的推移，Linux 逐渐得到了广泛的应用和发展。1992 年，GNU 项目的创始人理查德·斯托曼（Richard Stallman）发布了 GPL 许可证，宣布 GNU&#x2F;Linux 以及其他软件的代码可以自由使用、修改和发布。这极大地促进了 Linux 社区的发展和成长，吸引了更多的程序员参与到其中，使得 Linux 变得更加强大和普及。\n在发展过程中，Linux 也经历了多个版本和分支，如 Debian、Red Hat、SUSE 等。这些分支在保留 Linux 原有特性的基础上，也针对不同的应用场景和用户需求进行了适当的改进和定制。例如，Red Hat 的企业版 Linux 专注于提供稳定、安全的操作系统，以满足企业客户的需求；SUSE Linux 则专注于提供针对大型服务器和应用的操作系统。\n此外，还出现了许多基于 Linux 的开源软件和平台，如 Apache Web 服务器、MySQL 数据库、Docker 容器等。这些软件和平台不仅提供了开源的解决方案，也使得 Linux 更加完善和广泛应用。\n总结Linux 历史的发展有它偶然性和必然性，不管是因为游戏、版权还是社区软件，每一个版本的演进都不断推动 Linux 的发展和完善。不过不得不说的是，这些在 Linux 发展中赫赫有名的人，真的是值得每一个工程师去学习的，Ken Thompson 的兴趣、Andrew Tanenbaum 的 工程师脾气 等；当然这个过程中也是离不开像 麻省理工学院、贝尔实验室和通用电气公司 等大厂以及后续一些商业公司的推波助澜。\n参考文档和书籍\n鸟哥的Linux 私房菜基础学习版（第4版）\nChatGPT\n只是为了好玩 : Linux之父林纳斯自传\n\n","slug":"linux/linux-history-of-development","date":"2023-04-05T08:35:48.000Z","categories_index":"Linux","tags_index":"linux","author_index":"glmapper"},{"id":"baaad82d68657f51bd3c3465e15edac9","title":"win 系统中使用 gitbash 作为 idea 的默认终端","content":"意义不大，建议直接使用 wsl2 或者将 win 系统换成 ubuntu 等桌面版本 linux 系统进行开发\n","slug":"git/tool-config-git-bash-under-win","date":"2023-03-14T03:16:21.000Z","categories_index":"git","tags_index":"git","author_index":"glmapper"},{"id":"6732a7abc9d37de3b0905738d2c701f5","title":"K8S system OOM 和资源配置实践","content":"背景我们目前服务是托管在 Aws K8S 的，近期出现了一次由于生产环境流量增大而导致的 system OOM 问题，进而导致了部分核心业务受损。在此之前，团队并没有思考过关于 K8S 资源配置上存在的一些问题，也没有按照业务自身情况使用对应的 QoS 类，从而导致了故障的产生。\n本文将从这个角度切入，对 K8s 中的资源属性以及 QoS 进行介绍，最后给出生产环境使用的一些建议。\n\n\nCPU 和 MEMORY 资源不知道你是否有考虑过这样一个问题，为什么 CPU 可以超卖，而 Memory 不可以超卖? K8S 官方文档中对于水平扩容的默认机制也是基于 CPU 利用率的，而不是基于 Memory。\n\n\n\n\n\n\n\n\n\nRAM differs significantly from CPU in that it’s an incompressible resource. That means we can’t just throttle your RAM usage, RAM is state!\n什么是 incompressible resource？incompressible resource 意味着资源可以被节流（throttled）。这里，CPU 可以被认为是可压缩的，而内存是不可压缩的。当 Kubernetes 所管理的宿主机上不可压缩资源短缺时，就有可能触发 Eviction。比如，可用内存（memory.available）、可用的宿主机磁盘空间（nodefs.available），以及容器运行时镜像存储空间（imagefs.available）等等。\nQoSQoS：服务质量，Kubernetes 使用 QoS 类来决定 Pod 的调度和驱逐策略，即 当宿主机资源紧张的时候，kubelet 对 Pod 进行 Eviction （即资源回收）时需要用到的。\n下面这张表，笔者整理了 QoS 分类以及优缺点\n\n\n\nQoS\n解释\n优缺点\n备注\n适用场景\n\n\n\nGuaranteed\nPOD 中的内存和CPU 必须指定，并且 request&#x3D;limit\n-   缺失弹性能力，低谷期会有资源浪费-   可以规避 system oom 的出现，但不能保证容器 oom\n\n稳定性优先的服务\n\n\nBurstable\nPod 中至少一个容器具有内存或 CPU 的请求或限制\n-   有伸缩能力，一定程度上减少资源浪费-   当 limit 总和大于 node 可用资源时，会触发 system oom，意味着 Node is overcommitted。\n按照 QoS 的划分条件，云端服务目前属于 Burstable。\n稳定性要求较低的服务\n\n\nBestEffort\nPod 中的容器必须没有设置内存和 CPU 限制或请求\n&#x2F;\n一般不考虑此场景，这里不讨论\n\n\n\n此外，当内存不足时，POD 被驱逐的级别顺序是 BestEffort、Burstable、Guaranteed。\n结合实际场景的思考和建议对于我们实际的业务来看，我们一定是期望资源超卖以便于达到最大化的利用率，从而使得相应的成本能够节省下来。但是从 QoS 质量等级来看，是“鱼和熊掌”不可兼得的，所以需要做的就是找到一些平衡。\n\n期望：资源利用率最大化，资源超卖越多越好，这样可以节省更多的费用\n目标：关键业务要有一定的稳定性保障\n\n在我们的场景中，服务可以分为核心和非核心两种，对于稳定性要求来说，核心服务要远高于非核心服务，所以得出的结论是：\n\n1、对于非核心服务，稳定性保障要求较低的服务，我们可以适当的超卖资源，从而获得资源更大程度的利用率；\n2、对于核心服务，则允许服务资源存在一定的浪费，优先保证服务稳定性。\n\n参考\n为容器和 Pod 分配内存资源\nout-of-memory-oom-in-kubernetes-part-1-intro-and-topics-discussed\noomkilled-troubleshooting-kubernetes-memory-requests-and-limits\ntroubleshoot-kubernetes-oom\nhow-to-fix-oomkilled-exit-code-137\nKubernetes Requests, Limits, and Autoscalers: How They (Sometimes Don’t) Work Together | DigitalOce\n\n","slug":"solutions/solution-series-k8s-resources-request-limit","date":"2022-12-04T07:49:37.000Z","categories_index":"解决方案","tags_index":"kubernetes","author_index":"glmapper"},{"id":"679bdcba368529704928bcc9f610db76","title":"New Features Of JDK - JDK9 Modular System","content":"Modular System 是 JAVA9 中提供的新特性，它从一个独立的开源项目而来，名为 Jigsaw Project。在此之前，我们对于 Java 技术栈中模块化的认知是基于 OSGI 的，实际上 OSGI 也确实形成了它自己独有的体系，并且是一定程度上的行业标准。\n\n\nJAVA 模块化发展JAVA 从没有停止过在模块化事情上的努力，比如 JSR 294 提出的 superpackages，JSR 277 中的 Java Module System（后来被 JSR 376 替换掉了）；直到 Jigsaw 这个原型项目的出现，这个原本计划在 Java7 一起交付的功能，也一直被推迟到 Java9 才提供出来；作为原型项目，Jigsaw 提供了 JPMS（Java Platform Module System） 规范的参考实现。\n另一个是独立于 Java 社区发展的 OGSI。到目前为止，OSGi 已经发展超过 20 年，OSGi 是应用程序模块化的事实标准。一方面 OGSI 不是 Java 平台的直接组成部分，所以它不会影响平台本身的模块化发展，另一个重要的因素则是 OSGi 使用的是类加载器实现的模块化隔离，这与 Jigsaw 基于可访问性规则实现的隔离机制完全不同。\n话说回来，为什么模块化会如此的重要呢？\n首先是 JAVA 自身的不断臃肿，从 JAVA 1.1 的小于 10M 到 JAVA 8 的 200M+，不管是安装占用空间还是内存要求都有相应增加，这个增加虽说是由新功能的迭代带来的，并且这些新功能中的绝大部分是受欢迎的；但是换个角度说，每一项新功能都会为不需要它的用户造成膨胀，可以肯定的是，不会有哪个工程师或者哪个团队会使用到 Java 提供的所有能力(比如你做 web 项目，还不得不带上 swing)。\n另一点，也是 OSGI 能够发展的原因，依托类加载器来实现业务层面的隔离，并且具备动态载入的能力，这也使得 plugin 机制或者热加载机制能够有非常大的发挥空间。\nJava 9 中的 Module System\n\n\n\n\n\n\n\n\n模块化的前提是模块划分，JDK 自身也进行了模块化的处理，具体可以见 https://openjdk.org/jeps/200\nJava 9 的 Module System 到底是什么？官方说法是：模块化在包之上增加了更高级别的聚合，它包括一组密切相关的包和资源以及一个新的模块描述符文件。简单点说，它是一个 Java 包的包 抽象。\n目前 Module System 有 4 种类型的模块，如下表所示\n\n\n\n类型\n说明\n备注\n\n\n\n系统模块\nJava SE 和 JDK 模块，通过 list-modules 可以看到完整列表\n&#x2F;\n\n\n应用程序模块\n业务自己定义的模块\n&#x2F;\n\n\n自动模块\n当将非模块 jar 添加到模块路径时，会创建具有 jar 名称的模块\n1、默认导出所有包 2、默认情况下可以访问所有其他模块的类\n\n\n未命名模块\n当将 jar 或类添加到类路径时，所有这些类都会添加到未命名的模块中\n1、只导出到其他未命名的模块和自动模块。这意味着，应用程序模块无法访问这些类 2、它可以访问所有模块的类\n\n\n下面我们通过一个小案例来直观的体验下模块化，也就是上表中的 应用程序模块。\n模块案例这个案例中包含两个模块，glmapper.modules 模块用于导出自己的服务，test.modules 模块用来测试引用第一个模块。\n模块1 - glmapper.modules\n创建项目文件夹\n\n12mkdir my-projectcd my-project\n\n\n创建模块目录\n\n1mkdir my-module \n\n在 my-module 目录下创建 glmapper.modules 1mkdir glmapper.modules \n在模块下创建 package1com.glmapper.bridge.boot\n包中创建一个名为 HelloModules.java的新类1234567package com.glmapper.bridge.boot;public class HelloModules &#123;    public static void sayHello() &#123;        System.out.println(&quot;Hello, Glmapper Modules!&quot;);    &#125;&#125;\n在glmapper.modules根目录中添加模块描述符 module-info.java1234module glmapper.modules &#123;    // 导出 com.glmapper.bridge.boot 包的所有公共成员    exports com.glmapper.bridge.boot;&#125;\n\n此时的文件目录大致如下：\n12345678└── my-module    └── glmapper.modules        ├── com        │   └── glmapper        │       └── bridge        │           └── boot        │               └── HelloModules.java        └── module-info.java\n\n模块2 - test.modules\n在 my-module 下创建 test.modules 模块1mkdir test.modules\n创建模块描述符文件 module-info.java123module test.modules &#123;    requires glmapper.modules;&#125;\n创建 com.glmapper.bridge.main 包，并创建一个 TestMain.java 文件12345678910package com.glmapper.bridge.main;// 导入 glmapper.modules 的类依赖import com.glmapper.bridge.boot.HelloModules;public class TestMain &#123;    public static void main(String[] args) &#123;        // 调用依赖类的静态方法        HelloModules.sayHello();    &#125;&#125;\n\n此时的目录结构如下：\n123456789101112131415└── my-module    ├── glmapper.modules    │   ├── com    │   │   └── glmapper    │   │       └── bridge    │   │           └── boot    │   │               └── HelloModules.java    │   └── module-info.java    └── test.modules        ├── com        │   └── glmapper        │       └── bridge        │           └── main        │               └── TestMain.java        └── module-info.java\n\n构建运行模块\n构建模块()\n12// modules 是构建产物的输出目录javac -d modules --module-source-path my-module $(find my-module -name &quot;*.java&quot;)\n构建之后的目录结构如下\n123456789101112131415161718192021222324252627282930├── modules // 构建产物所在的目录│   ├── glmapper.modules│   │   ├── com│   │   │   └── glmapper│   │   │       └── bridge│   │   │           └── boot│   │   │               └── HelloModules.class│   │   └── module-info.class│   └── test.modules│       ├── com│       │   └── glmapper│       │       └── bridge│       │           └── main│       │               └── TestMain.class│       └── module-info.class└── my-module    ├── glmapper.modules    │   ├── com    │   │   └── glmapper    │   │       └── bridge    │   │           └── boot    │   │               └── HelloModules.java    │   └── module-info.java    └── test.modules        ├── com        │   └── glmapper        │       └── bridge        │           └── main        │               └── TestMain.java        └── module-info.java\n\n运行代码\n123# 运行模块需要指定 模块路径和主类 &gt; java --module-path modules -m test.modules/com.glmapper.bridge.main.TestMain&gt; Hello, Glmapper Modules!\n可以看到，我们得到了正确的结果。\n\n\n那么我们再来测试一种场景，就是在 glmapper.modules 中不导出包，重新构建时得到的结果如下：\n123456my-module/test.modules/com/glmapper/bridge/main/TestMain.java:3: 错误: 程序包 com.glmapper.bridge.boot 不可见import com.glmapper.bridge.boot.HelloModules;                          ^  (程序包 com.glmapper.bridge.boot 已在模块 glmapper.modules 中声明, 但该模块未导出它)1 个错误\n可以看到，当编译 test.modules 时，会检测出它所依赖的模块中的 package 是否被导出，如果没有导出那么就无法通过编译。\n接口使用上面案例中，为了便于测试，是在模块中提供了一个可访问的静态方法；下面我们继续改造，在 glmapper.modules 中提供 interface 以及 interface 的实现，并通过使用 provides…with 和 uses 指令来实现和 test.modules 模块的交互引用。\n\n在 glmapper.modules 中提供一个 HelloService 接口1234package com.glmapper.bridge.boot;public interface HelloService &#123;    void helloWorld();&#125;\nHelloService 接口实现类 HelloServiceImpl12345678910package com.glmapper.bridge.boot.impl;import com.glmapper.bridge.boot.HelloService;public class HelloServiceImpl implements HelloService &#123;    public void helloWorld() &#123;        System.out.println(&quot;Hello World...&quot;);    &#125;&#125;\n修改 glmapper.modules&#x2F;module-info.java12345module glmapper.modules &#123;    // 导出 com.glmapper.bridge.boot 包的所有公共成员    exports com.glmapper.bridge.boot;    provides com.glmapper.bridge.boot.HelloService with com.glmapper.bridge.boot.impl.HelloServiceImpl;&#125;\n修改 test.modules&#x2F;module-info.java1234module test.modules &#123;    requires glmapper.modules;    uses com.glmapper.bridge.boot.HelloService;&#125;\n修改 TestMain1234567891011121314151617181920package com.glmapper.bridge.main;import com.glmapper.bridge.boot.HelloModules;import com.glmapper.bridge.boot.HelloService;import com.glmapper.bridge.boot.impl.HelloServiceImpl;import java.util.ServiceLoader;public class TestMain &#123;    public static void main(String[] args) &#123;        HelloModules.sayHello();        // 这里可以通过 ServiceLoader SPI 方式来调用的        Iterable&lt;HelloService&gt; services = ServiceLoader.load(HelloService.class);        HelloService service = services.iterator().next();        service.helloWorld();                // 通过实例化对象调用        HelloService helloService = new HelloServiceImpl();        helloService.helloWorld();    &#125;&#125;\n重新编译并执行1234&gt; java --module-path modules -m test.modules/com.glmapper.bridge.main.TestMain    &gt; Hello, Glmapper Modules!  Hello World...  Hello World...\n\n小坑 module-info.java 中导出包不能支持对其子包的导出\n12345678module glmapper.modules &#123;    // 导出 com.glmapper.bridge.boot 包的所有公共成员    exports com.glmapper.bridge.boot;    // 这里需要 com.glmapper.bridge.boot.impl，否则 impl 子包中的内容对 test.modules 不可用    exports com.glmapper.bridge.boot.impl;    provides com.glmapper.bridge.boot.HelloService with    com.glmapper.bridge.boot.impl.HelloServiceImpl;&#125;\n总结本文对 Java 模块化进行了介绍，通过本文你可以大体了解到 Java 模块化发展的基本情况，了解 Java 9 提供的模块化能力和 OSGI 模块化能力的差异。然后我通过一个案例向你介绍了 Java 模块化的基本使用方式，希望对你能够有所帮助。\n参考https://www.infoq.com/articles/java9-osgi-future-modularity/https://www.oracle.com/corporate/features/understanding-java-9-modules.htmlhttps://www.baeldung.com/java-9-modularity#3-module-descriptor\n","slug":"java/java-open-jdk9-module","date":"2022-12-04T07:45:44.000Z","categories_index":"JAVA","tags_index":"openjdk","author_index":"glmapper"},{"id":"6c139a1ec6733d215aeb28747f12a741","title":"Mysql - 从一个小 case 理解 MVCC","content":"\n\n\n\n\n\n\n\n\n原文链接： https://juejin.cn/post/7163934829984088095 \n从 innoDB 的一致性非锁定读说起非锁定读和行快照数据一致性的非锁定读（consistent nonlocking read）是指 InnoDB 存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行 DELETE 或 UPDATE 操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据，下图是关于快照数据的一个简单示图：\n\n\n\n之所以称其为非锁定读，因为不需要等待访问的行上 X 锁的释放。快照数据是指该行的之前版本的数据，该实现是通过 undo 段来完成。而 undo 用来在事务中回滚数据，因此快照数据本身是没有额外的开销。此外，读取快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。因此，非锁定读机制可以极大地提高数据库的并发性。\n在 InnoDB 存储引擎的默认设置下，非锁定读是默认的读取方式，即读取不会占用和等待表上的锁。\n\n在不同事务隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读\n即使都是使用非锁定的一致性读，对于快照数据的定义也各不相同\n\nMVCC 的定义快照数据其实就是当前行数据之前的历史版本，每行记录可能有多个版本。一个行记录可能有不止一个快照数据，一般称这种技术为行多版本技术。由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control，MVCC）。\n一些前提知识在开始案例分析之前，这里先简单介绍一些准备知识，如数据库级别的查看和设置，数据库事务的简单使用命令等。\n数据库隔离级别的设置和查看\n1、查看数据库隔离级别\n\n1select @@global.tx_isolation,@@tx_isolation;\n\n\n2、设置数据库隔离级别\n\n1SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE&#125;\n\n设置数据库隔离级别 scope 有两种，一种是当前会话级别，另一种是全局级别，示例如下：\n1234// 全局的mysql&gt; set global transaction isolation level read uncommitted;// 当前会话mysql&gt; set session transaction isolation level read uncommitted;\n\n数据库事务的基本使用\n1、通过 SET AUTOCOMMIT&#x3D;0 禁止自动提交\n2、用 BEGIN， ROLLBACK，COMMIT 来完成事务的基本操作\nBEGIN 开始事务\nROLLBACK 回滚事务\nCOMMIT 提交事务\n\n\n\n事务隔离级别的案例分析前面简单介绍了非锁定读、MVCC 以及和本案例相关的一些数据库基本操作知识，下面来介绍在不同在不同事务隔离级别下，事务之间对于数据可见性和隔离性的一些基本问题。\n案例说明本案例中，提供了一张 orders 表，包括 id 和 marks 两个字段，id 为主键\n1234567mysql&gt; select * from orders;+----+-----------+| id | marks     |+----+-----------+|  1 | test1 ||  2 | test2     |+----+-----------+\n\n在案例中将通过开启不同的事务级别来进行测试。大致思路是：\n\n1、禁止事务自动提交\n2、将全局事务的隔离级别和会话级别的隔离级别都设置成一样的\n3、开启两个会话窗口，在两个会话窗口内分别开启两个事务，在事务 A 中更新 id &#x3D;x 的 mark 记录\n未提交时，分别在事务 A 和 事务 B 中查询 id &#x3D;x 的记录；\n提交后，分别在事务 A 和 事务 B 中查询 id &#x3D;x 的记录；\n\n\n\n其中 1和 2 用于保证条件一致，3 为需要测试的操作。\nread uncomitted1、将两个会话的事务级别设置成相同的，均为 read uncommitted\n\n2、在事务 A 中执行更新 orders 表中 id 为 1 的记录\n\n3、分别在两个事务中查询 id&#x3D;1 的记录\n\n现象：在事务 A 没有提交的情况下，事务 B 可以看到事务 A 中更新的记录值了，这就是脏读。此时回滚事务 A，然后再次查询：\n\n所以对于 read uncommitted，不同事务之间数据都可见，没有隔离性可言。\nread comitted将事务级别设置成 read committed，然后在事务 A 中更新 id 为 1 的记录。\n\n未 commit 时，事务 A 中更新的值对于事务 B 是不可见的；这也解释了事务 B 读取的快照数据。\n\n\n\ncommit 之后，事务 B 中可以读取到事务 A 更新的值了。\n\n\nREAD COMMITTED 事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据。\nrepeatable read将事务级别设置成 repeatable read，然后在事务 A 中更新 id 为 1 的记录；\n\n事务 A commit 之前，事务 A 中更新的数据对于事务 B 是不可见的；说明事务 B 读取的快照数据。\n\n\n\n事务 A commit 之后，事务 B 读取的还是以前的值，并没有读取到事务 A 中更新的值。结束事务 B 之后，再次查询，事务 B 查询到的值才是最新的。\n\n\nREPEATABLE READ 事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。\n关于幻读笔者在没有进行这个测试之前，对于幻读的意义理解是停留在类似这种描述上的：\n当某个事务在读取某个范围的记录的时候，另外一个事务又在该范围插入了新的记录，当前事务再次读取这个范围的记录，会产生幻行（Phantom Data）– 《高性能MySQL》第三版\n首先这个描述没有问题，笔者之前的理解是：在一个事务中 连续两次查询结果不一致（前提是基于可重复读隔隔离级别下），那这句话的反意就是，在一个事务中，如果连续两次查询结果一致，就不是幻读。\n来看下面的案例。\n场景 1使用 range 查询，IS 锁场景，事务 B 中插入主键间隙之内的一条数据。\n\n在可重复读的隔离级别下，事务 A 满足之前提到的可重复读的情况，不满足前面 在一个事务中 连续两次查询结果不一致 的说法；那么这里对于幻读的解释实际上就是：\n事务A 没有正常读取到最新的事务，理论上应该有 3 条数据，而实际查询出来只有 2 条，这种情况对于事务 A 来说产生了幻读？\n场景 2在事务 A 和事务 B 中插入同一条数据。这种情况，因为在两个事务中同时写入一条数据，当事务 A 写入 id 为 6 数据，但是没有提交事务的时候，理论上事务 B 又写入 id 为 6 的数据会被阻塞住，那么对于事务 B 来说，它就需要知道事务 A 中有同样的操作；来看案例\n\n此时事务 B 被阻塞等待事务 A 的提交。\n\n当 事务 A 提交之后，事务 B 抛出异常。再次在事务 B 中查询，理论上如果存在幻读情况，事务 B 中将读取不到 id 为 6 的记录值，经测试事务 B 中读取到了 事务 A 中 提交之后的最新数据，因此对于这种情况，事务 B 在事务开始时查询到的结果没有 6，随后又执行了一次同样的查询操作，但是返回的结果确包含了 id 为 6 的记录，因此产生幻读。\n\n这里相比于 case 1 ，事务 B 在查询第二次之前做了一次 insert 操作，insert 有一个潜在的规则是在插入数据之前需要读取当前最新记录数据，这也就和读提交读取最新记录是一致的，而不是读取的事务开始之前的数据了。\n关于幻读的总结ANSI SQL 隔离级别标准里可重复读级别是存在幻读问题；但是 InnoDB 的可重复读级别 通过MVCC机制解决了幻读问题！所以 InnoDB 的可重复读是不存在幻读问题的（这里的幻读指的是：当某个事务在读取某个范围的记录的时候，另外一个事务又在该范围插入了新的记录，当前事务再次读取这个范围的记录，会产生幻行（Phantom Data））。\ncase 2 中由于触发了当前读而导致数据冲突的问题，才导致了“幻读”的情况。insert、update 等语句执行之前，会先 select，再执行 insert、update。简单说，就是先读一次，再执行更新语句。而且这个读，是读最新的数据！\n关于脏读、不可重复读、幻读上述案例中，\n\n在 read uncommitted 隔离级别下，事务 B 可以读取到事务 A 未提交的数据，这种情况称之为 脏读。\n在 read committed 隔离界级别下，事务 B 可以读取到事务 A 已经提交的数据，但是在当前事务 B 处理过程之内，意味着其它事务的数据变更都会影响到事务 B 中获取到的行数据的值，这种情况称之为 不可重复读。\n在 repeatable-read 隔离级别下，分为两种情况：\n事务 A 中仅执行两次 range 查询，事务 B 插入新数据并提交事务时，事务 A 中第二次查询不会产线幻读情况。\n事务 A 执行两次插入查询中间执行 insert 操作，且于事务 B 中存在锁冲突时，事务 A 会将快照读改为当前读，从而第一次查询和第二次查询结果不一致。。\n\n\n\n参考https://www.zhihu.com/question/47007926\n","slug":"db/mysql-transaction-mvcc-case","date":"2022-11-12T03:23:22.000Z","categories_index":"数据库","tags_index":"mysql,mvcc","author_index":"glmapper"},{"id":"58f683d88937558e07ea2c785aa7588a","title":"RocketMQ Push 消费模型","content":"Push 模式是指由 Server 端来控制消息的推送，即当有消息到 Server 之后，会将消息主动投递给 client(Consumer 端)。\n使用 DefaultMQPushConsumer 消费消息下面是使用 DefaultMQPushConsumer 消费消息的官方示例代码：\n\n\n1234567891011121314151617// 初始化consumer，并设置consumer group nameDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;MyGroup&quot;);// 设置NameServer地址consumer.setNamesrvAddr(&quot;localhost:9876&quot;);//订阅一个或多个topic，并指定tag过滤条件，这里指定*表示接收所有tag的消息consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;);//注册回调接口来处理从Broker中收到的消息consumer.registerMessageListener(new MessageListenerConcurrently() &#123;    @Override    public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123;        System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs);        // 返回消息消费状态，ConsumeConcurrentlyStatus.CONSUME_SUCCESS 为消费成功        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;    &#125;&#125;);// 启动Consumerconsumer.start();\n\n这里看到主要是通过 consumer 注册回调接口来处理从 Broker 中收到的消息。这种监听回调的机制很容易想到是一种观察者模式或者事件机制；对于这种 C-S 模型的架构来说，如果要做到 Server 在有新消息时立即推送给 Client，那么 Client 和 Server 之间应该是有连接存在的，Client 端开放端口来 watch Server 的推送。这里好论证，即可以查看当前 Client 端所在进程开启了什么端口即可，通过如下指令查看：\n\n1、先通过 jps 查看 Consumer Client 的进程号\n\n12345678➜  rocketmq-4.9.4 git:(06f2208a3) jps10722 Jps4676 rocketmq-dashboard-1.0.1-SNAPSHOT.jar17664121 BrokerStartup4009 NamesrvStartup9419 PushConsumer9692 RemoteMavenServer36\n\n可以看到 PushConsumer 的进程号是 9419\n\n2、通过 lsof 命令查看进程端口占用\n\n12➜  rocketmq-4.9.4 git:(06f2208a3) lsof -nP -p 9419| grep LISTEN➜  \n\n这里没有看到 PushConsumer 有开启端口。同样，这里可以看看 Broker 的进程端口占用\n1234➜  rocketmq-4.9.4 git:(06f2208a3) lsof -nP -p 4121| grep LISTENjava    4121 glmapper  137u    IPv6 0xca1142b0f200067d        0t0                 TCP *:10912 (LISTEN)java    4121 glmapper  141u    IPv6 0xca1142b0f1fc8cfd        0t0                 TCP *:10911 (LISTEN)java    4121 glmapper  142u    IPv6 0xca1142b0f1fc935d        0t0                 TCP *:10909 (LISTEN)\n\n\n所以得到一个初步的结论是，在 Push 模式下，Consumer Client 并没有启动端口来接收 Server 的消息推送。 那么 RocketMQ 是怎么实现的？\n基于长轮询机制的伪 push 实现真正的 Push 方式，是 Server 端接收到消息后，主动把消息推送给 Client 端，这种情况一般需要 Client 和 Server 之间建立长连接。通过前面的分析，Client 既然没有开启端口用于接收 Server 的信息推送，那么只有一种可能就是 Client 自己去拉了消息，但是这种主动拉消息的方式是对于用户无感的，从使用上体验上来看，做到了和 push 一样的效果；这种机制就是“长轮询”。\n为啥不用长连接方式，让 Server 主动 Push 呢？其实很好理解，对于一个提供队列服务的 Server 来说，用 Push方式主动推送有两个问题：\n\n1、会增加 Server 端的工作量，进而影响 Server 的性能\n2、Client 的处理能力存在差异，Client 的状态不受 Server 控制，如果 Client 不能及时处理 Server 推送过来的消息，会造成各种潜在问题\n\n客户端侧发起的长轮询请求下图是初始化相关资源的过程，DefaultMQPushConsumer 是面向用户使用的 API client 类，内部处理实际上是委托给 DefaultMQPushConsumerImpl 来处理的。DefaultMQPushConsumerImpl#start 时，会初始化 MQClientInstance ，MQClientInstance 初始化过程中又会初始化一堆资源，比如请求-响应的通道，开启各种各样的调度任务（定期拉去 NameServerAddress、定期更新 Topic 路由信息、定期清理 Offline状态的 Broker、定期发送心跳给 Broker、定期持久化所有 Consumer Offset等等），开启 pullMessageService，开启 rebalance Service 等等。大致的调用链如下图\n\n下面这个代码片段是 pullMessageService 的 run 方法（pullMessageService 是 Runnable 子类）\n1234567891011121314151617@Overridepublic void run() &#123;    log.info(this.getServiceName() + &quot; service started&quot;);\t    while (!this.isStopped()) &#123;        try &#123;            // 从 pullRequestQueue 中取 pullRequest            PullRequest pullRequest = this.pullRequestQueue.take();            this.pullMessage(pullRequest);        &#125; catch (InterruptedException ignored) &#123;        &#125; catch (Exception e) &#123;            log.error(&quot;Pull Message Service Run Method exception&quot;, e);        &#125;    &#125;    log.info(this.getServiceName() + &quot; service end&quot;);&#125;\n\n通过代码，可以直观的看起，pullMessageService 会一直从 pullRequestQueue 中取 pullRequest，然后执行 pullMessage 请求。实际上 MessageQueue 是和 pullRequest 一一对应的 ，pullRequest 全部存储到该 Consumer 的 pullRequestQueue 队列里面；消费者会不停的从 PullRequest 的队列里取 request 然后向broker 请求消息。\n这里还有一个问题是队列取出之后什么时候放回去的？在 pullMessage 的回调方法中，如果正常得到了 broker 的响应，那么会把 PullRequest放回队列，相关代码可以从 org.apache.rocketmq.client.consumer.PullCallbackonSuccess 方法中得到答案。\n服务端阻塞请求服务端处理 pullRequest 请求的是 PullMessageProcessor，当没有消息时，则通过 PullRequestHoldService 将当前请求先 hold 住。\n1234567891011121314151617case ResponseCode.PULL_NOT_FOUND:    if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123;        long pollingTimeMills = suspendTimeoutMillisLong;        // 如果是 LongPolling，则 hold 住        if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;            pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills();        &#125;        String topic = requestHeader.getTopic();        long offset = requestHeader.getQueueOffset();        int queueId = requestHeader.getQueueId();        PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills,            this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter);        this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest);        response = null;        break;    &#125;\n\nPullRequestHoldService 中会将所有的 PullRequest 缓存到 pullRequestTable。PullRequestHoldService 也是一个 task，默认每次 hold 5s 然后再去检查是否有新的消息过来，如果有新的消息到来，则唤醒对应的线程来将消息返回给客户端。\n1234567891011121314151617181920// 已省略无关代码public void run() &#123;    // loop    while (!this.isStopped()) &#123;        // default hold 5s        if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123;            this.waitForRunning(5 * 1000);        &#125; else &#123;            this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills());        &#125;        long beginLockTimestamp = this.systemClock.now();        // 检查是否有新的消息到达        this.checkHoldRequest();        long costTime = this.systemClock.now() - beginLockTimestamp;        if (costTime &gt; 5 * 1000) &#123;            log.info(&quot;[NOTIFYME] check hold request cost &#123;&#125; ms.&quot;, costTime);        &#125;\t&#125;&#125;\n\n\n客户端回调处理我们在编写 consumer 代码时，基于 push 模式是通过如下方式来监听消息的\n123456789//注册回调接口来处理从Broker中收到的消息consumer.registerMessageListener(new MessageListenerConcurrently() &#123;    @Override    public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123;        System.out.printf(&quot;%s Receive New Messages: %s %n&quot;, Thread.currentThread().getName(), msgs);        // 返回消息消费状态，ConsumeConcurrentlyStatus.CONSUME_SUCCESS 为消费成功        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;    &#125;&#125;);\n\n通过前面的分析，对于如何通过“长轮询”实现伪“push” 有了大概得了解；客户端通过一个定时任务不断向 Broker 发请求，Broker 在没有消息时先 hold 住一小段时间，当有新的消息时会立即将消息返回给 consumer；本节就主要探讨 consumer 在收到消息之后的处理逻辑，以及是怎么触发 MessageListener 回调执行的。\n客户端发起请求的底层逻辑以异步调用为例，代码在\norg.apache.rocketmq.client.impl.MQClientAPIImpl#pullMessageAsync中，截取部分代码如下：\n1234567891011121314151617181920212223242526272829this.remotingClient.invokeAsync(addr, request, timeoutMillis, new InvokeCallback() &#123;    @Override    public void operationComplete(ResponseFuture responseFuture) &#123;        RemotingCommand response = responseFuture.getResponseCommand();        if (response != null) &#123;            try &#123;                PullResult pullResult = MQClientAPIImpl.this.processPullResponse(response, addr);                assert pullResult != null;                // 成功回调                pullCallback.onSuccess(pullResult);            &#125; catch (Exception e) &#123;                // 异常回调                pullCallback.onException(e);            &#125;        &#125; else &#123;            if (!responseFuture.isSendRequestOK()) &#123;                 // 异常回调                pullCallback.onException(new MQClientException(&quot;send request failed to &quot; + addr + &quot;. Request: &quot; + request, responseFuture.getCause()));            &#125; else if (responseFuture.isTimeout()) &#123;                 // 异常回调                pullCallback.onException(new MQClientException(&quot;wait response from &quot; + addr + &quot; timeout :&quot; + responseFuture.getTimeoutMillis() + &quot;ms&quot; + &quot;. Request: &quot; + request,                    responseFuture.getCause()));            &#125; else &#123;                 // 异常回调                pullCallback.onException(new MQClientException(&quot;unknown reason. addr: &quot; + addr + &quot;, timeoutMillis: &quot; + timeoutMillis + &quot;. Request: &quot; + request, responseFuture.getCause()));            &#125;        &#125;    &#125;&#125;);\n\nPullCallback 回调PullCallback 回调逻辑在 org.apache.rocketmq.client.impl.consumer.DefaultMQPushConsumerImpl#pullMessage方法中，以正常返回消息为例：\n1234567891011// 已省略无关代码public void onSuccess(PullResult pullResult) &#123;    // 将接收到的消息 交给 consumeMessageService 处理    DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest(        pullResult.getMsgFoundList(),        processQueue,        pullRequest.getMessageQueue(),        dispatchToConsume);    // 将 pullRequest 放回 pullRequestQueue DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);&#125;\n\nConsumeRequest 是一个 Runnable，submitConsumeRequest 就是将返回结果丢在一个单独的线程池中去处理返回结果的。ConsumeRequest 的 run 方法中，会拿到 messageListener，然后执行 consumeMessage 方法。\n总结到此，关于 RocketMQ push 消费模型基本就探讨完了。从实现机制上来看，push 本质上并不是在建立双向通道的前提下，由 Server 主动推送给 Client 的，而是由 Client 端触发 pullRequest 请求，以长轮询的方式“伪装”的结果。从代码上来，RocketMQ 代码中使用了非常多的异步机制，如 pullRequestQueue 来解耦发送请求和等待结果，各种定时任务等等。\n整体看，PushConsumer 采用了 长轮询+超时时间+Pull的模式， 这种方式带来的好处总结如下 ：\n\n1、减少 Broker 的压力，避免由于不同 Consumer 消费能力导致 Broker 出现问题\n2、确保了 Consumer 不会负载过高，Consumer 在校验自己的缓存消息没有超过阈值才会去从 Broker 拉取消息，Broker 不会主动推过来\n3、兼顾了消息的即时性，Broker 在没有消息的时候会先 hold 一小段时间，有消息会立即唤起线程将消息返回给 Consumer\n4、Broker 端无效请求的次数大大降低，Broker 在没有消息时会挂起 PullRequest，而 Consumer 在未接收到Response 且未超时时，也不会重新发起 PullRequest\n\n","slug":"mq/rocketmq/rocketmq-push-consumer-model","date":"2022-09-22T13:31:29.000Z","categories_index":"RocketMQ","tags_index":"RocketMQ","author_index":"glmapper"},{"id":"8c745d5436d89ed91d5d8624c45dc15a","title":"RocketMQ 本地部署问题总结","content":"本篇分为 RocketMQ 部署和 RocketMQ-dashboard 部署两部分，主要是 RocketMQ 部署问题较多，汇总了下网上各路大神以及官方 issue 的讨论汇总而来。\nRocketMQ 部署根据官方的快速开始 尝试在本地部署 RocketMQ；如果你是按照官方文档直接来搞，可能 90% 是不可能成功的。\n\n\n我自己本地部署时遇到了绝大多数网上都遇到的问题（从 4.2.0 到 4.9.3 版本均无法直接启动），比如：\n\nNo route info of this topic\nconnect to [127.0.0.1:9876] failed\norg.apache.rocketmq.client.exception.MQBrokerException: CODE: 14\n\nNo route info of this topic这里在官方 issue 上有讨论，而且很激烈 ：https://github.com/apache/rocketmq/issues/504；RocketMQ 作为 Apache 顶级项目，在 issue 中还会对 qiuck starter 有如此激烈的讨论和吐槽，是否也应该有一些反思？即使是有问题出现，也应该将详细的信息吐出来，不管是没有连接到 NameServer 还是 缺少 Topic，都应该将信息暴露给用户。从我部署来看，出现 No route info of this topic时，先通过手动创建了 Topic，没有解决。尝试看了下代码\n1234567891011121314151617private SendResult sendDefaultImpl(    Message msg,    final CommunicationMode communicationMode,    final SendCallback sendCallback,    final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123;    // 省略...    // 这里取到的 topicPublishInfo 里面的 messageQueue 为 空，导致 topicPublishInfo.ok 为 false    TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic());    if (topicPublishInfo != null &amp;&amp; topicPublishInfo.ok()) &#123;        boolean callTimeout = false;        // 省略...    &#125;    // 省略...    throw new MQClientException(&quot;No route info of this topic: &quot; + msg.getTopic() + FAQUrl.suggestTodo(FAQUrl.NO_TOPIC_ROUTE_INFO),                                null).setResponseCode(ClientErrorCode.NOT_FOUND_TOPIC_EXCEPTION);&#125;\n\n从 debug 分析来看，topicPublishInfo 里面的 messageQueue 是空的；NameServer 和 Broker 进程也都是正常的，原因在于配置存在问题，导致 NameServer 和 Broker 没有建立正常的连接关系，从而导致 NameServer 感知不到 Broker，所以拉不到信息。\n\n\n\n\n\n\n\n\n\n因为是本地部署，并且部署 rocketmq-dashboard 确可以正常连接到集群，都可以看到 Topic 信息；所以基本排除了防火墙、内外网不通等问题干；网上有很多类似的解题思路，各位仁兄在参考时一定要结合自己的实际情况来看，不要一股脑扎进去配置。\nconnect to [127.0.0.1:9876] failed这个问题也是有些莫名奇妙的，NameServer 是正常启动的，通过 telnet localhost 9876 端口也是正常的，但是官方 demo 启动时报了这个错。从网上摸索了下，得到的解决方案是：\n1、不要使用官方文档的启动命令，使用如下命令代替：\n1sh bin/mqbroker -n localhost:9876 -c conf/broker.conf\n\n2、broker.conf 配置文件中增加了如下配置\n123namesrvAddr = localhost:9876brokerIP1=localhostbrokerIP2=localhost\n\n重启启动 Broker 即可。\nMQBrokerException: CODE: 14这个异常信息给的比较靠谱：\n1Caused by CODE: 14 DESC: service not available now, maybe disk full\n\n通过异常可以非常明确的 get 到原因，就是磁盘空间不够了。我本地 mac 磁盘空间从剩余 10G ，清理到剩余 50G 之后，重新启动客户端 OK 了。\nRocketMQ-Dashboard 部署这个项目还是有点惊喜的，https://github.com/apache/rocketmq-dashboard/ 。\n部署可以参考：https://rocketmq.apache.org/docs/%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%BF%90%E7%BB%B4/17Dashboard ；这个部署比较简单，没有 RocketMQ 那么多套路和问题，部署完成之后，界面大致如下：\n\n\n\n\n\n\n\n\n\n\n如果图片链接无法展示，可以查阅原文：https://juejin.cn/post/7143906476229132318\n","slug":"mq/rocketmq/rocketmq-deploy-issue","date":"2022-09-22T13:29:02.000Z","categories_index":"RocketMQ","tags_index":"RocketMQ","author_index":"glmapper"},{"id":"c87a3afb2738074b526bbfc99d4f6216","title":"ab 测试","content":"Apache Benchmark Tool\n\n\n\n\n\n\n\n\nab is a tool for benchmarking your Apache Hypertext Transfer Protocol (HTTP) server. It is designed to give you an impression of how your current Apache installation performs. This especially shows you how many requests per second your Apache installation is capable of serving.\nab 是 apache http server 基准测试工具，它可以帮助我们去了解当前服务的表现，如每秒请求数等。下面是 ab 对应的所有 options 摘要信息：\n\n\n12345678ab [ -A auth-username:password ] [ -b windowsize ] [ -B local-address ] [ -c concurrency ] [ -C cookie-name=value ] [ -d ] [ -e csv-file ] [ -E client-certificate file ] [ -f protocol ] [ -g gnuplot-file ] [ -h ] [ -H custom-header ] [ -i ] [ -k ] [ -l ] [ -m HTTP-method ] [ -n requests ] [ -p POST-file ] [ -P proxy-auth-username:password ] [ -q ] [ -r ] [ -s timeout ] [ -S ] [ -t timelimit ] [ -T content-type ] [ -u PUT-file ] [ -v verbosity] [ -V ] [ -w ] [ -x &lt;table&gt;-attributes ] [ -X proxy[:port] ] [ -y &lt;tr&gt;-attributes ] [ -z &lt;td&gt;-attributes ] [ -Z ciphersuite ] [http[s]://]hostname[:port]/path\n\n下面是各参数的解释\n\n\n\noptions\nkeys\nexlpain\n\n\n\n-A\nauth-username : password\n向服务器提供 BASIC 身份验证凭据。用户名和密码由一个:分隔，并通过 wire base64编 码发送。无论服务器是否需要该字符串(即，是否发送了 401 身份验证)，都将发送该字符串。\n\n\n-b\nwindowsize\nTCP发送&#x2F;接收缓冲区大小，以字节为单位。\n\n\n-B\nlocal-address\n进行传出连接时要绑定的地址。\n\n\n-c\nconcurrency\n单次执行的并发 request 数量，默认一次执行一个请求\n\n\n-C\ncookie-name &#x3D; value\n给请求添加 Cookie\n\n\n-d\n\nDo not display the “percentage served within XX [ms] table”. (legacy support).不重要\n\n\n-e\ncsv-file\n编写一个逗号分隔值 (CSV) 文件，其中包含每个百分比（从 1% 到 100%）处理该百分比请求所需的时间（以毫秒为单位）。这通常比“gnuplot”文件更有用；因为结果已经被“装箱”了。\n\n\n-E\nclient-certificate-file\n连接到 SSL 网站时，使用提供的 PEM 格式的客户端证书向服务器进行身份验证。该文件应包含客户端证书，然后是中间证书，然后是私钥。在 2.4.36 及更高版本中可用。\n\n\n-f\nprotocol\n指定 SSL&#x2F;TLS 协议（SSL2、SSL3、TLS1、TLS1.1、TLS1.2 或 ALL）。 TLS1.1 和 TLS1.2 支持在 2.4.4 及更高版本中可用。\n\n\n-H\ncustom-header\n支持添加额外的 headers 到 request ；如 “Accept-Encoding: zip&#x2F;zop;8bit”\n\n\n-i\n\n执行 HEAD 请求而不是 GET 请求。\n\n\n-k\n\n开启 http keep-alive 特性，比如在一个 HTTP会话中执行多个请求。默认为无 KeepAlive。\n\n\n-m\nHTTP-method\n自定义 http method，2.4.10 之后版本可用\n\n\n-n\nrequests\n基准测试会话执行的请求数。默认情况下只执行单个请求，这通常会导致不具有代表性的基准测试结果。\n\n\n-p\nPOST-file\n包含要POST数据的文件。记住还要设置-T。\n\n\n-P\nproxy-auth-username : password\n在途中向代理提供BASIC身份验证凭据。用户名和密码由一个:分隔，并通过 wire base64编码发送。无论代理是否需要该字符串(即，是否发送了需要的407代理身份验证)，都将发送该字符串。\n\n\n-q\n\n当处理超过150个请求时，ab每10%或大约100个请求输出一个stderr进度计数。-q标志将抑制这些消息。\n\n\n-r\n\n不要在套接字接收错误时退出。\n\n\n-s\ntimeout\n在套接字超时之前等待的最大秒数。默认为30秒。在2.4.4及以后版本中可用。\n\n\n-S\n\n不要显示中值和标准偏差值，也不要在平均值和中值相差超过标准偏差的一倍或两倍时显示警告&#x2F;错误消息。默认为min&#x2F;avg&#x2F;max值。(遗留支持)\n\n\n-t\ntimelimit\n用于基准测试的最大秒数。这在内部意味着-n 50000。使用它可以在固定的总时间内对服务器进行基准测试。默认情况下没有时间限制。\n\n\n-T\ncontent-type\n用于 POST&#x2F;PUT 数据 数据的内容类型标头;如application&#x2F;x-www-form-urlencoded. 默认 text&#x2F;plain\n\n\n-u\nPUT-file\n包含要PUT的数据的文件。记住还要设置-T。\n\n\n-v\nverbosity\n设置详细级别- 4及以上将打印标题信息，3及以上将打印响应代码(404、200等)，2及以上将打印警告和信息。\n\n\n使用 ab 进行测试下面是一个非常简单的 api 代码，启动 web server 之后通过 http://localhost:8080/api/test 即可请求。\n12345678910@RestController@RequestMapping(&quot;api&quot;)public class PressureService &#123;    @RequestMapping(&quot;test&quot;)    public String test() throws InterruptedException &#123;        Thread.sleep(3000);        return &quot;abc&quot; + new String(&quot;bcd&quot;);    &#125;&#125;\n\n执行如下命令 ab -n 200 -c 100 http://localhost:8080/api/test；总共发送 200 个请求，每次请求并发 100，得到的结果如下：\n1234567➜  ~ ab -n 200 -c 100  http://localhost:8080/api/testThis is ApacheBench, Version 2.3 &lt;$Revision: 1879490 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking localhost (be patient)apr_pollset_poll: The timeout specified has expired (70007)\n\n可以看到这里没有得到正常的测试反馈结果；报了 apr_pollset_poll: The timeout specified has expired (70007)；出现这个 maessage 的原因是 timeout 连接超时了。 通过上面那个表中的 options 来看，可以通过加 -k 和 -s 来分别指定 下 keep-alive 和 超时时间，也可以通过 -r 来规避遇到socket接收错误后，不退出测试。\n使用 -k 和 -s123456789101112131415161718192021222324252627282930313233343536373839404142434445464748➜  ~ ab -n 200 -c 10 -s 5000 -k  http://localhost:8080/api/testThis is ApacheBench, Version 2.3 &lt;$Revision: 1879490 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking localhost (be patient)Completed 100 requestsCompleted 200 requestsFinished 200 requestsServer Software:Server Hostname:        localhostServer Port:            8080Document Path:          /api/testDocument Length:        6 bytesConcurrency Level:      10Time taken for tests:   352.210 secondsComplete requests:      200Failed requests:        8   (Connect: 0, Receive: 0, Length: 8, Exceptions: 0)Keep-Alive requests:    192Total transferred:      27840 bytesHTML transferred:       1152 bytesRequests per second:    0.57 [#/sec] (mean)Time per request:       17610.485 [ms] (mean)Time per request:       1761.049 [ms] (mean, across all concurrent requests)Transfer rate:          0.08 [Kbytes/sec] receivedConnection Times (ms)              min  mean[+/-sd] median   maxConnect:        0    0   0.1      0       1Processing:  3002 15972 44971.8   3006  218613Waiting:        0 11492 40519.5   3006  218613Total:       3002 15972 44971.9   3006  218613Percentage of the requests served within a certain time (ms)  50%   3006  66%   3006  75%   3007  80%   3007  90%   3008  95%  112001  98%  209597  99%  215607 100%  218613 (longest request)\n\n使用 -r在不适用 -r 的请求下，\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748➜  ~ ab -n 200 -c 100 -s 5000 -k -r  http://localhost:8080/api/testThis is ApacheBench, Version 2.3 &lt;$Revision: 1879490 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking localhost (be patient)Completed 100 requestsCompleted 200 requestsFinished 200 requestsServer Software:Server Hostname:        localhostServer Port:            8080Document Path:          /api/testDocument Length:        6 bytesConcurrency Level:      100Time taken for tests:   107.100 secondsComplete requests:      200Failed requests:        147   (Connect: 0, Receive: 0, Length: 147, Exceptions: 0)Keep-Alive requests:    53Total transferred:      7685 bytesHTML transferred:       318 bytesRequests per second:    1.87 [#/sec] (mean)Time per request:       53549.816 [ms] (mean)Time per request:       535.498 [ms] (mean, across all concurrent requests)Transfer rate:          0.07 [Kbytes/sec] receivedConnection Times (ms)              min  mean[+/-sd] median   maxConnect:        0    3   2.1      3       8Processing:  3002 43074 19044.3  49998   75116Waiting:        0 5502 15736.0      0   75116Total:       3002 43077 19045.5  50002   75117Percentage of the requests served within a certain time (ms)  50%  50002  66%  50003  75%  54088  80%  54089  90%  54090  95%  54092  98%  66104  99%  72112 100%  75117 (longest request)\n\nConnection reset by peer1234567➜  ~ ab -n 200 -c 100 -s 5000 -k  http://localhost:8080/api/testThis is ApacheBench, Version 2.3 &lt;$Revision: 1879490 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/Benchmarking localhost (be patient)apr_socket_recv: Connection reset by peer (54)\n\nConnection reset by peer也会导致 ab 中途退出，从本地测试来看，当并发数增加时，出现该问题的比率会增加；Connection Reset by peer 意味着远端终止了会话，即当操作系统接收到远端服务器的RST (TCP Reset)通知时会产生此错误。在使用 ab 时，可以通过 -r 来忽略这种错误，在遇到socket接收错误后，不退出测试。\nab 的结果解析版本相关123This is ApacheBench, Version 2.3 &lt;$Revision: 1879490 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/\n\n这部分信息是 ab 的版本信息，可以忽略。\n测试完成度1234Benchmarking localhost (be patient)Completed 100 requestsCompleted 200 requestsFinished 200 requests\n\n以上内容显示测试完成度，通过分行显示当前完成数量。\n测试服务器信息123Server Software:Server Hostname:        localhostServer Port:            8080\n\nServer Software 一栏没有数据，因为本地启动的 server 容器；其他两个就是地址和端口。\n地址和包大小12Document Path:          /api/testDocument Length:        6 bytes\n\n测试数据详情123456789101112Concurrency Level:      100Time taken for tests:   107.100 secondsComplete requests:      200Failed requests:        147   (Connect: 0, Receive: 0, Length: 147, Exceptions: 0)Keep-Alive requests:    53Total transferred:      7685 bytesHTML transferred:       318 bytesRequests per second:    1.87 [#/sec] (mean)Time per request:       53549.816 [ms] (mean)Time per request:       535.498 [ms] (mean, across all concurrent requests)Transfer rate:          0.07 [Kbytes/sec] received\n\n\nConcurrency Level：并发数，-c 参数值\nTime taken for tests：本次测试总共花费的时间\nComplete requests：本次请求执行的请求数总量\nFailed requests：失败的请求数量。因网络原因或服务器性能原因，发起的请求并不一定全部成功，通过该数值和Complete requests相除可以计算请求的失败率，作为测试结果的重要参考。\nKeep-Alive requests：使用长连接的请求数量\nTotal transferred：总共传输的数据量，指的是 ab 从被测服务器接收到的总数据量，包括文本内容和请求头信息。\nHTML transferred：从服务器接收到的 html 文件的总大小，等于 Document Length＊Complete requests\nRequests per second：平均每秒完成的请求数：QPS，是一个平均值，等于 Complete requests&#x2F;Time taken for tests\nTime per request：从用户角度看，完成一个请求所需要的时间（因用户数量不止一个，服务器完成 10 个请求，平均每个用户才接收到一个完整的返回，所以该值是下一项数值的10倍。）\nTime per request：服务器完成一个请求的时间。\nTransfer rate：网络传输速度，对于大文件的请求测试，这个值很容易成为系统瓶颈所在。要确定该值是不是瓶颈，需要了解客户端和被测服务器之间的网络情况，包括网络带宽和网卡速度等信息。\n\nTime per request 统计信息123456Connection Times (ms)              min  mean[+/-sd] median   maxConnect:        0    3   2.1      3       8Processing:  3002 43074 19044.3  49998   75116Waiting:        0 5502 15736.0      0   75116Total:       3002 43077 19045.5  50002   75117\n\n对上面第一个 Time per request 进行细分和统计。一个请求的响应时间可以分成网络链接（Connect），系统处理（Processing）和等待（Waiting）三个部分。表中 min 表示最小值； mean 表示平均值；[+&#x2F;-sd] 表示标准差（Standard Deviation） ，也称均方差（mean square error），该数值越大表示数据越分散，系统响应时间越不稳定。 median 表示中位数； max 当表示最大值。\nTotal 是从整个请求所需要的时间的角度来统计的。这里可以看到最慢的一个请求花费了 75117 ms，这个数据可以在下面的表中得到验证。\n12345678910Percentage of the requests served within a certain time (ms)  50%  50002  66%  50003  75%  54088  80%  54089  90%  54090  95%  54092  98%  66104  99%  72112 100%  75117 (longest request)\n\n这个表第一行表示有 50% 的请求都是在 50002 ms 内完成的，这个值是比较接近平均系统响应时间（第一个 Time per request: 53549.816 ms ）； 以此类推。\n前面看到响应时间最长的那个请求是 75117 ms，那么显然所有请求（100%）的时间都是小于等于 75117 ms 的，也就是表中最后一行的数据就是时间最长的那个请求（longest request）。\n参考\nhttps://www.cnblogs.com/gumuzi/p/5617232.html\nhttps://knowledge.broadcom.com/external/article/222862/what-does-connection-reset-by-peer-mean.html\nhttps://github.com/vibora-io/vibora/issues/154\nhttps://httpd.apache.org/docs/2.4/programs/ab.html\n\n","slug":"tests/test-benchmark-ab","date":"2022-09-22T13:26:42.000Z","categories_index":"test","tags_index":"test,ab test","author_index":"glmapper"},{"id":"2c6664cf4370278f829998c803443e3c","title":"浅析 SOFA 注册中心数据同步","content":"本篇主要对 SOFARegistry 的数据同步模块进行解析，对于注册中心的概念以及 SOFARegistry 的基础架构不做过多阐述，相关介绍可以见海量数据下的注册中心 - SOFARegistry 架构介绍 这篇文章。\n\n\n本文主要写作思路大致分为下面 2 个部分：第一部分借助 SOFARegistry 中的角色分类来说明哪些角色之间会进行数据同步，第二部分对数据同步的具体实现进行解析。\nSOFARegistry 的角色分类如上图，SOFARegistry 包含 4 个角色：\n\n\n\n角色\n说明\n\n\n\nClient\n提供应用接入服务注册中心的基本 API 能力，应用系统通过依赖客户端 JAR 包，通过编程方式调用服务注册中心的服务订阅和服务发布能力。\n\n\nSessionServer\n会话服务器，负责接受 Client 的服务发布和服务订阅请求，并作为一个中间层将写操作转发 DataServer 层。SessionServer 这一层可随业务机器数的规模的增长而扩容。\n\n\nDataServer\n数据服务器，负责存储具体的服务数据，数据按 dataInfoId 进行一致性 Hash 分片存储，支持多副本备份，保证数据高可用。这一层可随服务数据量的规模的增长而扩容。\n\n\nMetaServer\n元数据服务器，负责维护集群 SessionServer 和 DataServer 的一致列表，作为 SOFARegistry 集群内部的地址发现服务，在 SessionServer 或 DataServer 节点变更时可以通知到整个集群。\n\n\n在这 4 个角色中，MetaServer 作为元数据服务器本身不处理实际的业务数据，仅负责维护集群 SessionServer 和 DataServer 的一致列表，不涉及数据同步问题；Client 与 SessionServer 之间的核心动作是订阅和发布，从广义上来说，属于用户侧客户端与 SOFARegistry 集群的数据同步，可以见：https://github.com/sofastack/sofa-registry/issues/195，因此不在本文讨论范畴之内。\nSessionServer 作为会话服务，它主要解决海量客户端连接问题，其次是缓存客户端发布的所有 pub 数据；session 本身不持久化服务数据，而是将数据转写到 DataServer。DataServer 存储服务数据是按照 dataInfoId 进行一致性 Hash 分片存储的，支持多副本备份，保证数据高可用。\n从 SessionServer 和 DataServer 的功能分析中可以得出：\n\nSessionServer 缓存的服务数据需要与 DataServer 存储的服务数据保持一致\n\n\n\nDataServer 支持多副本来保证高可用，因此 DataServer 多副本之间需要保持服务数据一致。\n\n\nSOFARegistry 中对于上述两个对于数据一致性保证就是通过数据同步机制来实现的。\n数据同步的具体实现下面主要介绍数据同步的实现细节，主要包括 SessionServer 和 DataServer 之间的数据同步 和 DataServer 多副本之间的数据同步两块。\nSessionServer 和 DataServer 之间的数据同步SessionServer 和 DataServer 之间的数据同步，是基于推拉结合的机制\n\n推：DataServer 在数据有变化时，会主动通知 SessionServer，SessionServer 检查确认需要更新（对比 version） 后主动向 DataServer 获取数据。\n拉：除了上述的 DataServer 主动推以外，SessionServer 每隔一定的时间间隔，会主动向 DataServer 查询所有 dataInfoId 的 version 信息，然后再与 SessionServer 内存的 version 作比较，若发现 version 有变化，则主动向 DataServer 获取数据。这个“拉”的逻辑，主要是对“推”的一个补充，若在“推”的过程有错漏的情况可以在这个时候及时弥补。\n\n\n\n\n\n\n\n\n\n\n关于推和拉两种模式检查的 version 有一些差异，可以详见下面 推模式下的数据同步 和 **拉模式下的数据同步 **中的具体介绍\n推模式下的数据同步流程推模式是通过 SyncingWatchDog 这个守护线程不断 loop 执行来实现数据变更检查和通知发起的。\n123456789101112// 这里遍历所有的 slotfor (SlotState slotState : slotTableStates.slotStates.values()) &#123;    try &#123;        sync(slotState, syncSessionIntervalMs, syncLeaderIntervalMs, slotTableEpoch);    &#125; catch (Throwable e) &#123;        SYNC_ERROR_LOGGER.error(                &quot;[syncCommit]failed to do sync slot &#123;&#125;, migrated=&#123;&#125;&quot;,                slotState.slot,                slotState.migrated,                e);    &#125;&#125;\n按 slot 分组汇总数据版本。data 与每个 session 的连接都对应一个 SyncSessionTask，SyncSessionTask 负责执行同步数据的任务，核心同步逻辑在 com.alipay.sofa.registry.server.data.slot.SlotDiffSyncer#sync方法中完成，大致流程如下面时序图所示：这上图圈红部分的逻辑第四步，根据 dataInfoId diff 更新 data 内存数据，这里仅处理了被移除的 dataInfoId，对于新增和更新的没有做任务处理，而是通过后面的第 5 -7 步来完成；这么做的主要原因在于避免产生空推送导致一些危险情况发生。\n第 5 步中，比较的是所有变更 dataInfoId  的 pub version，具体比较逻辑参考后面 diffPublisher 小节中的介绍。\n数据变更的事件通知处理\n数据变更事件会被收集在 DataChangeEventCenter 的 dataCenter2Changes 缓存中，然后由一个守护线程 ChangeMerger 负责从 dataCenter2Changes 缓存中不断的读取，这些被捞到的事件源会被组装成 ChangeNotifier 任务，提交给一个单独的线程池(notifyExecutor)处理，整个过程全部是异步的。\n拉模式下的数据同步流程拉模式下，由 SessionServer 负责发起，com.alipay.sofa.registry.server.session.registry.SessionRegistry.VersionWatchDog默认情况下每 5 秒扫描一次版本数据，如果版本有发生变更，则主动进行拉取一次，流程大致如下：\n需要注意的是，拉模式对推送流程的补充，这里的 version 是每个 sub 的 lastPushedVersion， 而 推模式的version 是 pub 的数据的 version。关于 lastPushedVersion 的获取可以参考 com.alipay.sofa.registry.server.session.store.SessionInterests#selectSubscribers\n1234567891011121314store.forEach((String dataInfoId, Map&lt;String, Subscriber&gt; subs) -&gt; &#123;   // ...  long maxVersion = 0;  for (Subscriber sub : subs.values()) &#123;    // ...    // 获取当前 sub 的 pushVersion    final long pushVersion = sub.getPushedVersion(dataCenter);    // 如果 pushVersion 比最大(最新)版本大，则将当前  pushVersion 作为最新版本推送版本    if (maxVersion &lt; pushVersion) &#123;      maxVersion = pushVersion;    &#125;  &#125;  versions.put(dataInfoId, new DatumVersion(maxVersion));&#125;);\n\nDataServer 多副本之间的数据同步主要是 slot对应的 data 的 follower 定期和 leader 进行数据同步，其同步逻辑与 SessionServer 和 DataServer 之间的数据同步逻辑差异不大；发起方式也是一样的；data 判断如果当前节点不是 leader，就会进行与 leader 之间的数据同步。\n123456if (localIsLeader(slot)) &#123;   // 如果当前是 leader，则执行 session 同步或者 migrating&#125; else &#123;    // 如果当前不是 leader，则和 leader 同步数据    syncLeader(slotState, syncLeaderIntervalMs, slotTableEpoch);&#125;\n\n\n\n\n\n\n\n\n\n篇幅原因，这部分不展开讨论。\n增量同步 diff 计算逻辑分析不管是 SessionServer 和 DataServer 之间的同步，还是 DataServer 多副本之间的同步，都是基于增量 diff 同步的，不会一次性同步全量数据。本节对增量同步 diff 计算逻辑进行简单分析，核心代码在 com.alipay.sofa.registry.common.model.slot.DataSlotDiffUtils（建议阅读这部分代码时直接结合代码中的测试用例来看）；主要包括计算 digest 和 publishers 两个。\ndiffDigestDataSlotDiffUtils#diffDigest 方法接收两个参数\n\ntargetDigestMap 可以理解为目标数据\nsourceDigestMap 可以理解为基线数据\n\n核心计算逻辑如下代码分析\n12345678910111213141516171819202122232425262728// 遍历 sourceDigestMap 元素for (Map.Entry&lt;String, DatumDigest&gt; e : sourceDigestMap.entrySet()) &#123;  // dataInfoId  final String dataInfoId = e.getKey();  // 从 目标数据 集中根据 dataInfoId 获取数据摘要  DatumDigest targetDigest = targetDigestMap.get(dataInfoId);  // 如果目标数据集中没有当前 dataInfoId 对应的数据摘要，  // 则将当前 dataInfoId 作为新增项  if (targetDigest == null) &#123;    adds.add(dataInfoId);    continue;  &#125;  // 如果目标数据集中有当前 dataInfoId 对应的数据摘要，  // 但是数据摘要不同，则将当前 dataInfoId 作为待更新项  if (!targetDigest.equals(e.getValue())) &#123;    updates.add(dataInfoId);  &#125;&#125;// 如果目标数据集中的 dataInfoId 不再基线数据集中时，// 则将当前 dataInfoId 作为待移除项。List&lt;String&gt; removes = new ArrayList&lt;&gt;();for (String dataInfoId : targetDigestMap.keySet()) &#123;  if (!sourceDigestMap.containsKey(dataInfoId)) &#123;    removes.add(dataInfoId);  &#125;&#125;\n\n那么根据上述 diff 计算逻辑，这里有如下几种场景（假设基线数据集数据中 dataInfoId 为 a 和 b）\n\n目标数据集为空：返回 dataInfoId 为 a 和 b 两项作为新增项\n目标数据集与基线数据集相等，新增项、待更新项与待移除项均为空\n目标数据集中包括 a,b,c 三个 dataInfoId，则返回 c 作为待移除项\n目标数据集中包括 a 和 c 两个 dataInfoId，则返回 c 作为待移除项，b 作为新增项\n\ndiffPublisherdiffPublisher 与 diffDigest 计算稍有不同，diffPublisher 接收三个参数，除了目标数据集和基线数据集之外，还有一个 publisherMaxNum（默认 400），用于限制每次处理的数据个数；这里同样给出核心代码解释：\n1234567891011121314151617181920212223242526272829303132333435363738// 遍历所有目标数据集for (DatumSummary summary : targetDatumSummaries) &#123;      // 拿到 dataInfoId      final String dataInfoId = summary.getDataInfoId();      // 看基线数据集中是否包括当前 dataInfoId 对应的 Publisher 数据      Map&lt;String, Publisher&gt; publisherMap = sourcePublishers.get(dataInfoId);      // 这里表示 dataInfoId 移除被移除了，不需要做任何处理      if (publisherMap == null) &#123; continue; &#125;            Set&lt;String&gt; registerIds = summary.getPublisherVersions().keySet();      // 遍历 registerIds      for (String registerId : registerIds) &#123;        // 如果基线数据集中不包括此 registerId，则将当前 registerId 加入待移除列表中        if (!publisherMap.containsKey(registerId)) &#123;          List&lt;String&gt; list = removedPublishers.computeIfAbsent(dataInfoId, k -&gt; new ArrayList&lt;&gt;());          list.add(registerId);        &#125;      &#125;      List&lt;Publisher&gt; publishers = new ArrayList&lt;&gt;();      Map&lt;String, RegisterVersion&gt; versions = summary.getPublisherVersions();      // 遍历版本      for (Map.Entry&lt;String, Publisher&gt; p : publisherMap.entrySet()) &#123;        final String registerId = p.getKey();        // 如果目标数据集当前 dataInfoId 的 registerIds 集中不包括基线的        // 则作为更新项        if (!versions.containsKey(registerId)) &#123;          publishers.add(p.getValue());          continue;        &#125;        // 如果当前 registerId 版本相同，则不做处理        if (p.getValue().registerVersion().equals(versions.get(registerId))) &#123;          // the same          continue;        &#125;        // 不相等，则作为更新项        publishers.add(p.getValue());      &#125;    &#125;\n\n这里同样分析几种场景（下面只的是更新 dataInfoId 对应的 publisher，registerId 与 publisher是 一一对应）：\n\n目标数据集与基线数据集相同，且数据没有超过 publisherMaxNum，返回的待更新和待移除均为空，且没有剩余未处理数据\n需要移除的情况：基线中不包括目标数据集 dataInfoId 的 registerId （移除的是 registerId，不是 dataInfoId）\n需要更新的情况：\n目标数据集中存在基线数据集不存在的 registerId\n目标数据集和基线数据集存在的 registerId 的版本不同\n\n\n\n总结本文主要介绍了 SOFARegistry 中数据同步模块；首先从 SOFARegistry 角色分类阐述不同角色之间存在的数据同步问题，针对其中 SessionServer 与 DataServer 数据同步 和 DataServer 多副本之间数据同步进行了展开分析；在 SessionServer 与 DataServer 数据同步分析中，着重分析了推和拉两种场景下数据同步的整体流程；最后对 SOFARegistry 中数据增加的 diff 计算逻辑进行了介绍，并结合相关核心代码描述了具体的场景。\n整体来看，SOFARegistry 数据同步上的处理上有一些点值得我们学习：\n\nSOFARegistry 基于 ap，在一致性上是满足最终一致性；在实际的同步逻辑处理上，结合事件机制，基本都是异步化完成的，从而弱化了数据同步对于核心流程的影响。\n在拉模式和数据变更通知两个部分，内部采用了类似生产-消费模型，一方面是对于生产和消费逻辑的解耦，从代码上更独立；再者通过缓存或者队列来消除生产和消费速度不同而相互阻塞的问题。\n拉模式对推模式的补充；我们知道推模式是 server -&gt; client，发生在数据变更时，如果出现一些异常，导致某条 server -&gt; client 链路推送失败，则会导致不同 client 持有的数据不一致的情况；拉模式的补充，使得 client 可以主动去完成对于数据一致性的检查。\n\n\n\n\n\n\n\n\n\n\n最后，感谢大家的阅读，文中如有错误，请指出；也欢迎大家关注 sofastack 社区。原文链接：https://mp.weixin.qq.com/s/UqsFzSuxuOfdVGJUGEid8g?from=timeline&amp;isappinstalled=0&amp;scene=2&amp;clicktime=1657013852&amp;enterid=1657013852\n","slug":"sofa/sofa-registry-sync-data","date":"2022-09-12T02:58:30.000Z","categories_index":"SOFA","tags_index":"注册中心,分布式","author_index":"glmapper"},{"id":"3784314f76c771adae1123b249748729","title":"你知道 @Async 是怎么让方法异步执行的吗？","content":"在阅读本文之前，你可以通过 Creating Asynchronous Methods 指导来体验下创建异步方法的使用方式。\n为什么要写这篇文章，本质上对于这些 Spring 已经封装好的能力，并不需要去关注它底层到底是怎么玩的，比如 @Async，你肯定可以猜到对于打了这个注解的方法（或者类），在执行这个方法（或者类下所有方法）时，Spring 框架会将当前方法丢进到一个单独的线程池中去执行，以达到方法异步执行的目的。\n\n\n本篇文章的原始诉求来自于需要对 @Async 描述的方法进行 trace 埋点，当前大多数基于线程上下文传递 traceContext 的方式显然对于跨线程问题是不能满足的，需要特殊的处理；那么就需要对这些技术点进行剖析，以寻求切入点。\n前言@Async 是通过注解标记来开启方法的异步执行的；对于注解的底层实现，除了 java 原生提供那种依赖编译期植入的之外，其他的基本都差不多，即运行时通过反射等方式拦截到打了注解的类或者方法，然后执行时进行横切拦截；另外这里还有一个点就是方法异步执行，所以对于 @Async 的剖析，就一定绕不开两个基本的知识点，就是代理和线程池。在了解到这些之后，我们来拆解下 @Async 的基本原理。\n如何开启生效？\n\n\n\n\n\n\n\n\nThe @EnableAsync annotation switches on Spring’s ability to run @Async methods in a background thread pool.\n通过 @EnableAsync 来开启异步方法的能力。\n1234567@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AsyncConfigurationSelector.class)public @interface EnableAsync &#123;// ...`&#125;\n\n@EnableAsync 注解 Import 了 AsyncConfigurationSelector，这个在 SpringBoot 中是非常常见的一种写法，这里需要关注的是选择了哪个自动配置类；adviceMode 默认是 false，这里就以 ProxyAsyncConfiguration 为例：\n123456789101112@Override@Nullablepublic String[] selectImports(AdviceMode adviceMode) &#123;    switch (adviceMode) &#123;        case PROXY:            return new String[] &#123;ProxyAsyncConfiguration.class.getName()&#125;;        case ASPECTJ:            return new String[] &#123;ASYNC_EXECUTION_ASPECT_CONFIGURATION_CLASS_NAME&#125;;        default:            return null;    &#125;&#125;\n\nAsyncAnnotationBeanPostProcessor在 org.springframework.scheduling.annotation.ProxyAsyncConfiguration中最主要的就是创建 AsyncAnnotationBeanPostProcessor，从名字看，AsyncAnnotationBeanPostProcessor 就是来处理 @Async 注解的；目的很明确，就是创建对应 bean 的代理对象，以便于执行方法时能够进行 AOP 拦截（具体细节可以看 org.springframework.aop.framework.AbstractAdvisingBeanPostProcessor#postProcessAfterInitialization这个方法）。\n123456ProxyFactory proxyFactory = prepareProxyFactory(bean, beanName);if (!proxyFactory.isProxyTargetClass()) &#123;   evaluateProxyInterfaces(bean.getClass(), proxyFactory);&#125;proxyFactory.addAdvisor(this.advisor);customizeProxyFactory(proxyFactory);\n\nAnnotationAsyncExecutionInterceptor\n\n\n\n\n\n\n\n\n这里涉及到 AOP 的一些基础知识，可以查阅之前写的 https://juejin.cn/post/6844903623101513735 这篇文章\nAOP 中最外层的是代理类，然后是织入器(advisor)，再接着是切面（advice he PointCut）；前面已经将创建代理对象的逻辑进行了介绍，所以接下来是织入器(advisor)和切面的创建。实际上织入器(advisor)的创建逻辑也是在 AsyncAnnotationBeanPostProcessor 中完成的。\n1234567891011@Overridepublic void setBeanFactory(BeanFactory beanFactory) &#123;    super.setBeanFactory(beanFactory);\t// 创建  advisor    AsyncAnnotationAdvisor advisor = new AsyncAnnotationAdvisor(this.executor, this.exceptionHandler);    if (this.asyncAnnotationType != null) &#123;        advisor.setAsyncAnnotationType(this.asyncAnnotationType);    &#125;    advisor.setBeanFactory(beanFactory);    this.advisor = advisor;&#125;\n\n在 AsyncAnnotationAdvisor 的构造函数中，会构建 Advice 和 Pointcut\n123456789public AsyncAnnotationAdvisor(        @Nullable Supplier&lt;Executor&gt; executor, @Nullable Supplier&lt;AsyncUncaughtExceptionHandler&gt; exceptionHandler) &#123;\t// 省略其他代码\t/// ...    // 创建 advice    this.advice = buildAdvice(executor, exceptionHandler);    // 创建 pointcut    this.pointcut = buildPointcut(asyncAnnotationTypes);&#125;\n\nAdvice 就是具体执行拦截的逻辑，这里的 advice 实际上 AnnotationAsyncExecutionInterceptor(why ? 因饰Advice 是 MethodInterceptor 的父类)。\n1234567protected Advice buildAdvice(        @Nullable Supplier&lt;Executor&gt; executor, @Nullable Supplier&lt;AsyncUncaughtExceptionHandler&gt; exceptionHandler) &#123;\t// 这里    AnnotationAsyncExecutionInterceptor interceptor = new AnnotationAsyncExecutionInterceptor(null);    interceptor.configure(executor, exceptionHandler);    return interceptor;&#125;\n\n到这里，关于 @EnableAsync 是如何开启创建异步方法的逻辑基本就介绍完了；本质上还是 Spring AOP 的那套逻辑。\nTips除了 adviceMode，一般情况下还会涉及到另外一个参数，即 proxyTargetClass；proxyTargetClass 在设置为 true 和 false 时，对应使用的代理机制大致如下：\n\ntrue\n\n目标对象实现了接口 – 使用 CGLIB 代理机制\n目标对象没有接口(只有实现类) – 使用 CGLIB 代理机制\n\n\nfalse\n\n目标对象实现了接口 – 使用 JDK 动态代理机制(代理所有实现了的接口)\n目标对象没有接口(只有实现类) – 使用 CGLIB 代理机制\n\n\n\n线程池上一小节中，对 @EnableAsync 生效机制和对应的 AOP 对象创建逻辑进行了介绍；实际上 AOP 拦截到具体的方法之后的主要目的就是将执行逻辑丢到线程池中去执行。那这里就会涉及到本节的主题，即线程池。本节需要搞清楚几个问题：\n\n什么时候创建的线程池?\n创建的线程池类型是啥?\n方法执行任务是如何被提交的?\n\n创建 AnnotationAsyncExecutionInterceptor 时初始化线程池线程池的创建是在创建 AnnotationAsyncExecutionInterceptor 对象时完成，代码如下：\n123public AnnotationAsyncExecutionInterceptor(@Nullable Executor defaultExecutor) &#123;    super(defaultExecutor);&#125;\n\n在其父类 AsyncExecutionAspectSupport 中完成具体线程池创建\n1this.defaultExecutor = new SingletonSupplier&lt;&gt;(defaultExecutor, () -&gt; getDefaultExecutor(this.beanFactory));\n\n在 getDefaultExecutor 方法中， 会先从 Spring 容器找 TaskExecutor 类型的线程池 Bean，如果找不到，会扩大范围找 Executor 类型的线程池 Bean，如果找不到，则返回 null。\n\n\n\n\n\n\n\n\n\n这里是个延迟载入的操作，即只有当异步方法被调用时，才会触发 SingletonSupplier get 操作，从而触发 getBean 的逻辑，如果你在 debug 时出现没有正常走到断点的情况，可以关注下这个场景。\n默认线程池 SimpleAsyncTaskExecutor123456@Override@Nullableprotected Executor getDefaultExecutor(@Nullable BeanFactory beanFactory) &#123;    Executor defaultExecutor = super.getDefaultExecutor(beanFactory);    return (defaultExecutor != null ? defaultExecutor : new SimpleAsyncTaskExecutor());&#125;\n\n从这段逻辑看，如果从 Spring 容器中没有找到对应的线程池 Bean，那么就创建 SimpleAsyncTaskExecutor 作为默认的线程池。\n\n\n\n\n\n\n\n\n\nThis class also customizes the Executor by defining a new bean. Here, the method is named taskExecutor, since this is the specific method name for which Spring searches. In our case, we want to limit the number of concurrent threads to two and limit the size of the queue to 500. There are many more things you can tune. If you do not define an Executor bean, Spring creates a SimpleAsyncTaskExecutor and uses that.\n方法执行任务的提交基于前面的分析，方法执行任务的提交一定是发生在拦截到 @Async 注解时，也就是 AnnotationAsyncExecutionInterceptor 中；通过分析代码，在其父类 AsyncExecutionInterceptor中，验证了分析。下面是部分核心逻辑:\n1234567891011public Object invoke(final MethodInvocation invocation) throws Throwable &#123;    // 1、拿到 Method    // 2、根据 Method 获取 executor    AsyncTaskExecutor executor = determineAsyncExecutor(userDeclaredMethod);    // 3、创建方法执行任务 task    Callable&lt;Object&gt; task = () -&gt; &#123;    // ...    &#125;;    // 4、提交 task    return doSubmit(task, executor, invocation.getMethod().getReturnType());&#125;\n\ndetermineAsyncExecutor 中说明了， executor 是和方法对象绑定的，即每个方法都有一个自己的 executor；异步方法在第一次执行的时候创建自己的 executor，然后缓存到内存中。在 doSubmit 中，会根据 returnType 的类型进行相应的处理\n1234567891011121314151617181920212223242526protected Object doSubmit(Callable&lt;Object&gt; task, AsyncTaskExecutor executor, Class&lt;?&gt; returnType) &#123;    // CompletableFuture    if (CompletableFuture.class.isAssignableFrom(returnType)) &#123;        return CompletableFuture.supplyAsync(() -&gt; &#123;            try &#123;                return task.call();            &#125;            catch (Throwable ex) &#123;                throw new CompletionException(ex);            &#125;        &#125;, executor);    &#125;    // ListenableFuture    else if (ListenableFuture.class.isAssignableFrom(returnType)) &#123;        return ((AsyncListenableTaskExecutor) executor).submitListenable(task);    &#125;    // Future    else if (Future.class.isAssignableFrom(returnType)) &#123;        return executor.submit(task);    &#125;    // void    else &#123;        executor.submit(task);        return null;    &#125;&#125;\n\n如何自定义线程池SpringBoot 提供了 org.springframework.scheduling.annotation.AsyncConfigurer 接口让开发人员可以自定义线程池执行器；框架默认提供了一个空的实现类 AsyncConfigurerSupport，两个方法体内部都是空实现。这部分逻辑在 org.springframework.scheduling.annotation.AbstractAsyncConfiguration#setConfigurers体现：\n12345678910111213141516/*** Collect any &#123;@link AsyncConfigurer&#125; beans through autowiring.*/@Autowired(required = false)void setConfigurers(Collection&lt;AsyncConfigurer&gt; configurers) &#123;if (CollectionUtils.isEmpty(configurers)) &#123;    return;&#125;if (configurers.size() &gt; 1) &#123;    throw new IllegalStateException(&quot;Only one AsyncConfigurer may exist&quot;);&#125;AsyncConfigurer configurer = configurers.iterator().next();// for thisthis.executor = configurer::getAsyncExecutor;this.exceptionHandler = configurer::getAsyncUncaughtExceptionHandler;&#125;\n\nAsyncConfigurer 在项目中只能有一个实现 Bean，如果超过一个，将会抛出 IllegalStateException 异常。\n总结本文通过对 @Async 注解的分析，和你解释了 @Async 是怎么让方法异步执行的吗？ 这个问题；从分析过程中可以知道，对于绝大多数面向工程师使用的注解或者工具，本质上是离不开那些最最基本知识点的。当然，通过分析代码，一方面是可以进一步识别作者的意图，更主要的是可以看到那些意料之外的“骚操作” coding。\n","slug":"springboot/spring-boot-async-anno","date":"2022-09-12T01:05:44.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot","author_index":"glmapper"},{"id":"852e241ff76b8d8f5b786f53987404dc","title":"聊 一聊 maven 测试相关的插件","content":"在之前的 聊一聊 maven 生命周期和 maven 插件编写 这篇文章中，简单聊了点maven 构建生命周期和如何编写一个 maven 插件。本篇文章从插件入手，来探讨下 maven 中那些于测试相关的插件，这些插件与工程师日常开发是密切相关的，可能很多情况下你不需要关注，因为已经有前辈帮你搞完了；“事不关己高高挂起” 与 “知其然知其所以然” 是两种不同的态度，对待技术，我建议是后者！\n\n\nmaven-surefire-plugin在 Maven 项目中，用户基于 JUnit 或 TestNG 编写好了测试代码，这部分是工程师 coding 必须要要做好的；本地可以使用 idea 带的工具进行执行；倒是如果需要在 ci 中执行并且产出测试报告，idea 就帮不上什么忙了；此时，就需要依赖 maven 插件来帮助解决。执行测试代码，需要靠 maven-surefire-plugin 插件来实现。\n一般情况下，工程师不需要显示配置 maven-surefire-plugin 插件，它是 mvn test 默认依赖使用的。\n为什么用例没有执行看下面这张图，使用的 junit 版本是 4.13.2。\n\n一个非常简单的 demo，demo 中只有一个单元测试用例，当使用 mvn test 执行时发现:\n1Tests run: 0, Failures: 0, Errors: 0, Skipped: 0\n我去翻了一下插件的 使用介绍，看到了下面这段说明：\n1234567891011If nothing is configured, Surefire detects which JUnit version to use by thefollowing algorithm:1. if the JUnit 5 Platform Engine is present in the project    use junit-platform2. if the JUnit version in the project &gt;= 4.7 and the &lt;&lt;&lt;parallel&gt;&gt;&gt; configuration parameter has ANY value    use junit47 provider3. if JUnit &gt;= 4.0 is present    use junit4 provider4. else    use junit3.8.1\n\n图中可以看到 maven-surefire-plugin 版本是 2.22.2，demo 中所使用的 junit 版本是 4.13.2，属于第二种算法：use junit47 provider，就是说如果是 JUnit 4.7 及以上版本，可以明确声明一下：\n\n\n\n\n\n\n\n\n\n目前已经提供的 provider 有 surefire-junit3, surefire-junit4, surefire-junit47 以及 surefire-testng\n12345678910111213141516&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;            &lt;version&gt;2.22.2&lt;/version&gt;            &lt;dependencies&gt;                &lt;dependency&gt;                    &lt;groupId&gt;org.apache.maven.surefire&lt;/groupId&gt;                    &lt;artifactId&gt;surefire-junit47&lt;/artifactId&gt;                    &lt;version&gt;2.22.2&lt;/version&gt;                &lt;/dependency&gt;            &lt;/dependencies&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n重新执行 mvn test 发现确实可以了。\n\n那既然是基于版本去匹配的，那么换个思路，如果不通过配置来明确 junit 版本，是不是也可以通过另外一种降低 maven-surefire-plugin 来匹配；事实证明猎奇心理是有意思的，当把版本降到 2.21.0 时，发现用例也能正常跑。\n\n跳过用例默认情况下，surefire 插件会自动包含所有具有以下通配符模式的测试类：\n\n&quot;**/Test*.java&quot;- 包括其所有子目录和所有以“Test”开头的 Java 文件名。\n&quot;**/*Test.java&quot;- 包括其所有子目录和所有以“Test”结尾的 Java 文件名。\n&quot;**/*Tests.java&quot;- 包括其所有子目录和所有以“Tests”结尾的 Java 文件名。\n&quot;**/*TestCase.java&quot;- 包括其所有子目录和所有以“TestCase”结尾的 Java 文件名。\n\n如果测试类不遵循默认通配符模式，则需要通过配置 Surefire 插件覆盖它们并指定要包含（或排除）的测试，否则可能扫不到，如下面这个就没有被执行到。\n\n然后通过指定规则来匹配\n\n同理，也可以通过 excludes 来排除不需要执行的用例\n\n使用 mvn 指令来执行单个用例大多数情况下，工程师习惯于面向 idea 来执行单个用例，这种方式是非常便捷的；当然同样也可以使用 mvn 命令来指定单个用例执行，以上面的例子来看，执行 Diff 这个用例可以这样：\n1mvn test -Dtest=Diff\n-Dtest 表示当前测试方法所在的测试类，当然也支持通配符 *。\njacoco-maven-plugin执行用例之后一般需要产生测试报告，目前 jacoco 是最流行的。可以通过如下方式在 pom 中声明：\n1234567891011121314151617181920&lt;plugin&gt;    &lt;groupId&gt;org.jacoco&lt;/groupId&gt;    &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;0.8.2&lt;/version&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;goals&gt;                &lt;goal&gt;prepare-agent&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;        &lt;!-- attached to Maven test phase --&gt;        &lt;execution&gt;            &lt;id&gt;report&lt;/id&gt;            &lt;phase&gt;test&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;report&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n重新执行 mvn test 可以看到 jacoco 执行的日志\n1234567891011[INFO] --- jacoco-maven-plugin:0.8.2:report (report) @ maven-plugin-guides ---[INFO] Loading execution data file /Users/xxx/Documents/projects/github/gl-guides/maven-plugin-guides/target/jacoco.exec[INFO] Analyzed bundle &#x27;maven-plugin-guides&#x27; with 2 classes[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO] [INFO] gl-guides 0.0.1-SNAPSHOT ........................... SUCCESS [  0.172 s][INFO] maven-plugin-guides 0.0.1-SNAPSHOT ................. SUCCESS [  3.151 s][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------\n此时会在 target&#x2F;site 目录下产生数据报告（ps: 这个默认路径是可以修改的）\n打开 index.html 有详细的测试报告描述，大致如下：\n\n1、测试报告概览\n\n2、包概览\n\n3、类概览\n\n\n对于某个核心的逻辑，如果期望这些代码的覆盖率必须满足一定的指标，也是可以通过 jacoco 来配置和设定的；比如我的测试类 PrepareTestInstance\n12345678public class PrepareTestInstance &#123;    public int add(int a, int b) &#123;        if (a &lt; 0 || b &lt; 0) &#123;            throw new IllegalArgumentException();        &#125;        return a + b;    &#125;&#125;\n覆盖率必须达到80%，可以这样配置，增加插件的 execution \n1234567891011121314151617181920&lt;execution&gt;    &lt;id&gt;jacoco-check&lt;/id&gt;    &lt;goals&gt;        &lt;goal&gt;check&lt;/goal&gt;    &lt;/goals&gt;    &lt;configuration&gt;        &lt;rules&gt;            &lt;rule&gt;                &lt;element&gt;PACKAGE&lt;/element&gt;                &lt;limits&gt;                    &lt;limit&gt;                        &lt;counter&gt;LINE&lt;/counter&gt;                        &lt;value&gt;COVEREDRATIO&lt;/value&gt;                        &lt;minimum&gt;0.8&lt;/minimum&gt;                    &lt;/limit&gt;                &lt;/limits&gt;            &lt;/rule&gt;        &lt;/rules&gt;    &lt;/configuration&gt;&lt;/execution&gt;\n\n然后通过 mvn verify 来执行 check，如果覆盖率不满足，则会得到如下的报错：\n1234[INFO] --- jacoco-maven-plugin:0.8.2:check (jacoco-check) @ maven-plugin-guides ---[INFO] Loading execution data file /Users/xxx/Documents/projects/github/gl-guides/maven-plugin-guides/target/jacoco.exec[INFO] Analyzed bundle &#x27;maven-plugin-guides&#x27; with 2 classes[WARNING] Rule violated for package com.gl.guides.mvn: lines covered ratio is 0.4, but expected minimum is 0.8\n\n总结本文主要对 maven 的测试执行和测试报告产生对应的两个插件进行了介绍，希望通过本文，读者可以对这块有个基本的认识，以便于在日常的开发工作中，能够应对类似的问题和场景。\n如果本篇文章对你有帮助，请不要吝啬点赞评论哦～，读者的认可才是持续输出的动力所在…\n\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/7126543596567658503\n","slug":"maven/maven-plugin-about-test","date":"2022-07-31T03:09:51.000Z","categories_index":"maven","tags_index":"maven,maven plugin,testing","author_index":"glmapper"},{"id":"8b30d1846762e70f7f195028545f57f1","title":"修改 YApi 的用户角色(添加管理员)","content":"YApi 后端使用的是 MongoDB，先进入命令行管理工具：\n\n\n\n\n\n\n\n\n\nmongo\n然后进入 yapi 数据库：\n\n\n\n\n\n\n\n\n\n\n\nuse yapi\n随后查询下指定用户的用户 id：\n\n\n\n\n\n\n\n\n\ndb.getCollection(“user”).find({“username”:”glmapper”})\n也可以用邮箱来查：\n\n\n\n\n\n\n\n\n\ndb.getCollection(“user”).find({“email”:”&#103;&#108;&#109;&#x61;&#112;&#112;&#101;&#114;&#x5f;&#x32;&#48;&#x31;&#56;&#64;&#49;&#54;&#x33;&#x2e;&#99;&#111;&#109;“})\n查看返回数据中的“_id”字段的值，就是用户 id 了。\n最后使用以下的语句更新指定用户的 role 为 admin，指定用户即可变成管理员用户：\n\n\n\n\n\n\n\n\n\ndb.getCollection(“user”).update({“username”:”glmapper”}, {$set: {“role”:”admin”}})\n如果需要取消管理员权限，把 role 设置成 member 即可。\n","slug":"api/api-yapi-change-user-role-by-mongo","date":"2022-05-25T14:07:06.000Z","categories_index":"api","tags_index":"api,yapi","author_index":"glmapper"},{"id":"c77c046c2db83a536f549d9b602a59f0","title":"Spring Cloud Config Nacos 配置热更新分析","content":"\n","slug":"config/spring-cloud-config-nacos","date":"2022-04-17T14:05:36.000Z","categories_index":"Nacos","tags_index":"spring,spring cloud,nacos","author_index":"glmapper"},{"id":"e7fa060367ba032c738d6cb91dbbf7a2","title":"Spring Cloud Alibaba Nacos Config 是如何读取配置的？","content":"nacos 配置最高级别的隔离是 namespace，其后是 group；如果有配置隔离的诉求，建议优先使用 namespace 进行隔离。因为对于 sharedConfigs 和 extensionConfigs 来说，他们使用的是默认的 DEFALUT_GROUP，所以如果你配置了 sharedConfigs 和 extensionConfigs ，期望通过指定 group 进行隔离是做不到的。\n\n\n本文主要分析 Spring Cloud Alibaba Nacos 配置客户端读取配置的部分过程，逻辑入口是 com.alibaba.cloud.nacos.client.NacosPropertySourceLocator#locate；通过本篇，\n\n1、了解到 sharedConfigs、extensionConfigs 如何加载\n2、应用配置加载时，dataId 的计算逻辑\n3、如何通过 group 和 namespace 来隔离配置\n4、如何禁用默认的 DEFAULT_GROUP\n\n加载顺序和 sharedConfigs、extensionConfigs 加载逻辑这里的配置主要指的是 sharedConfigs、extensionConfigs 以及用户通过 namespace+group+dataId 指定的应用配置。\n加载顺序123456789// 配置临时存档的地方CompositePropertySource composite = new CompositePropertySource(      NACOS_PROPERTY_SOURCE_NAME);// 1、先加载 sharedConfigsloadSharedConfiguration(composite);‘// 2、接着加载 extensionConfigsloadExtConfiguration(composite);// 最后加载指定的应用配置loadApplicationConfiguration(composite, dataIdPrefix, nacosConfigProperties, env);\n\n这里除了需要关注顺序之后，还有一点非常重要，就是对于 sharedConfigs、extensionConfigs 两个指定的配置，他们不依赖用户指定的 group，而是使用默认的 DEFAULT_GROUP，下面来看。\nsharedConfigs 加载逻辑先通过代码大概理解下逻辑\n1234567891011private void loadSharedConfiguration(      CompositePropertySource compositePropertySource) &#123;   // 通过配置获取 sharedConfigs 列表   List&lt;NacosConfigProperties.Config&gt; sharedConfigs = nacosConfigProperties         .getSharedConfigs();   // 如果没有配置，则啥都不做   if (!CollectionUtils.isEmpty(sharedConfigs)) &#123;      checkConfiguration(sharedConfigs, &quot;shared-configs&quot;);      loadNacosConfiguration(compositePropertySource, sharedConfigs);   &#125;&#125;\n\n假设我通过 sharedConfigs 指定的配置如下：\n1234567spring.cloud.nacos.config.shared-configs=application.yaml,application.properties,application-staging.yaml,application-staging.properties,application-CN.properties,application-staging_CN2.properties\n通过 debug 面板看到，对于指定的 sharedConfigs，全部都挂在 DEFALUT_GROUP 下。\n\n\n\n\n\n\n\n\n\n\n不管是 sharedConfigs 还是 extensionConfigs，抑或是用户指定 group 的配置，nacos 在读取配置时，都是优先从本地开始读，如果本地没有，才从远端配置服务端去读取。\n\n\n\n\n\n\n\n\n\nspring.cloud.nacos.config.extension-config 配置加载和 sharedConfigs 基本一致，这里不展开介绍。\n应用配置加载逻辑中的 dataId 计算这里主要指的是加载用户指定的 group 情况下的应用配置加载，还是先通过代码看下基本逻辑：\n1234567891011121314151617181920private void loadApplicationConfiguration(      CompositePropertySource compositePropertySource, String dataIdPrefix,      NacosConfigProperties properties, Environment environment) &#123;   // 先获取文件的后缀名，比如 yml ，properties    String fileExtension = properties.getFileExtension();   // 获取 group   String nacosGroup = properties.getGroup();   // load directly once by default   loadNacosDataIfPresent(compositePropertySource, dataIdPrefix, nacosGroup,         fileExtension, true);   // load with suffix, which have a higher priority than the default   loadNacosDataIfPresent(compositePropertySource,         dataIdPrefix + DOT + fileExtension, nacosGroup, fileExtension, true);   // Loaded with profile, which have a higher priority than the suffix   for (String profile : environment.getActiveProfiles()) &#123;      String dataId = dataIdPrefix + SEP1 + profile + DOT + fileExtension;      loadNacosDataIfPresent(compositePropertySource, dataId, nacosGroup,            fileExtension, true);   &#125;&#125;\n\n上面代码片段中，加载配置有三种，第一是直接加载，这里的 dataId 使用的是 dataIdPrefix；第二是通过指定后缀加载；最后是通过 指定的 profile 加载。假设 spring.application.name 为 login-service，fileExtension 是 yaml， profile 为 staging，test，下面看下 dataId 的计算。\n直接加载第一部分是加载默认的，这里的默认指的是 dataId 为 dataIdPrefix，dataIdPrefix 可以通过 spring.cloud.nacos.config.prefix 配置，如果没有配置，则使用的是 spring.application.name；这里去加载时，会有从本地文件先加载的逻辑，以这种情况为例，Mac 下本地路径为：\n1 /Users/xxx/nacos/config/xxx/data/config-data-tenant/&#123;namespace&#125;/&#123;group&#125;/&#123;dataId&#125;\n\n如果本地没有，那就根据 namespace, group 和 dataId 去 nacos 服务端去获取，在直接加载这部分。\n使用指定的 suffix 加载ns 和 group 都没变，但是 dataId 变成了 dataIdPrefix + DOT + fileExtension，所以 dataId 就变成了 login-service.yaml，其他加载逻辑和第一部分保持一致。\n使用指定的 profile从代码可以看到，如果指定了多个 profile，则会遍历所有 profile 然后拼接 dataId；这里 dataId 的计算逻辑是 dataIdPrefix + SEP1 + profile + DOT + fileExtension；比如 dataIdPrefix 是 login-service，profile 是 staging，fileExtension 是 yaml，那么得到的 dataId 就是 login-service-staging.yaml，然后在根据 ns、group 和这个计算出来的 dataId 去 nacos 服务端拉去配置，其他逻辑和前面加载配置逻辑一致。\n配置加载过程1、优先使用本地配，代码逻辑在 \ncom.alibaba.nacos.client.config.NacosConfigService#getConfigInner\n12// 优先使用本地配置String content = LocalConfigInfoProcessor.getFailover(agent.getName(), dataId, group, tenant);\n\n\n2、配置资源定位\n配置资源定位通过三个参数 namespace + group + dataId 来确定\n\n从远端拉去之后，会优先创建本地快照，便于下次加载时能够优先从本地加载到\n3、文件格式解析上一步拿到的data，原始数据是字符串类型，然后会根据配置的后缀名，来匹配一个 loader 解析器，nacos 中提供了 4 种类型的解析器\n\n通过解析器将 string 类型的数据进行处理，然后放到 propertySource，这些 propertySource 会被放在 NACOS_PROPERTY_SOURCE_REPOSITORY 这个 ma p 结构中，ke y 为 dataId,group\n\n小结nacos 配置最高级别的隔离是 namespace，其后是 group；如果有配置隔离的诉求，建议优先使用 namespace 进行隔离。因为对于 sharedConfigs 和 extensionConfigs 来说，他们使用的是默认的 DEFALUT_GROUP，所以如果你配置了 sharedConfigs 和 extensionConfigs ，期望通过指定 group 进行隔离是做不到的。\n","slug":"springcloud/spring-cloud-config-nacos-config-locator","date":"2022-03-13T03:45:39.000Z","categories_index":"SpringCloud","tags_index":"nacos,config","author_index":"glmapper"},{"id":"e9b917f0ab2ca1b9d25a2dd79ca6610e","title":"1 分钟快速上手 Spring Cache","content":"如果你现在有一个现成的工程，你想给你工程的某个接口增加缓存，再不可以分布式缓存的情况下，你可以通过以下两步完成 Spring Cache 接入:\n\n\n1、引用依赖\n1234&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt;\n\n2、给你需要增加缓存的接口或者方法加上注解\n1234567891011121314@Service@CacheConfig(cacheNames = &quot;myCache&quot;)public class MyCacheService &#123;        @CachePut(key = &quot;#key&quot;, unless=&quot;#result == null&quot;)    public String save(String key) &#123;        // do something    &#125;        @Cacheable(key = &quot;#key&quot;)    public String find(String key) &#123;        // do something    &#125;&#125;\n\n当你完成这两步时，支持 local 缓存的方案已经完成了。\n基本使用（默认配置）快速开始部分，我们仅引入了一个依赖，然后对需要缓存的接口加了注解，其他什么配置都没有，所以这种方式使用的都是 Spring Cache 的默认配置。Spring Cache 的默认配置类是 CacheProperties，简单看下有哪些配置属性：\n\n\n\n属性\n子属性\n描述\n\n\n\ntype\n\n缓存类型，根据环境自动检测（auto-detected）\n\n\ncacheNames\n\n如果底层缓存管理器支持的话，要创建的以逗号分隔的缓存名称列表。通常，这将禁用动态创建额外缓存的能力。\n\n\ncaffeine\nspec：是创建缓存规范，具体见 CaffeineSpec 类\nCaffeine 作为缓存\n\n\ncouchbase\nexpiration：描述过期时间，默认情况下，内部 entries 不会过期\nCouchbase 作为缓存\n\n\nehcache\nconfig： 用于创建 ehcache 所提供的配置文件\nEhCache 作为缓存\n\n\ninfinispan\nconfig：用于创建 Infinispan 所提供的配置文件\nInfinispan 作为缓存\n\n\njcache\nconfig：用于初始化缓存管理器的配置文件的位置。配置文件依赖于底层缓存实现。\nJcache 作为缓存\n\n\nprovider：CachingProvider 实现的完全限定名，用于检索符合JSR-107的缓存管理器。仅当类路径上有多个JSR-107实现可用时才需要。\n\n\n\n\nredis\ntimeToLive：缓存过期时间\nRedis 作为缓存\n\n\ncacheNullValues：是否允许缓存 null 值\n\n\n\n\nkeyPrefix：key 前缀\n\n\n\n\nuseKeyPrefix：写入时是否使用 前缀\n\n\n\n\nenableStatistics：是否开启缓存指标统计能力\n\n\n\n\nSpring Cache 没有使用上表中的缓存，上表中所提到的缓存类型是在指定 type 时，对应所需的配置，默认情况下，在没有明确指定 type 时，使用的是 SIMPLE，CacheType 所有枚举类型如下：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public enum CacheType &#123;\t/**\t * Generic caching using &#x27;Cache&#x27; beans from the context.\t */\tGENERIC,\t/**\t * JCache (JSR-107) backed caching.\t */\tJCACHE,\t/**\t * EhCache backed caching.\t */\tEHCACHE,\t/**\t * Hazelcast backed caching.\t */\tHAZELCAST,\t/**\t * Infinispan backed caching.\t */\tINFINISPAN,\t/**\t * Couchbase backed caching.\t */\tCOUCHBASE,\t/**\t * Redis backed caching.\t */\tREDIS,\t/**\t * Caffeine backed caching.\t */\tCAFFEINE,\t/**\t * Simple in-memory caching.\t */\tSIMPLE,\t/**\t * No caching.\t */\tNONE&#125;\n\nSIMPLE 对应的缓存器是基于内存的，其底层存储基于 ConcurrentHashMap。\n使用 redis 作为缓存上述快速开始部分实现缓存存储是基于内存的，对于单体应用解决小流量接口缓存问题不大，但是在分布式环境和大流量接口场景下，是不行的。下面来对快速开始部分进行改造，实现目前常用的基于 Spring Cache + Redis 的方案。\n1、引入依赖\n1234&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;\n\n注意：网上一些时间较久的文章使用的是 spring-boot-starter-redis，这个依赖在 Spring Boot 1.4 版本之后被弃用了，改为使用 spring-boot-starter-data-redis 了，官方有明确说明，详见：https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-redis\n2、指定 cache type 为 redis\n1spring.cache.type=redis\n\n完成 1-2 时，就完成了基于 redis 默认配置的集成，此时连接的 redis 地址是 localshot:6379；当然也可以通过配置文件来定制 redis 的配置，\n12345678910111213141516171819202122232425#redis配置#Redis数据库索引（缓存将使用此索引编号的数据库）spring.redis.database=0#Redis服务器地址  spring.redis.host=localhost #Redis服务器连接端口spring.redis.port=6379 #Redis服务器连接密码（默认为空）  spring.redis.password=#连接超时时间 毫秒（默认2000）#请求redis服务的超时时间,这里注意设置成0时取默认时间2000spring.redis.timeout=2000#连接池最大连接数（使用负值表示没有限制）  #建议为业务期望QPS/一个连接的QPS,例如50000/1000=50#一次命令时间(borrow|return resource+Jedis执行命令+网络延迟)的平均耗时约为1ms,一个连接的QPS大约是1000spring.redis.pool.max-active=50 #连接池中的最大空闲连接 #建议和最大连接数一致,这样做的好处是连接数从不减少,从而避免了连接池伸缩产生的性能开销。spring.redis.pool.max-idle=50#连接池中的最小空闲连接  #建议为0，在无请求的状况下从不创建链接spring.redis.pool.min-idle=0 #连接池最大阻塞等待时间 毫秒（-1表示没有限制）  #建议不要为-1，连接池占满后无法获取连接时将在该时间内阻塞等待，超时后将抛出异常。spring.redis.pool.max-wait=2000\n\n此外，还可以通过创建缓存配置文件类可以设置缓存各项参数，比如缓存key 的过期时间，使用 key 前缀等，如下：\n定义缓存过期时间123456@Beanpublic RedisCacheConfiguration cacheConfiguration() &#123;  return RedisCacheConfiguration.defaultCacheConfig()    // 过期时间    .entryTtl(Duration.ofMinutes(60)));&#125;\n\n自定义 key 前缀key 前缀默认是 cacheName，比如你的 key 是 test，你的 cacheName 是 myCache，则默认情况下存入的 key 为：”myCache::test”, 如果需要调整，可以通过如下方式调整\n123456@Beanpublic RedisCacheConfiguration cacheConfiguration() &#123;  return RedisCacheConfiguration.defaultCacheConfig()    // 增加前缀     .prefixCacheNameWith(&quot;my-prefix::&quot;)));&#125;\n\n修改之后，key 为 &quot;my-prefix::myCache::glmapper&quot;。\n除了这些 redis 配置之外，通过 @CacheConfig 注解可以看到，还有 keyGenerator、cacheManager 和 cacheResolver，这些也可以通过自己实现来完成定制化。\n自定义 KeyGenerator顾名思义，keyGenerator 是用来生成 key 的，如上面例子中的\n1234@Cacheable(key = &quot;#key&quot;)public String find(String key) &#123;    // do something&#125;\n\n这里的 key 是通过 Spel 表达式从参数中获取的，当 Spel 表达式不能满足我们需求时，则可以使用自定义缓存 key 来实现，只需指定 KeyGenerator 接口的实现类的 bean 名称即可，如下\n12345678@Componentpublic class MyKeyGenerator implements KeyGenerator &#123;    @Override    public Object generate(Object target, Method method, Object... params) &#123;        String key = params[0] + &quot;-glmapper&quot;;        return key;    &#125;&#125;\n\n此时存储的 key 为：&quot;my-prefix::myCache::glmapper-glmapper&quot;。\n需要注意的是，keyGenerator 和 key 不能同时存在，比如：\n12345@Cacheable(key = &quot;#key&quot;, keyGenerator = &quot;myKeyGenerator&quot;)public String find(String key) &#123;    System.out.println(&quot;execute find...&quot;);    return this.mockDao.find(key);&#125;\n\n如果同时存在，则会抛出如下异常：\n1Both &#x27;key&#x27; and &#x27;keyGenerator&#x27; attributes have been set. These attributes are mutually exclusive: either set the SpEL expression used tocompute the key at runtime or set the name of the KeyGenerator bean to use.\n\n自定义 CachManager自定义 CacheManager 就是实现 CacheManager 接口即可，一般情况下，如果我们需要自定义 RedisConnectionFactory 和 RedisCacheConfiguration 的话，会用到自定义 CacheManager\n123456789101112131415@Bean(name = &quot;myCacheManager&quot;)public CacheManager myCacheManager(RedisConnectionFactory redisConnectionFactory) &#123;  RedisCacheConfiguration defaultConfiguration = RedisCacheConfiguration    .defaultCacheConfig()    .disableCachingNullValues()    .entryTtl(Duration              .ofSeconds(600L))    .serializeKeysWith(SerializationPair.fromSerializer(new StringRedisSerializer()))    .serializeValuesWith(    SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));  return RedisCacheManager.builder(redisConnectionFactory)    .cacheDefaults(defaultConfiguration)    .build();&#125;\n\n\n使用时，可以指定具体的 cacheManager\n12345@Cacheable(keyGenerator = &quot;myKeyGenerator&quot;, cacheManager = &quot;myCacheManager&quot;)public String find(String key) &#123;    System.out.println(&quot;execute find...&quot;);    return this.mockDao.find(key);&#125;\n\n自定义CacheResolverCacheResolver 是缓存解析器，默认的 Cache 解析实现类是org.springframework.cache.interceptor.SimpleCacheResolver，自定义 Cache 解析器需要实现CacheResolver 接口，使用方式和前面自定义 KeyGenerator 类似，即在注解属性 cacheResolver 配置自定义Bean名称。\nCacheResolver 解析器的目的是从 CacheOperationInvocationContext 中解析出 Cache，\n12345678910111213141516171819202122@Componentpublic class MyCacheResolver implements CacheResolver &#123;    private final CacheManager cacheManager;    public MyCacheResolver(CacheManager cacheManager) &#123;        this.cacheManager = cacheManager;    &#125;    @Override    public Collection&lt;? extends Cache&gt; resolveCaches(CacheOperationInvocationContext&lt;?&gt; context) &#123;        Cacheable annotation = context.getMethod().getAnnotation(Cacheable.class);        BasicOperation operation = context.getOperation();        if (operation instanceof CacheableOperation) &#123;            // do something        &#125;        Collection&lt;Cache&gt; ret = new ArrayList&lt;&gt;();        // 根据注解 或 方法得到的 cacheName 去 getCache，再返回不同的过期时间的 Cache        String[] cacheNames = annotation.cacheNames();        for (String cacheName : cacheNames) &#123;            ret.add(cacheManager.getCache(cacheName));        &#125;        return ret;    &#125;&#125;\n\n条件缓存 condition 和 unless最后再来关注下常见的条件缓存问题；有时候，一些值不适合缓存，可以使用 @Cacheable 的 condition 属性判读那些数据不缓存，它接收的是一个 Spel 表达式，该表达式的值是 true 或 false；true，数据被缓存，false不被缓存。\n12345@Cacheable(key = &quot;#key&quot;, condition = &quot;#key.startsWith(&#x27;glmapper::&#x27;)&quot;)    public String find(String key) &#123;        System.out.println(&quot;execute find...&quot;);        return this.mockDao.find(key);    &#125;\n\nkey 必须是 &quot;glmapper::&quot; 开头的才允许缓存。\n@Cacheable#unless 一般是对结果条件判读是否进行缓存使用的，这个示例使用的是入参作为判断条件，各位可以自己写一个根据结果进行缓存的示例，切记满足条件是不缓存。Spel #result变量代表返回值。\n123456@CachePut(unless=&quot;#result == null&quot;, keyGenerator = &quot;myKeyGenerator&quot;)public String save(String model) &#123;    System.out.println(&quot;execute save...&quot;);    this.mockDao.save(model, model);    return model;&#125;\n\n如果返回结果是 null，则不缓存。\nbeforeInvocation 可能导致潜在的缓存不一致问题beforeInvocation 是 CacheEvict 注解的属性，默认值为false，表示在调用方法之后进行缓存清理；如果设置true，表示在调用方法之前进行缓存清理。一般情况下推荐使用默认配置即可，如果设置成 true，有两种可能导致一致性问题：\n\n在清理之后，执行方法执行，并发设置缓存。\n注解的方法本身内部如果调用了填充缓存的方法。\n\n总结整体来看，Spring Cache 的上手难度不算大，其提供的注解能够覆盖大多数使用 cache 的场景，对于业务逻辑基本无侵入性。同时，Spring 也秉持了其一贯的作风，就是提供灵活的扩展机制，使得你可以自由的定制自己的各种功能。\n本篇简单介绍 Spring Cache 的基本使用方式，下面将会从源码进行分析 Spring Cache 的基本工作原理 \n基本原理如果你对 spring 事务模块比较熟悉的话，那么理解 Spring Cache 会简单很多，在官方文档中就有提到这个观点，Spring Cache 的实现从框架 API 抽象层面来看，和事物基本一样的，都是通过 AOP 来实现，以达到最小化业务侵入。\n\n\n\n\n\n\n\n\n\nSimilar to the transaction support, the caching abstraction allows consistent use of various caching solutions with minimal impact on the code.\n本篇将从注解解析、执行拦截、方法执行过程对 Spring Cache 基本原理进行分析。\n注解解析在1 分钟快速上手 Spring Cache中，需要关注几个注解：@CacheConfig，@CachePut，@Cacheable，@CacheEvict，此外也需要关注这些注解的属性；这里我们来看下这些注解是如何被解析，如何生效的。\n@CacheConfig\n\n\n属性\n含义\n案例\n\n\n\ncacheNames&#x2F;value\n缓存的名称\n例如： @CachePut(value&#x3D;”mycache”) @CachePut(cacheNames&#x3D;{”cache1”,”cache2”}\n\n\nkeyGenerator\nkey 生成器\n\n\n\ncacheManager\n缓存管理器\n\n\n\ncacheResolver\n用于拦截方法调用的缓存实例\n\n\n\n@CachePut\n\n\n属性\n含义\n案例\n\n\n\ncacheNames&#x2F;value\n缓存的名称\n例如： @CachePut(value&#x3D;”mycache”) @CachePut(value&#x3D;{”cache1”,”cache2”}\n\n\nkey\n缓存的 key\n例如： @CachePut(value&#x3D;”testcache”,key&#x3D;”#userName”)\n\n\ncondition\n缓存的条件\n例如： @CachePut(value&#x3D;”testcache”,condition&#x3D;”#userName.length()&gt;2”)\n\n\n@Cacheable\n\n\n属性\n含义\n案例\n\n\n\ncacheNames&#x2F;value\n缓存的名称\n每一个缓存名称代表一个缓存对象。当一个方法填写多个缓存名称时将创建多个缓存对象。当多个方法使用同一缓存名称时相同参数的缓存会被覆盖。所以通常情况我们使用“包名+类名+方法名”或者使用接口的RequestMapping作为缓存名称防止命名重复引起的问题。单缓存名称：@Cacheable(value&#x3D;”mycache”) 多缓存名称：@Cacheable(value&#x3D;{”cache1”,”cache2”}\n\n\nkey\n缓存的 key\nkey标记了缓存对象下的每一条缓存。如果不指定key则系统自动按照方法的所有入参生成key，也就是说相同的入参值将会返回同样的缓存结果。如果指定key则要按照 SpEL 表达式编写使用的入参列表。如下列无论方法存在多少个入参，只要userName值一致，则会返回相同的缓存结果。@Cacheable(value&#x3D;”testcache”,key&#x3D;”#userName”)\n\n\ncondition\n缓存的条件\n满足条件后方法结果才会被缓存。不填写则认为无条件全部缓存。条件使用 SpEL表达式编写，返回 true 或者 false，只有为 true 才进行缓存如下例，只有用户名长度大于2时参会进行缓存 @Cacheable(value&#x3D;”testcache”,condition&#x3D;”#userName.length()&gt;2”)\n\n\n@CacheEvict\n\n\n属性\n含义\n案例\n\n\n\ncacheNames&#x2F;value\n缓存的名称\n删除指定名称的缓存对象。必须与下面的其中一个参数配合使用例如： @CacheEvict(value&#x3D;”mycache”) 或者 @CacheEvict(value&#x3D;{”cache1”,”cache2”}\n\n\nkey\n缓存的 key\n删除指定key的缓存对象例如： @CacheEvict(value&#x3D;”testcache”,key&#x3D;”#userName”)\n\n\ncondition\n缓存的条件\n删除指定条件的缓存对象例如： @CacheEvict(value&#x3D;”testcache”,condition&#x3D;”#userName.length()&gt;2”)\n\n\nallEntries\n方法执行后清空所有缓存\n缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存。例如： @CacheEvict(value&#x3D;”testcache”,allEntries&#x3D;true)\n\n\nbeforeInvocation\n方法执行前清空所有缓存\n缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存。例如： @CacheEvict(value&#x3D;”testcache”，beforeInvocation&#x3D;true)\n\n\n属性解析Spring Cache 生效需要通过 @EnableCaching 注解来开启，这种做法和在 Spring 项目中非常常见；通过 @EnableCaching ，导入 CachingConfigurationSelector 类，进而根据EnableCaching 的值选择应该使用 AbstractCachingConfiguration 的哪个实现。Spring Cache 对业务接口拦截有两种模式，PROXY 和 ASPECTJ，默认情况下是 PROXY。每个模式提供一个Configuration，如 PROXY 对应的是 ProxyCachingConfiguration。这里已 ProxyCachingConfiguration 为例，ProxyCachingConfiguration 中会声明 BeanFactoryCacheOperationSourceAdvisor、CacheOperationSource 和 CacheInterceptor 三个 bean。其中 CacheOperationSource 会绑定一个 parser，用来解析注解。\n123456789101112public class SpringCacheAnnotationParser implements CacheAnnotationParser, Serializable &#123;   private static final Set&lt;Class&lt;? extends Annotation&gt;&gt; CACHE_OPERATION_ANNOTATIONS = new LinkedHashSet&lt;&gt;(8);    // 这里即为我们前面所提到的四个注解   static &#123;      CACHE_OPERATION_ANNOTATIONS.add(Cacheable.class);      CACHE_OPERATION_ANNOTATIONS.add(CacheEvict.class);      CACHE_OPERATION_ANNOTATIONS.add(CachePut.class);      CACHE_OPERATION_ANNOTATIONS.add(Caching.class);   &#125;   // ... 省略其他代码&#125;\n\n以 @CachePut 为例\n1234567891011121314151617181920private CacheOperation parsePutAnnotation(      AnnotatedElement ae, DefaultCacheConfig defaultConfig, CachePut cachePut) &#123;   CachePutOperation.Builder builder = new CachePutOperation.Builder();   builder.setName(ae.toString());   builder.setCacheNames(cachePut.cacheNames());   builder.setCondition(cachePut.condition());   builder.setUnless(cachePut.unless());   builder.setKey(cachePut.key());   builder.setKeyGenerator(cachePut.keyGenerator());   builder.setCacheManager(cachePut.cacheManager());   builder.setCacheResolver(cachePut.cacheResolver());   defaultConfig.applyDefault(builder);   CachePutOperation op = builder.build();   validateCacheOperation(ae, op);   return op;&#125;\n\n每个注解解析之后会对应一个 CacheOperation；@CachePut 对应的是 CachePutOperation，CachePutOperation 主要是来描述缓存 “put” 这个操作，实际执行缓存动作的并不是这个 CachePutOperation。\n执行拦截所有 Spring Cache 切面入口是 CacheInterceptor 这个类\n\n上图是我用例执行的一个堆栈信息，拦截到的注解是 @CachePut。CacheAspectSupport 是 CacheInterceptor 的父类，它包括了执行拦截的所有核心逻辑。有兴趣的可以自己阅读代码，不是很复杂。\n方法执行拦截到方法之后就是执行具体的动作，前面提到所有的执行动作都是在 CacheAspectSupport 中，以 @CachePut 为例\n1234567// 收集 @CachePutscollectPutRequests(contexts.get(CachePutOperation.class), cacheValue, cachePutRequests);// 处理任何已收集的 put 请求，无论是来自 @CachePut 还是 @Cacheablefor (CachePutRequest cachePutRequest : cachePutRequests) &#123;   cachePutRequest.apply(cacheValue);&#125;\n\napply 中执行具体的 put 动作\n12345678public void apply(@Nullable Object result) &#123;   if (this.context.canPutToCache(result)) &#123;      for (Cache cache : this.context.getCaches()) &#123;      // 将 key result ，写入到 cache 中         doPut(cache, this.key, result);      &#125;   &#125;&#125;\n\n除了这些常规流程之外，Sring Cache 也提供了对于异常场景的关注，可以通过子定义 CacheErrorHandler 来完成对异常场景的处理。\n总结这种接口+实现分离的设计带来的好处是，我们可以做到存储平台无关，对于后续的存储迁移和替换会非常方便。\n参考链接\nhttps://docs.spring.io/spring-boot/docs/2.1.6.RELEASE/reference/html/boot-features-caching.html#boot-features-caching-provider-simple\nhttps://docs.spring.io/spring-framework/docs/5.1.8.RELEASE/spring-framework-reference/integration.html#cache\n\n","slug":"spring/spring-cache-quick-start","date":"2022-02-21T03:43:24.000Z","categories_index":"spring","tags_index":"spring,cache","author_index":"glmapper"},{"id":"9bcb128fa947131484c11ffd6af6a280","title":"2021 年终总结-磊叔的 Work Life Balance","content":"\n\n\n\n\n\n\n\n\n生活，在喜怒哀乐间走走停停。不知道会遇见什么，只知道阳光这么好，别辜负了今天\n抓了一把花生米，开了一罐啤酒，打开新买的台式机，用上被新同事“嫌弃”声音太大的机械键盘，然后以文字的方式来唠一唠我的 2021。\n\n\n对我来说 2021 年是特殊的，换了工作、换了城市、也换了一种心态；这可能和城市节奏有关，从杭州到合肥，物理距离不过 400 多公里，但是从接触到的人和事来看，生活节奏是仅仅 400 多公里的距离无法描述的；这可能和公司节奏有关，从蚂蚁到华米，不同的行业领域，不同的公司文化，不同的业务场景，不同的同事关系；这也可能和从事的工作有关，从中间件到业务，从面向开发者视角到面向业务视角，不同视角的冲击很大，差异也很大。\n杭州我很喜欢杭州这座城市，这也是为什么在毕业不到一年的情况下义无反顾要从南京跑去杭州的主要原因（被我拖下水的还有老刘和孙总）；从 18 年到 21 年，杭州的三年，也是在蚂蚁的三年，这段经历充满了挑战和乐趣；在那里我认识了非常多优秀的同事，那些在书上或者博客上经常看到署名的人，那些国内 top 2 高校的毕业生，那些拥有各种花式奇葩花名的人；我很庆幸可以在蚂蚁待上三年，这倒不是因为什么大厂背景或者可炫耀的经历，而是那儿确实有太多有意思的人和故事。\n\n杨公堤旁\n\n\n\n断桥\n\n\n\n工专路 x 号\n\n\n合肥在此之前，关于合肥，我的印象一直停留在初中毕业，那是我第一次离开县城到一个“大城市”；我和我爸说，以后我考大学就考这里，如此的信誓旦旦，年少轻狂，然后三年后我去了开封……，但也是在那里，我开始走上技术路线的“伟大旅途”。\n关于回合肥这件事，首要因素是离家近一些，其次是因为房价；驱使我下定决心要回来，是外婆过世，妈妈自己在家哭的很伤心，我只能在租住的房子的阳台上看着月亮，想着过往；所以在参加完葬礼回到杭州之后，第一件事就是和主管提了离职。\n\n\n\n\n\n\n\n\n\n人其实很残酷且现实，我们一边讨论着珍惜当下，多陪陪家人，一边忙于生活奔波，无暇迩迩。西湖很美，灵隐寺的钟声很清脆，同一轮明月，总归是故乡的更圆，这可能就是每个人心里的故土情节。\n\n我一直都比较庆幸自己的运气很好，除了 “买车遇换代，首月扎轮胎” 之外，在合肥也遇到了一群和杭州一样优秀的同事，一样的可以讨论技术、股票、基金、买房和运动，这也是后面我所要说到的能够快速融入新环境的主要因素。\n关于华米，大家可能不大熟悉这家公司，在我来之前和他们讨论这家公司的时候，得到的答案大多是 “华为+小米” ，我没有反驳，就是觉得他们说的好像有点道理。不过在这里还是要为新东家发个声：华米的使命是 科技连接健康，从小米手环开始，到现在涉猎的智能穿戴设备和芯片，在软硬赛道上均有涉猎，你们手上的小米手环和手机上的小米运动、zepp 等就是源自这家公司。\n华米非常提倡大家运动，这种提倡是刻在文化里的，公司内部有非常多的体育类社团，每个月的第一周下午要全员走出去锻炼，在合肥有爬不完的大蜀山和遛不尽的柏雁湖…\n\n社区我真正参加技术社区要从 16 年开始算起，在此之前都是在学校实验室或者公司内做一些小范围的技术分享；17年开始是在掘金上写文章，那个时候的掘金做技术还是很纯粹的，也能经常看到阴明在社区里和大家交流，虽然界面很丑，写起来也不方便，但是它在那个阶段算是见证了技术成长和技术沉淀的，也白嫖了掘金很多值得纪念的周边\n\n18 年随着 SOFA 开源，逐步走上了技术社区这条“不归路”。\n在我的微信账号里，有超过 30% 的好友是通过技术社区认识的，这是参与技术社区带来的最大财富。我一直很鼓励身边做技术的同学一起参与技术社区或者开源项目，这是一件很难的事情，没有 kpi，还需要投入大量的个人精力，但是当你的某个 PR 被 merge 或者某个 issue 被讨论时，当你的代码被大多数人使用，跑在和你工作毫无关系的“别人家”的代码上时，当你出差在某个城市遇到“久闻大名”但未曾谋面的社区基友时，你会觉得一切都很值得，这就是开源社区带给技术人的纯粹乐趣，仅此而已。\n\n关于我我在我自己的博客介绍里曾说过，我想做一个“诗人”，虽然现在“诗人”是无业的代名词，但这个职业是伟大的，没有茶和酒，还有情怀，这是欠缺的，不仅仅是我。\n我对新环境的适应能力很强，可能是源于脸皮够厚，抑或是我不知道的其他原因，但总归是能够快速融入新的环境和集体，这一点是我老婆羡慕的，从我的角度分析，我觉得这是源自于技术人的纯粹，而非脸皮厚。\n一直以来，除了当“诗人”之外，另一个被坚持下来的爱好就是篮球，篮球虽然没能让我的身高能够再往上颠一颠，但在维护体重上面给予了充足的支持，我也尽最大努力的不让自己在微信头像上立下 “不瘦十斤，不换头像” 的 flag。\n\n写在最后荣总说，过了今年就没有你过的 2 开头的生日了，2021 年，而立之年，不在纠结到底是 29 还是 30，权当今年涨了 2 岁，后知后觉。\n\n买了车，买了房，家人身体健康，自己还没失业，也算是给自己 30 岁之前画一个小小的句号。\n\n","slug":"share/shares-2021","date":"2021-12-27T03:40:31.000Z","categories_index":"experience","tags_index":"SOFA,杭州,合肥","author_index":"glmapper"},{"id":"e6df084a71adfbb41be6ca4e81a75e09","title":"SpringBoot Actuator 潜在的 OOM 问题","content":"此问题背景产生于近期需要上线的一个功能的埋点；主要表现就是在应用启动之后的一段时间内，内存使用一直呈现递增趋势。\n\n\n\n下图为场景复线后，本地通过 jconsole 查看到的内部使用走势图。\n\n\n\n\n\n\n\n\n\n实际环境受限于配置，内存不会膨胀\n背景&amp;问题应用 a 使用 rest template 通过 http 方式调用 应用 b，应用项目中开启了 actuator，api 使用的是 micrometer；在 client 调用时，actuator 会产生一个 name 为 http.client.requests 的 metrics，此 metric 的 tag 中包含点目标的 uri。\n应用 b 提供的接口大致如下：\n123456789@RequestMapping(&quot;test_query_params&quot;)public String test_query_params(@RequestParam String value) &#123;    return value;&#125;@RequestMapping(&quot;test_path_params/&#123;value&#125;&quot;)public String test_path_params(@PathVariable String value) &#123;    return value;&#125;\n\n\n\n\n\n\n\n\n\n\nhttp://localhost:8080/api/test/test_query_params?value=\nhttp://localhost:8080/api/test/test_path_params/{value}_\n期望在 metric 的收集结果中应该包括两个 metrics，主要区别是 tag 中的 uri 不同，一个是 api/test/test_query_params， 另一个是 api/test/test_path_params/&#123;value&#125;；实际上从拿到的 metrics 数据来看，差异很大，这里以 pathvariable 的 metric 为例，数据如下： \n123456789101112131415161718192021222324252627282930313233343536tag: &quot;uri&quot;,values: [&quot;/api/test/test_path_params/glmapper58&quot;,&quot;/api/test/test_path_params/glmapper59&quot;,&quot;/api/test/test_path_params/glmapper54&quot;,&quot;/api/test/test_path_params/glmapper55&quot;,&quot;/api/test/test_path_params/glmapper56&quot;,&quot;/api/test/test_path_params/glmapper57&quot;,&quot;/api/test/test_path_params/glmapper50&quot;,&quot;/api/test/test_path_params/glmapper51&quot;,&quot;/api/test/test_path_params/glmapper52&quot;,&quot;/api/test/test_path_params/glmapper53&quot;,&quot;/api/test/test_path_params/glmapper47&quot;,&quot;/api/test/test_path_params/glmapper48&quot;,&quot;/api/test/test_path_params/glmapper49&quot;,&quot;/api/test/test_path_params/glmapper43&quot;,&quot;/api/test/test_path_params/glmapper44&quot;,&quot;/api/test/test_path_params/glmapper45&quot;,&quot;/api/test/test_path_params/glmapper46&quot;,&quot;/api/test/test_path_params/glmapper40&quot;,&quot;/api/test/test_path_params/glmapper41&quot;,&quot;/api/test/test_path_params/glmapper42&quot;,&quot;/api/test/test_path_params/glmapper36&quot;,&quot;/api/test/test_path_params/glmapper37&quot;,&quot;/api/test/test_path_params/glmapper38&quot;,&quot;/api/test/test_path_params/glmapper39&quot;,&quot;/api/test/test_path_params/glmapper32&quot;,&quot;/api/test/test_path_params/glmapper33&quot;,&quot;/api/test/test_path_params/glmapper34&quot;,&quot;/api/test/test_path_params/glmapper35&quot;,&quot;/api/test/test_path_params/glmapper30&quot;,&quot;/api/test/test_path_params/glmapper31&quot;,&quot;/api/test/test_path_params/glmapper25&quot;,&quot;/api/test/test_path_params/glmapper26&quot;,....]\n\n\n\n可以非常明显的看到，这里将{value} 参数作为了 uri 组件部分，并且体现在 tag 中，并不是期望的 api/test/test_path_params/&#123;value&#125;。\n问题原因及解决两个问题，1、这个埋点是怎么生效的，先搞清楚这个问题，才能顺藤摸瓜。2、怎么解决。\n默认埋点是如何生效的因为是通过 resttemplate 进行调用访问，那么埋点肯定也是基于对 resttemplate 的代理；按照这个思路，笔者找到了 org.springframework.boot.actuate.metrics.web.client.MetricsRestTemplateCustomizer 这个类。RestTemplateCustomizer 就是对 resttemplate 进行定制的，MetricsRestTemplateCustomizer 通过名字也能得知期作用是为了给 resttemplate 增加 metric 能力。\n再来讨论 RestTemplateCustomizer，当使用RestTemplateBuilder构建RestTemplate时，可以通过RestTemplateCustomizer进行更高级的定制，所有RestTemplateCustomizer beans 将自动添加到自动配置的RestTemplateBuilder。也就是说如果 想 MetricsRestTemplateCustomizer 生效，那么构建 resttemplate 必须通过 RestTemplateBuilder 方式构建，而不是直接 new。\nhttp.client.requests 中的 uri塞 tag 的代码在org.springframework.boot.actuate.metrics.web.client.RestTemplateExchangeTags 类中，作用时机是在 MetricsClientHttpRequestInterceptor 拦截器中。当调用执行完成后，会将当次请求 metric 记录下来，在这里就会使用到 RestTemplateExchangeTags 来填充 tags。 下面仅给出 uri 的部分代码\n123456789101112131415161718/** * Creates a &#123;@code uri&#125; &#123;@code Tag&#125; for the URI of the given &#123;@code request&#125;. * @param request the request * @return the uri tag */public static Tag uri(HttpRequest request) &#123;\treturn Tag.of(&quot;uri&quot;, ensureLeadingSlash(stripUri(request.getURI().toString())));&#125;/** * Creates a &#123;@code uri&#125; &#123;@code Tag&#125; from the given &#123;@code uriTemplate&#125;. * @param uriTemplate the template * @return the uri tag */public static Tag uri(String uriTemplate) &#123;\tString uri = (StringUtils.hasText(uriTemplate) ? uriTemplate : &quot;none&quot;);\treturn Tag.of(&quot;uri&quot;, ensureLeadingSlash(stripUri(uri)));\n\n\n\n\n\n\n\n\n\n\n其余的还有 status 和 clientName 等 tag name。\n通过断点，可以看到，这里 request.getURI() 拿到的是带有参数的完整请求链接。\n\n这些 tag 的组装最终在 DefaultRestTemplateExchangeTagsProvider 中完成，并返回一个 列表。\n123456private Timer.Builder getTimeBuilder(HttpRequest request, ClientHttpResponse response) &#123;    return this.autoTimer.builder(this.metricName)                // tagProvider 为 DefaultRestTemplateExchangeTagsProvider\t\t\t\t.tags(this.tagProvider.getTags(urlTemplate.get().poll(), request, response))\t\t\t\t.description(&quot;Timer of RestTemplate operation&quot;);&#125;\n\n解决这里先来看下官方对于 request.getURI  的解释\n1234567/** * Return the URI of the request (including a query string if any, * but only if it is well-formed for a URI representation). * @return the URI of the request (never &#123;@code null&#125;) */URI getURI();\n\n返回请求的 URI，这里包括了任何的查询参数。那么是不是拿到不用参数的 path 就行呢？\n\n这里尝试通过 request.getURI().getPath() 拿到了预期的 path（@pathvariable 拿到的是模板）。\n再回到 DefaultRestTemplateExchangeTagsProvider，所有的 tag 都是在这里完成组装，这个类明显是一个默认的实现(Spring 体系下基本只要是Defaultxxx 的，一般都能扩展 )，查看它的接口类 RestTemplateExchangeTagsProvider 如下：\n12345678910111213141516171819202122/** * Provides &#123;@link Tag Tags&#125; for an exchange performed by a &#123;@link RestTemplate&#125;. * * @author Jon Schneider * @author Andy Wilkinson * @since 2.0.0 */@FunctionalInterfacepublic interface RestTemplateExchangeTagsProvider &#123;\t/**\t * Provides the tags to be associated with metrics that are recorded for the given\t * &#123;@code request&#125; and &#123;@code response&#125; exchange.\t * @param urlTemplate the source URl template, if available\t * @param request the request\t * @param response the response (may be &#123;@code null&#125; if the exchange failed)\t * @return the tags\t */\tIterable&lt;Tag&gt; getTags(String urlTemplate, HttpRequest request, ClientHttpResponse response);&#125;\n\nRestTemplateExchangeTagsProvider 的作用就是为 resttemplate 提供 tag 的，所以这里通过自定义一个 RestTemplateExchangeTagsProvider，来替换DefaultRestTemplateExchangeTagsProvider，以达到我们的目标，大致代码如下：\n1234567891011121314@Override public Iterable&lt;Tag&gt; getTags(String urlTemplate, HttpRequest request, ClientHttpResponse response) &#123;    Tag uriTag;    // 取 request.getURI().getPath() 作为 uri 的 value    if (StringUtils.hasText(request.getURI().getPath())) &#123;      uriTag = Tag.of(&quot;uri&quot;, ensureLeadingSlash(stripUri(request.getURI().getPath())));    &#125; else &#123;      uriTag = (StringUtils.hasText(urlTemplate) ? RestTemplateExchangeTags.uri(urlTemplate)                    : RestTemplateExchangeTags.uri(request));    &#125;    return Arrays.asList(RestTemplateExchangeTags.method(request), uriTag,                RestTemplateExchangeTags.status(response), RestTemplateExchangeTags.clientName(request));    &#125;\n\n会不会 OOM理论上，应该参数不同，在使用默认 DefaultRestTemplateExchangeTagsProvider 的情况下，meter 会随着 tags 的不同迅速膨胀，在 micrometer 中，这些数据是存在 map 中的\n123// Even though writes are guarded by meterMapLock, iterators across value space are supported// Hence, we use CHM to support that iteration without ConcurrentModificationException riskprivate final Map&lt;Id, Meter&gt; meterMap = new ConcurrentHashMap&lt;&gt;();\n\n一般情况下不会，这里是因为 spring boot actuator 自己提供了保护机制，对于默认情况，tags 在同一个 metric 下，最多只有 100 个\n123456/*** Maximum number of unique URI tag values allowed. After the max number of* tag values is reached, metrics with additional tag values are denied by* filter.*/private int maxUriTags = 100;\n\n如果你想使得这个数更大一些，可以通过如下配置配置\n1management.metrics.web.client.max-uri-tags=10000\n如果配置值过大，会存在潜在的 oom 风险。\n","slug":"springboot/springboot-series-actuator-oom","date":"2021-11-29T03:37:27.000Z","categories_index":"SpringBoot","tags_index":"OOM,SpringBoot,actuator","author_index":"glmapper"},{"id":"0733c66f6904b8d3bf1d0aaecefb6227","title":"为什么你的 SpringBoot 自动配置失效了","content":"本文源自近期项目中遇到的问题， bug 总是出现在你自以为是的地方…\n\n\n问题描述下面是一个简单复现的代码片段，在你没有阅读完本文时，如果能做出正确的判断，那恭喜你可以节省阅读本文的时间了。\n1、自动配置类：AutoTestConfiguration\n1234567891011@Configuration@EnableConfigurationProperties(TestProperties.class)@ConditionalOnProperty(prefix = &quot;test&quot;, name = &quot;enable&quot;)public class AutoTestConfiguration &#123;    @Bean    @ConditionalOnMissingBean    public TestBean testBean(TestProperties properties)&#123;        System.out.println(&quot;this is executed.....&quot;);        return new TestBean();    &#125;&#125;\n\n2、配置类 TestProperties\n12345678910@ConfigurationProperties(prefix = &quot;test&quot;)public class TestProperties &#123;    private boolean enable = true;    public boolean isEnable() &#123;        return enable;    &#125;    public void setEnable(boolean enable) &#123;        this.enable = enable;    &#125;&#125;\n\n这两个类都在 root package 下，可以保证能够正常被 Spring 扫描到；那么问题是 TestBean 会不会被正常创建？当然这里的结论是不会。\n可能有的同学会说你的 TestProperties 没有加 @Configuration 注解，Spring 不认识它，那真的是这样吗？很显然也不是。\n在排查这个问题的过程中，也有遇到其他问题，也是之前没有遇到过的；即使 Spring 源码我看过很多遍，但是仍然会有一些边边角角让你意想不到的地方；下面就针对这个问题，慢慢来揭开它的面纱。\n@EnableConfigurationProperties 注解行为在之前的版本中，TestProperties 是有被 @Configuration 注解标注的\n1234567891011@Configuration // 可以被 spring 扫描@ConfigurationProperties(prefix = &quot;test&quot;)public class TestProperties &#123;    private boolean enable = true;    public boolean isEnable() &#123;        return enable;    &#125;    public void setEnable(boolean enable) &#123;        this.enable = enable;    &#125;&#125;\n\n常规的思路是，当 TestProperties 被扫描到之后，spring env 中就会有 test.enable=true 的 k-v 存在，当执行 AutoTestConfiguration 自动配置类刷新时，@ConditionalOnProperty(prefix = &quot;test&quot;, name = &quot;enable&quot;) 则会生效，进而 TestBean 被正常创建。\n但事实并非如此，下面是对于此问题的验证\n配置有效，AutoTestConfiguration 未刷新两个点：\n\n1、AutoTestConfiguration#testBean 执行会输出一个 log（用于判断 AutoTestConfiguration 是否正常刷新）\n监听 ApplicationReadyEvent 事件，拿 test.enable 值（用于判端配置是否正常加载，也就是 TestProperties 是否被正常刷新）\n\n代码如下：\n123456789101112@SpringBootApplicationpublic class Application implements ApplicationListener&lt;ApplicationReadyEvent&gt; &#123;   @Autowired   private ApplicationContext applicationContext;   public static void main(String[] args) &#123;      SpringApplication.run(Application.class, args);   &#125;   @Override   public void onApplicationEvent(ApplicationReadyEvent event) &#123;      System.out.println(this.applicationContext.getEnvironment().getProperty(&quot;test.enable&quot;)  + &quot;------&quot;);   &#125;&#125;\n\n\n执行得到的结果是 AutoTestConfiguration#testBean 没有被执行，但test.enable 为 true。\n这里说明 TestProperties 是有被刷新的，但是并没有对 @ConditionalOnProperty 起到作用，那么这里基本可以猜到是自动配置类上的 @ConditionalOnProperty 和 @EnableConfigurationProperties 的作用顺序问题。\n在验证顺序问题之前，我尝试在 application.properties 中增加如下配置，re run 项目：\n1test.enable=true\n\n到这里我得到了另一个 bean 冲突的问题。\nprefix-type异常提示如下：\n123Parameter 0 of method testBean in com.glmapper.bridge.boot.config.AutoTestConfiguration required a single bean, but 2 were found:\t- testProperties: defined in file [/Users/glmapper/Documents/project/exception-guides/target/classes/com/glmapper/bridge/boot/config/TestProperties.class]\t- test-com.glmapper.bridge.boot.config.TestProperties: defined in null\n\n这里出现了 test-com.glmapper.bridge.boot.config.TestProperties 这个 name 的 bean。我尝试在代码中去检查是否有显示给定这个 bean 名字，但是没有找到，那只有一种可能，就是这个是被 spring 自己创建的。\n这个过程在 spring 刷新阶段非常靠前，在排查这个问题时，还是耽误了一些时间，最后还是把问题定位一致前置到 beandefinitions 初始化才找到。\n这里是 @EnableConfigurationProperties 注解的一个行为，依赖 EnableConfigurationPropertiesRegistrar，源码如下：\n1234567891011class EnableConfigurationPropertiesRegistrar implements ImportBeanDefinitionRegistrar &#123;         .getQualifiedAttributeName(EnableConfigurationPropertiesRegistrar.class, &quot;methodValidationExcludeFilter&quot;);   @Override   public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123;      registerInfrastructureBeans(registry);      registerMethodValidationExcludeFilter(registry);      ConfigurationPropertiesBeanRegistrar beanRegistrar = new ConfigurationPropertiesBeanRegistrar(registry);      // to register      getTypes(metadata).forEach(beanRegistrar::register);   &#125;\n\n通过代码比较容易看出，EnableConfigurationPropertiesRegistrar 会将目标 metadata 注册成 bean；继续 debug，找到了产生 prefix-type 格式 name 的 bean。\n\n下面是 getName 的具体代码\n123456private String getName(Class&lt;?&gt; type, MergedAnnotation&lt;ConfigurationProperties&gt; annotation) &#123;    // 拿 prefix   String prefix = annotation.isPresent() ? annotation.getString(&quot;prefix&quot;) : &quot;&quot;;   // prefix + &quot;-&quot; + 类全限定名    return (StringUtils.hasText(prefix) ? prefix + &quot;-&quot; + type.getName() : type.getName());&#125;\n\n到这里我们先明确一个问题：\n\n\n\n\n\n\n\n\n\n如果你使用 @EnableConfigurationProperties 来开启配置类，那么就不要在配置类上使用@Configuration 等能够被 Spring scan 识别到的注解，以免在后续的使用中同一类型的 bean 多个实例\n@ConditionalOnProperty在回到配置不生效问题上来，这里在官方 issue 是有记录的：https://github.com/spring-projects/spring-boot/issues/2282。\n不过这里还是通过分析代码来还原下问题产生的根本原因；这里主要从两个方面来分析：\n\n@ConditionalOnProperty match 值逻辑，需要明确在匹配 value 时，从哪些 PropertySource 读取的。\n@ConditionalOnProperty match 失败和 bean 刷新的逻辑\n\n@ConditionalOnProperty match 逻辑首先是 @ConditionalOnProperty 在执行计算时，匹配 value 的值来源问题，通过 debug 代码很容易就得到了所有的 source 来源，如下图：\n\n从 debug 看，本案例有 4 个来源（具体如上图），实际上从源码来看，source 涵盖了 spring env 所有来源：\n123456[ConfigurationPropertySourcesPropertySource &#123;name=&#x27;configurationProperties&#x27;&#125;, StubPropertySource &#123;name=&#x27;servletConfigInitParams&#x27;&#125;, StubPropertySource &#123;name=&#x27;servletContextInitParams&#x27;&#125;, PropertiesPropertySource &#123;name=&#x27;systemProperties&#x27;&#125;, OriginAwareSystemEnvironmentPropertySource &#123;name=&#x27;systemEnvironment&#x27;&#125;, RandomValuePropertySource &#123;name=&#x27;random&#x27;&#125;, OriginTrackedMapPropertySource &#123;name=&#x27;Config resource &#x27;class path resource [application.properties]&#x27; via location &#x27;optional:classpath:/&#x27;&#x27;&#125;]\n所以本文案例中不生效原因就是上面这些 PropertySource 都没有 test.enable，也就是 TestProperties 没被刷新，或者其在自动配置类之后才刷新。\n@ConditionalOnProperty skip 逻辑这里主要解释 @ConditionalOnPropert 和 bean 被刷新的逻辑关系，具体实现在 ConditionEvaluator 类中\n1234public boolean shouldSkip(@Nullable AnnotatedTypeMetadata metadata, @Nullable ConfigurationPhase phase) &#123;    // 1、没有 Conditional 注解，则扫描时不会跳过当前 bean    // 2、遍历 conditions 进行判断是否满足&#125;\n所以对于自动配置类上的注解，Conditional 是作为当前类是否允许被刷新的前提，只有 Conditional 条件满足，才会将当前的自动配置类加入到待刷新 bean 列表中去，如果 Conditional 不满足，这个 bean 将直接被跳过，不会被放到 BeandefinitonMap 中去，也就不会有后续的刷新动作。\n@ConditionalOnProperty 作用时机在 BeanDefiniton 被创建之前，其执行时机要比 @EnableConfigurationProperties 作用要早，这也就说明了，为什么 TestProperties 中 test.enable&#x3D;true， AutoTestConfiguration 也不会刷新的原因了。\n总结本文通过一个简单 case，对于项目中遇到的 SpringBoot 配置失效导致 bean 未被刷新问题进行了回溯，总结如下：\n\nConditional 相关注解对于自动配置类来说，作用时机较早，用于决定当前自动配置类是否允许被刷新\n@EnableConfigurationProperties enable 的类，会默认注册一个 bean，bean 名字格式为 prefix-type\n\n","slug":"springboot/springboot-series-autoconfigure-invalid","date":"2021-11-15T03:35:18.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,自动配置","author_index":"glmapper"},{"id":"fcd3e7ce113bd1990030da77cb454e76","title":"git 中 merge 和 rebase 小记","content":"作为一线工程师的你，对于 git一定不会陌生，git 作为一个开源的分布式版本控制系统，有着广泛的用户基础。git 使用有很多可视化的工具，idea 自身也大多都集成了 git 套件，如下：\n\n\n\n不过相比于这些可视化工具，我更喜欢使用命令行的方式。\n本篇背景也是源于实际工作，一个同学遇到的问题是：他从 master 分支自己拉了一个开发分支，但是由于时间很长，所以在提交之前他执行了:\n1git pull\n\n然后 push ，当提交 mr 时发现，自己的提交里有很多别人的 commit 记录。ok，这里背景交代清楚，我们通过一个实际的 case 来看看。\ngit pull 发生了什么？\n从 master 分支切出一个 dev 分支\n切到 master 分支，代码修改，然后提交\n切回 dev ，执行 git pull\n\n在执行 git pull 之前，先看下 git log\n\n执行 git pull 之后\n\n所以可以非常明显的看到，git pull 操作中有把 master merge 到当前 dev，实际上 git pull 是下面两个指令的整合：\n1git pull = git fetch + git merge\n\n那既然是 merge，所以 dev 中后续的提交，都会带上此次 merge 的 commit 记录；\n\n这就是那位同学遇到的问题。如果我们不想让自己的提交中含有其他无关的 commit 怎么办？此时就需要 rebase 出场了。\ngit rebase\n从 master 切 一个 rebase-dev 分支\n从 master 切 一个 rebase-dev2 分支\n修改 rebase-dev2，然后提交，merge 到 master\n\n\n两次提交记录；这里基于前面提到的 git pull 行为，如果我们期望 rebase-dev 的提交不包括 rebase-dev2 的提交，但是从 log 看， rebase-dev 已经在最新 commit 后面了\n\ngit rebase 本质上是需要给 rebase-dev 变基，就是将基线拉到最新 commit 之前，在 rebase-dev 分支下，执行 git rebase master，此时再观察下 log\n\n可以看到 rebase-dev 已经跑到上面了，下面在 rebase-dev 做修改提交\n\n可以看下，此时提交就没有 rebase-dev2 的 commit 记录了。\n关于 git merge 和 git rebase 的小结\ngit merge：分支代码合并后不会破坏原分支的代码提交记录，但是会产生额外的提交记录并进行两条分支的合并\ngit rebase：不会新增提交记录到目标分支，rebase 后可以将对象分支的提交历史续到目标分支上，形成线性提交历史记录\n\n\n\n\n\n\n\n\n\n\n所以你学废了吗？\n","slug":"git/git-cmd-rebase-merge","date":"2021-11-09T03:32:40.000Z","categories_index":"git","tags_index":"git,merge,rebase","author_index":"glmapper"},{"id":"b98b36bd5e2d6f53b8f282c8597b8e9d","title":"mysql 日志文件","content":"日志文件记录了影响 mysql 数据库的各种类型活动，mysql 中常见的日志文件主要包括以下 4 种：\n\n错误日志\n二进制日志\n慢查询日志\n查询日志\n\n这些日志文件可以帮助我们对mysql数据库的运行状态进行诊断，从而更好的进行数据库层面的优化。\n\n\n错误日志错误日志文件对 mysql 的启动，运行，关闭过程进行了记录。错误日志不仅记录了所有的错误信息，也记录了一些警告信息或者正确的信息。可以通过以下方式 找到错误日志的路径：\n1234567mysql&gt; show variables like &#x27;log_error&#x27;;+---------------+----------------------------------+| Variable_name | Value                            |+---------------+----------------------------------+| log_error     | ./weihengdeMacBook-Pro.local.err |+---------------+----------------------------------+1 row in set (0.00 sec)\n\n可以看到错误日志的全路径，这里我本机没有做过调整，所以默认使用的是主机名作为错误日志的文件名。如果你的 mysql 数据库不能正常启动，可以第一时间查找的文件就是错误日志文件，这里可能会记录相关的错误日志，通过这个日志来找到不能正常启动的原因。下面截取部分日志：\n1234562021-05-06T08:57:03.359102Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.2021-05-06T08:57:03.439761Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.2021-05-06T08:57:03.495740Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Bind-address: &#x27;127.0.0.1&#x27; port: 33060, socket: /tmp/mysqlx.sock2021-05-06T08:57:03.521389Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.2021-05-06T08:57:03.521511Z 0 [System] [MY-013602] [Server] Channel mysql_main configured to support TLS. Encrypted connections are now supported for this channel.2021-05-06T08:57:03.529529Z 0 [System] [MY-010931] [Server] /opt/homebrew/Cellar/mysql/8.0.23_1/bin/mysqld: ready for connections. Version: &#x27;8.0.23&#x27;  socket: &#x27;/tmp/mysql.sock&#x27;  port: 3306  Homebrew.\n\n慢查询日志long_query_timemysql 启动时可以设定一个阈值，mysql 会将运行时间超过该值的所有 sql语句都记录到慢查询日志中。如下：\n12345678910mysql&gt; show variables like &#x27;long_query_time&#x27;;+-----------------+-----------+| Variable_name   | Value     |+-----------------+-----------+| long_query_time | 10.000000 |+-----------------+-----------+1 row in set (0.02 sec)mysql&gt; show variables like &#x27;log_slow_queries&#x27;;Empty set (0.01 sec)\n\n设置 long_query_time 阈值之后，mysql 数据库会记录运行时间超过该阈值的所有 sql 语句，但是对于时间刚好等于 long_query_time 值的不会被记录。从 mysql 5.1 开始，long_query_time开始以微秒记录 sql 语句运行的时间，在此之前都是用秒作为单位记录的。\nlog_queries_not_using_indexes这是另一个和慢查询有关的参数，这个参数表示，如果运行的 sql 语句没有使用索引，则 mysql 数据库同样会将这条 sql 语句记录到慢查询日志文件。\n1234567mysql&gt; show variables like &#x27;log_queries_not_using_indexes&#x27;;+-------------------------------+-------+| Variable_name                 | Value |+-------------------------------+-------+| log_queries_not_using_indexes | OFF   |+-------------------------------+-------+1 row in set (0.00 sec)\n\nlog_throttle_queries_not_using_indexes1234567mysql&gt; show variables like &#x27;log_throttle_queries_not_using_indexes&#x27;;+----------------------------------------+-------+| Variable_name                          | Value |+----------------------------------------+-------+| log_throttle_queries_not_using_indexes | 0     |+----------------------------------------+-------+1 row in set (0.01 sec)\n\nmysql 5.6.5 版本开始新增了 log_throttle_queries_not_using_indexes 这个参数，用来表示每分钟允许记录到 slow log 的且未使用索引的 sql 语句次数。该值默认是0，表示没有限制。在生产环境，如果没有使用索引，此类 sql 语句会频繁的被记录到 slow log，从而导致 slow log 文件不断增加，因此可以通过配置该值进行控制。\n","slug":"middleware/middleware-mysql-log-file","date":"2021-11-08T03:30:18.000Z","categories_index":"Middleware","tags_index":"mysql,log","author_index":"glmapper"},{"id":"9d1ebf7903ce83ad9e7fd07935406bb4","title":"聊一聊 Mockito","content":"Mockito 是 mocking 框架，它让你用简洁的API做测试。而且 Mockito 简单易学，它可读性强和验证语法简洁。\n\n\n从一个最简单的案例看起 \n12345678910111213141516@Testpublic void testAnswer() &#123;    MockitoAnswerService service = Mockito.mock(MockitoAnswerService.class);    Mockito.when(service.getResult(Mockito.anyString(), Mockito.anyList(), Mockito.any(MockitoAnswerParam.class))).then(new Answer&lt;String&gt;() &#123;        @Override        public String answer(InvocationOnMock invocation) throws Throwable &#123;            Object[] arguments = invocation.getArguments();            // 3            System.out.println(arguments.length);            return &quot;MOCK_ANSWER_RESULT&quot;;        &#125;    &#125;);    String result = service.getResult(&quot;1&quot;, new ArrayList&lt;&gt;(), new MockitoAnswerParam());    Assert.assertTrue(result.equals(&quot;MOCK_ANSWER_RESULT&quot;));&#125;\n\n从代码看，主要有这样几个关键行为：\n\nmock\nwhen\nthen\nanswer\n\n下面将以这几个行为作为分析的着手点。\nmock 对象做了哪些事情123456789101112/**     * Creates mock object of given class or interface.     * &lt;p&gt;     * See examples in javadoc for &#123;@link Mockito&#125; class     *     * @param classToMock class or interface to mock     * @return mock object     */@CheckReturnValuepublic static &lt;T&gt; T mock(Class&lt;T&gt; classToMock) &#123;    return mock(classToMock, withSettings());&#125;\n\n接受一个 class 类型与一个 mockSettings，classToMock 就是我们需要 mock 对象的类型，而mockSettings 则记录着此次 mock 的一些信息。\nmockMockito 内部持有了一个 MockitoCore 对象 MOCKITO_CORE， mock 最后是委托给 MOCKITO_CORE 来处理。\norg.mockito.internal.MockitoCore #mock\n123456789101112131415public &lt;T&gt; T mock(Class&lt;T&gt; typeToMock, MockSettings settings) &#123;    if (!MockSettingsImpl.class.isInstance(settings)) &#123;        throw new IllegalArgumentException(            &quot;Unexpected implementation of &#x27;&quot;            + settings.getClass().getCanonicalName()            + &quot;&#x27;\\n&quot;            + &quot;At the moment, you cannot provide your own implementations of that class.&quot;);    &#125;    MockSettingsImpl impl = MockSettingsImpl.class.cast(settings);    MockCreationSettings&lt;T&gt; creationSettings = impl.build(typeToMock);    // 创建 mock 对象    T mock = createMock(creationSettings);    mockingProgress().mockingStarted(mock, creationSettings);    return mock;&#125;\n\nmock 对象的产生在MockitoCore中一是做了一下初始化工作，接着继续将 mock 对象创建交给了 MockUtil\norg.mockito.internal.util.MockUtil#createMock\n12345678910111213141516171819202122public static &lt;T&gt; T createMock(MockCreationSettings&lt;T&gt; settings) &#123;        MockHandler mockHandler = createMockHandler(settings);        Object spiedInstance = settings.getSpiedInstance();        T mock;        if (spiedInstance != null) &#123;            mock =                    mockMaker                            .createSpy(settings, mockHandler, (T) spiedInstance)                            .orElseGet(                                    () -&gt; &#123;                                        T instance = mockMaker.createMock(settings, mockHandler);                                        new LenientCopyTool().copyToMock(spiedInstance, instance);                                        return instance;                                    &#125;);        &#125; else &#123;            mock = mockMaker.createMock(settings, mockHandler);        &#125;        return mock;    &#125;\n\n在 MockUtil 中比较关键的两个处理：\n\n创建 MockHandler 对象，MockHandler 是一个接口，MockHandler 对象的实例是 InvocationNotifierHandler 类型，它只是负责对外的包装，内部实际起作用的是MockHandlerImpl，这个类承载了 Mockito 的主要逻辑，后面详细说明。\n调用 mockMaker 来创建最终的实例，MockMaker 也是一个接口，其实现为ByteBuddyMockMaker。\n\n12345678910public class ByteBuddyMockMaker implements ClassCreatingMockMaker &#123;        private ClassCreatingMockMaker defaultByteBuddyMockMaker = new SubclassByteBuddyMockMaker();    @Override    public &lt;T&gt; T createMock(MockCreationSettings&lt;T&gt; settings, MockHandler handler) &#123;        return defaultByteBuddyMockMaker.createMock(settings, handler);    &#125;    // 省略其他代码&#125;\n\n可以看到，ByteBuddyMockMaker 内部用于创建 mock 对象的是 SubclassByteBuddyMockMaker。具体实现如下（为方便代码阅读，这里将一些无关代码去掉了）：\n1234567891011121314151617181920@Overridepublic &lt;T&gt; T createMock(MockCreationSettings&lt;T&gt; settings, MockHandler handler) &#123;     Class&lt;? extends T&gt; mockedProxyType = createMockType(settings);    Instantiator instantiator = Plugins.getInstantiatorProvider().getInstantiator(settings);    T mockInstance = null;    try &#123;        // 实例化        mockInstance = instantiator.newInstance(mockedProxyType);        MockAccess mockAccess = (MockAccess) mockInstance;        mockAccess.setMockitoInterceptor(new MockMethodInterceptor(handler, settings));        return ensureMockIsAssignableToMockedType(settings, mockInstance);    &#125; catch (ClassCastException cce) &#123;        // ignore code    &#125; catch (org.mockito.creation.instance.InstantiationException e) &#123;        // ignore code    &#125;&#125;\n\n可以比较明确的看到，其创建了一个 mock proxy（在之前的版本是直接创建代理类的），这里通过追踪代码，最终创建的逻辑在 org.mockito.internal.creation.bytebuddy.SubclassBytecodeGenerator#mockClass。这个方法内部逻辑比较多，但是核心部分就是通过 https://bytebuddy.net 动态生成一个代理类。\n1234567891011121314151617181920212223242526272829303132// ....DynamicType.Builder&lt;T&gt; builder =                byteBuddy                        .subclass(features.mockedType)                        .name(name)                        .ignoreAlso(isGroovyMethod())                        .annotateType(                                features.stripAnnotations                                        ? new Annotation[0]                                        : features.mockedType.getAnnotations())                        .implement(new ArrayList&lt;Type&gt;(features.interfaces))                        .method(matcher)                        .intercept(dispatcher)                        .transform(withModifiers(SynchronizationState.PLAIN))                        .attribute(                                features.stripAnnotations                                        ? MethodAttributeAppender.NoOp.INSTANCE                                        : INCLUDING_RECEIVER)                        .method(isHashCode())                        .intercept(hashCode)                        .method(isEquals())                        .intercept(equals)                        .serialVersionUid(42L)                        .defineField(&quot;mockitoInterceptor&quot;, MockMethodInterceptor.class, PRIVATE)                        .implement(MockAccess.class)                        .intercept(FieldAccessor.ofBeanProperty());//....return builder.make()                .load(                        classLoader,                        loader.resolveStrategy(features.mockedType, classLoader, localMock))                .getLoaded();\n\n这里其实是 bytebuddy 动态生成类的基本动作，但是毕竟只是代码，下面是我将当前创建的 mockedProxyType 字节码写到 .class 文件得到的：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//// Source code recreated from a .class file by IntelliJ IDEA// (powered by FernFlower decompiler)//package com.example.testproperties;import com.example.testproperties.MockitoAnswerService.MockitoMock.1791756687.auxiliary.UFw2zv6r;import com.example.testproperties.MockitoAnswerService.MockitoMock.1791756687.auxiliary.oa15uI8r;import com.example.testproperties.MockitoAnswerService.MockitoMock.1791756687.auxiliary.vbeEWzX6;import java.util.List;import org.mockito.internal.creation.bytebuddy.MockAccess;import org.mockito.internal.creation.bytebuddy.MockMethodInterceptor;import org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.DispatcherDefaultingToRealMethod;import org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.ForEquals;import org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.ForHashCode;public class MockitoAnswerService$MockitoMock$1791756687 extends MockitoAnswerService implements MockAccess &#123;    private static final long serialVersionUID = 42L;    private MockMethodInterceptor mockitoInterceptor;    public boolean equals(Object var1) &#123;        return ForEquals.doIdentityEquals(this, var1);    &#125;    public String toString() &#123;        return (String)DispatcherDefaultingToRealMethod.interceptSuperCallable(this, this.mockitoInterceptor, cachedValue$oKHFaZjn$4cscpe1, new Object[0], new UFw2zv6r(this));    &#125;    public int hashCode() &#123;        return ForHashCode.doIdentityHashCode(this);    &#125;    protected Object clone() throws CloneNotSupportedException &#123;        return DispatcherDefaultingToRealMethod.interceptSuperCallable(this, this.mockitoInterceptor, cachedValue$oKHFaZjn$7m9oaq0, new Object[0], new oa15uI8r(this));    &#125;    public String getResult(String arg1, List&lt;Object&gt; arg2, MockitoAnswerParam arg3) &#123;        return (String)DispatcherDefaultingToRealMethod.interceptSuperCallable(this, this.mockitoInterceptor, cachedValue$oKHFaZjn$rr3ccu3, new Object[]&#123;var1, var2, var3&#125;, new vbeEWzX6(this, var1, var2, var3));    &#125;    public MockMethodInterceptor getMockitoInterceptor() &#123;        return this.mockitoInterceptor;    &#125;    public void setMockitoInterceptor(MockMethodInterceptor var1) &#123;        this.mockitoInterceptor = var1;    &#125;    public MockitoAnswerService$MockitoMock$1791756687() &#123;    &#125;&#125;\n\n可以比较直观的看到，getResult 方法被插了拦截器，且当前类是作为目标被测试类的子类。来看下 DispatcherDefaultingToRealMethod#interceptSuperCallable 方法：\n123456789101112131415@RuntimeType@BindingPriority(BindingPriority.DEFAULT * 2)public static Object interceptSuperCallable(    @This Object mock,    @FieldValue(&quot;mockitoInterceptor&quot;) MockMethodInterceptor interceptor,    @Origin Method invokedMethod,    @AllArguments Object[] arguments,    @SuperCall(serializableProxy = true) Callable&lt;?&gt; superCall)    throws Throwable &#123;    if (interceptor == null) &#123;        return superCall.call();    &#125;    return interceptor.doIntercept(        mock, invokedMethod, arguments, new RealMethod.FromCallable(superCall));&#125;\n\n按照参数来看，cachedValue$oKHFaZjn$rr3ccu3 这坨东西居然是原始方法…。在前面那个代码中也提到，这里 interceptor 是类型为 MockMethodInterceptor 的实例，在创建字节码时就有体现这一点。所以在方法调用上，会走 doIntercept 的逻辑。\nmock 方法的执行上面提到，mock 本质上时通过 byteBuddy 创建了一个被 mock 类的子类，并且未被 mock 类方法插上了拦截器。所以我们基本就可以猜测到，mock 方法的实际执行，会被 mock 对象包装过的方法及拦截器 hook 掉，从而走到预设的逻辑。下面具体分析。（下面是通过执行堆栈追踪到的具体执行逻辑,org.mockito.internal.creation.bytebuddy.MockMethodInterceptor#doIntercept）\n1234567891011121314151617181920212223242526272829303132333435Object doIntercept(            Object mock,            Method invokedMethod,            Object[] arguments,            RealMethod realMethod,            Location location)            throws Throwable &#123;        // If the currently dispatched method is used in a hot path, typically a tight loop and if        // the mock is not used after the currently dispatched method, the JVM might attempt a        // garbage collection of the mock instance even before the execution of the current        // method is completed. Since we only reference the mock weakly from hereon after to avoid        // leaking the instance, it might therefore be garbage collected before the        // handler.handle(...) method completes. Since the handler method expects the mock to be        // present while a method call onto the mock is dispatched, this can lead to the problem        // described in GitHub #1802.        //        // To avoid this problem, we distract the JVM JIT by escaping the mock instance to a thread        // local field for the duration of the handler&#x27;s dispatch.        //        // When dropping support for Java 8, instead of this hatch we should use an explicit fence        // https://docs.oracle.com/javase/9/docs/api/java/lang/ref/Reference.html#reachabilityFence-java.lang.Object-        weakReferenceHatch.set(mock);        try &#123;            return handler.handle(                    createInvocation(                            mock,                            invokedMethod,                            arguments,                            realMethod,                            mockCreationSettings,                            location));        &#125; finally &#123;            weakReferenceHatch.remove();        &#125;    &#125;\n\n这里在内部，有包装了一层，将原始方法及mock 对象参数等，放到了 org.mockito.internal.invocation.InterceptedInvocation 这个类中。这种做法还是比较常见的，使得所有的模型按照组件内部封装的模型进行转换和执行，在组件内部形成语义上的闭环。weakReferenceHatch 是一个 ThreadLocal 变量，这里就是将 mock 对象放在 ThreadLocal 中，已便于后面基于当前线程上下文的所有动作都可以共享这个 mock 对象。那最核心的执行部分就是 handler#handle(Invocation invocation)。\n这里的 Hander 是 MockHandler，Mockito 内部实现此接口的有三个，实际使用最多的是 MockHandlerImpl 实现方式，这里以 MockHandlerImpl 的 handle 为例。下面是代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public Object handle(Invocation invocation) throws Throwable &#123;    // doAnswer 时会执行        if (invocationContainer.hasAnswersForStubbing()) &#123;            // stubbing voids with doThrow() or doAnswer() style            InvocationMatcher invocationMatcher =                    matchersBinder.bindMatchers(                            mockingProgress().getArgumentMatcherStorage(), invocation);            invocationContainer.setMethodForStubbing(invocationMatcher);            return null;        &#125;    // VerificationMode 是对验证信息的封装,它是一个接口,含有 verify 函数, 例如常用的 never,times 返回的都是 Times 类型,而 Times 类型就是 VerificationMode 的一种实现。 然后,调用 mockingProgress 来缓存 mode 信息。        VerificationMode verificationMode = mockingProgress().pullVerificationMode();\t\t// 用来匹配 when 条件        InvocationMatcher invocationMatcher =                matchersBinder.bindMatchers(                        mockingProgress().getArgumentMatcherStorage(), invocation);        mockingProgress().validateState();        // if verificationMode is not null then someone is doing verify()        if (verificationMode != null) &#123;            // We need to check if verification was started on the correct mock            // - see VerifyingWithAnExtraCallToADifferentMockTest (bug 138)            if (((MockAwareVerificationMode) verificationMode).getMock() == invocation.getMock()) &#123;                VerificationDataImpl data =                        new VerificationDataImpl(invocationContainer, invocationMatcher);                verificationMode.verify(data);                return null;            &#125; else &#123;                // this means there is an invocation on a different mock. Re-adding verification                // mode                // - see VerifyingWithAnExtraCallToADifferentMockTest (bug 138)                mockingProgress().verificationStarted(verificationMode);            &#125;        &#125;        // 准备 stubbing 调用        invocationContainer.setInvocationForPotentialStubbing(invocationMatcher);        OngoingStubbingImpl&lt;T&gt; ongoingStubbing = new OngoingStubbingImpl&lt;T&gt;(invocationContainer);        mockingProgress().reportOngoingStubbing(ongoingStubbing);        // 寻找此 invocation 是否有 answer        StubbedInvocationMatcher stubbing = invocationContainer.findAnswerFor(invocation);        // TODO #793 - when completed, we should be able to get rid of the casting below        notifyStubbedAnswerLookup(                invocation,                stubbing,                invocationContainer.getStubbingsAscending(),                (CreationSettings) mockSettings);\t\t// 如果有 answer 则进行 answer 的回调，上面的 例子中有，所以 case 执行会走到这里        if (stubbing != null) &#123;            stubbing.captureArgumentsFrom(invocation);            try &#123;                return stubbing.answer(invocation);            &#125; finally &#123;                // Needed so that we correctly isolate stubbings in some scenarios                // see MockitoStubbedCallInAnswerTest or issue #1279                mockingProgress().reportOngoingStubbing(ongoingStubbing);            &#125;        &#125; else &#123;            Object ret = mockSettings.getDefaultAnswer().answer(invocation);            DefaultAnswerValidator.validateReturnValueFor(invocation, ret);            // Mockito uses it to redo setting invocation for potential stubbing in case of partial            // mocks / spies.            // Without it, the real method inside &#x27;when&#x27; might have delegated to other self method            // and overwrite the intended stubbed method with a different one.            // This means we would be stubbing a wrong method.            // Typically this would led to runtime exception that validates return type with stubbed            // method signature.            invocationContainer.resetInvocationForPotentialStubbing(invocationMatcher);            return ret;        &#125;    &#125;\n\n这里说明以下，handle 方法在 when 中会被执行一次，再后面实际调用时还会执行一次，所以一次 when(method) 到实际 mock 调用，会执行两次。这里最开始在 debug 时，每次第一次走到都没符合预期返回 then 的值，后面通过分析堆栈发展调用入口时 when 中 mock 发起，并非时后面实际测试调用发起，才解释了这个没有预期返回结果的情况。\n这里补充下 InvocationMatcher 的 runtime 信息\n\nMockHandlermockito 会为每个创建的 mock 对象创建一个 MockHandler, 它的实现类是 MockHandlerImpl。该对象主要用于处理 mock 对象的每个被拦截方法。执行每个拦截方法的时候，都会交给这个 handler 处理。\nMockingProgress用来存放正在 mock 中的数据，如 OngoingStubbingImpl、argumentMatcherStorage、verificationMode 等。MockingProgress 的实现类是 MockingProgressImpl 。从 MockHandlerImpl#handle 的代码中可以看到，在整个执行逻辑中会平凡的出现 mockingProgress() ，mockingProgress() 是 ThreadSafeMockingProgress 中提供的静态方法，ThreadSafeMockingProgress 为不用线程分配了不同的 MockingProgress ，采用了 ThreadLocal 方式实现，保证了线程安全。\nOngoingStubbingImplmock 方法的一个包装。会为每个 mock 对象的方法创建一个 OngoingStubbingImpl，用来监控和模拟该方法行为。如上面service.getResult(Mockito.anyString(), Mockito.anyList(), Mockito.any(MockitoAnswerParam.class)) 行为。一个 mock 方法对应多个 OngoingStubbingImpl，因为每调用一次 mock 方法都会创建一个 OngoingStubbingImpl 对象。\n123456//see MockHandlerImpl#handleinvocationContainer.setInvocationForPotentialStubbing(invocationMatcher);// 这里是对上述描述的代码解释OngoingStubbingImpl&lt;T&gt; ongoingStubbing = new OngoingStubbingImpl&lt;T&gt;(invocationContainer);mockingProgress().reportOngoingStubbing(ongoingStubbing);\n\nmockSettings\n\n\n\n\n\n\n\n\nMockSettings has been introduced for two reasons. Firstly, to make it easy to add another mock setting when the demand comes. Secondly, to enable combining together different mock settings without introducing zillions of overloaded mock() methods.\n引入 MockSettings 有两个原因。 首先，当有需求时，可以很容易地添加另一个模拟设置。 其次，在不引入无数重载的 mock() 方法的情况下，将不同的模拟设置组合在一起。\n怎么理解这个 mockSettings ？举个例子：\n创建具有不同 defaultAnswer 和 name 的 mock\n1234Foo mock = mock(Foo.class, withSettings()                                  .defaultAnswer(RETURNS_SMART_NULLS)                                  .name(&quot;cool mockie&quot;)                                  );\n\n创建具有不同 defaultAnswer name 和 extraInterfaces 的 mock\n1234Foo mock = mock(Foo.class, withSettings()                                  .defaultAnswer(RETURNS_SMART_NULLS)                                  .name(&quot;cool mockie&quot;)                                  .extraInterfaces(Bar.class));\n\n\n什么是 extraInterfaces指定 mock 应该实现的额外接口，可能对遗留代码或某些极端情况有用。这个神秘的功能应该偶尔使用。被测对象应该确切地知道它的合作者和依赖关系。 如果实际场景碰巧有经常这样使用它的，那往往说明你的代码可能不具备简单、干净和可读的特性。\n1Foo foo = mock(Foo.class, withSettings().extraInterfaces(Bar.class, Baz.class));\n\n现在，mock 实现了额外的接口，因此可以进行以下转换：\n12Bar bar = (Bar) foo;Baz baz = (Baz) foo;\n\n什么的 name当前 mock 对象的名字，没有什么实际的用处，即使 name 相同，也是不同的两个 mock 对象（可通过 hashCode 判断得出）\n12Foo foo = mock(Foo.class, withSettings().name(&quot;foo&quot;));Foo foo = mock(Foo.class, &quot;foo&quot;);\n\n@Mock 注解 的 name 默认是 filedName 。\n什么是 defaultAnswer对 mock 对象的方法进行调用预期的设定，可以通过 thenReturn() 来指定返回值，thenThrow() 指定返回时所抛异常，通常来说这两个方法足以应对一般的需求。但有时我们需要自定义方法执行的返回结果，Answer 接口就是满足这样的需求而存在的，它可以用来处理那些 mock 对象没有 stubbing 的方法的返回值。\n12345678910111213141516@Testpublic void testAnswer() &#123;    MockitoAnswerService service = Mockito.mock(MockitoAnswerService.class);    Mockito.when(service.getResult(Mockito.anyString(), Mockito.anyList(), Mockito.any(MockitoAnswerParam.class))).then(new Answer&lt;String&gt;() &#123;        @Override        public String answer(InvocationOnMock invocation) throws Throwable &#123;            Object[] arguments = invocation.getArguments();            // 3            System.out.println(arguments.length);            return &quot;MOCK_ANSWER_RESULT&quot;;        &#125;    &#125;);    String result = service.getResult(&quot;1&quot;, new ArrayList&lt;&gt;(), new MockitoAnswerParam());    Assert.assertTrue(result.equals(&quot;MOCK_ANSWER_RESULT&quot;));&#125;\n\n还有一些如 stubbingLookupListeners 等这里不做过多说明，详细可参考官方文档。\n","slug":"tests/test-mock-mockito","date":"2021-11-06T03:26:33.000Z","categories_index":"test","tags_index":"test,mock,Mockito","author_index":"glmapper"},{"id":"29ce492a4d6518491078a1705c4387c8","title":"JVM-Java 对象模型","content":"Java对象保存在堆内存中。在内存中，一个Java对象包含三部分：对象头、实例数据和对齐填充。其中对象头是一个很关键的部分，因为对象头中包含锁状态标志、线程持有的锁等标志。\n\n\n对象头对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。\n对markword的设计方式上，非常像网络协议报文头：将mark word划分为多个比特位区间，并在不同的对象状态下赋予比特位不同的含义。下图描述了在32位虚拟机上，在对象不同状态时 mark word各个比特位区间的含义。\n\n在JVM的内存结构中，对象保存在堆内存中，而我们在对对象进行操作时，其实操作的是对象的引用。那么对象本身在JVM中的结构是什么样的呢？本文的所有分析均基于 HotSpot 虚拟机。\nOop-Klass 模型HotSpot是基于 c++ 实现，而c++是一门面向对象的语言，本身是具备面向对象基本特征的，所以Java中的对象表示，最简单的做法是为每个Java类生成一个c++类与之对应。但HotSpot JVM并没有这么做，而是设计了一个OOP-Klass Model。OOP（Ordinary Object Pointer）指的是普通对象指针，而Klass用来描述对象实例的具体类型。\n为什么 HotSpot 要设计一套oop-klass model呢？答案是：HotSopt JVM的设计者不想让每个对象中都含有一个vtable（虚函数表）; 这个解释似乎可以说得通。众所周知，C++和Java都是面向对象的语言，面向对象语言有一个很重要的特性就是多态。关于多态的实现，C++和Java有着本质的区别。\n多态是面向对象的最主要的特性之一，是一种方法的动态绑定，实现运行时的类型决定对象的行为。多态的表现形式是父类指针或引用指向子类对象，在这个指针上调用的方法使用子类的实现版本。多态是IOC、模板模式实现的关键。\n在 C++ 中通过虚函数表的方式实现多态，每个包含虚函数的类都具有一个虚函数表（virtual table），在这个类对象的地址空间的最靠前的位置存有指向虚函数表的指针。在虚函数表中，按照声明顺序依次排列所有的虚函数。由于C++在运行时并不维护类型信息，所以在编译时直接在子类的虚函数表中将被子类重写的方法替换掉。\n在 Java 中，在运行时会维持类型信息以及类的继承体系。每一个类会在方法区中对应一个数据结构用于存放类的信息，可以通过Class对象访问这个数据结构。其中，类型信息具有superclass属性指示了其超类，以及这个类对应的方法表（其中只包含这个类定义的方法，不包括从超类继承来的）。而每一个在堆上创建的对象，都具有一个指向方法区类型信息数据结构的指针，通过这个指针可以确定对象的类型。\noop-klass 结构关于 opp-klass 模型的整体定义，在 HotSpot 的 源码 中可以找到。oops 模块可以分成两个相对独立的部分：OOP 框架和 Klass 框架。在 oopsHierarchy.hpp 里定义了 oop 和 klass 各自的体系。\n\noop 体系123456789101112131415161718192021222324//定义了oops共同基类typedef class   oopDesc*                            oop;//表示一个Java类型实例typedef class   instanceOopDesc*            instanceOop;//表示一个Java方法typedef class   methodOopDesc*                    methodOop;//表示一个Java方法中的不变信息typedef class   constMethodOopDesc*            constMethodOop;//记录性能信息的数据结构typedef class   methodDataOopDesc*            methodDataOop;//定义了数组OOPS的抽象基类typedef class   arrayOopDesc*                    arrayOop;//表示持有一个OOPS数组typedef class   objArrayOopDesc*            objArrayOop;//表示容纳基本类型的数组typedef class   typeArrayOopDesc*            typeArrayOop;//表示在Class文件中描述的常量池typedef class   constantPoolOopDesc*            constantPoolOop;//常量池告诉缓存typedef class   constantPoolCacheOopDesc*   constantPoolCacheOop;//描述一个与Java类对等的C++类typedef class   klassOopDesc*                    klassOop;//表示对象头typedef class   markOopDesc*                    markOop;\n\n上面列出的是整个Oops模块的组成结构，其中包含多个子模块。每一个子模块对应一个类型，每一个类型的OOP都代表一个在JVM内部使用的特定对象的类型。\n从上面的代码中可以看到，有一个变量opp的类型是oppDesc ，OOPS类的共同基类型为oopDesc。\n在Java程序运行过程中，每创建一个新的对象，在JVM内部就会相应地创建一个对应类型的OOP对象。 在HotSpot中，根据JVM内部使用的对象业务类型，具有多种oopDesc的子类。除了oppDesc类型外，opp体系中还有很多instanceOopDesc、arrayOopDesc 等类型的实例，他们都是oopDesc的子类。\n\n这些 OOPS 在 JVM 内部有着不同的用途，例如 ， instanceOopDesc 表示类实例， arrayOopDesc 表示数组。 也就是说，当我们使用new创建一个 Java 对象实例的时候，JVM 会创建一个instanceOopDesc对象来表示这个 Java 对象。同理，当我们使用new创建一个 Java 数组实例的时候，JVM 会创建一个arrayOopDesc 对象来表示这个数组对象。\n\n在 HotSpot 中，oopDesc 类定义在 oop.hpp 中，instanceOopDesc 定义在 instanceOop.hpp 中，arrayOopDesc 定义在 arrayOop.hpp 中。\n123456789101112131415161718192021222324252627282930class oopDesc &#123;  friend class VMStructs;  private:      volatile markOop  _mark;      union _metadata &#123;        wideKlassOop    _klass;        narrowOop       _compressed_klass;      &#125; _metadata;  private:      // field addresses in oop      void*     field_base(int offset)        const;      jbyte*    byte_field_addr(int offset)   const;      jchar*    char_field_addr(int offset)   const;      jboolean* bool_field_addr(int offset)   const;      jint*     int_field_addr(int offset)    const;      jshort*   short_field_addr(int offset)  const;      jlong*    long_field_addr(int offset)   const;      jfloat*   float_field_addr(int offset)  const;      jdouble*  double_field_addr(int offset) const;      address*  address_field_addr(int offset) const;&#125;class instanceOopDesc : public oopDesc &#123;&#125;class arrayOopDesc : public oopDesc &#123;&#125;\n\n通过上面的源码可以看到，instanceOopDesc实际上就是继承了oopDesc，并没有增加其他的数据结构，也就是说instanceOopDesc中主要包含以下几部分数据：markOop _mark和union _metadata 以及一些不同类型的 field。\nHotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头、实例数据和对齐填充。在虚拟机内部，一个Java对象对应一个instanceOopDesc的对象。其中对象头包含了两部分内容：_mark和_metadata，而实例数据则保存在oopDesc中定义的各种field中。\n_mark文章开头我们就说过，之所以我们要写这篇文章，是因为对象头中有和锁相关的运行时数据，这些运行时数据是synchronized以及其他类型的锁实现的重要基础，而关于锁标记、GC分代等信息均保存在_mark中。因为本文主要介绍的oop-klass模型，在这里暂时不对对象头做展开，下一篇文章介绍。\n_metadata前面介绍到的_metadata是一个共用体，其中_klass是普通指针，_compressed_klass是压缩类指针。在深入介绍之前，就要来到oop-Klass中的另外一个主角klass了。\nklass 体系12345678910111213141516171819202122232425262728293031323334//klassOop的一部分，用来描述语言层的类型class  Klass;//在虚拟机层面描述一个Java类class   instanceKlass;//专有instantKlass，表示java.lang.Class的Klassclass     instanceMirrorKlass;//专有instantKlass，表示java.lang.ref.Reference的子类的Klassclass     instanceRefKlass;//表示methodOop的Klassclass   methodKlass;//表示constMethodOop的Klassclass   constMethodKlass;//表示methodDataOop的Klassclass   methodDataKlass;//最为klass链的端点，klassKlass的Klass就是它自身class   klassKlass;//表示instanceKlass的Klassclass     instanceKlassKlass;//表示arrayKlass的Klassclass     arrayKlassKlass;//表示objArrayKlass的Klassclass       objArrayKlassKlass;//表示typeArrayKlass的Klassclass       typeArrayKlassKlass;//表示array类型的抽象基类class   arrayKlass;//表示objArrayOop的Klassclass     objArrayKlass;//表示typeArrayOop的Klassclass     typeArrayKlass;//表示constantPoolOop的Klassclass   constantPoolKlass;//表示constantPoolCacheOop的Klassclass   constantPoolCacheKlass;\n\n和oopDesc是其他 oop 类型的父类一样，Klass 类是其他 klass 类型的父类。\n\nKlass 向 JVM 提供两个功能：\n\n实现语言层面的 Java 类（在 Klass 基类中已经实现）\n实现 Java 对象的分发功能（由 Klass 的子类提供虚函数实现）\n\n文章开头的时候说过：之所以设计oop-klass模型，是因为HotSopt JVM的设计者不想让每个对象中都含有一个虚函数表。\nHotSopt JVM的设计者把对象一拆为二，分为klass和oop，其中oop的职能主要在于表示对象的实例数据，所以其中不含有任何虚函数。而klass为了实现虚函数多态，所以提供了虚函数表。所以，关于Java的多态，其实也有虚函数的影子在。\n_metadata是一个共用体，其中_klass是普通指针，_compressed_klass是压缩类指针。这两个指针都指向instanceKlass对象，它用来描述对象的具体类型。\ninstanceKlassJVM在运行时，需要一种用来标识Java内部类型的机制。在HotSpot中的解决方案是：为每一个已加载的Java类创建一个instanceKlass对象，用来在JVM层表示Java类。\n1234567891011121314151617//类拥有的方法列表  objArrayOop     _methods;  //描述方法顺序  typeArrayOop    _method_ordering;  //实现的接口  objArrayOop     _local_interfaces;  //继承的接口  objArrayOop     _transitive_interfaces;  //域  typeArrayOop    _fields;  //常量  constantPoolOop _constants;  //类加载器  oop             _class_loader;  //protected域  oop             _protection_domain;      ....\n\n可以看到，一个类该具有的东西，这里面基本都包含了。\n在JVM中，对象在内存中的基本存在形式就是oop。那么，对象所属的类，在JVM中也是一种对象，因此它们实际上也会被组织成一种oop，即klassOop。同样的，对于klassOop，也有对应的一个klass来描述，它就是klassKlass，也是klass的一个子类。klassKlass作为oop的klass链的端点。关于对象和数组的klass链大致如下图：\n\n在这种设计下，JVM 对内存的分配和回收，都可以采用统一的方式来管理。oop-klass-klass Klass 关系如图：\n\n内存存储关于一个Java对象，他的存储是怎样的? 对象的实例（instantOopDesc)保存在堆上，对象的元数据（instantKlass）保存在方法区，对象的引用保存在栈上。\n方法区用于存储虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。  所谓加载的类信息，其实不就是给每一个被加载的类都创建了一个 instantKlass对象么。\n123456789101112131415class Model&#123;    public static int a = 1;    public int b;    public Model(int b) &#123;        this.b = b;    &#125;&#125;public static void main(String[] args) &#123;    int c = 10;    Model modelA = new Model(2);    Model modelB = new Model(3);&#125;\n\n\n存储结构如下：\n\n从上图中可以看到，在方法区的instantKlass中有一个int a=1的数据存储。在堆内存中的两个对象的oop中，分别维护着int b=3,int b=2的实例数据。和oopDesc一样，instantKlass也维护着一些fields，用来保存类中定义的类数据，比如int a=1。\n总结每一个Java类，在被JVM加载的时候，JVM会给这个类创建一个instanceKlass，保存在方法区，用来在JVM层表示该Java类。当我们在Java代码中，使用new创建一个对象的时候，JVM会创建一个instanceOopDesc对象，这个对象中包含了两部分信息，对象头以及元数据。对象头中有一些运行时数据，其中就包括和多线程相关的锁的信息。元数据其实维护的是指针，指向的是对象所属的类的instanceKlass。\n\n\n\n\n\n\n\n\n\n本文整合自 openjdk 源码及网络相关知识，引用中已备注参考来源，如有侵权，请联系删除。感谢参考文章作者对于技术社区的知识传播。原文：https://juejin.cn/post/7027106902425206797\n引用\nhttp://www.voidcn.com/article/p-pzznrtkc-ez.html\nhttps://www.jianshu.com/p/b6cb4c694951\nhttps://blog.csdn.net/linxdcn/\n\n","slug":"jvm/jvm-openjdk-oop-klass","date":"2021-11-05T03:23:39.000Z","categories_index":"jvm","tags_index":"jvm,oop-klass","author_index":"glmapper"},{"id":"47efb9065838ed77b0a81f4071199b1e","title":"finalize 方法重写对 GC 的影响分析","content":"关于 Object 的 finalize 方法，在日常开发中可能有超过 99% 的人都没有关注过，因为业务开发很少有重写 finalize 方法的场景；开发者对于 finalize 的认知大多在是“面试八股文”中，而且也不乏见到将 finalize、finally 以及 final 放在一块比较的 case，面试官可能是出于对初学者 java 基本语言知识的考量，但是这真的有意义吗？\n\n\n\n本文将用一个非常简单的 case 来直观的看下，finalize 方法重写带来的影响。\nfinalize 方法是什么下面我们直接来看下 finalize 的代码注释。\n1234* Called by the garbage collector on an object when garbage collection* determines that there are no more references to the object.* A subclass overrides the &#123;@code finalize&#125; method to dispose of* system resources or to perform other cleanup.\n\nfinalize 是 java 的顶级父类 Object 中的一些方法，默认情况下 finalize 方法是空实现；其调时机是：当前对象没有任何引用时，执行 GC 时被调用。子类可以重写了 finalize 方法去释放系统资源或执行其他清理。\n12345678910111213* The general contract of &#123;@code finalize&#125; is that it is invoked* if and when the Java&amp;trade; virtual* machine has determined that there is no longer any* means by which this object can be accessed by any thread that has* not yet died, except as a result of an action taken by the* finalization of some other object or class which is ready to be* finalized. The &#123;@code finalize&#125; method may take any action, including* making this object available again to other threads; the usual purpose* of &#123;@code finalize&#125;, however, is to perform cleanup actions before* the object is irrevocably discarded. For example, the finalize method* for an object that represents an input/output connection might perform* explicit I/O transactions to break the connection before the object is* permanently discarded.\n\nfinalizer 方法的调用时机由 JavaTM 开发商决定：简单说就是要确定对象的任何方法都不（再）会被调用时，再调用其 finalize 方法。除非一些其他的已经准备好被终止的对象或类将调用 finalize 方法，包括在其终止动作之中（即调用对象的 finalize 方法，此时该对象的 finalize 方法将是最后被调用的方法，在这之后，对象的任何方法都不（再）会被调用。finalize 方法中可以执行任何操作，包括再次使该对象可用于其它线程（重新初始化）；但是 finalize 的通常目的是在对象（一定）不再被需要时（对象将被丢弃）之前执行清除操作。例如，表示input&#x2F;output 连接的对象的 finalize 方法可能会在对象被永久丢弃之前执行显式 I&#x2F;O 事务来中断连接。\n123456* The Java programming language does not guarantee which thread will* invoke the &#123;@code finalize&#125; method for any given object. It is* guaranteed, however, that the thread that invokes finalize will not* be holding any user-visible synchronization locks when finalize is* invoked. If an uncaught exception is thrown by the finalize method,* the exception is ignored and finalization of that object terminates.\n\njava 语言不对任何对象的 finalize 方法调用发生的线程做限制，即任何线程都可以调用对象的 finalize 方法，然而，调用 finalize 方法的线程将不能持有任何用户可见的线程同步锁。当 finalize 方法被调用时，如果 finalize 方法抛出异常，且异常未被捕获时，异常将被忽略，finalize 方法将中止。\n123456* After the &#123;@code finalize&#125; method has been invoked for an object, no* further action is taken until the Java virtual machine has again* determined that there is no longer any means by which this object can* be accessed by any thread that has not yet died, including possible* actions by other objects or classes which are ready to be finalized,* at which point the object may be discarded.\n\n当对象的 finalize 方法被调用后，不会再有基于该对象的方法调用，直到 JVM 再次进行回收动作时该对象将被释放，占用的内存将被回收。\n另外，任何对象的 finalize 方法只会被 JVM 调用一次。finalize（）方法引发的任何异常都会导致该对象的终止被暂停，否则被忽略。\nfinalize 方法重写对 GC 的影响这里丢一个简单的例子，TestMain 类重写了 finalize 方法，并且在 finalize 方法中已创建的对象总数 COUNT 做减操作，并且没隔 100000 次输出下当前 COUNT。\n1234567891011121314151617181920212223242526public class TestMain &#123;    private static AtomicInteger COUNT = new AtomicInteger(0);    public TestMain() &#123;        COUNT.incrementAndGet();    &#125;    /**     * 重写 finalize 方法测试     * @throws Throwable     */    @Override    protected void finalize() throws Throwable &#123;        COUNT.decrementAndGet();    &#125;    public static void main(String args[]) &#123;        for (int i = 0 ;; i++) &#123;            TestMain item = new TestMain();            if ((i % 100000) == 0) &#123;                System.out.format(&quot;creating %d objects, current %d are alive.%n&quot;, new Object[] &#123;i, COUNT.get() &#125;);            &#125;        &#125;    &#125;&#125;\n\n运行环境：MacOS 10.14.6\nJVM 参数：-XX:+PrintGCDetails -Xms200M -Xmx200M -Xmn100M\n执行这段代码，可以在控制台观察，会出现以下几个阶段:\n阶段一：第一次执行 GC 的时候123456789101112131415161718creating 0 objects, current 1 are alive.creating 100000 objects, current 100001 are alive.creating 200000 objects, current 200001 are alive.creating 300000 objects, current 300001 are alive.creating 400000 objects, current 400001 are alive.creating 500000 objects, current 500001 are alive.creating 600000 objects, current 600001 are alive.creating 700000 objects, current 700001 are alive.creating 800000 objects, current 800001 are alive.creating 900000 objects, current 900001 are alive.creating 1000000 objects, current 1000001 are alive.creating 1100000 objects, current 1100001 are alive.creating 1200000 objects, current 1200001 are alive.// ygc 失败，下面直接进行 fgc 了[GC (Allocation Failure) [PSYoungGen: 76800K-&gt;12800K(89600K)] 76800K-&gt;71066K(192000K), 0.3839994 secs] [Times: user=1.87 sys=0.07, real=0.38 secs] // 执行 fgc[Full GC (Ergonomics) [PSYoungGen: 12800K-&gt;0K(89600K)] [ParOldGen: 58266K-&gt;70801K(102400K)] 71066K-&gt;70801K(192000K), [Metaspace: 3696K-&gt;3696K(1056768K)], 1.3266229 secs] [Times: user=4.89 sys=0.17, real=1.33 secs]creating 1300000 objects, current 1296221 are alive.\n\n看下 GC 之后，COUNT 中统计的存活的对象数还是有很多。\n阶段二：频繁 fgc12345678910111213creating 3200000 objects, current 3132405 are alive.creating 3300000 objects, current 3230808 are alive.[Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;75818K(89600K)] [ParOldGen: 102171K-&gt;102028K(102400K)] 178971K-&gt;177846K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.8383374 secs] [Times: user=4.93 sys=0.09, real=0.84 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76768K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178797K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.3276008 secs] [Times: user=2.24 sys=0.01, real=0.33 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76784K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178813K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.2876044 secs] [Times: user=1.74 sys=0.03, real=0.29 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76775K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178803K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.2761930 secs] [Times: user=1.74 sys=0.02, real=0.28 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76778K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178806K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.3522859 secs] [Times: user=1.67 sys=0.02, real=0.35 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76786K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178814K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.2609472 secs] [Times: user=1.36 sys=0.02, real=0.26 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76793K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178821K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.2691448 secs] [Times: user=1.28 sys=0.01, real=0.27 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76787K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178816K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.2254074 secs] [Times: user=1.37 sys=0.01, real=0.22 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76779K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178808K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.2670959 secs] [Times: user=1.77 sys=0.02, real=0.27 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76778K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178807K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.2704234 secs] [Times: user=1.71 sys=0.02, real=0.27 secs] [Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76785K(89600K)] [ParOldGen: 102028K-&gt;102028K(102400K)] 178828K-&gt;178813K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.3302090 secs] [Times: user=1.84 sys=0.02, real=0.33 secs] \n\n差不多在 330 万次时，就开始持续有 fgc 的情况了；可以看到各个数据区都被占满了。\n阶段三：OOM12345678910111213141516[Full GC (Ergonomics) [PSYoungGen: 76800K-&gt;76784K(89600K)] [ParOldGen: 102028K-&gt;101994K(102400K)] 178828K-&gt;178778K(192000K), [Metaspace: 3716K-&gt;3716K(1056768K)], 0.4323213 secs] [Times: user=2.13 sys=0.04, real=0.43 secs] [Full GC (Ergonomics) Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: GC overhead limit exceeded[PSYoungGen: 76799K-&gt;76697K(89600K)] [ParOldGen: 101994K-&gt;101994K(102400K)] 178793K-&gt;178691K(192000K), [Metaspace: 3720K-&gt;3720K(1056768K)], 0.3325707 secs] [Times: user=1.70 sys=0.02, real=0.33 secs] Heap PSYoungGen      total 89600K, used 76800K [0x00000007b9c00000, 0x00000007c0000000, 0x00000007c0000000)  eden space 76800K, 100% used [0x00000007b9c00000,0x00000007be700000,0x00000007be700000)  from space 12800K, 0% used [0x00000007be700000,0x00000007be700000,0x00000007bf380000)  to   space 12800K, 0% used [0x00000007bf380000,0x00000007bf380000,0x00000007c0000000) ParOldGen       total 102400K, used 101994K [0x00000007b3800000, 0x00000007b9c00000, 0x00000007b9c00000)  object space 102400K, 99% used [0x00000007b3800000,0x00000007b9b9a8e0,0x00000007b9c00000) Metaspace       used 3751K, capacity 4670K, committed 4864K, reserved 1056768K  class space    used 404K, capacity 434K, committed 512K, reserved 1048576K\tat java.lang.ref.Finalizer.register(Finalizer.java:87)\tat java.lang.Object.&lt;init&gt;(Object.java:37)\tat com.glmapper.bridge.boot.finalize.TestMain.&lt;init&gt;(TestMain.java:13)\tat com.glmapper.bridge.boot.finalize.TestMain.main(TestMain.java:28)\n\n在创建了 330 万个对象后就抛出 java.lang.OutOfMemoryError: GC overhead limitt exceeded 异常退出了。从我工程测试日志中看到，基本全都都是 fgc（只有一次 ygc），从代码看，这些对象并没有什么特殊，代码层面也没有引用，但是 JVM 就直接使用代价更高的 Full GC 来清理老生代和持久代的空间了。所以 why ?\n那作为对比，我们把代码中重写 finalize 的代码逻辑去掉再跑一次：\n123456789101112131415161718192021222324252627282930creating 111000000 objects [GC (Allocation Failure) [PSYoungGen: 99328K-&gt;0K(100864K)] 100161K-&gt;833K(203264K), 0.0008235 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] creating 112000000 objects creating 113000000 objects creating 114000000 objects creating 115000000 objects creating 116000000 objects creating 117000000 objects [GC (Allocation Failure) [PSYoungGen: 99328K-&gt;0K(100864K)] 100161K-&gt;833K(203264K), 0.0005181 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] creating 118000000 objects creating 119000000 objects creating 120000000 objects creating 121000000 objects creating 122000000 objects creating 123000000 objects creating 124000000 objects [GC (Allocation Failure) [PSYoungGen: 99328K-&gt;0K(100864K)] 100161K-&gt;833K(203264K), 0.0004161 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] creating 125000000 objects creating 126000000 objects creating 127000000 objects creating 128000000 objects creating 129000000 objects creating 130000000 objects [GC (Allocation Failure) [PSYoungGen: 99328K-&gt;32K(101376K)] 100161K-&gt;865K(203776K), 0.0004908 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] creating 131000000 objects creating 132000000 objects creating 133000000 objects creating 134000000 objects creating 135000000 objects creating 136000000 objects\n\n可以看到，在创建 13600 万对象时仍然可以继续跑，并且通过 GC 日志看，也只有 ygc , 没有一次 fgc。所以这个和重写 finalize 时的差距还是非常大的。那么下面就来分析下具体原因。\nGC 影响分析这里思路很简单，首先我们要知道是什么对象导致了 OOM，要找出来。\n找到占用空间的元凶在启动参数中加上 -XX:+HeapDumpOnOutOfMemoryError 参数，重新执行一次，在出现 OOM 时会执行一次 heap dump\n123java.lang.OutOfMemoryError: GC overhead limit exceededDumping heap to java_pid88685.hprof ...Heap dump file created [320504328 bytes in 3.050 secs]\n\n通过分析工具（我使用的是 Jprofile 2）,看到都是 Finalizer 这个类的对象实例\n\n在我的测试代码中，非常明确没有创建 Finalizer 对象的逻辑，那为什么会有这么多 Finalizer 对象实例呢？其实从上面 OOM 堆栈那里已经可以看出些端倪了：\n12345class space    used 404K, capacity 434K, committed 512K, reserved 1048576K\tat java.lang.ref.Finalizer.register(Finalizer.java:87)    at java.lang.Object.&lt;init&gt;(Object.java:37)    at com.glmapper.bridge.boot.finalize.TestMain.&lt;init&gt;(TestMain.java:13)    at com.glmapper.bridge.boot.finalize.TestMain.main(TestMain.java:28)\n\n在堆栈中看到了 Finalizer.register 这样一个方法执行，把断点打在这里：\n\n对于重写 finalize 方法的类，在创建其实例时，会同时创建一个 Finalizer 实例，这些所有的 Finalizer 实例又会为 Finalizer 类所引用，由于存在这么一个引用链关系存在，所以整个的这些对象都是存活的；所以当 Eden 区满了之后，此时所有的对象还是存活的，所以并不会被回收掉，继而只能将他们进一步放到 Suvivor 区去，但是由于这些对象不会被释放，引用一直存在，所以 Suvivor 区也很快被占满，既然这些对象被放到老年代，直到存入元数据空间，最后 OOM；所以前面提到的，不是 JVM 不使用 ygc ，而是基于既定规则下，ygc 并不能将这些存活的对象回收掉。关于引用链通过 Jprofile 也可以直观的得到结论\n\n如何被回收的？那是不是就一直没法被回收呢？其实也不是，我们看到在执行了 fgc 之后，还是有一些对象被回收掉的。那就是说，这些被引用的对象，还是有可能被释放的；那其实就看这个对象什么时候从下面这个队列中被弹出。\n1private static ReferenceQueue&lt;Object&gt; queue = new ReferenceQueue&lt;&gt;();\n\n被弹出的对象在下一次 GC 的时候就会被认为已经没有任何引用从而被回收掉。\nFinalizer 线程: FinalizerThreadFinalizerThread 的职责非常简单，就是不停的循环等待 ReferenceQueue 中的新增对象，然后弹出这个对象，调用它的 finalize() 方法，将该引用从 Finalizer 类中移除，因此下次 GC 再执行的时候，这个 Finalizer 实例以及它引用的那个对象就可以回垃圾回收掉了。\nfinalize() 方法的调用会比你创建新对象要早得多，因此大多数时候，Finalizer 线程能够赶在下次 GC 带来更多的 Finalizer 对象前清空这个队列。\n既然如此，那为什么会出现 OOM 呢？因为 Finalizer 线程和主线程相比它的优先级要低。这意味着分配给它的CPU 时间更少，因此它的处理速度没法赶上新对象创建的速度。这就是问题的根源——对象创建的速度要比Finalizer 线程调用 finalize() 结束它们的速度要快，这导致最后堆中所有可用的空间都被耗尽了，结果就出现了 OOM 这种情况。（PS: 案例代码在一直循环创建新的对象）\n总结通过上面的 case 和分析，可以知道，对于重写了 finalize 的类，其对象的生命周期和普通对象的生命周期是完全不一样的。对于重写了 finalize 的类，其生命周期大致如下：\n\nJVM 创建 TestMain 对象\nJVM 创建一个 Finalizer 对象，指向 TestMain 对象\n\n\n\n\nFinalizer 类持有新创建的 Finalizer 的实例，使得下一次新生代 GC 无法回收这些对象\n新生代 GC 无法清空 Eden 区（引用被持有了），因此会将这些对象移到 Survivor 区或者老生代\n\n\n\n\n垃圾回收器发现这些对象实现了finalize() 方法，因为会把它们添加到 ReferenceQueue 队列中\nFinalizerThread 处理 ReferenceQueue 队列，将里面的对象逐个弹出，并调用它们的 finalize() 方法\n\n\n\n\nfinalize() 方法调用完后，FinalizerThread 会将引用从 Finalizer 类中去掉，因此在下一轮 GC 中，这些对象就可以被回收了\n\n所以，如果你有使用 finalize() 方法的情况，如果不是使用常规的方式来清理对象的话，最好是多考虑一下。\n","slug":"java/java-advance-gc-finalize","date":"2021-11-02T03:17:56.000Z","categories_index":"SOFA","tags_index":"gc,ClassLoader,SOFAArk","author_index":"glmapper"},{"id":"d159ca8c012acf521f858fbe565b5e98","title":"log4j2 日志 PatternLayout 配置对 SOFAArk PluginClassLoader 的影响","content":"log4j2 相关类在 sofaark 插件中是导出的，因此当出现 log4j2 的类需要被加载时，会委托给 PluginClassLoader 进行加载。\n\n\n背景1234567891011121314151617181920212223242526272829303132333435363738394041&quot;Log4j2-TF-7-AsyncLoggerConfig-8&quot; Id=52 BLOCKED on sun.misc.URLClassPath@26eb1b56 owned by &quot;Log4j2-TF-7-AsyncLoggerConfig-4&quot; Id=17    at sun.misc.URLClassPath.getNextLoader(URLClassPath.java:479)    -  blocked on sun.misc.URLClassPath@26eb1b56    at sun.misc.URLClassPath.getResource(URLClassPath.java:248)    at java.net.URLClassLoader$1.run(URLClassLoader.java:366)    at java.net.URLClassLoader$1.run(URLClassLoader.java:363)    at java.security.AccessController.doPrivileged(Native Method)    at java.net.URLClassLoader.findClass(URLClassLoader.java:362)    at java.lang.ClassLoader.loadClass(ClassLoader.java:448)    at com.alipay.sofa.ark.container.service.classloader.AbstractClasspathClassLoader.resolveLocalClass(AbstractClasspathClassLoader.java:302)    at com.alipay.sofa.ark.container.service.classloader.PluginClassLoader.loadClassInternal(PluginClassLoader.java:102)\t  // 插件加载  \t\tat com.alipay.sofa.ark.container.service.classloader.AbstractClasspathClassLoader.loadClass(AbstractClasspathClassLoader.java:71)    at java.lang.ClassLoader.loadClass(ClassLoader.java:380)    at org.apache.logging.log4j.core.impl.ThrowableProxy.loadClass(ThrowableProxy.java:563)    at org.apache.logging.log4j.core.impl.ThrowableProxy.toExtendedStackTrace(ThrowableProxy.java:689)    at org.apache.logging.log4j.core.impl.ThrowableProxy.&lt;init&gt;(ThrowableProxy.java:138)    at org.apache.logging.log4j.core.impl.ThrowableProxy.&lt;init&gt;(ThrowableProxy.java:122)    at org.apache.logging.log4j.core.impl.Log4jLogEvent.getThrownProxy(Log4jLogEvent.java:564)    at org.apache.logging.log4j.core.pattern.ExtendedThrowablePatternConverter.format(ExtendedThrowablePatternConverter.java:63)    at org.apache.logging.log4j.core.pattern.PatternFormatter.format(PatternFormatter.java:38)    at org.apache.logging.log4j.core.layout.PatternLayout$PatternSerializer.toSerializable(PatternLayout.java:333)    at org.apache.logging.log4j.core.layout.PatternLayout.toText(PatternLayout.java:232)    at org.apache.logging.log4j.core.layout.PatternLayout.encode(PatternLayout.java:217)    at org.apache.logging.log4j.core.layout.PatternLayout.encode(PatternLayout.java:57)    at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.directEncodeEvent(AbstractOutputStreamAppender.java:177)    at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.tryAppend(AbstractOutputStreamAppender.java:170)    at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.append(AbstractOutputStreamAppender.java:161)    at org.apache.logging.log4j.core.appender.RollingFileAppender.append(RollingFileAppender.java:268)    at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:156)    at org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:129)    at org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(AppenderControl.java:120)    at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:84)    at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:448)    at org.apache.logging.log4j.core.async.AsyncLoggerConfig.asyncCallAppenders(AsyncLoggerConfig.java:115)    at org.apache.logging.log4j.core.async.AsyncLoggerConfigDisruptor$Log4jEventWrapperHandler.onEvent(AsyncLoggerConfigDisruptor.java:112)    at org.apache.logging.log4j.core.async.AsyncLoggerConfigDisruptor$Log4jEventWrapperHandler.onEvent(AsyncLoggerConfigDisruptor.java:98)    at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:128)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1152)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:627)    at java.lang.Thread.run(Thread.java:861)\n\nlog4j2 相关类在 sofaark 插件中是导出的，因此当出现 log4j2 的类需要被加载时，会委托给 PluginClassLoader 进行加载。\nPatternLayout 中配置 %throwable 对于产生不同 Converter 的影响SOFABoot 开始执行加载 log4j2 的配置文件\n\n解析配置文件，并根据 PatternLayout 中的各个配置创建不同的 pc\n\n规则映射列表\n\n找到对应 Converter，然后通过反射创建此对象，然后放在 patternConverters 中去。\n\n什么情况下会产生 ExtendedThrowablePatternConverter ？这里有两个条件会产生这个 Converter\n配置 “xEx”, “xThrowable”, “xException”\nlog4j2 的配置文件中 PatternLayout 如果配置了 “xEx”, “xThrowable”, “xException”，由上面分析可以知道，解析时，rules 哪里匹配到对应 converterName，则会创建。\n没有配置 %throwable 时会创建为什么？来看下一段代码：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 给 PatternLayout 创建对应的 PatternFormatter，用于在输出日志时按指定的规则输出。// PatternFormatter 执行 format 要依赖 Converter// 1.alwaysWriteExceptions 默认为 true, 只能在配置文件中 配置修改。public List&lt;PatternFormatter&gt; parse(final String pattern, final boolean alwaysWriteExceptions,           final boolean disableAnsi, final boolean noConsoleNoAnsi) &#123;    final List&lt;PatternFormatter&gt; list = new ArrayList&lt;&gt;();    final List&lt;PatternConverter&gt; converters = new ArrayList&lt;&gt;();    final List&lt;FormattingInfo&gt; fields = new ArrayList&lt;&gt;();    parse(pattern, converters, fields, disableAnsi, noConsoleNoAnsi, true);    final Iterator&lt;FormattingInfo&gt; fieldIter = fields.iterator();    boolean handlesThrowable = false;\t// 当前 Logger 对应的所有 converters 集合，这里的 converters 是从上面 parse pattern 时按照     // pattern 的 style 生成的，    for (final PatternConverter converter : converters) &#123;        if (converter instanceof NanoTimePatternConverter) &#123;            // LOG4J2-1074 Switch to actual clock if nanosecond timestamps are required in config.            // LOG4J2-1248 set config nanoclock            if (config != null) &#123;                config.setNanoClock(new SystemNanoClock());            &#125;        &#125;        LogEventPatternConverter pc;        if (converter instanceof LogEventPatternConverter) &#123;             pc = (LogEventPatternConverter) converter;            // 目前官方提供的 converte在，还有 Throwable 的  handlesThrowable 返回是 true            // 所以，如果 pattern 中没有 %throwable, 这里会一直返回的都是 false            handlesThrowable |= pc.handlesThrowable();        &#125; else &#123;            pc = new LiteralPatternConverter(config, Strings.EMPTY, true);        &#125;        FormattingInfo field;        if (fieldIter.hasNext()) &#123;            field = fieldIter.next();        &#125; else &#123;            field = FormattingInfo.getDefault();        &#125;        list.add(new PatternFormatter(pc, field));    &#125;\t// alwaysWriteExceptions = true    // handlesThrowable 在配置 %throwable 时是 true，其他均为 false    // 也就是说当前 Logger 没有配置 %throwable 时，就会创建 ExtendedThrowablePatternConverter    // 作为默认的异常处理 Converter    if (alwaysWriteExceptions &amp;&amp; !handlesThrowable) &#123;        final LogEventPatternConverter pc = ExtendedThrowablePatternConverter.newInstance(config, null);        list.add(new PatternFormatter(pc, FormattingInfo.getDefault()));    &#125;    return list;&#125;\n\n结论：根据 pattern 中的不同元素类型，产生不同类型的 PatternConverter，如果在日志文件中配置了 %throwable , 则会对应产生一个 ThrowablePatternConverter 类型的 PatternConverter。如果没有配置 %throwable，则默认使用 ExtendedThrowablePatternConverter。\nconverter 差异分析不同 PatternConverter 的作用是在日志输出时做相应数据的 format，所以对应 PatternConverter 来说，核心的方法就是 format 方法。下面看 ThrowablePatternConverter 和 ExtendedThrowablePatternConverter 的 format 方法差异。\nThrowablePatternConverter#format1234567891011@Overridepublic void format(final LogEvent event, final StringBuilder buffer) &#123;    final Throwable t = event.getThrown();    if (isSubShortOption()) &#123;        formatSubShortOption(t, getSuffix(event), buffer);    &#125;    else if (t != null &amp;&amp; options.anyLines()) &#123;        formatOption(t, getSuffix(event), buffer);    &#125;&#125;\n\nformatOption 就是把 Throwable 的 stackTracer 写到 buffer 中\nExtendedThrowablePatternConverter#format1234567891011121314151617181920212223242526272829303132@Overridepublic void format(final LogEvent event, final StringBuilder toAppendTo) &#123;    // 这里多了一个 getThrownProxy    final ThrowableProxy proxy = event.getThrownProxy();    final Throwable throwable = event.getThrown();    if ((throwable != null || proxy != null) &amp;&amp; options.anyLines()) &#123;        if (proxy == null) &#123;            super.format(event, toAppendTo);            return;        &#125;        String suffix = getSuffix(event);        final String extStackTrace = proxy.getExtendedStackTraceAsString(options.getIgnorePackages(), options.getTextRenderer(), suffix);        final int len = toAppendTo.length();        if (len &gt; 0 &amp;&amp; !Character.isWhitespace(toAppendTo.charAt(len - 1))) &#123;            toAppendTo.append(&#x27; &#x27;);        &#125;        if (!options.allLines() || !Strings.LINE_SEPARATOR.equals(options.getSeparator())) &#123;            final StringBuilder sb = new StringBuilder();            final String[] array = extStackTrace.split(Strings.LINE_SEPARATOR);            final int limit = options.minLines(array.length) - 1;            for (int i = 0; i &lt;= limit; ++i) &#123;                sb.append(array[i]);                if (i &lt; limit) &#123;                    sb.append(options.getSeparator());                &#125;            &#125;            toAppendTo.append(sb.toString());        &#125; else &#123;            toAppendTo.append(extStackTrace);        &#125;    &#125;&#125;\n\nfinal ThrowableProxy proxy = event.getThrownProxy() 结合最上面的异常堆栈来看，在构建 ThrowableProxy 对象实例时会去对堆栈中的数据进行序列化操作构建 CacheEntry（toExtendedStackTrace）,从而触发类加载动作。\n\n\n\n\n\n\n\n\n\nA proxy is used to represent a throwable that may not exist in a different class loader or JVM. When an application deserializes a ThrowableProxy, the throwable may not be set, but the throwable’s information is preserved in other fields of the proxy like the message and stack trace.\n附1：Disruptor 消费者的等待策略-DAsyncLoggerConfig.WaitStrategy&#x3D;xxx\n\n\n\n名称\n措施\n场景\n\n\n\nBlockingWaitStrategy\n加锁\nCPU资源紧缺，吞吐量和延迟并不重要的场景\n\n\nBusySpinWaitStrategy\n自旋\n通过不断重试，减少切换线程导致的系统调用，而降低延迟。推荐在线程绑定到固定的CPU的场景下使用\n\n\nPhasedBackoffWaitStrategy\n自旋 + yield + 自定义策略\nCPU资源紧缺，吞吐量和延迟并不重要的场景\n\n\nSleepingWaitStrategy\n自旋 + yield + sleep\n性能和CPU资源之间有很好的折中。延迟不均匀\n\n\nTimeoutBlockingWaitStrategy\n加锁，有超时限制\nCPU资源紧缺，吞吐量和延迟并不重要的场景\n\n\nYieldingWaitStrategy\n自旋 + yield + 自旋\n性能和CPU资源之间有很好的折中。延迟比较均匀\n\n\n深色底纹为默认策略\n附2：Disruptor 队列长度并配置队列堵塞丢弃策略\n-Dlog4j2.AsyncQueueFullPolicy&#x3D;Default&#x2F;Discard   (默认 Default )\n\n-Dlog4j2.DiscardThreshold&#x3D;ERROR&#x2F;INFO&#x2F;…    （默认 info)\n\n\n1、DefaultAsyncQueueFullPolicy—等待队列，转为同步操作策略(默认)1234567891011public class DefaultAsyncQueueFullPolicy implements AsyncQueueFullPolicy &#123;    @Override    public EventRoute getRoute(final long backgroundThreadId, final Level level) &#123;        // LOG4J2-1518: prevent deadlock when RingBuffer is full and object being logged calls        // Logger.log in application thread        // See also LOG4J2-471: prevent deadlock when RingBuffer is full and object        // being logged calls Logger.log() from its toString() method in background thread        return EventRoute.SYNCHRONOUS;    &#125;&#125;\n\n2、DiscardingAsyncQueueFullPolicy—按照日志等级抛弃日志策略12345678910111213@Overridepublic EventRoute getRoute(final long backgroundThreadId, final Level level) &#123;    if (level.isLessSpecificThan(thresholdLevel)) &#123;        if (discardCount.getAndIncrement() == 0) &#123;            LOGGER.warn(&quot;Async queue is full, discarding event with level &#123;&#125;. &quot; +                        &quot;This message will only appear once; future events from &#123;&#125; &quot; +                        &quot;are silently discarded until queue capacity becomes available.&quot;,                        level, thresholdLevel);        &#125;        return EventRoute.DISCARD;    &#125;    return super.getRoute(backgroundThreadId, level);&#125;\n\n附3：Disruptor 默认队列大小\n-DAsyncLogger.RingBufferSize&#x3D;xxx\n\n12345678910111213141516171819202122// propertyName -&gt; AsyncLoggerConfig.RingBufferSizestatic int calculateRingBufferSize(final String propertyName) &#123;    // Constants.ENABLE_THREADLOCALS 默认 false    // RINGBUFFER_NO_GC_DEFAULT_SIZE 4096    // 256 * 1024=262144    int ringBufferSize = Constants.ENABLE_THREADLOCALS ? RINGBUFFER_NO_GC_DEFAULT_SIZE : RINGBUFFER_DEFAULT_SIZE;    final String userPreferredRBSize = PropertiesUtil.getProperties().getStringProperty(propertyName,                                                                                        String.valueOf(ringBufferSize));    try &#123;        int size = Integer.parseInt(userPreferredRBSize);        // RINGBUFFER_MIN_SIZE=128        if (size &lt; RINGBUFFER_MIN_SIZE) &#123;            size = RINGBUFFER_MIN_SIZE;            LOGGER.warn(&quot;Invalid RingBufferSize &#123;&#125;, using minimum size &#123;&#125;.&quot;, userPreferredRBSize,                        RINGBUFFER_MIN_SIZE);        &#125;        ringBufferSize = size;    &#125; catch (final Exception ex) &#123;        LOGGER.warn(&quot;Invalid RingBufferSize &#123;&#125;, using default size &#123;&#125;.&quot;, userPreferredRBSize, ringBufferSize);    &#125;    return Integers.ceilingNextPowerOfTwo(ringBufferSize);&#125;\n\n\nConstants.ENABLE_THREADLOCALS 这个值分为 web 和 非 web 应用两种情况，非 web 应用时，默认是 true，web 应用默认是 false，判断依据是，classpath 是否有 javax.servlet.Servlet 类。可以通过 -Dlog4j2.is.webapp=true/false 来手动设定。\n\n\n\n\n\n\n\n\n\nps: -Dlog4j2.enable.threadlocals：  This system property can be used to switch off the use of threadlocals, which will partly disable Log4j’s garbage-free behaviour: to be fully garbage-free, Log4j stores objects in ThreadLocal fields to reuse them, otherwise new objects are created for each log event. Note that this property is not effective when Log4j detects it is running in a web application.\n","slug":"sofa/sofa-ark-plugin-classloader-log4j","date":"2021-11-01T03:10:19.000Z","categories_index":"SOFA","tags_index":"gc,ClassLoader,SOFAArk,log,类加载","author_index":"glmapper"},{"id":"9622fa03747232916676b6477e1a4975","title":"记：SOFA Meepup 合肥站-SOFA 微服务体系技术生态于实践","content":"SOFA Meepup 合肥站从 5 月份开始筹划，至 7.24 在合肥成功举办，历时 2 个多月的时间，从到场人数来看，并没有受到大雨的影响，合肥开发者同学对于技术的热衷没有我们预想的那么佛系，尤其是在微服务领域。在线观看人数也大于预测，这对于所有参与组织活动的同学及给予大力支持的社区来说，都是极大的鼓励和反馈。\n点点滴滴，希望以文字的形式记录下来，记录这次活动之旅。\n\n\n\n缘起SOFA 是蚂蚁集团（当时叫蚂蚁金服）在 2018 年一季度开始陆陆续续对外开源的一系列产品族，除了微服务体系之外，还有云原生相关的产品组件。期间历经一次品牌升级，托管的 github 仓库也从 alipay 迁移至 sofastack，目前蚂蚁集团 SOFA 产品在社区由 sofastack 社区和蚂蚁集团 sofa 团队共同维护发展。下面是其官网地址和 github 仓库地址：\n官网：https://www.sofastack.tech/github： https://github.com/sofastack其实在 2019 年的时候，将 SOFA Meetup 活动办到合肥的想法已经萌生，只不过局限于当时的一些特殊情况，没能继续推进这个事情的落地。2021 年 5 月份，我从蚂蚁集团 SOFA 团队离职，当时和 SOFA 团队负责人鲁大师（鲁直）又提及这个事情，他表示非常支持 SOFA Meetup 在合肥举办，所以在推进这个事情上给我打了一针强心剂。\n回到合肥之后，第一时间和安徽开发者社区（嗨码社区）江总（江冬勤，阿里云 mvp）一起，就 SOFA Meetup 在合肥举办的事情做了初步的沟通，并着手联系 sofastack 社区负责同学，开始推进活动落地，随后活动社区发起者合肥清博大数据王总（王欢）、七牛老白、apisix 头哥也加入到活动策划小组中来，使得活动的整体落地节奏大大加快。\n进行时\n\n\n\n\n\n\n\n\n2019 年，我曾以讲师的身份参与了 sofa meetup 上海站的活动，当时并没有觉得举办活动是个多麻烦的事情，定个场地，发发宣传这种；但是作为参与整个合肥站从发起到结束这样的整个流程人来说，才知道是真的不容易，这里必须给 SOFAGirl 花花（英花）同学点赞：从准备阶段的法务、财务申请审批、进度同步、内容审核、讲师安排，到物料、场地、直播，再到现场安排、主持… 从来都亲力亲为。\n临近活动，sofastack 社区同学和头哥从上海、成都、杭州等地陆续赶来，受 “烟花” 台风影响，他们的高铁乘次都遭遇了被取消的问题，虽然活动有备案，是进行视频直播分享，但相对于现场分享来说，其力度和影响是远远不够的，大家又紧急的调整购买了可行的乘次，sofastack 有两位同学直到晚上 9 点多才到合肥，头哥也是抽出了陪孩子的时间，50 分钟的分享，花几个小时折返沪庐。\n活动是 7.24 号下午 1.30 开始，合肥早上天气还是挺好的，有点风，不下雨；到了中午 12.30 左右，天气换了个风格，开始降起了暴雨，当时我们在会场调侃说，本来报名的同学是已经开始准备过来参加活动了，刚准备出门看到这么大的雨，然后就不来了。但是事实是，大雨并没有对此产生多大的影响，至中场休息前，会前准备的座位已经不够了，又在后面加了一排；这也说明了，对于技术人来说，无关环境，期望的是通过技术分享来接收一些新的知识理念和技术思路，是学习的态度。\n\n好事多磨，后续的一切都顺利进行。1.30 开始，英花做了开场主持，老白介绍了社区的一些情况，我做了《微服务技术生态体系》的主题开场，后面就是讲师们精彩的 topic 分享。\n1、禅总（忘禅）《蚂蚁注册中心 SOFARegistry 分享》\n头哥（王晔倞）《基于API 网关的微服务治理演进与架构实践》\n纶珥小师弟《蚂蚁集团分布式链路组件 SOFATracer 原理与实践》\n思科吕思泉老师《准实时的日志聚合平台》\nMOSN Boy 良恩《Service Mesh 在蚂蚁集团的实践》\n资料获取ppt 资料可以从 sofastack 官网直接下载：https://www.sofastack.tech/activities/sofa-meetup-8/\n相聚sofastack 是我深度参与的第一个开源项目，也经历了从 sofa 团队成员到 sofastack 社区成员的角色变换。这次来合肥的 sofastack 讲师和运营同学，曾都是我在 sofa 团队时并肩作战的小伙伴和师兄，晚上在接到他们时，感觉格外亲切，吃饭唠嗑，逛逛合肥的罍街，夜游天鹅湖，比较遗憾的是，没有留下多一些合影留念。\n感想参与技术社区，不仅仅是出于对于技术的追求和热爱，更珍贵的是可以认识很多非常优秀的技术人和同路者；最后感谢各位来到现场的同学和在线观看直播和互动的同学，你们的参与是社区更具活力的根本。\n\n","slug":"share/shares-sofa-meetup-7","date":"2021-07-25T08:06:55.000Z","categories_index":"experience","tags_index":"SOFA","author_index":"glmapper"},{"id":"d753fae6fcae22e0a4f351ebed82c72a","title":"使用 docker 部署 kafka 集群","content":"\n\n\n\n\n\n\n\n\n参考文档：https://github.com/wurstmeister/kafka-docker\n在你的文件系统中找个目录，然后新建一个 docker-compose.yaml 文件\n123➜  kafka-guides total 8-rw-r--r--@ 1 sgl  staff   1.1K  7 13 21:56 docker-compose.yaml\n\n编辑 docker-compose.yaml 文件\n\n\n12345678910111213141516171819202122232425262728version: &#x27;2&#x27;services:  zookeeper:    image: wurstmeister/zookeeper   ## zk 镜像    ports:      - &quot;2181:2181&quot;                 ## 对外暴露的端口号  kafka:    image: wurstmeister/kafka       ## kafka 镜像    volumes:        - /etc/localtime:/etc/localtime ## 挂载位置（kafka镜像和宿主机器之间时间保持一致）    ports:      - &quot;9092:9092&quot;    environment:      KAFKA_ADVERTISED_HOST_NAME: 192.168.10.67     ## 修改:宿主机IP  ---- 192.168.10.67  是我当前的机器ip      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181       ## kafka 运行是基于zookeeper的      KAFKA_ADVERTISED_PORT: 9092      KAFKA_LOG_RETENTION_HOURS: 120      KAFKA_MESSAGE_MAX_BYTES: 10000000      KAFKA_REPLICA_FETCH_MAX_BYTES: 10000000      KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS: 60000      KAFKA_NUM_PARTITIONS: 3      KAFKA_DELETE_RETENTION_MS: 1000  kafka-manager:    image: sheepkiller/kafka-manager                ## 镜像：kafka-manager    environment:        ZK_HOSTS: 192.168.10.67                     ## 修改:宿主机IP    ports:      - &quot;9001:9000&quot;                                 ## 暴露端口 9001\n\n启动服务：\n12345678910111213141516171819202122~ docker-compose up -d# 执行日志大致如下Pulling kafka (wurstmeister/kafka:)...latest: Pulling from wurstmeister/kafka540db60ca938: Pull complete789c480dd801: Pull complete0705a4c47ffe: Pull complete661f40345821: Pull completea84fa3c6a2b3: Pull completeDigest: sha256:4bad02cf8f07d0bf65d5cc73cce7aa75f9a90e32b585f867fce7c3fff229bd6dStatus: Downloaded newer image for wurstmeister/kafka:latestPulling kafka-manager (sheepkiller/kafka-manager:)...latest: Pulling from sheepkiller/kafka-manager469cfcc7a4b3: Pull complete4458b033eac3: Pull complete838a0ff6e24f: Pull complete0128a98dafdb: Pull completeDigest: sha256:615f3b99d38aba2d5fdb3fb750a5990ba9260c8fb3fd29c7e776e8c150518b78Status: Downloaded newer image for sheepkiller/kafka-manager:latestCreating kafka-guides_kafka-manager_1 ... doneCreating kafka-guides_zookeeper_1     ... doneCreating kafka-guides_kafka_1         ... done\n\n此时可以通过访问 http://localhost:9001/ 来打开 kafka manager 页面进行验证。也可以通过 docker-compose ps 查看\n1234567➜  kafka-guides docker-compose ps            Name                          Command               State                        Ports------------------------------------------------------------------------------------------------------------------------kafka-guides_kafka-manager_1   ./start-kafka-manager.sh         Up      0.0.0.0:9001-&gt;9000/tcp,:::9001-&gt;9000/tcpkafka-guides_kafka_1           start-kafka.sh                   Up      0.0.0.0:9092-&gt;9092/tcp,:::9092-&gt;9092/tcpkafka-guides_zookeeper_1       /bin/sh -c /usr/sbin/sshd  ...   Up      0.0.0.0:2181-&gt;2181/tcp,:::2181-&gt;2181/tcp,                                                                        22/tcp, 2888/tcp, 3888/tcp\n\n停止服务 docker-compose stop\n123456# 停止服务➜  kafka-guides docker-compose stopStopping kafka-guides_kafka_1         ... doneStopping kafka-guides_zookeeper_1     ... doneStopping kafka-guides_kafka-manager_1 ... done\n\n停止并删除服务 docker-compose down\n","slug":"docker/docker-compose-kakfa-install","date":"2021-07-23T13:47:16.000Z","categories_index":"docker","tags_index":"docker,kafka","author_index":"glmapper"},{"id":"36de71f48064befd8223d8b0f7b379a4","title":"SpringAop 代理模式及 AopContext 问题小记","content":"AOP 称为面向切面编程，其底层原理就是动态代理；JAVA 中比较常见的动态代理有两种，分别是 JDK 动态代理和 CGLIB 动态代理，这点从 Spring Aop 的 AopProxy 的实现就可以得出验证。\n123AopProxy    --- JdkDynamicAopProxy    --- CglibAopProxy\n\nSpring 作为 Java 应用领域最牛 X 的基础框架产品，在对于一些版本变更导致的兼容性问题的处理上一直被诟病，对于这两种代理方式的选择上，Spring 不同版本存在一定的差异，这也是本文产生的一个原因。\n\n\n从一个异常说起本来是打算写个 AOP demo 来验证下 AopContext 在跨线程场景下丢失 proxy 对象问题的，由于在 pom 中指定依赖了 spring-aop 版本（5.1.2），而工程 spring-boot 版本使用是 2.4.2，启动时就抛出了如下的异常（仅截取了后 3 段 casuse by）：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;jdkServiceImpl&#x27; defined in file [/Users/sgl/Documents/projects/github/aop-guides/target/classes/com/glmapper/bridge/boot/jdk/JdkServiceImpl.class]: Initialization of bean failed; nested exception is org.springframework.aop.framework.AopConfigException: Unexpected AOP exception; nested exception is java.lang.IllegalStateException: Unable to load cache item\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:617)\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:531)\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)\tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1380)\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1300)\tat org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:640)\t... 46 moreCaused by: org.springframework.aop.framework.AopConfigException: Unexpected AOP exception; nested exception is java.lang.IllegalStateException: Unable to load cache item\tat org.springframework.aop.framework.CglibAopProxy.getProxy(CglibAopProxy.java:214)\tat org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:110)\tat org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.createProxy(AbstractAutoProxyCreator.java:473)\tat org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.wrapIfNecessary(AbstractAutoProxyCreator.java:352)\tat org.springframework.aop.framework.autoproxy.AbstractAutoProxyCreator.postProcessAfterInitialization(AbstractAutoProxyCreator.java:301)\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:444)\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1792)\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:609)\t... 55 moreCaused by: java.lang.IllegalStateException: Unable to load cache item\tat org.springframework.cglib.core.internal.LoadingCache.createEntry(LoadingCache.java:79)\tat org.springframework.cglib.core.internal.LoadingCache.get(LoadingCache.java:34)\tat org.springframework.cglib.core.AbstractClassGenerator$ClassLoaderData.get(AbstractClassGenerator.java:134)\tat org.springframework.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:319)\tat org.springframework.cglib.proxy.Enhancer.createHelper(Enhancer.java:572)\tat org.springframework.cglib.proxy.Enhancer.createClass(Enhancer.java:419)\tat org.springframework.aop.framework.ObjenesisCglibAopProxy.createProxyClassAndInstance(ObjenesisCglibAopProxy.java:58)\tat org.springframework.aop.framework.CglibAopProxy.getProxy(CglibAopProxy.java:205)\t... 62 moreCaused by: java.lang.VerifyError: Stack map does not match the one at exception handler 9Exception Details:  Location:    com/glmapper/bridge/boot/jdk/JdkServiceImpl$$EnhancerBySpringCGLIB$$3045df64.&lt;init&gt;()V @9: athrow  Reason:    Current frame&#x27;s flags are not assignable to stack map frame&#x27;s.  Current Frame:    bci: @0    flags: &#123; flagThisUninit &#125;    locals: &#123; uninitializedThis &#125;    stack: &#123; &#x27;java/lang/RuntimeException&#x27; &#125;  Stackmap Frame:    bci: @9    flags: &#123; &#125;    locals: &#123; &#125;    stack: &#123; &#x27;java/lang/Throwable&#x27; &#125;\n\n看到这个异常有点莫名其妙，然后尝试通过关键字去网上搜了下，确实找到了一个非常类似的 case Unexpected AOP exception; nested exception is java.lang.IllegalStateException: Unable to load cache item。从问题描述来看，大致有以下几个方向：\n\n1、spring boot devtools 热部署导致\n2、CGLIB 或 Objenesis 不理解 Java 13 字节代码\n3、依赖问题\n\n在我的 demo 中，1 和 2 都是未涉及的，所以将专注点放在 3 上面。一开始尝试 Stack map does not match the one at exception handler 9 全局查找，尝试找到产生堆栈的代码片段，实际上是没有在代码中找到的；随后翻看了 openjdk 的源码才找到。另一个比较疑惑的问题在于：这个异常产生仅当通过 run test unit 的时候才会有，正常通过启动工程并发起调用并不会出现。当我把 Spring Aop 版本切换到 5.3.3 时，run test unit 也可以正常被执行。\n图1：spring-aop 版本为 5.3.3, Class.forName 正常执行到下一行\n\n图2：spring-aop 版本为 5.1.2\n\n执行直接报错\n其实堆栈来看，两者并无差异。到这里不打算继续深究原因，回到 VerifyError 异常：\n\n\n\n\n\n\n\n\n\n当 “verifier” 检测到 classfile 虽然格式良好，但包含某种内部不一致或安全问题时抛出。\n加上产生的条件：在 springboot 测试场景下，使用低于管控版本的 spring aop 从而导致该问题；合理规避吧…\nSpring aop 动态代理机制在不同版本中的差异这里仅作为备忘点介绍一下，大多数情况下在使用的时候并不会关注到。\n\n1、Spring 5.x 版本开始，AOP 默认依旧使用 JDK 动态代理，并非网上说的默认改成了 CGLIB。\n2、SpringBoot 2.x 开始，由于使用 JDK 动态代理可能导致的类型转化异常问题，默认使用 CGLIB。\n3、SpringBoot 2.x 中，如果需要默认使用 JDK 动态代理可以通过配置项 spring.aop.proxy-target-class=false 来进行修改，proxyTargetClass 配置已无效。\n\n相关论证可以见：AopAutoConfiguration、@EnableAspectJAutoProxy 及官方文档说明。\nAopContext关于 AopContext 可能部分开发者对其是陌生的；但是有这样一种场景一定是你遇到过的：\n123456789101112131415@Servicepublic class JdkServiceImpl implements JdkService &#123;    @Override    @Metrics(name = &quot;helloJdk&quot;)    public void helloJdk() &#123;\t\t// invoke inner        inner();    &#125;    @Metrics(name = &quot;inner&quot;)    public void inner() &#123;        System.out.println(&quot;this is Jdk inner method&quot;);    &#125;&#125;\n\n当你写了一个自定义注解，然后通过 aop 去拦截时，对于类内部方法之间的调用无法拦截，如上代码片段，在 helloJdk 中调用 inner，同样打上了 @Metrics 注解，实际上 inner 的调用是不会被 aop 拦截到的；原因在于，这里的 inner 调用实际上等同于 this.inner()，而当前的 this 对象是 JdkServiceImpl 对象本身，并非代理类，所以切不到是正常的。\n\n那这里其实就可能通过 AopContext 来辅助一下，这里有个前提条件，通过注解添加配置（加在类上）：\n1@EnableAspectJAutoProxy(proxyTargetClass = true, exposeProxy = true)\n\n或通过 xml 配置文件添加配置：\n1&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; expose-proxy=&quot;true&quot;/&gt;\n\n否则会抛出如下错误：\n\n\n\n\n\n\n\n\n\nCannot find current proxy: Set ‘exposeProxy’ property on Advised to ‘true’ to make it available.\n原因在于，当 exposeProxy 为 true 时，才会将当前 proxy 对象塞到 AopContext 中。\n12345if (this.advised.exposeProxy) &#123;\t// Make invocation available if necessary.\toldProxy = AopContext.setCurrentProxy(proxy);\tsetProxyContext = true;&#125;\nAopContext 的实现很简单，就是在内部维护了一个 ThreadLocal：\n1private static final ThreadLocal&lt;Object&gt; currentProxy = new NamedThreadLocal&lt;&gt;(&quot;Current AOP proxy&quot;);\n\n所以在使用这个工具类的时候，还需要关注另一个问题，就是当在跨线程，或者使用线程池的情况下，需要手动将 proxy 透传到新的线程中，否则，即使开始 exposeProxy &#x3D; true，同样也会出现 Cannot find current proxy: Set ‘exposeProxy’ 报错。\n","slug":"spring/spring-proxy-aopcontext","date":"2021-07-17T08:17:04.000Z","categories_index":"spring","tags_index":"spring,aop","author_index":"glmapper"},{"id":"0092fc26e9bf86d6199cb316ea25f766","title":"你知道 Junit 是怎么跑的吗？","content":"Junit 是由 Kent Beck 和 Erich Gamma 于 1995 年底着手编写的框架，自此以后，Junit 框架日益普及，现在已经成为单元测试 Java 应用程序的事实上的标准。\n\n\n\n\n\n\n\n\n\n在软件开发领域中，从来没有这样的事情：少数几行代码对大量代码起着如此重要的作用 — Martin Fowler\n\n\n从一个简单的例子开始认识 Junit本文注重点在于研究 Junit 运行的基本原理和执行单元测试的流程，所以对于一些额外的信息和数据不单独准备，本文所使用的测试 case 如下：\n123456789101112131415161718192021222324252627282930313233343536package com.glmapper.bridge.boot;import org.junit.*;public class JunitSamplesTest &#123;    @Before    public void before()&#123;        System.out.println(&quot;.....this is before test......&quot;);    &#125;    @After    public void after()&#123;        System.out.println(&quot;.....this is after test......&quot;);    &#125;    @BeforeClass    public static void beforeClass()&#123;        System.out.println(&quot;.....this is before class test......&quot;);    &#125;    @AfterClass    public static void afterClass()&#123;        System.out.println(&quot;.....this is after class test......&quot;);    &#125;    @Test    public void testOne()&#123;        System.out.println(&quot;this is test one&quot;);    &#125;    @Test    public void testTwo()&#123;        System.out.println(&quot;this is test two&quot;);    &#125;&#125;\n执行结果如下：\n123456789.....this is before class test......Disconnected from the target VM, address: &#x27;127.0.0.1:65400&#x27;, transport: &#x27;socket&#x27;.....this is before test......this is test one.....this is after test...........this is before test......this is test two.....this is after test...........this is after class test......\n\n从代码和执行结果来看，BeforeClass 和 AfterClass 注解分别在测试类开始之前和之后执行，Before 和 After 注解在测试类中每个测试方法的前后执行。\n问题域从开发者的角度来看，对于任何一个技术产品组件，如果想要更好的使用它，就意味着必须了解它。通过上面提供的 case 可以看到，Junit 使用非常简单，基本 0 门槛上手，通过给测试的方法加一个 @Test 注解，然后将待测试逻辑放在 被 @Test 标注的方法内，然后 run 就好了。简单源于组件开发者的顶层抽象和封装，将技术细节屏蔽，然后以最简洁的 API 或者注解面向用户，这也是 Junit 能够让广大开发者容易接受的根本原因，值得我们借鉴学习。\n回归正题，基于上面分析，Junit 使用简单在于其提供了非常简洁的 API 和注解，那对于我们来说，这些就是作为分析 Junit 的基本着手点；通过这些，来拨开 Junit 的基本原理。基于第一节的小案例，这里抛出这样几个问题：\n\nJunit 是怎么触发执行的\n为什么被标注 @Test 注解的方法会被执行，而没有标注的不会\nBefore 和 After 执行时机\nBeforeClass 和 AfterClass 执行时机\nJunit 是怎么将执行结果收集并返回的（这里不关注 IDE 提供的渲染）\n\nJunit 是如何执行的？这里把断点直接打在目标测试方法位置，然后 debug 执行通过堆栈来找到用例执行的整个路径。因为本 case 是通过 idea 启动执行，所以可以看到的入口实际是被 idea 包装过的。但是这里也抓到了 JUnitCore 这样的一个入口。\nJUnitCore 是运行测试用例的门面入口，通过源码注释可以看到，JUnitCore 从 junit 4 才有，但是其向下兼容了 3.8.x 版本系列。我们在跑测试用例时，其实大多数情况下在本地都是通过 IDE 来触发用例运行，或者通过 mvn test 来运行用例，实际上，不管是 IDE 还是 mvn 都是对 JUnitCore 的封装。我们完全可以通过 main 方法的方式来运行，比如运行下面代码的 main 方法来通过一个 JUnitCore 实例，然后指定被测试类来触发用例执行，为了尽量使得堆栈更贴近 Junit 自己的代码，我们通过这种方式启动来减少堆栈对于代码执行路径的干扰。\n12345678910111213141516171819202122232425262728293031323334353637public class JunitSamplesTest &#123;    @Before    public void before()&#123;        System.out.println(&quot;.....this is before test......&quot;);    &#125;    @After    public void after()&#123;        System.out.println(&quot;.....this is after test......&quot;);    &#125;    @BeforeClass    public static void beforeClass()&#123;        System.out.println(&quot;.....this is before class test......&quot;);    &#125;    @AfterClass    public static void afterClass()&#123;        System.out.println(&quot;.....this is after class test......&quot;);    &#125;    @Test    public void testOne()&#123;        System.out.println(&quot;this is test one&quot;);    &#125;    @Test    public void testTwo()&#123;        System.out.println(&quot;this is test two&quot;);    &#125;    public static void main(String[] args) &#123;        JUnitCore jUnitCore = new JUnitCore();        jUnitCore.run(JunitSamplesTest.class);    &#125;&#125;\n这里得到了最简化的测试执行入口：如果使用 java 命令来引导启动，其实就是从 JunitCore 内部自己的 main 方法开始执行的\n1234567891011/**  * Run the tests contained in the classes named in the args. If all tests run successfully, exit with a status of 0. Otherwise exit with a status of 1. Write * feedback while tests are running and write stack traces for all failed tests after the tests all complete. * Params: * args – names of classes in which to find tests to run **/public static void main(String... args) &#123;    Result result = new JUnitCore().runMain(new RealSystem(), args);    System.exit(result.wasSuccessful() ? 0 : 1);&#125;\n\n为什么被标注 @Test 注解的方法会被执行，而没有标注的不会这里比较好理解，被打了 @Test 注解的方法，一定是 Junit 通过某种方式将其扫描到了，然后作为待执行的一个集合或者队列中。下面通过分析代码来论证下。\n\n\n\n\n\n\n\n\n\norg.junit.runners.BlockJUnit4ClassRunner#getChildren\n1234@Overrideprotected List&lt;FrameworkMethod&gt; getChildren() &#123;    return computeTestMethods();&#125;\n\n通过方法 computeTestMethods 方法名其实就可以看出其目的，就是计算出所有的测试方法。\n\ngetAnnotatedMethods 通过指定的 annotationClass 类型，将当前 TestClass 中类型为 annotationClass 类型注解标注的方法过滤出来，\n\ngetFilteredChildren 中最后将获取得到的测试方法放在 filteredChildren 中缓存起来。这里简单汇总下 @Test 注解被识别的整个过程（其他注解如 @Before 都是一样的）\n\n1、Junit 在初始化构建 Runner 的过程，内部会基于给定的 测试类创建一个 TestClass 对象模型，用于描述当前测试类在 Junit 中的表示。\n1234567891011121314151617181920// clazz 是待测试类public TestClass(Class&lt;?&gt; clazz) &#123;    this.clazz = clazz;    if (clazz != null &amp;&amp; clazz.getConstructors().length &gt; 1) &#123;        // 测试类不能有有参构造函数        throw new IllegalArgumentException(            &quot;Test class can only have one constructor&quot;);    &#125;    Map&lt;Class&lt;? extends Annotation&gt;, List&lt;FrameworkMethod&gt;&gt; methodsForAnnotations =        new LinkedHashMap&lt;Class&lt;? extends Annotation&gt;, List&lt;FrameworkMethod&gt;&gt;();    Map&lt;Class&lt;? extends Annotation&gt;, List&lt;FrameworkField&gt;&gt; fieldsForAnnotations =        new LinkedHashMap&lt;Class&lt;? extends Annotation&gt;, List&lt;FrameworkField&gt;&gt;();    // 扫描待测试类中所有的 Junit 注解，包括 @Test @Before @After 等等    scanAnnotatedMembers(methodsForAnnotations, fieldsForAnnotations);\t// 过滤出打在方法上的注解，    this.methodsForAnnotations = makeDeeplyUnmodifiable(methodsForAnnotations);    // 过滤出打在变量上的注解    this.fieldsForAnnotations = makeDeeplyUnmodifiable(fieldsForAnnotations);&#125;\nmethodsForAnnotations 和 fieldsForAnnotations 缓存了当前待测试类所有被 junit 注解标注过的方法和变量\n\n2、getFilteredChildren 中，从 methodsForAnnotations 中筛选出所有 @Test 注解标注的方法。（getDescription()-&gt; getFilteredChildren -&gt; computeTestMethods -&gt; 从 methodsForAnnotations 按类型过滤）\n\n3、返回所有 @Test 注解标注的方法\n\n\nBefore 和 After 执行时机要搞定这个问题，其实有必要了解下 Junit 中一个比较重要的概念 Statement。\n123456public abstract class Statement &#123;    /**     * Run the action, throwing a &#123;@code Throwable&#125; if anything goes wrong.     */    public abstract void evaluate() throws Throwable;&#125;\n\nStatement 从 junit 4.5 版本被提出，Statement 表示在运行 JUnit 测试组件的过程中要在运行时执行的一个或多个操作，简单说就是，对于被 @Before @After 注解标注的方法，在 JUnit 会被作为一种 Statement 存在，分别对应于 RunBefores 和 RunnerAfter，这些 statement 中持有了当前运行所有的 FrameworkMethod。\nFrameworkMethod 是 JUnit 中所有被 junit 注解标注方式的内部描述，@Test, @Before, @After, @BeforeClass, @AfterClass 标注的方法最终都作为 FrameworkMethod 实例存在。\nStatement 的创建有两种方式，基于 FrameworkMethod 的 methodBlock 和基于 RunNotifier 的 classBlock，这里介绍 methodBlock ，classBlock 下节讨论。\n12345678910111213141516171819202122protected Statement methodBlock(final FrameworkMethod method) &#123;        Object test;        try &#123;            test = new ReflectiveCallable() &#123;                @Override                protected Object runReflectiveCall() throws Throwable &#123;                    return createTest(method);                &#125;            &#125;.run();        &#125; catch (Throwable e) &#123;            return new Fail(e);        &#125;        Statement statement = methodInvoker(method, test);        statement = possiblyExpectingExceptions(method, test, statement);        statement = withPotentialTimeout(method, test, statement);        statement = withBefores(method, test, statement);        statement = withAfters(method, test, statement);        statement = withRules(method, test, statement);        statement = withInterruptIsolation(statement);        return statement;    &#125;\n\nwithAfters、withBefores 会将 RunAfters 和 RunBefore 绑定到 statement，最后 形成一个 statement 链，这个链的执行入口时 RunAfters#evaluate。\n12345678910111213141516171819@Overridepublic void evaluate() throws Throwable &#123;    List&lt;Throwable&gt; errors = new ArrayList&lt;Throwable&gt;();    try &#123;        next.evaluate();    &#125; catch (Throwable e) &#123;        errors.add(e);    &#125; finally &#123;        // 在 finally 中执行 after 方法        for (FrameworkMethod each : afters) &#123;            try &#123;                invokeMethod(each);            &#125; catch (Throwable e) &#123;                errors.add(e);            &#125;        &#125;    &#125;    MultipleFailureException.assertEmpty(errors);&#125;\n\nnext 链中包括 before 和待执行的测试方法\n所以我们看到的就是 before -&gt; testMethod -&gt; after。\n\n\n\n\n\n\n\n\n\n这里其实和预想的不太一样，关于 before 和 after 这种逻辑，第一想法是通过代理的方式，对测试方法进行代理拦截，类似 Spring AOP 中的 Before 和 After，其实不然。\nBeforeClass 和 AfterClass 执行时机前面分析了 methodBlock，了解到 junit 中通过这个方法创建 statement 并且将 before 和 after 的方法绑定给 statement，以此推断，classBlock 的作用就是将 BeforeClass 和 AfterClass 绑定给statement 。\n1234567891011protected Statement classBlock(final RunNotifier notifier) &#123;    // childrenInvoker 这里会调用到 methodBlock    Statement statement = childrenInvoker(notifier);    if (!areAllChildrenIgnored()) &#123;        statement = withBeforeClasses(statement);        statement = withAfterClasses(statement);        statement = withClassRules(statement);        statement = withInterruptIsolation(statement);    &#125;    return statement;&#125;\n\nBeforeClass 和 before 都会对应创建一个 RunnerBefores，区别在于 BeforeClass 在创建 RunnerBefores 时，不会指定目标测试方法。\n\nBeforeClass 在执行 statement 之前，运行该类和超类上所有非覆盖的@BeforeClass方法;如果有抛出异常，停止执行并传递异常。\nAfterClass 在执行 statement 链最后，在该类和超类上运行所有未覆盖的 @AfterClass 方法；始终执行所有 AfterClass 方法：如有必要，将前面步骤抛出的异常与来自 AfterClass 方法的异常合并到 org.junit.runners.model.MultipleFailureException 中。\n\nJunit 是怎么将执行结果收集并返回的junit 所有执行的结果都存放在 Result 中\n123456789101112// 所有 case 数private final AtomicInteger count;// 忽略执行的 case 数（被打了 ignore）private final AtomicInteger ignoreCount;// 失败 case 数private final AtomicInteger assumptionFailureCount;// 所有失败 case 的结果private final CopyOnWriteArrayList&lt;Failure&gt; failures;// 执行时间private final AtomicLong runTime;// 开始时间private final AtomicLong startTime;\n\nResult 中内置了一个默认的来监听器，这个监听器会在每个 case 执行完成之后进行相应的回调，Listener 如下：\n123456789101112131415161718192021222324252627282930313233343536@RunListener.ThreadSafeprivate class Listener extends RunListener &#123;// 设置开始时间    @Override    public void testRunStarted(Description description) throws Exception &#123;        startTime.set(System.currentTimeMillis());    &#125;        // 执行完所有 case    @Override    public void testRunFinished(Result result) throws Exception &#123;        long endTime = System.currentTimeMillis();        runTime.addAndGet(endTime - startTime.get());    &#125;    // 执行完某个 case    @Override    public void testFinished(Description description) throws Exception &#123;        count.getAndIncrement();    &#125;    // 执行完某个 case 失败    @Override    public void testFailure(Failure failure) throws Exception &#123;        failures.add(failure);    &#125;    // 执行完某个ignore case    @Override    public void testIgnored(Description description) throws Exception &#123;        ignoreCount.getAndIncrement();    &#125;    @Override    public void testAssumptionFailure(Failure failure) &#123;    // Assumption 产生的失败        assumptionFailureCount.getAndIncrement();    &#125;&#125;\n\n\n\n\n\n\n\n\n\nJUnit 4 开始在测试中支持假设 Assumptions，在 Assumptions 中，封装了一组使用的方法，以支持基于假设的条件测试执行。假设实际就是指定某个特定条件，假如不能满足假设条件，假设不会导致测试失败，只是终止当前测试。这也是假设与断言的最大区别，因为对于断言而言，会导致测试失败。\n所以 JUnit 通过监听器机制收集所有的测试信息，最终封装到 Result 中返回。\n总结Junit 中有一些比较基本的概念，比如 Runner，statement 等；在初始化时，默认情况下 junit 会构建出 BlockJUnit4ClassRunner 这样的一个 Runner，并且在这个 Runner 中会持有被测试类的所有信息。Runner 运行测试并在执行此操作时将重要事件通知 RunNotifier。\n\n\n\n\n\n\n\n\n\n也可以使用 RunWith 调用自定义 Runner，这里只要你的 Runner 是 org.junit.runner.Runner 子类即可；创建自定义运行程序时，除了在此处实现抽象方法外，还必须提供一个构造函数，这个构造函数将包含测试的类作为参数–如：SpringRunner。\nRunner 的 run 方法内部就是构建和执行 Statement 链的过程，Statement 中描述了单元测试中需要执行的一系列操作，每个 case 均以 RunnerAfter -&gt; TargetMethod -&gt; RunnerBefore 的执行顺序依次执行；执行过程中，junit 通过监听器机制回调 case 调用的每个生命周期阶段，并将各个case 执行的信息进行收集汇总，最终返回执行结果 Result。\n","slug":"tests/test-junit-run-principle","date":"2021-07-02T13:47:16.000Z","categories_index":"test","tags_index":"test,junit","author_index":"glmapper"},{"id":"9706f0d2ad5a1a3cd4e67af63c8aabab","title":"测试 Test Double","content":"TestDouble 简单理解就是测试替身，在多数情况下，我们的系统能够正常运行，不仅仅依托系统本身，还需要依赖一些外部服务，比如其他系统提供的 http、rpc 服务，系统自身以来的像 redis 缓存服务或者 mysql 这类数据库服务。在微服务场景下，业务按照业务领域将一个系统拆分为多个系统，系统之间的交互不仅仅是简单的 A-&gt;B，可能是 A -&gt;B -&gt; C -&gt;D，对于编写单元测试的开发者来说，当我需要编写系统A 的测试用例时，不可能去构建完整的调用链路，那么在测试工程中，通常会以 “测试替身” 来解决外部依赖所带来的测试复杂性问题。\n\n\n\n\n\n术语\n解释\n\n\n\nSUT（System Under Test）\n被测系统\n\n\nDOC（depended-on component）\n第三方依赖组件\n\n\n在进行单元测试时，使用 Test Double 最主要的目的就是减少被测试对象的依赖，使得测试更加单一，只需要关注在被测系统本身的一些测试场景；除此之外， Test Double 从某种角度来说，可以让测试案例执行的测试时间更短，运行也更稳定（替代了真实的外部依赖）。\nTest Double 和实际交付使用的实际对象还是存在本质差别的，所以在实际的测试过程中，不建议 Test Double 的过度使用，因为可能会造成测试场景和实际场景脱节。\n测试替身类型测试替身主要包括以下几种类型：\n\nDummy Object\nTest Stub\nTest Spy\nMock Object\nFake Object\n\n\nDummy Object虚拟对象，本质上不会对测试产生任何影响，实际上只作为类似参数填充类角色存在。\nTest Stub测试桩是用来接受SUT内部的间接输入(indirect inputs)，并返回特定的值给SUT。可以理解 Test Stub 是在SUT 内部打的一个桩，可以按照我们的要求返回特定的内容给 SUT，Test Stub 的交互完全在 SUT 内部，因此，它不会返回内容给测试案例，也不会对 SUT 内部的输入进行验证。\n\nTest Stub 是指一个完全代替待测系统依赖组件的对象，这个对象按照我们设计的输出与待测系统进行交互，可以理解是在待测系统内部打的一个桩。这个桩既不会与测试用例(代码)交互，也不会在待测系统内部进行验证。Test Stub常用于响应待测系统的请求，然后返回特定的值。接下来，这个值会对待测系统产生影响，然后我们就在测试用例里面去验证这个影响。\nTest Stub的实现方式一般有两种：\n\nHard-Coded Test Stub - 会返回固定 response 的 Test Stub\nConfigurable Test Stub - 会根据测试需求返回相应 response 的 Test Stub，可配置化 当我们遇到下面场景时，Test Stub就可以派上用场\n\n\n依赖组件无法使用，影响测试结果\n依赖组件运行太慢，影响测试速度\n成为Responder响应者，当需要给待测系统注入特定数据，从而对待测系统产生影响\n成为Saboteur破坏者，当需要给待测系统注入无效数据，从而对待测系统产生异常影响，观察待测系统如何处理错误情况\n\nTest SpyTest Spy像一个间谍，安插在了 SUT 内部，专门负责将 SUT 内部的间接输出(indirect outputs)传到外部。它的特点是将内部的间接输出返回给测试案例，由测试案例进行验证，Test Spy 只负责获取内部情报，并把情报发出去，不负责验证情报的正确性。\n\nTest Spy 是指一个待测系统依赖组件的替身，并且会捕捉和保存待测对象对依赖系统的输出，这个输出会用于测试代码中的验证。Test Spy 主要用于记录和验证待测对象对依赖系统的输出。\nTest Spy 是把待测对象对依赖系统的输出拿到了测试代码里面进行验证，这样的话，如果 SUT 的输出不符合期望，Test Spy 并不像 Mock Object 那样第一时间让测试失败，而是可以在测试代码中加入更多判断信息，让验证和测试结果更加可控和可视化。\nMock ObjectMock Object 和 Test Spy 有类似的地方，它也是安插在 SUT 内部，获取到 SUT 内部的间接输出(indirect outputs)，不同的是，Mock Object 还负责对情报(indirect outputs)进行验证，总部(外部的测试案例)信任 Mock Object 的验证结果。\n\n\n\n\n\n\n\n\n\n\nMock 更像是行为既定，通过 mock 对象预期输入产生预期输出。\nMock Object 一个重要的特点是它可以对无法在待测系统上直接被观察到的行为或输出进行验证。无法观察到的系统行为或输出可以是数据插入数据库，可以是数据写入文件，也可以是对其他组件的调用。以数据库类型 Mock Object 举例，这个 Mock 的数据库会去接受待测系统发过来的数据，并且对这个数据进行验证，一旦验证通过就会对数据进行处理(插入或更新操作)，然后测试代码会去验证插入是否成功。\nFake ObjectFake Object 并不关注 SUT 内部的间接输入(indirect inputs)或间接输出(indirect outputs)，它仅仅是用来替代一个实际的对象，并且拥有几乎和实际对象一样的功能，保证 SUT 能够正常工作。实际对象过分依赖外部环境，Fake Object 可以减少这样的依赖。这也是 Fake 和 Test Stub 最主要的区别。\n简单说就是采用更加简单的方法实现依赖组件的功能，典型的例子就是使用 H2 来代替 Mysql 的测试。\n参考文档\nbliki: TestDouble\nMocks Aren’t Stubs\nTest Double\n\n","slug":"tests/test-test-double","date":"2021-06-01T03:07:53.000Z","categories_index":"test","tags_index":"test,TestDouble","author_index":"glmapper"},{"id":"366cd935770e27ff74dc4ef2425c6648","title":"聊一聊 maven 生命周期和 maven 插件编写","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6919490393893502984\n最近接到一个业务同学的诉求：用户会在他们大数据平台新建很多模型表，但是再编写业务代码时，需要手动的去创建和模型表对应的 DO 类，那对于有少量表的情况还可以接受，但是对于十几张甚至几十张表的情况，就会很头疼。\n我们知道 mybatis 实际上是有提供类似插件工具（mybatis-generator）的，社区也有非常多类似的代码生成工具，但是受限于一些情况，没有办法采用它们，那最简单的就是自己写个插件来完成这种工作量大且重复性高的事情。\n\n\n\nmaven 大家一定都不陌生，这篇文章不对 maven 中的一些概念和插件生命周期进行说明，网上资料很多，仅记录如何去如何编写一个 maven 插件。\nmaven 插件和普通的 maven 项目的区别不大，它也有自己的 GAV。区别在于， 每一个 maven 插件会包含了一些列的 goal，每一个 goal 对应于一个 Mojo 类，这个 Mojo 类需要实现org.apache.maven.plugin.Mojo 这个接口，Mojo 接口中提供了一个需要子类实现的 execute 方法。在实际的开发插件工作中，我们的任务其实就是实现这个 execute 方法里面的逻辑，在 execute 方法中去把插件需要做的事情处理好。下面先简单介绍下 maven 里面的一些基本知识：生命周期、阶段、goal，最后再来写一个 maven 插件。\nmaven 生命周期Maven 构建遵循特定的生命周期来部署和分发目标项目，maven 中有三个内置的生命周期：\n\ndefault：负责项目部署的主要生命周期\nclean：清理上一次 build 产生的所有的文件(target&#x2F;)\nsite：创建项目的站点文档\n\n每个生命周期由一系列阶段组成；默认的构建生命周期包括 23 个阶段，这些是主要的构建生命周期。另一方面，clean 生命周期由 3 个阶段组成，而 site 生命周期由4个阶段组成。下面详细说下这些阶段。\nmaven 阶段Maven 阶段表示 Maven 构建生命周期中的各个阶段，每个阶段负责一个特定的任务，默认的包括以下这些：\n\nvalidate：检查构建所需的所有信息是否都可用\ncompile：编译源代码\ntest-compile：编译测试源代码\ntest：运行单元测试\npackage：打包(产物常见的如：jar, war，…)\nintegration-test：集成测试\ninstall：将包安装到本地存储库\ndeploy：将包 deploy 到远程存储库\n\nmaven 中的阶段是有先后顺序只分的，当运行靠后的阶段时，前面的也会执行，但是也可以通过一些参数来跳过一些操作，最常见的就是 skipTests 。\n比如，当我们执行\n1mvn install\n\n\n可以看到，compile、test 等比较靠前的阶段也都被执行了。\nmaven goal生命周期中会有阶段，阶段中会有一些列目标，每个目标负责一个特定的任务；当我们运行一个阶段时，默认会绑定到这个阶段的所有目标都按顺序执行。下面以 compile 为例：\n以下是一些与之相关的阶段和默认目标:\n\ncompile:compile -&gt; 编译器插件的编译目标绑定到编译阶段\ncompile:testCompile -&gt; 被绑定到测试编译阶段\n\n怎么去看特定阶段的目标和他的插件信息呢？mvn help:describe -Dcmd=PHASENAME，比如：\n1mvn help:describe -Dcmd=compile\n\n123456789101112131415161718192021222324252627[INFO] &#x27;compile&#x27; is a phase corresponding to this plugin:org.apache.maven.plugins:maven-compiler-plugin:3.1:compileIt is a part of the lifecycle for the POM packaging &#x27;jar&#x27;. This lifecycle includes the following phases:* validate: Not defined* initialize: Not defined* generate-sources: Not defined* process-sources: Not defined* generate-resources: Not defined* process-resources: org.apache.maven.plugins:maven-resources-plugin:2.6:resources* compile: org.apache.maven.plugins:maven-compiler-plugin:3.1:compile* process-classes: Not defined* generate-test-sources: Not defined* process-test-sources: Not defined* generate-test-resources: Not defined* process-test-resources: org.apache.maven.plugins:maven-resources-plugin:2.6:testResources* test-compile: org.apache.maven.plugins:maven-compiler-plugin:3.1:testCompile* process-test-classes: Not defined* test: org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test* prepare-package: Not defined* package: org.apache.maven.plugins:maven-jar-plugin:2.4:jar* pre-integration-test: Not defined* integration-test: Not defined* post-integration-test: Not defined* verify: Not defined* install: org.apache.maven.plugins:maven-install-plugin:2.4:install* deploy: org.apache.maven.plugins:maven-deploy-plugin:2.7:deploy\n\n编写一个插件编写一个插件大体可以分为以下几步：\nstep1：新建一个 maven-archetype-mojo\nstep2：添加一个 mojo 类123456@Mojo(name = &quot;build-glmapper&quot;, defaultPhase = LifecyclePhase.PACKAGE, threadSafe = true, requiresDependencyResolution = ResolutionScope.RUNTIME, requiresDependencyCollection = ResolutionScope.RUNTIME)public class RepackageMojo extends AbstractMojo &#123;    public void execute() throws MojoExecutionException, MojoFailureException &#123;        getLog().info(&quot;this is a test case for mojo&quot;);    &#125;&#125;\n\nstep3：pom.xml 处理pom 里面，首先是 packaging 不是 pom 也不是 jar，而是\n1&lt;packaging&gt;maven-plugin&lt;/packaging&gt;\n\n引入一些必要的依赖：\n123456789101112131415161718192021222324&lt;dependency&gt;      &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;      &lt;artifactId&gt;maven-archiver&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;    &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;    &lt;artifactId&gt;maven-plugin-api&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;    &lt;artifactId&gt;maven-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.maven.plugin-tools&lt;/groupId&gt;    &lt;artifactId&gt;maven-plugin-annotations&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.maven.shared&lt;/groupId&gt;    &lt;artifactId&gt;maven-common-artifact-filters&lt;/artifactId&gt;&lt;/dependency&gt;\n\n引入打包插件的 plugin\n12345678910111213141516&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-plugin-plugin&lt;/artifactId&gt;            &lt;version&gt;3.5&lt;/version&gt;            &lt;configuration&gt;                &lt;mojoDependencies&gt;                \t&lt;!-- plugin 的名字 --&gt;                    &lt;dependency&gt;com.bridge.glmapper.boot:glmapper-plugin&lt;/dependency&gt;                &lt;/mojoDependencies&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n\nstep4：install 你的插件 &amp; 测试插件允许\n引入的工程中通过 maven plugin 菜单也能看到：\n\n这里有个小细节，就是执行插件的阶段，比如我们的插件名字是 glmapper-plugin，但是实际上执行时使用的是 glmapper，也就是当插件名满足：xxx-maven-plugin 或maven-xxx-plugin命名规则时，可以直接使用 xxx，即可。\n总结本文简单介绍了下 maven 的一些基础知识，以供备忘，也通过一个小 case 介绍了如何编写一个 maven plugin，如果你觉得还不错，欢迎点赞支持！！！\n","slug":"maven/maven-plugin-lifecycle-program","date":"2021-01-19T03:05:33.000Z","categories_index":"maven","tags_index":"maven,maven plugin","author_index":"glmapper"},{"id":"7765f5a7acd8dc6c589523580059b0dd","title":"启动一个没有 main 函数的 java 程序","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6918637397857009677\n作为一名 JAVA 开发者，不知道大家有没有去想过，JAVA  程序为什么一定要从 main 函数执行开始，其实关于这个话题，我大概从网上搜了下，其实不乏有 main 方法是我们学习Java语言学习的第一个方法，也是每个 java 使用者最熟悉的方法, 每个 Java 应用程序都必须有且仅有一个 main 方法 这种说法。那么真的是这样吗？今天就来聊聊这个事情。\n\n\n为什么 main 函数是 java 执行入口我们在通过一般的 IDE 去 debug 时，main 函数确实是在堆栈的最开始地方…\n\n但是如果你熟悉 SpringBoot 的启动过程，你会知道，你看到的 main 函数并不是真正开始执行启动的 main 函数，关于这点，我在之前 SpringBoot 系列-FatJar 启动原理 这篇文章中有过说明；即使是通过 JarLaunch 启动，但是入口还是 main，只不过套了一层，然后反射去调用你应用的 main 方法。\n123456789101112131415public class JarLauncher extends ExecutableArchiveLauncher &#123;    // BOOT-INF/classes/    static final String BOOT_INF_CLASSES = &quot;BOOT-INF/classes/&quot;;    // BOOT-INF/lib/    static final String BOOT_INF_LIB = &quot;BOOT-INF/lib/&quot;;    // 空构造函数    public JarLauncher() &#123;    &#125;    // 省略无关代码...    // main 函数    public static void main(String[] args) throws Exception &#123;    \t// 引导启动入口    \tnew JarLauncher().launch(args);    &#125;&#125;\n\n这里抛开 JarLaunch 这种引导启动的方式，单从最普通 java 程序来看，我们来看下 main 函数作为入口的原因。\n找的最开始、最遥远的地方JDK 里面的代码太多了，如果在不清楚的情况下去找，那和大海捞针差不多；那我们想一下，既然 java 要去执行 main，首先它要找到这个 main，那 main 方法是写在我们代码里面的，所以对于 java 来说，它就不得不去先把我们包含 main 方法的类加载起来。所以：\n\n我们找到了 LauncherHelper#checkAndLoadMain 这个上一层入口；通过这个方法的代码注释，我们就知道了，网上关于介绍 main 作为启动方法的一系列验证是缘起何处了：\n\n可以从 fatjar manifest 中找到启动类的 classname\n使用 System ClassLoader 加载这个类\n验证这个启动类的合法性\n这个类是否存在\n有没有 main 函数\n是不是 static 的\n是不是 public 的\n有没有 string 数组作为参数\n\n\n如果没有 main 函数，那当前的这个类是不是继承了 FX Application（关键）\n\n\n\n\n\n\n\n\n\n\nPS: 这里摘取一篇关于为什么是 public 的描述：JAVA 指定了一些可访问的修饰符如：private，protected，public。每个修饰符都有它对应的权限，public 权限最大，为了说明问题，我们假设 main 方法是用 private 修饰的，那么 main 方法出了 Demo 这个类对外是不可见的。那么，JVM 就访问不到 main 方法了。因此，为了保证JVM在任何情况下都可以访问到main方法，就用 public修饰\n这个说法我个人理解是有点欠妥的，首先是 java 里面有反射机制，访问修饰符的存在在 JVM 规范里面说的最多的是因为安全问题，并不是 JVM 能不能访问的问题，因为 JVM 里面有一百种方式去访问一个 private。\nLauncherHelper 被执行调用的地方从堆栈看，checkAndLoadMain 上层没有了，那猜测可能就是有底层 JVM（c 部分）来驱动的。继续去扒一下，在 jdk 的 java.c 文件中捞到了如下代码片段：\n12345678jclass GetLauncherHelperClass(JNIEnv *env)&#123;    if (helperClass == NULL) &#123;        NULL_CHECK0(helperClass = FindBootStrapClass(env,                &quot;sun/launcher/LauncherHelper&quot;));    &#125;    return helperClass;&#125;\n到这也论证了前面的猜测，确实是由底层来驱动执行的。那么既然都看到这里了，也有必要看下我们的 JAVA 程序启动、JVM 启动过程是怎样的。\nJVM 是如何驱动 JAVA 程序执行的这里我的思路还是从可以见的代码及堆栈一层一层往上去拨的，通过 GetLauncherHelperClass 找到了 LoadMainClass，后面再找打整体启动入口。\nLoadMainClass下面是代码（代码的可读性和理解要比文字更直接）：\n1234567891011121314151617181920212223242526272829303132333435/* * Loads a class and verifies that the main class is present and it is ok to * call it for more details refer to the java implementation. */static jclass LoadMainClass(JNIEnv *env, int mode, char *name)&#123;    jmethodID mid;    jstring str;    jobject result;    jlong start, end;    // 去找到 LauncherHelper    jclass cls = GetLauncherHelperClass(env);    NULL_CHECK0(cls);    // 根据 _JAVA_LAUNCHER_DEBUG 环境变量决策是否设置来打印 debug 信息    if (JLI_IsTraceLauncher()) &#123;        start = CounterGet();    &#125;    // 这里可以看到就是调用 LauncherHelper#checkAndLoadMain 的入口    NULL_CHECK0(mid = (*env)-&gt;GetStaticMethodID(env, cls,                &quot;checkAndLoadMain&quot;,                &quot;(ZILjava/lang/String;)Ljava/lang/Class;&quot;));\t// 创建类名的 String 对象，也就是我们的启动类名    str = NewPlatformString(env, name);    // 调用静态对象方法 -&gt; main    result = (*env)-&gt;CallStaticObjectMethod(env, cls, mid, USE_STDERR, mode, str);\t    if (JLI_IsTraceLauncher()) &#123;        end   = CounterGet();        printf(&quot;%ld micro seconds to load main class\\n&quot;,               (long)(jint)Counter2Micros(end-start));        printf(&quot;----%s----\\n&quot;, JLDEBUG_ENV_ENTRY);    &#125;    return (jclass)result;&#125;\n\nJava 程序的 Entry point对于 C&#x2F;C++ 来说，其启动入口和 java 一样，也都是 main。下面我们略过一些无关代码，将 JAVA 程序驱动启动的核心流程代码梳理下\n1、入口，main.c 的 main 方法 -&gt; JLI_Launch\n1234567891011121314intmain(int argc, char **argv)&#123;\t// 省略其他代码 ...     return JLI_Launch(margc, margv,                   sizeof(const_jargs) / sizeof(char *), const_jargs,                   sizeof(const_appclasspath) / sizeof(char *), const_appclasspath,                   FULL_VERSION,                   DOT_VERSION,                   (const_progname != NULL) ? const_progname : *margv,                   (const_launcher != NULL) ? const_launcher : *margv,                   (const_jargs != NULL) ? JNI_TRUE : JNI_FALSE,                   const_cpwildcard, const_javaw, const_ergo_class);&#125;\n\n2、JLI_Launch，JVM 的实际 Entry point\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/* * Entry point. */intJLI_Launch(int argc, char ** argv,              /* main argc, argc */        int jargc, const char** jargv,          /* java args */        int appclassc, const char** appclassv,  /* app classpath */        const char* fullversion,                /* full version defined */        const char* dotversion,                 /* dot version defined */        const char* pname,                      /* program name */        const char* lname,                      /* launcher name */        jboolean javaargs,                      /* JAVA_ARGS */        jboolean cpwildcard,                    /* classpath wildcard*/        jboolean javaw,                         /* windows-only javaw */        jint ergo                               /* ergonomics class policy */)&#123;    // 省略无关代码        // main class    char *main_class = NULL;    // jvm 路径    char jvmpath[MAXPATHLEN];    // jre 路径    char jrepath[MAXPATHLEN];    // jvm 配置路径    char jvmcfg[MAXPATHLEN];        // 省略无关代码 ...    // 选择运行时 jre 的版本，会有一些规则    SelectVersion(argc, argv, &amp;main_class);    // 创建执行环境，包括找到 JRE、确定 JVM 类型、初始化 jvmpath 等等    CreateExecutionEnvironment(&amp;argc, &amp;argv,                               jrepath, sizeof(jrepath),                               jvmpath, sizeof(jvmpath),                               jvmcfg,  sizeof(jvmcfg));    // 省略无关代码 ...      // 从 jvmpath load 一个 jvm    if (!LoadJavaVM(jvmpath, &amp;ifn)) &#123;        return(6);    &#125;\t    // 设置 classpath\t   \t// 解析参数，如 -classpath、-jar、-version、-verbose:gc .....    if (!ParseArguments(&amp;argc, &amp;argv, &amp;mode, &amp;what, &amp;ret, jrepath))    &#123;        return(ret);    &#125;    /* java -jar 启动的话，要覆盖 class path */    if (mode == LM_JAR) &#123;        SetClassPath(what);    &#125;       // 省略无关代码 ...   //    return JVMInit(&amp;ifn, threadStackSize, argc, argv, mode, what, ret);&#125;\n\nJVMInitJVMInit 对于不同的操作系统有不同的实现，这里以 linux 的实现为例：\n12345678int JVMInit(InvocationFunctions* ifn, jlong threadStackSize,        int argc, char **argv,        int mode, char *what, int ret)&#123;    ShowSplashScreen();    // 新线程的入口函数进行执行，新线程创建失败就在原来的线程继续支持这个函数    return ContinueInNewThread(ifn, threadStackSize, argc, argv, mode, what, ret);&#125;\n\n这里比较深，ContinueInNewThread 里面又使用了一个 ContinueInNewThread0，从代码解释来看，大概意思是：先把当前线程阻塞，然后使用一个新的线程去执行，如果新线程创建失败就在原来的线程继续支持这个函数。核心代码：\n1rslt = ContinueInNewThread0(JavaMain, threadStackSize, (void*)&amp;args);\n\nJavaMain1、这里第一个比较关键的就是 InitializeJVM，初始化创建一个 Java Virtual Machine（jvm.so -&gt; CreateJavaVM 代码比较多，实际上真正的初始化和启动jvm，是由 jvm.so 中的JNI_CreateJavaVM 实现）。\n2、接下来就是到我们前面反推到的 LoadMainClass 了，找到我们真正 java 程序的入口类，就是我们应用程序带有 main 函数的类。\n3、获取应用程序 Class -&gt; GetApplicationClass，这里简单说下，因为和最后的那个 demo 有关，也和本文的题目有关。\n1234// 在某些情况下，当启动一个需要助手的应用程序时，// 例如，一个没有主方法的 JavaFX 应用程序，mainClass将不是应用程序自己的主类，// 而是一个助手类appClass = GetApplicationClass(env);\n\n4、调用 main 函数执行应用进程启动\n1(*env)-&gt;CallStaticVoidMethod(env, mainClass, mainID, mainArgs);\n\n简单回顾对于平常我们常见的 java 应用程序来说，main 函数确实作为执行入口，这个是有底层 JVM 驱动执行逻辑决定。但是从整个分析过程也可以看出，main 函数并不是唯一一种入口，那就是以非 main 入口启动的方式，也就是 JavaFX。\n使用 FX Application 方式启动 java 程序JAVA GUI 的旅程开始于 AWT，后来被一个更好的 GUI 框架所取代，其被称为 Swing。Swing 在GUI 领域有将近 20 年的历史。但是，它缺乏许多当今需求的视觉功能，其不仅要求可在多个设备上运行，还要有很好的外观和感觉。在 JAVA GUI 领域最有前景的是JavaFX，JAVA 自带的三个 GUI 工具包–AWT，Swing，和 JavaFX  – 它们做几乎相同的工作。而 JavaFX 使用一些不同的方法进行 GUI 编程，本文不针对 JavaFX 展开细说，有兴趣的同学可以自行查阅。\n每一个 JavaFX 应用程序是应用程序类的扩展，其提供了应用程序执行的入口点。一个独立的应用程序通常是通过调用这个类定义的静态方法来运行的。应用程序类定义了三个生命周期的方法：init()， start() 和 stop()。\n那么结合上一节中关于启动入口的讨论，这里给出一个小 demo 来把一个 springboot 工程启动起来（基于 ide，java -jar 可能会有区别，这里未验证）\n1234567891011121314@SpringBootApplicationpublic class Log4j2GuidesApplication extends Application &#123;    // main -&gt; mains    public static void mains(String[] args) throws Exception &#123;        SpringApplication.run(Log4j2GuidesApplication.class, args);        System.out.println(&quot;222&quot;);    &#125;        @Override    public void start(Stage stage) throws Exception &#123;        mains(new String[0]);        System.out.println(&quot;111&quot;);    &#125;&#125;\n\n\n这里有一个有意思的情况，一般情况下，如果没有非守护线程存活（通常是 web 模块提供）时进程会在启动完之后就退出，但是这里我没有开启 web 端口，但是启动完时，进程并没有退出，即使在 start 里面抛出异常，也不能显示的去阻断，这和 JavaFX Application 的生命周期有关，前面有提到。\n总结JAVA 应用的启动不一定是非要是 main 作为入口，关于其他的引导启动方式没有继续调研，如果大家有知道其他方式，也欢迎留言补充。\n参考\n理解基本的 JavaFX 类，并知道如何使用它们\n\n","slug":"java/java-base-non-main","date":"2021-01-17T03:01:11.000Z","categories_index":"JAVA","tags_index":"java,FX Application","author_index":"glmapper"},{"id":"ac12a67b37981f610a8117ecfb8572d8","title":"JAVA 进程被 kill 排查","content":"可能会导致 JAVA 进程被 kill 的原因\n\nJava 应用程序的问题：发生 OOM 导致进程 Crash\nJVM 自身故障：JVM 或J DK 自身的 Bug 导致进程 Crash\n被操作系统 OOM-Killer\n\n\n\nJava 应用程序的问题：发生 OOM 导致进程 Crash一般情况下，出现 OOM 异常，JVM 的 GC 会进行回收，是不会直接导致 JVM 进程退出的。如果出现退出的情况，那就是内存泄漏，由于内存占用越来越大，最后就直接到 crash 了，这种 JVM 的 OOM 导致的异常，比较好排查。排查步骤如下：\n\n1、-XX:+HeapDumpOnOutOfMemoryError 和 -XX:HeapDumpPath&#x3D;*&#x2F;java.hprof\n2、根据 HeapDumpPath 指定的路径查看是否产生 dump 文件\n3、根据 dump 文件进行分析\n\nJVM自身故障：JVM 或 JDK 自身的 Bug 导致进程 Crash当 JVM 出现致命错误时，会生成一个 hs_err_pid_xxx.log 这样的文件，该文件包含了导致 JVM crash 的重要信息，可以通过分析该文件定位到导致 crash 的根源，从而改善以保证系统稳定。当出现 crash 时，该文件默认会生成到工作目录下，然而可以通过 JVM 参数 -XX:ErrorFile 指定生成路径\n-XX:ErrorFile&#x3D;&#x2F;xxx&#x2F;xxx&#x2F;hs_err_pid.log附 Java BUG dataBase 库：https://bugs.java.com/bugdatabase/view_bug.do?bug_id=8134389\n被操作系统 OOM-KillerLinux 内核有个机制叫 OOM killer（Out-Of-Memory killer），该机制会监控那些占用内存过大，尤其是瞬间很快消耗大量内存的进程，为了防止内存耗尽而内核会把该进程杀掉。可以去 &#x2F;var&#x2F;log&#x2F;messages 里翻系统报错日志，执行如下命令:\n\ndmesg | grep java\ngrep -i ‘killed process’ &#x2F;var&#x2F;log&#x2F;messages\n\n","slug":"jvm/jvm-problem-command","date":"2021-01-06T08:06:55.000Z","categories_index":"jvm","tags_index":"jvm,OOM","author_index":"glmapper"},{"id":"52e98439128c052ce4502d6cce12b2b7","title":"docker 基础备忘","content":"Docker 已经不是什么新鲜的事物了，Docker 崛起的核心是因为 Docker 镜像的存在，这个创新使得 Docker 在短短几年内就可以迅速地改变了整个云计算领域的发展历程。Docker 镜像的存在解决了传统 paas 平台对于打包问题的根本难题，使得“压缩包”赋予了一种极其宝贵的能力：本地环境和云端环境的高度一致！\n\n\n\n\n\n\n\n\n\n\n\nDocker 镜像，其实就是一个压缩包。但是这个压缩包里的内容，比 PaaS 的应用可执行文件 + 启停脚本的组合就要丰富多了。实际上，大多数 Docker 镜像是直接由一个完整操作系统的所有文件和目录构成的，所以这个压缩包里的内容跟你本地开发和测试环境用的操作系统是完全一样的\nDocker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。最初实现是基于 LXC，从 0.7 版本以后开始去除 LXC，转而使用自行开发的 libcontainer，从 1.11 开始，则进一步演进为使用 runC 和 containerd。\n\n\n\n\n\n\n\n\n\nrunc 是一个 Linux 命令行工具，用于根据 OCI容器运行时规范 创建和运行容器。containerd 是一个守护程序，它管理容器生命周期，提供了在一个节点上执行容器和管理镜像的最小功能集。\n容器技术与 Docker 架构容器到底是什么玩意？容器技术是一种沙盒技术，就是能够像一个“箱子”一样，把你的应用“装”起来的技术。通过这样一种“箱子”，使的应用与应用之间相互不干扰，另外就是被装进“箱子”的应用，也具备了可以被方便地搬来搬去的灵活性。\n容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。对于 Docker 等大多数 Linux 容器来说，Cgroups 技术是用来制造约束的主要手段，而 Namespace 技术则是用来修改进程视图的主要方法。实际上是在创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。就是 Linux 容器最基本的实现原理了，所以说，容器，其实是一种特殊的进程而已。\nDocker 架构下图是 Docker 官方提供的 Docker 架构图：\n\nDocker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。\n下面的图片比较了 Docker 和传统虚拟化方式的不同之处。传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。\n\n在这个对比图里，我们应该把 Docker 画在跟应用同级别并且靠边的位置。这意味着，用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。\n隔离与限制使用虚拟化技术作为应用沙盒，就必须要由 Hypervisor 来负责创建虚拟机，这个虚拟机是真实存在的，并且它里面必须运行一个完整的 Guest OS 才能执行用户的应用进程。这就不可避免地带来了额外的资源消耗和占用。而相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；而另一方面，使用 Namespace 作为隔离手段的容器并不需要单独的 Guest OS，这就使得容器额外的资源占用几乎可以忽略不计。所以说，“敏捷”和“高性能”是容器相较于虚拟机最大的优势，但是万事都有两面，有利就有弊，对于 Docker 这种基于 Linux Namespace 的隔离机制，相比于虚拟化技术最大的不足就是：隔离得不彻底。\n\n1、多个容器之间使用的就还是同一个宿主机的操作系统内核。\n\n\n\n\n\n\n\n\n\n\n通过 Mount Namespace 单独挂载其他不同版本的操作系统文件，比如 CentOS 或者 Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。而相比之下，拥有硬件虚拟化技术和独立 Guest OS 的虚拟机就要方便得多了。最极端的例子是，Microsoft 的云计算平台 Azure，实际上就是运行在 Windows 服务器集群上的，但这并不妨碍你在它上面创建各种 Linux 虚拟机出来\n\n2、在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。\n\n\n\n\n\n\n\n\n你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题\n\n\n正是这种隔离不彻底上的问题，使得还需要另外一种技术来保障容器的稳定性，不至于资源都被一个容器全部吃掉，或者因为某个容器的修改导致其他容器也受到影响。这里就需要提到 Cgroups。\nLinux Cgroups 的全称是 Linux Control Group，它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等；Linux Cgroups 的设计是比较易用的，简单理解就是给每一个子系统目录加上一组资源限制文件的组合；对于 Docker 等 Linux 容器项目来说，只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。如：\n1$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash\n\nDocker 中的三个角色镜像Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。\n由于镜像会包括操作系统完整的 root 文件系统，所以我们一般看到的镜像都是比较大的。Docker 在设计时，其充分利用了 Union FS 的技术，将镜像设计为分层存储的架构模式。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。\n容器容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 namespace 。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。\n\n\n\n\n\n\n\n\n\n容器也是分层存储，每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡，所以按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高\n仓库集中的存储、分发镜像的服务：Docker Registry。 \n参考链接\n《深入剖析Kubernetes：张磊》\nhttps://yeasy.gitbook.io/docker_practice/\nhttps://www.cnblogs.com/bjlhx/p/13202505.html\nhttp://dockone.io/article/783\nhttp://merrigrove.blogspot.com/2015/10/visualizing-docker-containers-and-images.html\n\n","slug":"docker/docker-docker-command","date":"2020-12-24T15:14:59.000Z","categories_index":"docker","tags_index":"docker","author_index":"glmapper"},{"id":"7831cd475225b7056a3087c302042c96","title":"Linux 中的 namespace","content":"基本介绍namespace 是 Linux 内核用来隔离内核资源的方式。通过 namespace 可以让一些进程只能看到与自己相关的一部分资源，而另外一些进程也只能看到与它们自己相关的资源，这两拨进程根本就感觉不到对方的存在。具体的实现方式是把一个或多个进程的相关资源指定在同一个 namespace 中。\nLinux namespaces 是对全局系统资源的一种封装隔离，使得处于不同 namespace 的进程拥有独立的全局系统资源，改变一个 namespace 中的系统资源只会影响当前 namespace 里的进程，对其他 namespace 中的进程没有影响。\n\n\nnamespace 的作用从前面介绍我们基本明确了 namespace 的作用，那就是“隔离”。Linux 内核实现 namespace 的一个主要目的就是实现轻量级虚拟化(容器)服务；在同一个 namespace 下的进程可以感知彼此的变化，而对外界的进程一无所知。这样就可以让容器中的进程产生错觉，认为自己置身于一个独立的系统中，从而达到隔离的目的。也就是说 linux 内核提供的 namespace 技术为 docker 等容器技术的出现和发展提供了基础条件。\n从 docker 实现者的角度考虑该如何实现一个资源隔离的容器。比如是不是可以\n\n通过 chroot 命令切换根目录的挂载点，从而隔离文件系统。\n为了在分布式的环境下进行通信和定位，容器必须要有独立的 IP、端口和路由等，这就需要对网络进行隔离。\n容器需要一个独立的主机名以便在网络中标识自己\n进程间的通信隔离。\n用户权限隔离\n运行在容器中的应用需要有进程号(PID)，需要与宿主机中的 PID 进行隔离。\n\n也就是说这六种隔离能力是实现一个容器的基础，下面就看下 linux 内核的 namespace 特性提供了什么样的隔离能力：\n|名称| Flag| 隔离的资源|| ———— | ———— ||Cgroup |CLONE_NEWCGROUP |Cgroup root directory(cgroup 的根目录)||IPC |CLONE_NEWIPC |System V IPC, POSIX message queues(信号量、消息队列和共享内存)||Network |CLONE_NEWNET |Network devices,stacks, ports, etc.（网络设备、网络栈、端口）||Mount |CLONE_NEWNS |Mount points（挂载点）||PID |CLONE_NEWPID |Process IDs（进程 ID）||Time |CLONE_NEWTIME |Boot and monotonic clocks（启动和单调时钟）||User |CLONE_NEWUSER |User and group IDs（用户和用户组）||UTS |CLONE_NEWUTS |Hostname and NIS domian name（主机名和 NIS 域名）|\n\n\n\n\n\n\n\n\n\nCgroup namespace 是后面才增加的，本篇不做过多介绍，将另起篇幅。\nnamespace 的基本操作查看进程所属的 namespace&#x2F;proc&#x2F;[pid]&#x2F;ns 目录下会包含进程所属的 namespace 信息，使用下面的命令可以查看当前进程所属的 namespace 信息：\n1234567891011$ ll /proc/$$/ns总用量 0dr-x--x--x 2 admin admin 0 12月 12 11:19 ./dr-xr-xr-x 9 admin admin 0 12月 12 11:18 ../lrwxrwxrwx 1 admin admin 0 12月 12 11:19 cgroup -&gt; cgroup:[4026537386]lrwxrwxrwx 1 admin admin 0 12月 12 11:19 ipc -&gt; ipc:[4026536810]lrwxrwxrwx 1 admin admin 0 12月 12 11:19 mnt -&gt; mnt:[4026537383]lrwxrwxrwx 1 admin admin 0 12月 12 11:19 net -&gt; net:[4026536400]lrwxrwxrwx 1 admin admin 0 12月 12 11:19 pid -&gt; pid:[4026537385]lrwxrwxrwx 1 admin admin 0 12月 12 11:19 user -&gt; user:[4026531837]lrwxrwxrwx 1 admin admin 0 12月 12 11:19 uts -&gt; uts:[4026537384]\n\n或者\n1234567891011$ ll /proc/7370/ns总用量 0dr-x--x--x 2 admin admin 0 12月 12 11:20 ./dr-xr-xr-x 9 admin admin 0 12月  9 18:43 ../lrwxrwxrwx 1 admin admin 0 12月 12 11:20 cgroup -&gt; cgroup:[4026537386]lrwxrwxrwx 1 admin admin 0 12月 12 11:20 ipc -&gt; ipc:[4026536810]lrwxrwxrwx 1 admin admin 0 12月 12 11:20 mnt -&gt; mnt:[4026537383]lrwxrwxrwx 1 admin admin 0 12月 12 11:20 net -&gt; net:[4026536400]lrwxrwxrwx 1 admin admin 0 12月 12 11:20 pid -&gt; pid:[4026537385]lrwxrwxrwx 1 admin admin 0 12月 12 11:20 user -&gt; user:[4026531837]lrwxrwxrwx 1 admin admin 0 12月 12 11:20 uts -&gt; uts:[4026537384]\n\n从输出的 namespace 信息可以看到，namespace 文件都是链接文件; 以 cgroup:[4026537386] 为例：\n\ncgroup 是 namespace 的类型\n数字（inode number ）标识一个 namespace，可以理解为 namespace 的 ID如果两个进程的某个 namespace 文件指向同一个链接文件，说明其相关资源在同一个 namespace 中。\n\n参考\nhttps://man7.org/linux/man-pages/man7/namespaces.7.html\nhttps://www.cnblogs.com/sparkdev/p/9365405.html\nhttps://segmentfault.com/a/1190000011821634\nhttps://segmentfault.com/a/1190000017474527?utm_source=sf-related\n\n","slug":"linux/linux-concept-namespace","date":"2020-12-12T15:30:20.000Z","categories_index":"Linux","tags_index":"linux,namespace","author_index":"glmapper"},{"id":"f83619a0774898a96f9e31bd15954ca9","title":"JAVA 虚拟机中的动态类加载","content":"\n\n\n\n\n\n\n\n\n原文连接：https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.762&amp;rep=rep1&amp;type=pdf\n\n\n0 摘要ClassLoader 是在 Java 平台上动态装入软件组件的强大机制，它们在以下这些特性的支持上非常有意思：\n\nlaziness\ntype-safe linkage\nuser-defined extensibility\nmultiple communicating namespaces\n\n本篇文章将介绍 ClassLoader 的概念，并演示它们的一些特别用途。此外，本文还讨论了如何在用户定义的动态类加载中维护类型安全。\n1 介绍在本文中，我们研究了 Java 虚拟机的一个重要特性：动态类加载。这就是提供 Java 平台强大功能的底层机制-在运行时安装软件组件的能力。一个典型的例子是动态下载到 web 浏览器中的 applet。虽然许多其他系统也支持某种形式的动态加载和链接，但是 Java 平台是这些系统中唯一包含以下所有特性的平台：\n\nLazy loading：类是按需加载的，类加载应该被尽可能地延迟，从而减少内存的使用并改善系统响应时间。\nType-safe linkage：动态类加载不能违反 Java 虚拟机的类型安全。为了保证类型安全性，动态加载必须不需要额外的运行时检查。附加的链接时间检查是可以接受的，因为这些检查只执行一次。\nUser-definable  class loading policy：ClassLoader 对象也是 Java 中的一类对象，所以开发者完全可以控制动态类加载的行为。比如，用户定义的 ClassLoader  可以指定被加载类的远端位置，或者为从特定源加载的类分配适当的安全属性。\nMultiple namespaces：ClassLoader 为不同的组件提供单独的 namespaces。例如，Hotjava浏览器从不同的源将 applet 加载到单独的类加载器中。这些 applet 可能包含相同名称的类，但是 Java 虚拟机将这些类视为不同的类型（classloader 不同）。\n\n相比之下，现有的动态链接机制并不支持所有这些特性。尽管大多数操作系统都支持某种形式的动态链接库，但这样的机制是针对C&#x2F; c++代码的，并且不是类型安全的。Lisp、Smalltalk 和 Self 等动态语言通过附加的运行时检查(而不是链接时检查)来实现类型安全。\n本文的主要研究是首次对 ClassLoader 进行深入的描述，ClassLoader 是 Java 平台引入的一个概念，ClassLoader 从 JDK 1.0 版本就已经提供了，其最开始的目前是用于在 Hotjava 浏览器中动态加载 applet 类。也就是从那时起，ClassLoader 的使用得到了扩展，以处理范围更广的组件和场景。如服务器端组件(servlet)、Java平台的扩展机制、以及 javabean 组件。尽管 ClassLoader 的作用越来越重要，但相关文章中并没有对其底层机制进行充分的描述。\n本文的另一个研究点是通过 ClassLoader 为长期存在的类型安全问题提供了一种解决方案。JDK 的早期版本(1.0和1.1)在 ClassLoader 实现中包含一个严重的缺陷。编写不当的 ClassLoader 可能破坏 Java 虚拟机的类型安全保证。请注意，类型安全问题没有直接带来任何安全风险，因为不受信任的代码(例如下载的applet)不允许创建 ClassLoader。尽管如此，需要编写自定义 ClassLoader 的应用程序开发者可能会无意中损害类型安全。\n虽然这个问题已经存在一段时间了，但是这个问题在业界还没有非常普适的解决方案。例如，前面的讨论集中在类型安全性的缺乏是否是用户可定义 ClassLoader 的基本限制，以及我们是否必须限制 ClassLoader 的能力、放弃延迟类加载或在运行时引入额外的动态类型检查。我们在本文中提出的解决方案已经在 JDK 1.2 中实现，解决了类型安全问题，同时保留了 ClassLoader 的所有其他需要的特性。\n我们假设读者具有 Java 编程语言的基本知识。本文的其余部分组织如下：首先对 ClassLoader 进行更详细的介绍。第 3 节讨论 ClassLoader 的应用程序。第 4 节描述由于使用 ClassLoader 而可能出现的类型安全问题及其解决方案。最后给出结论。\n2 关于 ClassLoaderClassLoader 的主要作用就是支持在 java 平台上动态加载软件组件。软件分发的基本单元是 class（类）。 classes 以一种平台无关的、独立的、标准的二进制类文件格式形式分发。单个类的表示称为类文件。类文件由 Java 编译器生成，可以加载到任何 Java 虚拟机中。类文件不需要存储在实际文件中；它可以存储在内存缓冲区中，或者从网络流中获得。\nJava虚拟机执行存储在类文件中的字节代码。然而，字节码序列只是虚拟机执行程序所需要的一部分。类文件还包含对字段、方法和其他类名称的符号引用。例如，class C 的声明如下：\n123456class C &#123;\tvoid f()&#123;    \tD d = new D();        // ...    &#125;&#125;\n 表示 C 的类文件包含对类 d 的符号引用。符号引用在链接时解析为实际的类类型。类类型是 Java 虚拟机中具体化的 first-class 对象。类类型在用户代码中表示为类 java.lang.Class 的对象。为了解析对类的符号引用，Java虚拟机必须加载类文件并创建类类型。\n\n\n\n\n\n\n\n\n\nfirst-class: 简而言之，这意味着对对象的使用没有任何限制。它和其它对象一样。first-class 对象是可以动态创建、销毁、传递给函数、作为值返回的实体，并且具有编程语言中其他变量具有的所有权限。https://stackoverflow.com/questions/245192/what-are-first-class-objects\n类类型在用户代码中表示为类java.lang.Class的对象。为了解析对类的符号引用，Java虚拟机必须加载类文件并创建类类型。\n类加载概述Java 虚拟机使用 classloaders 去加载类文件和创建 class 对象。classloader 也是普通的对象，可以使用 java 代码编写定义，但是它们必须是 ClassLoader 这个抽象类的子类，ClassLoader 代码如下所示（省略其他无关代码）：\n1234567class ClassLoader&#123;    public Class loadClass(String name);    protected final Class defineClass(String name, byte[] buf, int off, int len);    protected final Class findLoadedClass(String name);    protected final Class findSystemClass(String name);    // ... &#125;\n\n在上图的描述中， ClassLoader.loadClass 方法接受一个类名作为参数，并返回一个类对象，该类对象是类类型的运行时表示。关于 defineClass、findLoadedClass、findSystemClass 下面再聊。在上面的案例中，假设类 C 是被 classloader L 加载的，那么 L 就是 C 的 defining loader，java 虚拟机将使用 L 去加载 C 引用的类。在虚拟机分配类 D 的对象之前，它必须解析对 D 的引用，如果还没有加载 D，虚拟机将调用 C 的类加载器 L 的 loadClass 方法来加载 D:\n1L.loadClass(&quot;D&quot;)\n\n加载 D之后，虚拟机就可以解析了引用并创建类 D 的对象。\n多 Class LoadersJava 应用程序可以使用几种不同类型的类装入器来管理各种软件组件。下图显示了用 Java 编写的 web 浏览器如何使用类加载器。\n这个示例演示了两种类型的 ClassLoader 的使用:用户定义的 ClassLoader 和 Java 虚拟机提供的系统 ClassLoader。用户定义的 ClassLoader 可用于创建来自用户定义的源的类。例如，浏览器应用程序为下载的 applet 创建类加载器。我们为 web 浏览器应用程序本身使用一个单独的类加载器，所有系统类(如java.lang.String)都被加载到系统类加载器中，Java 虚拟机直接支持系统类装入器。\n图中的箭头表示 ClassLoader 之间的委托关系；ClassLoader L1 可以委托另一个ClassLoader L2 代表自身去加载类 C，在这种情况下，L1 委托 C 给 L2。例如，applet 和 应用程序类 ClassLoader 将所有系统类委托给系统类 ClassLoader，因此，所有系统类在 applet 和应用程序之间共享。这是可以的，因为如果 applet 和系统代码对类型 java.lang.String 有不同的概念，就会违反类型安全性。委托 ClassLoader 加载允许我们在共享一组公共类的同时保持名称空间隔离，在 Java 虚拟机中，类类型唯一由类名和 ClassLoader 的组合决定，Applet 和应用程序 ClassLoader 委托给系统类装入器，这就保证了所有的系统类型（java.lang.String）的唯一性。另外，在 applet 1 中加载的名为 C 的类被认为是不同于 applet 2 中名为 C 的类的类型，尽管这两个类具有相同的名称，但它们是由不同的 ClassLoader 定义的。事实上，这两个类是完全不相关的。例如，它们可能有不同的方法或字段。\n一个 applet 中的类不能干扰另一个 applet 中的类，因为 applet 是有各自单独的 ClassLoader 中加载的，这对于保证 Java 平台安全性至关重要。同样，由于浏览器位于单独的 ClassLoader 中，因此 applet 不能访问用于实现浏览器的类，applet 只允许访问在系统类中公开的标准 Java API。\nJava 虚拟机通过创建应用程序 ClassLoader 并使用它加载初始的浏览器类来启动，应用程序在初始类的公共类方法 void main(String[]) 中开始执行，该方法的调用驱动所有的进一步执行，指令的执行可能导致附加类别的加载，在这个应用程序中，浏览器还为下载的 applet 创建额外的ClassLoader。\n垃圾收集器卸载不再引用的 applet 类，每个类对象都包含一个对其定义 ClassLoader 的引用；每个 ClassLoader 引用它定义的所有类，从垃圾收集器的角度来看，这意味着类与它们的定义 ClassLoader 是强连接的，当类的定义 ClassLoader 垃圾收集时，类将被卸载。\nClassLoader 的例子下面介绍一个简单的 ClassLoader 的实现。如前所述，所有用户定义的 ClassLoader 类都是 ClassLoader 的子类。ClassLoader 的子类可以覆盖loadClass 方法，从而提供用户定义的加载策略。这是一个在给定目录中查找类的自定义 ClassLoader ：\n123456789101112131415161718192021222324252627282930313233343536373839/** * @author: guolei.sgl (guolei.sgl@antfin.com) 2020/12/4 7:42 下午 * @since: **/public class FileClassLoader extends ClassLoader &#123;    private String directory;    public FileClassLoader(String directory)&#123;        this.directory = directory;    &#125;    public synchronized Class loaderClass(String name) throws ClassNotFoundException&#123;        Class c = findLoadedClass(name);        if (c != null) &#123;            return c;        &#125;        try &#123;            c = findSystemClass(name);        &#125; catch (ClassNotFoundException e)&#123;            // keep looking        &#125;        try &#123;           byte[] data = getClassData(directory,name);           return defineClass(name,data,0,data.length);        &#125; catch (IOException e)&#123;            // keep looking            throw new ClassNotFoundException();        &#125;    &#125;        private byte[] getClassData(String directory, String name) throws IOException&#123;        // 省略        return null;    &#125;&#125;\n\n公共构造函数 FileClassLoader() 只记录目录名。在 loadClass 的 定义中，我们使用 findLoadedClass 方法检查类是否已经加载。如果findLoadedClass 返回 null，则表示该类尚未加载。然后，我们通过调用 findSystemClass 委托给系统类加载器，如果我们试图加载的类不是系统类，我们就调用 getClassData方法来读取类文件。\n在读入类文件之后，我们将其传递给 defineClass 方法，defineClass 方法从类文件 构造类的运行时表示（即 Class 对象）。请注意，loadClass 方法使用了 synchronized 关键字，这样也保证了多个线程加载同一个类时的线程安全性。\n类的初始化和 Defining Loaders当一个 classloader 委托给另一个 classloader 时，发起 load 的 classloader 不一定是完成  class 加载并定义的 classloader，如下代码片段：\n123456try &#123;    FileClassLoader cl = new FileClassLoader(&quot;/foo/bar&quot;);    Class stringClass = cl.loaderClass(&quot;java.lang.String&quot;);&#125; catch (ClassNotFoundException e) &#123;    // &#125;\n\nFileClassLoader 类的实例将 java.lang.String 的加载委托给系统类加载器，因此，java.lang.String 是由系统类加载器加载和定义的，即使加载是由 FileClassLoader 发起的。\nDefinition 2.1： 假设 C 是 L.defineclass() 的结果，则 L defining loader C，或者等价地，L 定义 C。\nDefinition 2.2： 假设 C 是 L.loadClass() 的结果，则 L initiating loader  C，或者等价的，L 初始加载 C。\n在 Java 虚拟机中，每个类 C 都与它的 defining loader 永久关联，正是 C 的 defining loader 启动了 C 引用的任何类的加载。\n\n\n\n\n\n\n\n\n\n关于 defining loader 和 initiating loader ： 我们知道，在 java 中，类加载默认是双亲委派机制，那么基于此，来简单聊下 defining loader 和 initiating loader。\n\n\n\n\n\n\n\n\n\n假设委托层次结构为 L-&gt; Lp -&gt; Lq，类在 Lp 中定义，在这种情况下：\n\nL 将类加载委托给 Lp\nLp 将类加载委托给 Lq\nLq 不会加载该类，调用将返回到 Lp\nLp 将加载这个类，因为它是在 Lp 中定义的，并且调用返回到 L\n\n\n\n\n\n\n\n\n\n\n在这里，Lp 和 L 都是 initiating  class loaders(初始类加载器)，Lp 是 defining class loader\n类似地，如果委托等级是 L-&gt; Lp，并且类在 L 中定义\n\nL 成为定义和初始化类加载器。\nLp 不是初始化类加载器。\n\n\n\n\n\n\n\n\n\n\n简单地说，如果类加载器能够返回对委托链中的类实例的引用，那么它就是初始化类加载器。即初始类加载器可能会有多个，但是 defining class loader 有且只有一个。\n3 应用程序中的 Class Loaders在本节中，我们将通过几个示例演示类装入器的强大功能。\n重新加载类（Reloading Classes）通常需要在诸如服务器之类的长期运行的应用程序中升级软件组件，升级不得要求应用程序关闭并重新启动。在 Java 平台上，此功能可以转换为重新加载已经在运行的虚拟机中加载的类的子集，它对应于模式演化问题，通常可能很难解决，一些困难如下：\n\n可能有一些活动对象是我们想要 reload 的类的实例，那么就需要迁移这些对象，以符合新类的模式。例如，如果类的新版本包含一组不同的实例字段，我们必须以某种方式将现有的一组实例字段值映射到新版本类中的字段。\n将静态字段值映射到 reload 的类版本中的一组不同的静态字段。\n应用程序可能正在执行一个方法，该方法可能是我们想要 reload 的类。\n\n在本文中，我们不讨论这些问题。但是我们将展示如何使用类加载器绕过它们，也就是通过在单独的类加载器中组织这些软件组件，开发者通常可以避免处理架构演变，那也就意味着，新类要由单独的加载器加载。\n图 3 说明了 Server 类如何动态地将服务请求重定向到 Server 的新版本。关键技术是将 Server 类、旧 Service  和新 Service 加载到单独的类加载器中。例如，我们可以使用上一节中介绍的 FileClassLoader 类来定义 Server。\n123456789101112131415161718192021222324252627282930313233public class Server &#123;    private Object service;    public void updateService(String location) &#123;        try &#123;            FileClassLoader cl = new FileClassLoader(location);            Class c = cl.loaderClass(&quot;Service&quot;);            service = c.newInstance();        &#125; catch (ClassNotFoundException e)&#123;\t\t\t// ignore        &#125; catch (IllegalAccessException e)&#123;\t\t\t// ignore        &#125; catch (InstantiationException e)&#123;\t\t\t// ignore        &#125;    &#125;    public void processRequest(String args) &#123;        try &#123;            Class c = service.getClass();            Method m = c.getMethod(&quot;run&quot;,String.class);            m.invoke(service,args);        &#125; catch (NoSuchMethodException e)&#123;\t\t\t// ignore        &#125; catch (InvocationTargetException e)&#123;\t\t\t// ignore        &#125; catch (IllegalAccessException e)&#123;\t\t\t// ignore        &#125;    &#125;&#125;\n\nServer.processRequest 方法将所有传入请求重定向到存储在私有字段中的 service 对象。它使用 Java 核心反射 API 调用 service 对象上的“run”方法。另外，Server.updateService 方法允许动态加载 Service 类的新版本以替换现有的 Service 对象。updateService 的调用者提供新类文件的位置。进一步的请求将被重定向到 Service 引用的新对象。为了重新加载，Server 直接引用 Service 类:\n1234567891011121314151617public class Server &#123;    private Service service;    public void updateService(String location) &#123;        try &#123;            FileClassLoader cl = new FileClassLoader(location);            Class c = cl.loaderClass(&quot;Service&quot;);            service = (Service) c.newInstance();        &#125; catch (ClassNotFoundException e)&#123;\t\t\t// ignore        &#125; catch (IllegalAccessException e)&#123;\t\t\t// ignore        &#125; catch (InstantiationException e)&#123;\t\t\t// ignore        &#125;    &#125;    // ..&#125;\n一旦 Server 类将符号引用解析为 Service 类，它将包含到该类类型的强链接（hard linke），无法更改已解析的引用，这对于从类加载器返回的新版本的 Service，Server.updateService 方法最后一行中的类型转换将失败。\n反射允许 Server 类在没有直接引用的情况下使用 Service 类。或者，Server 和 Service 可以共享一个公共接口或超类:\n1234567891011121314151617181920212223242526272829public class Server &#123;    private ServiceInterface service;    public void updateService(String location) &#123;        try &#123;            FileClassLoader cl = new FileClassLoader(location);            Class c = cl.loaderClass(&quot;Service&quot;);            service = (ServiceInterface) c.newInstance();        &#125; catch (ClassNotFoundException e)&#123;        &#125; catch (IllegalAccessException e)&#123;        &#125; catch (InstantiationException e)&#123;        &#125;    &#125;    public void processRequest(String args) &#123;        service.run(args);    &#125;&#125;public class Service implements ServiceInterface&#123;    @Override    public void run(String args)&#123;        System.out.println(args);    &#125;&#125;\n\n通过接口进行分派通常比反射更有效，不能重新加载接口类型本身，因为 Server 类只能引用一个 ServiceInterface 类型，getServiceClass 方法每次都必须返回一个实现相同 ServiceInterface 的类。\n在我们调用 updateService 方法之后，所有未来的请求将由新的 Server 处理。然而，旧的 Server 类可能还没有完成对一些早期请求的处理。因此，两个 Server 类可能会共存一段时间，直到完成对旧类的所有使用，删除对旧类的所有引用，卸载旧类为止。\n检测 Classes Files（Instrumenting Classes Files）类加载器可以在进行 defineClass 调用之前检测类文件。例如，在 FileClassLoader 的例子中，我们可以插入一个调用来检测类文件的内容:\n123456789try &#123;    byte[] data = getClassData(directory,name);    // 检测 classFile    byte[] newdata = instrumentClassFile(data);    return defineClass(name,newdata,0,newdata.length);&#125; catch (IOException e)&#123;    // keep looking    throw new ClassNotFoundException();&#125;\n\n根据 Java 虚拟机规范，instrumented 类文件必须有效。虚拟机会将所有常规检查（例如运行字节码验证程序）应用于已检测的类文件，只要遵守类文件格式，程序员在修改类文件时就具有很大的自由度。例如，instrumented 类文件可能在现有方法，新字段或新方法中包含新的字节码指令，也可以删除现有方法，但是生成的类文件可能不会与其他类链接。\ninstrumented 的类文件必须定义一个与原始类文件名称相同的类。 loadClass 方法应返回其名称与作为参数传入的名称相匹配的类对象。 \n类加载器只能检测其定义的类，而不能委派给其他加载器的类。所有用户定义的类加载器应首先委托给系统类加载器，因此不能通过类加载器来\ninstrument 系统类。用户定义的类加载器无法通过尝试自己定义系统类来绕过此限制。例如，如果类加载器定义了自己的 String 类，则无法将该类的对象传递给需要标准 String 对象的 Java API。虚拟机将捕获并报告这些类型错误。\n在许多情况下，类文件检测都是有用的。例如，一个已检测的类文件可能包含性能分析钩子，这些性能钩子方法计算特定方法的执行次数。通过用对某些类的引用替换对那些类的有资源意识的版本的引用，可以监视和控制资源分配。可以使用类加载器来实现参数化的类，为参数类型的每个不同调用扩展和定制类文件中的代码。\n4 维护类型安全链接到目前为止提供的示例已经证明了多个委托类加载器的用处。但是，正如我们将看到的，要确保在存在类加载器的情况下进行类型安全的链接需要特别注意。 Java编程语言依赖于基于名称的静态类型。在编译时，每种静态类类型都对应一个类名称。在运行时，类加载器会引入多个名称空间。运行时类类型不仅由其名称单独确定，还由一对：其类名称及其定义的类加载器确定。因此，用户定义的类加载器引入的名称空间可能与Java编译器管理的名称空间不一致，从而危害类型安全。\n时间命名空间一致性（Temporal Namespace Consistency）oadClass 方法可能会在不同时间为给定名称返回不同的类类型。为了维护类型安全，虚拟机必须能够始终为给定的类名和加载器获得相同的类类型。例如，考虑以下代码中对类X的两个引用：\n12345class C &#123;\tvoid f(X x)&#123;...&#125;    ...    void g()&#123;f(new x());&#125;&#125;\n\n如果 C 的类加载器将 X 的两次出现映射到不同的类类型，则 g 内部对 f 的方法调用的类型安全性将受到损害。虚拟机不能相信任何用户定义的loadClass 方法会对给定的名称一致地返回相同的类型，所以它在内部维护一个已加载的类缓存。被加载的类缓存将类名和初始加载器映射到类类型。当虚拟机从 loadClass 方法获得一个类后，它执行以下操作:\n\n将根据传递给 loadClass 方法的名称检查类的真实名称。如果 loadClass 返回的类没有所请求的名称，则会引发错误。\n如果名称匹配，则将生成的类缓存在已加载的类缓存中。虚拟机永远不会在同一类加载器上多次调用具有相同名称的 loadClass 方法\n\n委托类加载命名空间一致性（Namespace Consistency among Delegating Loaders）我们现在描述委派类装入器可能产生的类型安全问题\n\n\n\n\n\n\n\n\n\nNotation 4.1：下面会会用 &lt;C, Ld&gt; Li 这样一个符号来代表一个类类型，其中 C 表示类名，Ld  表示类的 defining loader，Li  表示 loading loader。如果我们不关心 defining loader 时，我们使用 C Li  这个符号去表示 Li  是 C 的初始化加载器。当我们不关心初始化加载器时，我们使用指定的 &lt;C, Ld&gt; 去表示 C 是被 Ld定义的。\n如果 L1 委托 L2 去加载 C，则 C:L1 &#x3D; C:L2现在我们将给出一个演示类型安全问题的示例。为了明确涉及到哪些类装入器，我们在通常出现类名的地方使用了上述表示法。\n\nC 由 L1 定义。结果，L1 用于启动 C.f 内部引用的 Spoofed 和 Delegated 类的加载。 L 定义 Spoofed。但是，L1 将 Delegated 的加载委托给 L2，然后由 L2 定义 Delegated。由于 Delegated 由 L2 定义，因此 Delegated.g 将使用 L 来启动 Spoofed 的加载。碰巧的是，L2定义了另一种 Spoofed 类型。C 期望 &lt;Spoofed，L1&gt;的实例由 Delegated.g 返回。但是，Delegated.g 实际上返回&lt;Spoofed，L2&gt; 的实例，这是一个完全不同的类。\n这是 L1 和 L2 的命名空间之间的不一致。如果未发现这种不一致，则可以使用委派的类加载器将一种类型伪造为另一种类型。若要了解这种类型的安全问题如何导致不良行为，请假设以下两个版本的“Spoofed”定义如下：\n\n现在，类&lt;C，L1&gt;可以显示&lt;Spoofed，L2&gt;实例的私有字段，并从整数值伪造一个指针：\n\n我们可以在&lt;Spoofed，L2&gt;实例中访问私有字段秘密值，因为该字段在&lt;Spoofed，L1&gt;中声明为公共字段。我们还能够在&lt;Spoofed，L1&gt;实例中将整数字段伪造为整数数组，并取消引用从该整数伪造的指针。类型安全问题的根本原因是虚拟机没有考虑到类类型是由类名和定义加载器确定的。相反，虚拟机依赖于Java编程语言的概念，即在类型检查期间只使用类名作为类型。这个问题已经得到纠正，如下所述。\n解决方案类型安全问题的一个直接解决方案是在Java虚拟机中统一使用类名及其定义加载器来表示类类型。但是，确定定义加载器的唯一方法是通过初始加载器实际加载类。在前一节的例子中，在确定 C.f 对 Delegated.g 的调用是否是类型安全的之前，我们必须首先在 L1和L2中都加载 Spoofed，然后查看是否获得相同的定义加载程序。这种方法的缺点是它牺牲了类的延迟加载性质。\n我们的解决方案保留了简单方法的类型安全性，但避免了急切的类加载。关键思想是维护一组加载器约束，在类加载发生时动态更新这些约束。在上面的例子中，我们没有在 L 1和 L2 中加载 Spoofed，而是简单地记录了一个约束:Spoofed:L1&#x3D;Spoofed:L2。如果 Spoofed 稍后被 L1或 L 2加载，我们将需要验证现有的加载器约束集不会被违反。如果约束  Spoofed:L1&#x3D;Spoofed:L2是在 L1 和 L2加载 Spoofed 之后引入的，会怎么样?现在施加约束并撤消以前的类加载已经太晚了。\n因此，我们必须同时考虑加载的类缓存和加载器约束设置。我们需要保持不变：加载的类缓存中的每个条目都满足加载器的所有约束。保持不变式如下:\n\n每次将一个新条目添加到已加载的类缓存中时，我们都要验证没有违反任何现有的加载器约束。如果不能在不违反现有加载器约束的情况下将新条目添加到加载的类缓存中，则类加载失败。\n每次添加新的加载器约束时，我们都要验证缓存中加载的所有类是否满足新的约束。如果一个新的加载器约束不能被所有加载的类满足，那么触发添加新的加载器约束的操作将失败。\n\n让我们看看如何将这些检查应用到前面的示例中。C.f 方法的第一行使虚拟机生成约束 Spoofed:L1&#x3D;Spoofed:L2。如果 L1和 L2 在我们生成这个约束时已经加载了 Spoofed 类，那么一个异常将立即在程序中引发。否则，约束将被成功记录。假设 Delegated.g 首先加载 Spoofed:L2，当稍后C.f 尝试加载 Spoofed:L1 时，将引发一个异常。\n约束规则现在我们声明生成约束的规则。这些对应于一个类类型可能被另一个类引用的情况。当在不同的加载器中定义两个这样的类时，名称空间之间可能存在不一致。\n\n如果 &lt;C, L1&gt; 引用了一个字段 ： T filedname, 这个字段是在 &lt;D,L2&gt;  中被申明，那我们就产生了这样一个约束：T:L1 &#x3D; T:L2\n如果 &lt;C, L1&gt; 引用了一个方法 ：T0 methodname(T1 ,….., Tn)； 这个方法在  &lt;D,L2&gt;  中被申明，那我们就产生了一个约束：T0:L1 &#x3D; T0:L2,…, Tn:L1 &#x3D; Tn:L2。\n如果 &lt;C, L1&gt; 重写了一个方法：T0 methodname(T1 ,….., Tn)；这个方法在  &lt;D,L2&gt;  中被申明，那我们就产生了一个约束：T0:L1 &#x3D; T0:L2,…, Tn:L1 &#x3D; Tn:L2。\n\n约束集{T:L1&#x3D; T:L2, T:L2 &#x3D; T:L3}表示在 L1和 L2、L 2和 L3 中，T 必须以相同的类类型加载。即使在程序执行过程中，T 从未被 L2 加载，L 1和 L2 也无法加载不同版本的 T。如果违反了加载程序约束，则将抛出 java.lang.LinkageError 异常。当相应的类加载器被垃圾回收时，加载器约束将从约束集中删除。\n替代解决方案另外一种与前不同的替代方案是，建议方法重写也应该基于动态类型，而不是基于静态(基于名称)类型。这种方案是从链接时间开始统一地使用类型的动态概念。下面的代码说明了该模型和前面提到的模型之间的差异:\n123class&lt;Super,L1&gt; &#123;    void f(Spoofed x)&#123;... code1....&#125;&#125;\n\n假设 L1 和 L2 定义了不同版本的 Spoofed。Saraswat 认为 Super 和 Sub 中的 f 方法具有不同的类型签名 :Super.f 方法参数类型是&lt;Spoofed,L1&gt;, 而 Sub.f 方法参数类型是 &lt;Spoofed,L2&gt;。这样的话，Sub.f 在这个模型下就没有办法去 override Super.f 方法。\n在我们前面设定的模型中，如果 Main 是被 L2 加载的，当 f 被调用时，就会产生 linkageError 异常。这个行为和替代模型是非常相似的：在替代模型中会产生 NoSuchMethodError。\n在我们的模型中，当 Main 由 L1加载时，方法上的差异变得明显，当 Main 由 L 1加载时，对f的调用将调用 code2。当代码 2 尝试访问 Spoofed 的任何字段或方法时，将引发 linkageError。我们认为，在这种情况下失败比静默运行本不应该执行的代码更好。程序员在编写上面的 Super 和 Sub 类时，期望 Sub.f 确实根据 Java 编程语言的语义覆盖了 Super.f。这些期望在替代模型的提议中被违反了。\n结论我们已经提出了Java平台中的类加载器的概念。类加载器结合了四个理想的功能：延迟加载，类型安全的链接，多个名称空间和用户可扩展性。特别是类型安全，需要特别注意。我们已经展示了如何在不限制类加载器功能的情况下保持类型安全。类加载器是一种简单而强大的机制，已被证明在管理软件组件方面非常有价值。\n","slug":"jvm/jvm-dynamic-load-class","date":"2020-12-11T02:59:14.000Z","categories_index":"jvm","tags_index":"classloader,jvm","author_index":"glmapper"},{"id":"576894077f580ac3b5f04a4d2847ddda","title":"maven 中 repository 是如何工作的","content":"本文中，我们将来看下如何在 maven 项目中定义和解决依赖关系，然后深入研究 maven 存储库如何使这些依赖关系可供使用的。\n\n\n什么是 maven 依赖项？关于这个相信都不会陌生，就是在 里面申明这样一个配置\n1234567&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;com.glmapper.bridge.boot&lt;/groupId&gt;    &lt;artifactId&gt;client&lt;/artifactId&gt;    &lt;version&gt;$&#123;version&#125;&lt;/version&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;\n\nmaven 坐标大多数的 dependency 申明都会包括 groupId、artifactId、version 这些标签项，这样一组 key&#x2F;value 对的组合成了maven 坐标，来标识一个特定的 dependency，和地图的经纬度坐标一样，通过这个坐标我们就可以精准的指定一个特定的 dependency。\nmaven 是如何定位和解析 dependencies？maven 的仓库和其他的像 APT、YUM 等不同，它不存在类似于主索引文件这样的东西存在能够去列举出当前仓库中所有可用的 artifacts。maven 使用的是通过给定依赖项的坐标值，然后再根据 maven repository layout 构造出依赖的 URL。\nmaven repository layout 映射对于一个 maven artifact，它的 URL 大概格式如下：\n12/$groupId[0]/../$&#123;groupId[n]/$artifactId/$version/$artifactId-$version.$extension# 如 /com/glmapper/bridge/boot/client/1.0.0/client-1.0.0.jar\n\ngroupId 的规则groupId 是一个字符串数组，以 . 分隔，如 org.springframework.boot，那实际上实际路径会转换成的文件路径是 &#x2F;org&#x2F;springframework&#x2F;boot&#x2F; 。\nartifactmaven 的核心功能之一是其处理传递依赖性的能力。也就是说，以递归的方式查找和下载依赖项的依赖项以及它们的依赖项，直到它们全部满足为止。\npom我们把 com.glmapper.bridge.boot 的 groupId 转换成 &#x2F;com&#x2F;glmapper&#x2F;bridge&#x2F;boot，然后用 $artifactId 和$versionId 构造 URL 的其余部分，像这样:\n1/com/glmapper/bridge/boot/client/1.0.0/client-1.0.0.pom\n\njar和 pom 差不多，如下：\n1/com/glmapper/bridge/boot/client/1.0.0/client-1.0.0.jar\n\n\n\n\n\n\n\n\n\n\nhttps://blog.packagecloud.io/eng/2017/03/09/how-does-a-maven-repository-work/#maven-metadataxml\n","slug":"maven/maven-repository","date":"2020-12-06T15:25:12.000Z","categories_index":"maven","tags_index":"maven","author_index":"glmapper"},{"id":"fa977817638d540050b6c44615352923","title":"yum 指令","content":"\n\n\n\n\n\n\n\n\nyum(Yellowdog Updater Modified)：是一个基于 RPM 的软件包管理器，能够从指定服务器自动下载RPM包并且安装，可以处理软件之间的依赖关系，一次性安装所有依赖的软件包，无需一个个下载安装。\n工作原理示意图yum 客户端及服务器的工作原理如下图所示\n\n\n\nyum 的配置文件配置文件所在目录：/etc/yum.repos.d\n1234567# vim /etc/yum.repos.d/alios.repo----------------------------------------[alios.7u2.base.$basearch]name=aliosbaseurl=http://yum.tbsite.net/alios/7u2/os/$basearch/  # $basearch：系统基础架构，如 x86_64gpgcheck=0----------------------------------------\n\nx.repo 文件相关配置 key 简介：\n如果两个仓库里的 RPM 包是一样的，一个在远程服务器上，另一个在本地光盘上，那么本地光盘的访问速度通常会快于远程服务器上。在配置文件中，我们可以定义这样的两个仓库，为其中一个设定优先级\n\n\n\n\n\n\n\n\n\n注: gpgme.GpgmeError: (7, 32870, u’\\ufffd\\ufffd\\ufffd\\u8c78\\ufffd\\ufffd\\ufffd\\u02b5\\ufffd\\ufffd\\ufffd ioctl \\ufffd\\ufffd\\ufffd\\ufffd’) #如果执行报这个错，表示当前系统字符编码不支持 Unicode，改一下就好\n配置 yum 数据源默认情况下 yum 使用的源都是国外的地址，那我们如果期望下载速度更快一些时，就可以考虑使用国内的一些源，比如 aliyun 提供的, 以配置 docker yum 数据源为例：\n12345$ sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo已加载插件：bestyumcache, fastestmirror, langpacksadding repo from: http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repograbbing file http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.reporepo saved to /etc/yum.repos.d/docker-ce.repo\n\n然后就可以在 /etc/yum.repos.d/ 下看到 docker-ce.repo\n12345678910111213141516171819202122$ sudo cat docker-ce.repo[docker-ce-stable]name=Docker CE Stable - $basearchbaseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/$basearch/stableenabled=1gpgcheck=1gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg[docker-ce-stable-debuginfo]name=Docker CE Stable - Debuginfo $basearchbaseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/debug-$basearch/stableenabled=0gpgcheck=1gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg[docker-ce-stable-source]name=Docker CE Stable - Sourcesbaseurl=https://mirrors.aliyun.com/docker-ce/linux/centos/7/source/stableenabled=0gpgcheck=1gpgkey=https://mirrors.aliyun.com/docker-ce/linux/centos/gpg# ...省略其他\n\nyum 的一些基本功能yum 基本功能主要包括：查询、删除、更新&#x2F;升级以及软件组等\n查询yum 查询有以下几种姿势，这里挨个举例。\n\nyum search xxx搜索某个软件名称或者描述的重要关键字\n1234567891011$ yum search java已加载插件：bestyumcache, branch, fastestmirror, langpacksLoading mirror speeds from cached hostfilekubernetes                                                                                                                                                                  579/579================================================================================ N/S matched: java =================================================================================abrt-java-connector.x86_64 : JNI Agent library converting Java exceptions to ABRT problemsaether-javadoc.noarch : Java API documentation for Aetheralicpp-gcc492-netlib-java.x86_64 : alicpp-gcc492-netlib-java-1.1.2.odpsant-antunit-javadoc.noarch : Javadoc for ant-antunitant-contrib-javadoc.noarch : Javadoc for ant-contribant-javadoc.noarch : Javadoc for ant\n\nyum info xxx列出软件功能（不太方便透露的信息，以 xxxx 代替了）\n12345678910111213141516171819$ yum info docker已加载插件：bestyumcache, branch, fastestmirror, langpacksLoading mirror speeds from cached hostfile可安装的软件包名称    ：docker架构    ：x86_64版本    ：xxxx发布    ：xxxx  大小    ：103 M源      ：xxxx简介    ：xxxx网址    ：xxxx协议    ： Commercial描述    ： CodeUrl:git@xxxx         : CodeRev:e3xx79d         : AoneLog: xxxx         : AoneUrl:xxxx         : xxx container service docker-xxx; branch: vxxx\n\n\nyum list列出 yum 服务器上面所有的软件名称，这里就不列了（下面一个是按规则搜的）\n\nyum list xxxx找出以 xxx 开头的软件名称\n\n\n12345$ yum list docker已加载插件：bestyumcache, branch, fastestmirror, langpacksLoading mirror speeds from cached hostfile可安装的软件包docker.x86_64    version-xxx   xxxx\n\n\n\nyum list updates列出 yum 服务器上可提供本机进行升级的软件（返回的信息是 yum list 的子集，这里也不举例了）\n\n安装 or 升级\n\n1、yum install&#x2F;update 软件名称\n\n2、 yum install 软件名称 -y #安装过程中免输入y确认\n\n删除yum remove 软件名称\n\n软件组\n\nyum grouplist &#x2F;&#x2F;查看容器和本机上可用与安装过的软件组\n\nyum groupinfo group_name &#x2F;&#x2F;查看group内所有组名称\n\nyum install&#x2F;remove group_name &#x2F;&#x2F;安装与删除\n\n\n除此之外，如果我们想升级所有的软件包，可以通过如下方式搞定\n\nyum -y update 升级所有包，改变软件设置和系统设置,系统版本内核都升级\nyum -y upgrade 升级所有包，不改变软件设置和系统设置，系统版本升级，内核不改变\n\n\n\n\n\n\n\n\n\n\n已经上线的用 yum -y upgrade 比较稳，全新的用 yum -y update 会更好\n参考\nhttp://yum.baseurl.org/\nhttps://blog.csdn.net/guohaosun/article/details/81481848\nhttps://blog.51cto.com/wuyelan/1546674\n\n","slug":"linux/linux-cmd-yum","date":"2020-10-26T15:55:22.000Z","categories_index":"Linux","tags_index":"linux,yum","author_index":"glmapper"},{"id":"720aeef568b7f074067984fdc263021a","title":"JVM 性能调优监控工具","content":"本篇主要学习记录下工作中常用的 JDK 自带的一些 JVM 性能调优监控工具，通过了解这些工具，可以在排查问题时给予我们非常大的帮助，将一些隐藏在底下的东西拿到明面上来做分析。\n\n\njps(Java Virtual Machine Process Status Tool)jps 主要用来输出 JVM 中运行的进程状态信息。语法格式如下：\n1jps [options] [hostid]\n\n如果不指定 hostid 就默认为当前主机或服务器，命令行参数选项说明如下：\n-q 不输出类名、Jar名和传入main方法的参数\n12➜  ~ jps -q42060\n\n-m 输出传入 main 方法的参数(与默认 jps 指令返回的信息相同)\n12➜  ~ jps -m42060 TestSofaBootApplication\n\n-l 输出 main 类或 jar 的全限名\n12➜  ~ jps -l42060 com.glmapper.bridge.boot.TestSofaBootApplication\n\n-v 输出传入 JVM 的参数\n12➜  ~ jps -v42060 TestSofaBootApplication -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:51645,suspend=y,server=n -XX:TieredStopAtLevel=1 -Xverify:none -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:/Users/xxxx/Library/Caches/JetBrains/IntelliJIdea2020.1/captureAgent/debugger-agent.jar -Dfile.encoding=UTF-8\n\n在排查问题时，我们通过都会通过 jps 来看下当前机器运行的进程有哪些，通过不同的参数来快速找到我们目标进程所在的 pid，以便于我们后续的一系列排查操作。\njstack(Java Stack Trace)jstack 主要用来查看某个 Java 进程内的线程堆栈信息。如果 java 程序崩溃生成 core 文件，jstack 工具可以用来获得 core 文件的 java stack 和 native stack 的信息，从而可以轻松地知道 java 程序是如何崩溃和在程序何处发生问题。另外，jstack 工具还可以附属到正在运行的 java 程序中，看到当时运行的 java 程序的 java stack 和 native stack 的信息, 如果现在运行的 java 程序呈现 hung 的状态，jstack 是非常有用的。\n下面是 jstack 语法格式：\n123jstack [option] pidjstack [option] executable corejstack [option] [server-id@]remote-hostname-or-ip\n\n不管是什么指令，我们都要学会先通过 -h 去查一下\n12345678910111213141516➜  ~ jstack -hUsage:    jstack [-l] &lt;pid&gt;        (连接到正在运行的进程)    jstack -F [-m] [-l] &lt;pid&gt;        (连接到挂起的进程)    jstack [-m] [-l] &lt;executable&gt; &lt;core&gt;        (连接到 core 文件)    jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt;        (连接到远程调试服务器)Options:    -F  to force a thread dump. Use when jstack &lt;pid&gt; does not respond (process is hung)    -m  to print both java and native frames (mixed mode)    -l  long listing. Prints additional information about locks    -h or -help to print this help message\n\nOptions 参数说明如下：\n\n\n\n选项\n作用\n\n\n\n-F\n当正常输出的请求不被响应时，强制输出线程堆栈\n\n\n-m\n如果调用到本地方法的话，可以显示 C&#x2F;C++ 的堆栈\n\n\n-l\n除堆栈外，显示关于锁的附加信息，在发生死锁时可以用 jstack -l pid 来观察锁持有情况\n\n\n下面我们重点来聊一聊，jstack 中信息到底要怎么看。\njstack 堆栈信息介绍下面是 jstack 输出的一段 tacer 数据\n12345&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fb93b802000 nid=0x2703 waiting on condition [0x0000700005e5d000]   java.lang.Thread.State: TIMED_WAITING (sleeping)\tat java.lang.Thread.sleep(Native Method)\tat com.glmapper.bridge.boot.TestJstack.testWaitingOnConditionCondition(TestJstack.java:19)\tat com.glmapper.bridge.boot.TestJstack.main(TestJstack.java:10)\n\n通过这段数据我们大概能 get 到的点主要包括以下信息：\n\nmain 线程名\n#1 堆栈序号，没有实际含义，可忽略\nprio 线程优先级\nos_prio 操作系统层次的优先级\ntid 线程标识\nnid 线程id\n\n线程状态介绍从上面 jstack 输出的信息可以看到线程状态相关的信息，比如\nTIMED_WAITING1java.lang.Thread.State: TIMED_WAITING (sleeping)\n\nRUNNABLE1java.lang.Thread.State: RUNNABLE\n\n还有一些 &quot;GC task thread#0 (ParallelGC)&quot; os_prio=31 tid=0x00007fcee9004000 nid=0x1f07 runnable 信息，这种是 jvm 用来回收内存的，先不关注，这里主要看下 java.lang.Thread.State;\n1234567891011121314151617181920212223242526public enum State &#123;    /**     * 当线程对象创建时存在的状态，此时线程不可能执行     */    NEW,   /**    * 当调用thread.start()后，线程变成为 Runnable 状态。只要得到CPU，就可以执行；    */    RUNNABLE,    /**     * 如果进入同步方法或同步代码块，没有获取到锁，则会进入该状态；     */    BLOCKED,    /**     * 执行thread.join()或在锁对象调用obj.wait()等情况就会进该状态，表明线程正处于等待某个资源或条件发生来唤醒自己；     */    WAITING,    /**     * 执行Thread.sleep(long)、thread.join(long)或obj.wait(long)等就会进该状态，与Waiting的区别在于Timed_Waiting的等待有时间限制；     */    TIMED_WAITING,    /**     * 终止     */    TERMINATED;&#125;\n\n再回到上面堆栈信息，可以观察到，当状态是 TIMED_WAITING 时，堆栈中会出现 waiting on condition xxxx 信息，类似的还有：\n\nwaiting on monitor entry : 在等待获取锁，一般对应 BLOCKED\nin Object.wait() : 获取锁后又执行obj.wait()放弃锁，一般对应 WAITING\n\n下面就针对这些状态举一些简单的小例子。\n线程状态举例及 jstack 分析waiting on condition1、执行代码\n123456789101112/** * 产生 waiting on condition */private static void testWaitingOnConditionCondition()&#123;    while (true)&#123;        try &#123;            Thread.sleep(60000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n2、执行结果\n12345&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fb93b802000 nid=0x2703 waiting on condition [0x0000700005e5d000]   java.lang.Thread.State: TIMED_WAITING (sleeping)\tat java.lang.Thread.sleep(Native Method)\tat com.glmapper.bridge.boot.TestJstack.testWaitingOnConditionCondition(TestJstack.java:19)\tat com.glmapper.bridge.boot.TestJstack.main(TestJstack.java:10)\n\n3、结果分析\n这里就比较明显的是 main 线程中正在 sleep 方法。不过这里 TIMED_WAITING 后面的括号里还特殊表明了 sleeping，在一些场景下，常见的还有 parking，下面继续看例子。\nwaiting on condition (parking)1、执行代码\n123456789101112private static void testWaitingOnConditionConditionWithParking()&#123;    // 提供一个阻塞对了    BlockingQueue&lt;String&gt; blockingQueue = new ArrayBlockingQueue&lt;String&gt;(1);    // 先加一个    blockingQueue.add(&quot;test-parking&quot;);    try &#123;        //继续加，这里肯定加不进去，所以会阻塞        blockingQueue.put(&quot;test-parking-xxx&quot;);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;&#125;\n\n2、执行结果\n123456789&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fd6d5008800 nid=0x2803 waiting on condition [0x000070000ffc1000]   java.lang.Thread.State: WAITING (parking)\tat sun.misc.Unsafe.park(Native Method)\t- parking to wait for  &lt;0x000000076af3a938&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\tat java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\tat java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\tat java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:353)\tat com.glmapper.bridge.boot.TestJstack.testWaitingOnConditionConditionWithParking(TestJstack.java:113)\tat com.glmapper.bridge.boot.TestJstack.main(TestJstack.java:13)\n\n3、结果分析\nmain 线程进入了 waiting on conditon 状态，等待某一个资源，可以看到是在 a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec 进行了等待，阻塞住了。\nwaiting on monitor entry1、执行代码\n1234567891011121314151617181920212223242526272829303132333435363738/** * 产生 waiting on monitor entry */private static void testWaitingOnMonitorEntry()&#123;    final Object obj = new Object();    final Thread thread = new Thread()&#123;        @Override        public void run() &#123;            // 锁 obj 对象            synchronized (obj)&#123;                System.out.println(Thread.currentThread().getName());                try &#123;                    Thread.sleep(60000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;;    final Thread thread1 = new Thread()&#123;        @Override        public void run() &#123;            // 锁 obj 对象            synchronized (obj)&#123;                System.out.println(Thread.currentThread().getName());                try &#123;                    Thread.sleep(60000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;;    thread.setName(&quot;test-thread&quot;);    thread.start();    thread1.setName(&quot;test-thread1&quot;);    thread1.start();&#125;\n\n2、执行结果\n12345678910&quot;test-thread1&quot; #14 prio=5 os_prio=31 tid=0x00007f9563880800 nid=0x5c03 waiting for monitor entry [0x000070000b029000]   java.lang.Thread.State: BLOCKED (on object monitor)\tat com.glmapper.bridge.boot.TestJstack$2.run(TestJstack.java:50)\t- waiting to lock &lt;0x000000076af261d0&gt; (a java.lang.Object)&quot;test-thread&quot; #13 prio=5 os_prio=31 tid=0x00007f956387f800 nid=0x5a03 waiting on condition [0x000070000af26000]   java.lang.Thread.State: TIMED_WAITING (sleeping)\tat java.lang.Thread.sleep(Native Method)\tat com.glmapper.bridge.boot.TestJstack$1.run(TestJstack.java:38)\t- locked &lt;0x000000076af261d0&gt; (a java.lang.Object)\n\n3、结果分析\ntest-thread 获取到 obj 对象上的锁，因此正在执行 sleep 操作，状态为 TIMED_WAINTING, 而 test-thread1 由于未获取到 obj 对象上的锁，因此处于BLOCKED 状态。\n\n\n\n\n\n\n\n\n\ntest-thread1 正在 “waiting to lock &lt;0x000000076af261d0&gt;”，试图在地址为 0x000000076af261d0 所在的对象获取锁，而该锁却被 test-thread 线程占有 [locked &lt;0x000000076af261d0&gt;]。test-thread 线程正在 “waiting on condition”，说明正在等待某个条件触发，由 jstack 来看，此线程正在sleep。\nobject.wait()1、执行代码\n1234567891011121314151617181920212223242526272829303132private static void testObjectWait() &#123;    final Thread thread = new Thread() &#123;        @Override        public void run() &#123;            synchronized (this) &#123;                System.out.println(Thread.currentThread().getName());                try &#123;                    wait();                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;;    thread.start();    thread.setName(&quot;test-object-wait&quot;);    try &#123;        Thread.sleep(5000);    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;    synchronized (thread) &#123;        System.out.println(Thread.currentThread().getName());        try &#123;            Thread.sleep(30000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        thread.notify();    &#125;&#125;\n\n2、执行结果\n1234567891011121314&quot;test-object-wait&quot; #13 prio=5 os_prio=31 tid=0x00007fd43a809000 nid=0xa803 in Object.wait() [0x0000700010926000]   java.lang.Thread.State: WAITING (on object monitor)\tat java.lang.Object.wait(Native Method)\t- waiting on &lt;0x000000076af26140&gt; (a com.glmapper.bridge.boot.TestJstack$3)\tat java.lang.Object.wait(Object.java:502)\tat com.glmapper.bridge.boot.TestJstack$3.run(TestJstack.java:73)\t- locked &lt;0x000000076af26140&gt; (a com.glmapper.bridge.boot.TestJstack$3)&quot;main&quot; #1 prio=5 os_prio=31 tid=0x00007fd43b001800 nid=0x2603 waiting on condition [0x000070000f2e4000]   java.lang.Thread.State: TIMED_WAITING (sleeping)\tat java.lang.Thread.sleep(Native Method)\tat com.glmapper.bridge.boot.TestJstack.testObjectWait(TestJstack.java:93)\t- locked &lt;0x000000076af26140&gt; (a com.glmapper.bridge.boot.TestJstack$3)\tat com.glmapper.bridge.boot.TestJstack.main(TestJstack.java:10)\n\n3、结果分析\n由于调用了 object.wait() 方法的时候放弃了锁，所以 test-object-wait 这个线程就出现了 Object.wait() 状态，线程的状态就是 waiting；等待 notify 来进行唤醒。由于 mian 线程在获得 test-object-wait 的线程锁后，调用了 Thread.sleep 方法，所以此时进入了 wating on condition 等待某一个资源，进入到 time_waiting 状态。\n小结一般情况我们在做问题排查时，如果系统非常慢，我们需要特别关注 Blocked，Waiting on condition 这些状态。如果系统的 cpu 负载比较高的话，则可以死循环等思路去摸查，此时要关注下 Runable 状态；那如果堆栈中有 Deadlock，那就是产生了死锁。\njstat(JVM统计监测工具)jstat 是 JVM 统计监测工具，其语法格式如下： 1jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]\n vmid 是 Java 虚拟机 ID，在 Linux/Unix 系统上一般就是进程 ID。interval 是采样时间间隔; count 是采样数目。比如下面输出的是 GC 信息，采样时间间隔为 1000ms，采样数为 3： 12345➜  ~ jstat -gc 58950 1000 3 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT10752.0 10752.0  0.0    0.0   65536.0   6554.0   175104.0     0.0     4480.0 785.7  384.0   75.9       0    0.000   0      0.000    0.00010752.0 10752.0  0.0    0.0   65536.0   6554.0   175104.0     0.0     4480.0 785.7  384.0   75.9       0    0.000   0      0.000    0.00010752.0 10752.0  0.0    0.0   65536.0   6554.0   175104.0     0.0     4480.0 785.7  384.0   75.9       0    0.000   0      0.000    0.000\n 输出信息的列释义：\n\nS0C、S1C、S0U、S1U：Survivor 0&#x2F;1区容量（Capacity）和使用量（Used）\nEC、EU：Eden区容量和使用量\nOC、OU：年老代容量和使用量\nPC、PU：永久代容量和使用量\nYGC、YGT：年轻代 GC 次数和 GC 耗时\nFGC、FGCT：Full GC 次数和 Full GC耗时\nGCT：GC 总耗时\n\njmap(Memory Map)jmap 用来查看堆内存使用状况，一般结合 jhat 使用。其使用语法如下：\n123jmap [option] &lt;pid&gt;jmap [option] &lt;executable &lt;core&gt;jmap [option] [server_id@]&lt;remote server IP or hostname&gt;\n\nOptions 参数说明如下：\n\n\n\n选项\n作用\n\n\n\n\n打印与 Solaris pmap 相同的信息\n\n\n-heap\n打印 java 堆摘要\n\n\n-histo[:live]\n打印 java 对象堆的直方图;如果指定了“live”子选项，则只计算live对象\n\n\n-clstats\n打印 classloader 统计信息\n\n\n-finalizerinfo\n打印 等待终结 对象的信息\n\n\n–dump: :\n以 hprof 二进制格式dump java heap\n\n\n-F\n使用 -dump:  or -histo 强制执行\n\n\n-J\n将  直接传递给运行时系统\n\n\ndump-options 又包括以下几个选项：\n\nlive ： 只 dump 活动对象;如果未指定，堆中的所有对象将被dump。\nformat&#x3D;b ： 二进制格式\nfile&#x3D; ： dump 到指定文件\n\njmap -heap通过指定 pid，可以将当前进程的 heap 信息打印在 console 上，包括使用的 GC 算法、堆配置参数和各代中堆内存使用情况，如下：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253$ jmap -heap 3493Attaching to process ID 3493, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.172-b245using parallel threads in the new generation.(eden 区使用的是并发线程)using thread-local object allocation.(使用线程本地对象分配)Concurrent Mark-Sweep GC (使用 CMS 垃圾收集器)# 堆配置信息Heap Configuration:   MinHeapFreeRatio         = 40   MaxHeapFreeRatio         = 70   MaxHeapSize              = 2147483648 (2048.0MB)   NewSize                  = 805306368 (768.0MB)   MaxNewSize               = 805306368 (768.0MB)   OldSize                  = 1342177280 (1280.0MB)   NewRatio                 = 2   SurvivorRatio            = 8   MetaspaceSize            = 21807104 (20.796875MB)   CompressedClassSpaceSize = 1073741824 (1024.0MB)   MaxMetaspaceSize         = 17592186044415 MB   G1HeapRegionSize         = 0 (0.0MB)# 堆使用情况Heap Usage:New Generation (Eden + 1 Survivor Space):   capacity = 724828160 (691.25MB)   used     = 35156456 (33.527809143066406MB)   free     = 689671704 (657.7221908569336MB)   4.850315970063856% usedEden Space:   capacity = 644349952 (614.5MB)   used     = 19878008 (18.95714569091797MB)   free     = 624471944 (595.542854309082MB)   3.084970820328392% usedFrom Space:   capacity = 80478208 (76.75MB)   used     = 15278448 (14.570663452148438MB)   free     = 65199760 (62.17933654785156MB)   18.984577787815553% usedTo Space:   capacity = 80478208 (76.75MB)   used     = 0 (0.0MB)   free     = 80478208 (76.75MB)   0.0% usedconcurrent mark-sweep generation:   capacity = 1342177280 (1280.0MB)   used     = 166885296 (159.1542205810547MB)   free     = 1175291984 (1120.8457794189453MB)   12.433923482894897% used55843 interned Strings occupying 6689024 bytes.\n\njmap -clstats通过指定 pid ，可以将当前进程的 classloader 统计信息打印在 console 上，包括类加载器名称、对象是否存活、对象地址、父类加载器、已加载的类大小等信息，如下：\n12345678910111213141516171819202122232425$ jmap -clstats  3493Attaching to process ID 3493, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.172-b245finding class loader instances ..done.computing per loader stat ..done.please wait.. computing liveness.......................liveness analysis may be inaccurate ...class_loader\tclasses\tbytes\tparent_loader\talive?\ttype&lt;bootstrap&gt;\t3211\t5818395\t  null  \tlive\t&lt;internal&gt;0x00000000b150ed50\t1\t1491\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b8715670\t1\t900\t    0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000cb417140\t1\t1503\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b98b4388\t1\t1491\t  null  \tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b5a419a0\t1\t900\t    0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b358df50\t1\t1493\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b7b277b8\t1\t1503\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000c2527c58\t1\t1505\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b98b4580\t1\t1491\t0x00000000b0026260\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b9b307b8\t1\t1493\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000e236b038\t1\t900\t    0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b0108400\t1\t1493\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a0400x00000000b010bc00\t3\t7946\t0x00000000b0022f60\tlive\torg/jacoco/compass/agent/rt/internal/fastjson/util/ASMClassLoader@0x00000001000eb8300x00000000b358e148\t1\t1493\t0x00000000b0020830\tdead\tsun/reflect/DelegatingClassLoader@0x000000010000a040\n\njmap -histo使用 jmap -histo pid 可以查看堆内存中的对象数目、大小统计直方图，如下：\n1234567891011121314151617181920212223# jmap -histo:live 1493  带上 live 则只统计存活对象$ jmap -histo 1493  num     #instances         #bytes  class name----------------------------------------------   1:       1314509      144436976  [C   2:       1572864       37748736  org.apache.logging.log4j.core.async.AsyncLoggerConfigDisruptor$Log4jEventWrapper   3:         77458       32776608  [B   4:       1061561       25477464  java.lang.String   5:        731623       23411936  java.util.HashMap$Node   6:         32930       22826616  [I   7:        150340       15546784  [Ljava.util.HashMap$Node;   8:        144895       14968208  [Ljava.lang.Object;   9:        377379       12076128  java.util.concurrent.ConcurrentHashMap$Node  10:        230943       11085264  java.util.HashMap  11:         81124        3893952  java.nio.HeapByteBuffer  12:          3396        3869944  [Ljava.util.concurrent.ConcurrentHashMap$Node;  13:         78418        3764064  java.nio.HeapCharBuffer  14:         75784        3031360  java.util.TreeMap$Entry  15:         72865        2914600  java.util.LinkedHashMap$Entry  16:        166213        2659408  java.util.HashSet  17:         18355        2643120  com.mysql.jdbc.Field  18:         18394        2044336  java.lang.Class  19:         19966        1757008  java.lang.reflect.Method\n\n\n\n\n\n\n\n\n\n\nPS: 上图中的 [C [B 指的是 class 的对象类型，下面是常见类型的参考\n\nB  byte\nC  char\nD  double\nF  float\nI  int\nJ  long\nZ  boolean\n[  数组，如 [I 表示 int[]\n[L+类名 其他对象，如 [Ljava.lang.Object\n\njmap -dump绝大多数情况下，我们不会直接在 console 来打印分析，更常规的做法是 dump 到指定的文件，然后通过一些可视化工具来辅助分析；那执行 dump 到文件一般使用如下指令：\n12345jmap -dump:format=b,file=dumpFileName pid   # 语法$ jmap -dump:format=b,file=test-dump.bin 85716  # 举例Dumping heap to /Users/guolei.sgl/test-dump.bin ...Heap dump file created\n\n对于 dump 下来的文件，可以通过 jprofile 等图形化工具来分析，如下\n\n也可以通过 jhat 查看，操作方式如下：\n1、起 http 服务\n12345678910jhat -port 9300 test-dump.binReading from test-dump.bin...Dump file created Wed Oct 28 17:54:24 CST 2020Snapshot read, resolving...Resolving 1151952 objects...Chasing references, expect 230 dots......................................................................................................................................................................................................................................Eliminating duplicate references......................................................................................................................................................................................................................................Snapshot resolved.Started HTTP server on port 9300Server is ready.\n\n2、dump 类概要信息\n访问 localhost:9300 查看 dump 概要信息\n\n3、class 详情\n点击某个类查看详细信息\n\n小结本文介绍了一些 JDK 自带的一些性能调优监控工具，通过对这些工具的掌握，可以使的我们在实际的开发或者运维中能够快速的去定位和解决一些问题，常见的有 OOM、内存泄漏、线程死锁、CPU 负载高等等；目前社区也有很多好用的工具，例如 Arthas，perfma 等。\n","slug":"jvm/jvm-self-command","date":"2020-10-26T15:49:29.000Z","categories_index":"jvm","tags_index":"jvm,JDK","author_index":"glmapper"},{"id":"3da34a407a5e481b18f31bdb1ed34b7e","title":"Linux Top 命令指南","content":"top 命令允许用户监视 Linux 上的进程和系统资源使用情况，它是系统管理员工具箱中最有用的工具之一，并且在每个发行版中都预装了它。与 ps 等其他命令不同，它是交互式的，我们可以浏览进程列表、终止进程，等等。本文中，我们将了解如何使用 top 命令。\n\nGetting startedtop 命令非常简单，只需要在终端中输入 top 即可。top 指令将启动一个交互式命令行应用程序，如下所示，输出的上半部分包含有关进程和资源使用情况的统计信息，下半部分包含当前运行的进程的列表。可以使用箭头键和页面向上&#x2F;向下键浏览列表。如果你想退出，只需按 q 键。\n123456789101112131415161718192021222324$ toptop - 21:07:28 up 21 days,  4:31,  1 user,  load average: 0.12, 0.06, 0.07Tasks:  33 total,   1 running,  31 sleeping,   0 stopped,   1 zombie%Cpu(s):  0.2 us,  0.5 sy,  0.0 ni, 89.7 id,  0.0 wa,  0.0 hi,  0.0 si,  9.6 stKiB Mem : 33554432 total, 31188884 free,   513100 used,  1852448 buff/cacheKiB Swap:  2097148 total,  2097148 free,        0 used. 31188884 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 52601 root      39  19 1310268  14900   9836 S   0.3  0.0  22:59.21 logagent-collec     1 root      20   0   45416   5244   3968 S   0.0  0.0   5:35.71 systemd   340 root      20   0   64700  21336  17684 S   0.0  0.1   8:33.90 systemd-journal   357 root      20   0  101836   2768   2312 S   0.0  0.0   0:01.13 gssproxy   384 dbus      20   0   28632   2800   2464 S   0.0  0.0   0:00.04 dbus-daemon   432 root      20   0   84760   5852   4984 S   0.0  0.0   0:00.01 sshd   461 agent     20   0   52376   5200   3684 S   0.0  0.0   0:00.01 ilogtail  1690 agent     20   0 2193388 246304  11264 S   0.0  0.7  23:45.88 java  2527 admin     20   0  161744   4268   3704 R   0.0  0.0   0:00.72 top  3245 root      20   0  559140  12412   5860 S   0.0  0.0  64:48.67 logagent  3420 root      20   0  745052  58464  43820 S   0.0  0.2  11:16.32 metricbeat  3447 root      20   0  957796  55548  43708 S   0.0  0.2  10:14.47 metricbeat  5093 root      20   0 1905356 159280   9584 S   0.0  0.5  35:00.14 java  7458 root      20   0   13700   2564   2356 S   0.0  0.0   0:00.00 bash  7464 root      20   0   86268   4436   3740 S   0.0  0.0   0:00.00 sudo  # ... 省略其他\n\ntop 有许多变体，但在本文的其余部分中，我们将讨论最常见的变体 — props -ng 包附带的变体，下面来运行验证体验下：\n1234$ top -v  procps-ng version 3.3.10Usage:  top -hv | -bcHiOSs -d secs -n max -u|U user -p pid(s) -o field -w [cols]\n\n在 top 的界面中发生了相当多的事情，将在下一节中对其逐一进行分析。\n了解 top 的界面 - the summary area第一小节中 top 的输出界面，我们可以比较明显的看到被分成了两个部分，这个小节中我们将关注在上半部分信息，这部分一般被称之为：summary area\n系统时间、正常运行时间和用户会话\n系统时间：当前系统的时间(21:07:28)\n正常运行：系统运行时长(21 days, 4:31)\n活动用户会话个数：1\n\n1top - 21:07:28 up 21 days,  4:31,  1 user,\n\n活动用户会话包括 TTY 和 PTY 两种。实际上，如果您通过桌面环境登录到 Linux 系统，然后启动终端模拟器，您将发现将有两个活动会话。\n\n\n\n\n\n\n\n\n\nTTY: 通过命令行或桌面环境在系统上物理地运行PTY: 终端模拟器窗口或通过 SSH\n如果我们期望得到更多关于活动用户会话的信息，可以通过 who 命令来得到，如下：\n12$ whoadmin    pts/0        2020-10-31 17:15 (xx.xx.xx.xx)\n\n内存使用情况Memory 部分显示的是关于系统内存使用情况的信息，如下：\n12KiB Mem : 33554432 total, 31188208 free,   513488 used,  1852736 buff/cacheKiB Swap:  2097148 total,  2097148 free,        0 used. 31188208 avail Mem\n\nMem 和 Swap 分别显示的是 RAM 和 swap 空间信息；当 RAM 使用率接近满时，RAM 中不经常使用的区域将被写入 Swap 空间，以便稍后需要时检索。但是，由于访问磁盘的速度很慢，过分依赖 Swap 可能会损害系统性能。\n\n\n\n\n\n\n\n\n\n关于 Swap\n\n物理内存就是计算机的实际内存大小，由RAM芯片组成的。虚拟内存则是虚拟出来的、使用磁盘代替内存。虚拟内存的出现，让机器内存不够的情况得到部分解决。当程序运行起来由操作系统做具体虚拟内存到物理内存的替换和加载(相应的页与段的虚拟内存管理)。这里的虚拟内存即所谓的 swap;\n当用户提交程序，然后产生进程，在机器上运行。机器会判断当前物理内存是否还有空闲允许进程调入内存运行，如果有那么则直接调入内存进行运行；如果没有，那么会根据优先级选择一个进程挂起，把该进程交换到swap中等待，然后把新的进程调入到内存中运行。根据这种换入和换出，实现了内存的循环利用，让用户感觉不到内存的限制。从这也可以看出swap扮演了一个非常重要的角色，就是暂存被换出的进程。\n内存与swap之间是按照内存页为单位来交换数据的，一般Linux中页的大小设置为4kb。而内存与磁盘则是按照块来交换数据的\n\ntotal、free、used 就是这些单词含义所描述的一样，分别是当前对应空间的总大小、空闲大小、已使用大小。avail mem 值指的是可以分配给进程而不会导致更多的交换的内存量。\nLinux 内核层面上总是以不同的方式来尝试减少访问磁盘的次数；它在 RAM 中维护一个“磁盘缓存（disk cache）”，存储磁盘中经常使用的区域，另外，磁盘写被存储到一个“磁盘缓冲区（disk buffer）”，内核最终将它们写到磁盘上。它们消耗的总内存是 buff/cache 值。这看起来像是一件坏事，但实际上不是，原因是缓存使用的内存将在需要时分配给进程。\n任务-TasksTasks 部分显示的是有关系统上运行的进程的统计信息\n1Tasks:  33 total,   1 running,  31 sleeping,   0 stopped,   1 zombie\n\ntotal 比较好理解，它表示的就是当前系统正在运行的进程总数。但是对于其他几个状态相关的数字，我们需要了解一点 Linux 内核如何处理进程的背景知识。\n进程执行是 I&#x2F;O 限制的工作(如读取磁盘)和 cpu 限制的工作(如执行算术操作)的混合模式。当一个进程执行 I&#x2F;O 时，CPU 是空闲的，所以 os 在这段时间切换到执行其他进程。此外，该操作系统允许一个给定的进程执行非常短的时间，然后它切换到另一个进程。这就是操作系统“多任务处理”的表现。做所有这些需要我们跟踪流程的“状态”。在 Linux 中，进程可能处于以下状态:\n\n\n\n\n\n\n\n\n\n1、Runnable (R): 处于这种状态的进程要么在 CPU 上执行，要么存在于运行队列中，准备执行。2、Interruptible sleep(S): 处于这种状态的进程在等待事件完成。3、Uninterruptible sleep (D): 在这种情况下，一个进程正在等待一个 I&#x2F;O 操作完成。4、Stopped (T): 这些进程已经被一个作业控制信号(如按 Ctrl+Z)停止，或者因为它们正在被跟踪。5、Zombie (Z): 僵尸进程\n一个进程可以创建许多子进程，当父进程仍然存在时，这些子进程是可以退出的，但是，这些数据结构必须保留下来，直到父进程获得子进程的状态。这种数据结构仍然存在的终止进程称为僵尸进程。D 和 S 状态都是在 top 信息中体现为 sleeping，T 状态体现为 stopped，Z 状态体现为 zombie。\nCPU 使用情况CPU 使用情况，显示了在各种任务上花费的 CPU 时间的百分比。\n1%Cpu(s):  0.3 us,  0.4 sy,  0.0 ni, 90.3 id,  0.0 wa,  0.0 hi,  0.0 si,  9.0 st\nus 指的是 CPU 在用户空间中执行进程所花费的时间。类似地，sy 指的就是运行内核空间进程所花费的时间。Linux 中使用 nice 值来表示进程的优先级，值越高，优先级越低，后面我们会了解到，默认的 nice 值是可以被修改的。在手动设置 nice 的情况下，执行进程所花费的时间显示为 ni 值。ni 后面是 id，它是 CPU 保持空闲的时间，大多数操作系统在 CPU 空闲时将其设置为“省电模式”。接下来是 wa 值，它是 CPU 等待 I/O 完成所花费的时间。\n中断(Interrupt)是向处理器发出的有关需要立即关注的事件的信号；外设通常使用硬件中断来告知系统有关事件的信息，例如键盘上的按键。另一方面，软件中断是由于处理器上执行的特定指令而产生的。在这两种情况下，操作系统都将处理它们，处理硬件中断和软件中断所花费的时间分别由hi和si给出。\n在虚拟化环境中，会将一部分 CPU 资源分配给每个虚拟机（VM）。操作系统会检测到何时有工作要做，如果检测到他需要执行但是由于 CPU 在其他 VM 上繁忙而无法执行时，以这种方式浪费的时间就是“窃取”时间，显示为st。\n平均负载-Load averageload average 部分表示的是在最近 1、5 和 15 分钟内的系统平均“负载”。\n1load average: 0.11, 0.07, 0.07\n\n负载是对系统执行的计算工作量的度量。在 Linux上，负载是在任何给定时刻处于 R 和 D 状态的进程数。load average 值为您提供了必须等待多长时间才能完成任务的相对度量。这里有几个小例子，我们来直观的理解下这两个概念。\n\n1、在单核心系统上，load average 为 0.4 意味着系统只完成了它能完成的 40% 的工作。load average 为 1 意味着系统正好处于满负荷状态——即使添加一点点额外的工作，系统也会过载。一个 load average 为 2.12 的系统意味着它超载了 112% 的工作，超出了它的处理能力。\n2、在多核系统上，应该首先用 load average 除以 CPU 核数，以得到类似的度量。\n\n此外，load average 实际上并不是我们大多数人所知道的典型的平均负载。它是一个“指数移动平均”，这意味着以前的 load average 的一小部分被考虑到当前的值（关于这个点，可以通过这篇文章来了解更多技术细节）。\n了解 top 的界面 - the task areasummury area 相对简单，通过它我们可以快速了解到当前系统运行的一些摘要统计信息。但是一个细节性的信息，我们只能通过 task area 中来得到。\n12345678910111213141516PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 52601 root      39  19 1310268  14900   9836 S   0.3  0.0  22:59.21 logagent-collec     1 root      20   0   45416   5244   3968 S   0.0  0.0   5:35.71 systemd   340 root      20   0   64700  21336  17684 S   0.0  0.1   8:33.90 systemd-journal   357 root      20   0  101836   2768   2312 S   0.0  0.0   0:01.13 gssproxy   384 dbus      20   0   28632   2800   2464 S   0.0  0.0   0:00.04 dbus-daemon   432 root      20   0   84760   5852   4984 S   0.0  0.0   0:00.01 sshd   461 agent     20   0   52376   5200   3684 S   0.0  0.0   0:00.01 ilogtail  1690 agent     20   0 2193388 246304  11264 S   0.0  0.7  23:45.88 java  2527 admin     20   0  161744   4268   3704 R   0.0  0.0   0:00.72 top  3245 root      20   0  559140  12412   5860 S   0.0  0.0  64:48.67 logagent  3420 root      20   0  745052  58464  43820 S   0.0  0.2  11:16.32 metricbeat  3447 root      20   0  957796  55548  43708 S   0.0  0.2  10:14.47 metricbeat  5093 root      20   0 1905356 159280   9584 S   0.0  0.5  35:00.14 java  7458 root      20   0   13700   2564   2356 S   0.0  0.0   0:00.00 bash  7464 root      20   0   86268   4436   3740 S   0.0  0.0   0:00.00 sudo\n\n先来说明下各个列的含义：\n\n\n\n项目\n解释\n\n\n\nPID\n这是进程ID，一个惟一的正整数，用于标识进程。\n\n\nUSER\n这是启动进程的用户的“有效”用户名(映射到用户ID)。Linux 为进程分配一个真实的用户 ID 和一个有效的用户ID；后者允许进程代表另一个用户进行操作。(例如，非 root 用户可以提升到 root 用户来安装软件)\n\n\nPR NI\n“NI” 字段显示进程的 “nice” 值，“PR” 字段是从内核的角度显示了进程的调度优先级，“nice” 值影响的是进程的优先级。\n\n\nVIRT, RES, SHR and %MEM\nVIRT、RES、SHR 这三个字段都与进程的内存消耗有关。VIRT 是一个进程所消耗的内存总量。这包括程序代码、进程在内存中存储的数据，以及已经 swap 到磁盘的任何内存区域。RES是进程在 RAM 中消耗的内存，%MEM 表示这个值占总可用 RAM 的百分比。最后，SHR 是与其他进程共享的内存量。\n\n\nS\n表示进程状态\n\n\nTIME+\nTIME+ 列表示的是进程自启动以来所使用的总 CPU 时间，精确到百分之一秒。\n\n\nCOMMAND\nCOMMAND 列表示的是当前进程的名称。\n\n\ntop 命令的使用示例到目前为止，我们已经讨论了 top 的界面信息所描述的含义。但是，top 除了显示这个信息之外，它还可以管理进程，并且我们可以控制 top 输出的各个方面。在本节中，我们将举几个例子。（在下面的大多数例子中，你必须在 top 运行时按下一个键。这些按键是区分大小写的，所以如果你在大写锁定状态下按了k，你实际上已经按了一个k，但是这个命令并不会工作）\nkill 进程如果你想杀死一个进程，只要在top运行时按k。这将出现一个提示，它将询问进程的进程ID并按enter。\n1PID to signal/kill [default pid = 384]\n当然上面的这段输出的后面是可以手动输入进程 ID，下面的 34444444444444 就是手动输入的进程ID\n1PID to signal/kill [default pid = 384] 34444444444444\n如果保留此空白，top 将使用一个SIGTERM，它允许进程优雅地终止。如果您想强制终止进程，您可以在这里输入SIGKILL。你也可以在这里输入信号号，例如，SIGTERM 的数字是 384，而 SIGKILL 的数字是。如果你将进程ID留空并直接按enter，它将终止列表中最顶端的进程。正如前面提到的，我们也可以使用箭头键滚动，并通过这种方式更改想要终止的进程。\n排序进程列表使用像 top 这样的工具的一个最常见的原因是找出哪个进程消耗的资源最多。我们可以按以下键排序列表:\n\nM：用于按内存使用情况排序\nP：来按CPU使用率排序\nN：按进程ID排序\nT：来按运行时间排序默认情况下，top 按降序显示所有结果，但是我们可以通过按R键切换到升序。还可以使用 -o 开关对列表进行排序。例如，如果想排序进程的CPU使用量，可以这样做:1top -o %CPU\n\n显示线程列表而不是进程列表前面已经介绍过 Linux 如何在进程之间切换。我们知道，进程是不共享内存或其他资源的，这使得这种切换相当慢。和其他操作系统一样，Linux 支持一种“轻量级”的替代方案，称为“线程”。“线程”是进程的一部分，“线程”可以共享内存和其他资源的某些区域，同时它们也可以像进程一样并发运行。默认情况下，top在其输出中显示一个进程列表。如果想列出线程代替进程，按 H 即可，此时 “Tasks” 行将显示的是 “Threads”，显示的是线程的数量，而不是进程的数量。\n11 Threads: 351 total,   2 running, 349 sleeping,   0 stopped,   0 zombie\n细心的读者可能会发现， summury area 中的 “Tasks” 行已经改变成 “Threads” 的了，但是在 task area 中，对应的列表中的属性却没有任何更改，那既然进程和线程不同，这怎么可能呢? 原因是在 Linux 内核内部，线程和进程使用相同的数据结构进行处理，因此，每个线程都有自己的ID、状态等等。如果我们要切换回进程视图，则再次按 H 即可。此外，也可以使用 top -H 在默认情况下显示线程。\n显示进程完整路径默认情况下，COMMAND 列下的所有进程名显示的都是摘要名，如果我们期望显示当前进程的完成路径，可以通过按 c 来切换视角，或者直接使用 top -c 来启动交互界面。\n以树形结构显示父子进程可以通过在 top 交互中按 V 来切到 forest view 视角，即以以树形结构显示父子进程。\n12345432      root      20   0   84760   5852   4984 S   0.0  0.0   0:00.01  - /usr/sbin/sshd -D98518    root      20   0  118432   6884   5792 S   0.0  0.0   0:00.00      - sshd: admin [priv]98520    admin     20   0  118432   3648   2556 S   0.0  0.0   0:01.32          - sshd: admin@pts/098521    admin     20   0  120656   4936   3768 S   0.0  0.0   0:00.34              - -bash130138   admin     20   0  161748   4208   3624 R   0.0  0.0   0:00.27                  - top -c\n\n列出用户的进程要列出某个用户的进程，请在top运行时按 u。然后，输入用户名，或者留空以显示所有用户的进程；或者直接通过 top -u xxx 来指定 xxx 用户的所有进程信息。\n 1234567KiB Swap:  2097148 total,  2097148 free,        0 used. 31179088 avail MemWhich user (blank for all) root   # waiting for input  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND    1 root      20   0   45416   5244   3968 S   0.0  0.0   5:37.57 /usr/lib/systemd/systemd --system --deserialize 18  340 root      20   0   72892  30836  27184 S   0.0  0.1   8:36.56 /usr/lib/systemd/systemd-journald  357 root      20   0  101836   2768   2312 S   0.0  0.0   0:01.14 /usr/sbin/gssproxy -D  432 root      20   0   84760   5852   4984 S   0.0  0.0   0:00.01 /usr/sbin/sshd -D\n\n过滤进程如果我们需要处理许多进程，那么简单的排序实际上对我们的帮助并不是很大。那么在这种情况下，我们可以按 o 来激活 top 的过滤模式，然后通过输入一个过滤器表达式来过滤到我们的目前进程。过滤器表达式是指定属性和值之间关系的语句，例如：\n\nCOMMAND&#x3D;java: 进程名&#x3D;java 的\n!COMMAND&#x3D;java: 进程名 !&#x3D;java 的\n%CPU&gt;3.0: CPU &gt; 3.0 的如果要清除所有过滤条件的话，按 = 即可。\n\n总结\n\n\n\n\n\n\n\n\n本文主要是对A Guide to the Linux “Top” Command 这篇文章的一些内容翻译，感谢原作者提供的分享\ntop 命令对于监视和管理 Linux 系统上的进程非常有帮助，本文只是从表面做了一些简单的介绍，还有很多我们没有涉及到的内容；例如，如何在 top 中添加更多的列。更多信息，可以通过运行 man top 查看 man 页面，来进行更深层面的学习。\n","slug":"linux/linux-cmd-top","date":"2020-08-10T01:53:31.000Z","categories_index":"Linux","tags_index":"linux,top","author_index":"glmapper"},{"id":"8d3c27cae87c9531596050d409b7764c","title":"聊一聊 BeanPostProcessor 不生效","content":"关于 BeanPostProcessor 各位一定不陌生，在 SpringBoot 源码系列-Bean 的生命周期与扩展 这篇文章中，我有介绍过 bean 的创建流程及相关扩展，就有提到 BeanPostProcessor，包括它的作用时机及如何使用，这篇文章提到的这种属于比较常规的流程，因此在绝大多数场景下，都是符合我们认知的。但是最近在排查一个问题时，发现在某些场景下，BeanPostProcessor 不生效了…\n\n\n问题描述\n\n\n\n\n\n\n\n\n代码详见：extention-FactoryBean; clone 之后可以直接运行 DemoApplication 即可，可以观察到 控制台不输出 GlmapperBeanPostProcessor 里面 print out 的字符串。\n运行代码，即可观察到具体的执行现场；代码里除了 BeanPostProcessor 之外，另外一个是 FactoryBean，也就是本篇所要聊的重点：FactoryBean getObjectType 为 null 时导致 bean 提前初始化，从而使得作用与目标 bean 的 BeanPostProcessors 都失效了。\n下面将基于这个问题，展开进行分析。\nbean 生命周期先来看下 ApplicationContext 和 bean 生命周期(仅列出部分关键流程)：\n从流程中可以看到：BeanPostProcessor 的注册是在 ApplicationContext 生命周期中完成的，故而当 bean 创建时，如果相应拦截器 BeanPostProcessor 还没有注册，那么其就不会起作用，这个可能有以下两种原因：\n\n1、bean 本身是一个 BeanPostProcessor ，且实现了 PriorityOrdered 或者 Ordered 接口\n2、bean 由于某种原因，被提前初始化了，初始化的时候相应拦截器 BeanPostProcessor 还没有注册\n\n关于第一个其实很好理解，不再赘述，本篇主要基于第二个原因进行说明。\nbean 由于某种原因，被提前初始化了，初始化的时候相应拦截器 BeanPostProcessor 还没有注册bean 被提前初始化的情况就比较多了，归纳下来都能符合同一个规律：在 创建所有 non-lazy-init bean 这一步之前，也即在创建 BeanFactoryPostProcessor 或者 BeanPostProcessor 的过程中，引发了 bean 的创建，导致其被提前初始化，大体可以分为两种情形：\n\n用户自定义的 BeanFactoryPostProcessor 或者 BeanPostProcessor 中会通过构造函数、属性注入等方式引用到目标 bean 导致其被提前创建\n在上述过程中由于 Spring 自身对 FactoryBean 的 typeCheck(类型检测) 机制导致目标 bean 被提前创建\n\n对于第一种情形，比较简单，这个通常是用户的配置导致的，比如我的 TestBeanFactoryPostProcessor 中通过属性注入了目标 bean 导致了其被提前创建，最终拦截器失效(如果去掉相应 TestBeanFactoryPostProcessor 配置，可以看到拦截器是能够成功的 )。\n\n\n\n\n\n\n\n\n\n简单代码如下，作用在 TestFacade 上的 BeanFactoryPostProcessor 可能会由于 TestFacade 的提前被创建而失效\n12345678public class TestBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123;    @@Autowired    private TestFacade testFacade;    @Override    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123;        // ...    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n如何找到 bean 被提前初始化的时机呢？可以在 org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBean(java.lang.String, org.springframework.beans.factory.support.RootBeanDefinition, java.lang.Object[]) 打一个条件断点，通过 beanName 进行匹配，然后顺着 debug 堆栈往回找，就能够看到是在哪里导致了 bean 被提前创建。\n对于第二种情形，其实也是通过上述方法先找到被提前创建的源头，只不过这种情形更加隐晦，也更加复杂，这里我们单独在下面的部分中来分析。\n关于 isTypeMatch从 Spring 2.x 版本开始，BeanFactory 中就已经有 isTypeMatch 这个方法了\n12345678910111213141516/*** Check whether the bean with the given name matches the specified type.* More specifically, check whether a &#123;@link #getBean&#125; call for the given name* would return an object that is assignable to the specified target type.* &lt;p&gt;Translates aliases back to the corresponding canonical bean name.* Will ask the parent factory if the bean cannot be found in this factory instance.* @param name the name of the bean to query* @param typeToMatch the type to match against (as a &#123;@code Class&#125;)* @return &#123;@code true&#125; if the bean type matches,* &#123;@code false&#125; if it doesn&#x27;t match or cannot be determined yet* @throws NoSuchBeanDefinitionException if there is no bean with the given name* @since 2.0.1* @see #getBean* @see #getType*/boolean isTypeMatch(String name, @Nullable Class&lt;?&gt; typeToMatch) throws NoSuchBeanDefinitionException;\n\n从方法注释可以简单了解到，isTypeMatch 的作用就是：判断 JavaBean 是否匹配指定的类型。他包括两个参数：\n\nname：容器中定义的 JavaBean 的名称。\n\ntypeToMatch：要匹配的目标类型。回到案例，我们需要关注的是 isTypeMatch 和我们前面提到的 FactoryBean getObjectType 为 null 时导致 bean 提前初始化，从而使得作用与目标 bean 的 BeanPostProcessors 都失效了。有什么关系呢？这里有两个比较关键的信息：\n\n1、FactoryBean getObjectType 为 null\n\n2、目标 bean 的 BeanPostProcessors 都失效了\n\n\n其实大概能够猜到的是，FactoryBean getObjectType 为 null 时，导致了 当前 bean 被提前初始化，而此时 bean 的 BeanPostProcessors 还没有被注册到当前 bean ，从而导致了目标 bean 的 BeanPostProcessors 都失效。 这个也是本篇的结论，但是还是需要来看看具体原因的细节是什么样的。\n我们知道，在 Spring 中，当进行 byType (除了用户主动配置 byType 注入以外，使用 @autowired 以及 @Bean 中的方法参数时等都使用的是 byType 注入) 注入时，会通过 org.springframework.beans.factory.ListableBeanFactory#getBeanNamesForType(java.lang.Class&lt;?&gt;, boolean, boolean) 来寻找相应类型的 bean 。\n针对 FactoryBean 而言，当判断其类型时，会先创建一个简单的(非完整的，仅仅是调用构造函数) bean ，调用其 getObjectType() ，如果发现返回为 null，那么就会再创造完整的 bean ，然后再通过 getObjectType() 获取类型进行匹配。\n详细分析基于上面提到的点，结合本案例，来 debug 看下 FactoryBean typeCheck(类型检测) 机制导致的 BeanPostProcessor 不生效的原因。这里主要还是看下 isTypeMatch 方法执行是如何触发 bean 提前初始化的。\nisTypeMatch 方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798@Overridepublic boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException &#123;    String beanName = transformedBeanName(name);        // Check manually registered singletons.    Object beanInstance = getSingleton(beanName, false);    // 常规情况下，这里 beanInstance 是不为 null 的，但是对于提前加载的 beanInstance == null    if (beanInstance != null &amp;&amp; beanInstance.getClass() != NullBean.class) &#123;        // 判断类型是不是 FactoryBean        if (beanInstance instanceof FactoryBean) &#123;            // 返回给定名称是否为工厂解除引用(以工厂解除引用前缀开始)。 &amp;xxxx             if (!BeanFactoryUtils.isFactoryDereference(name)) &#123;                // 这里拿 FactoryBean#getObjectType                Class&lt;?&gt; type = getTypeForFactoryBean((FactoryBean&lt;?&gt;) beanInstance);                return (type != null &amp;&amp; typeToMatch.isAssignableFrom(type));            &#125;            else &#123;                // 实例类型是否匹配                return typeToMatch.isInstance(beanInstance);            &#125;        &#125;        // 处理泛型和代理        else if (!BeanFactoryUtils.isFactoryDereference(name)) &#123;            if (typeToMatch.isInstance(beanInstance)) &#123;                // 直接匹配暴露实例?                return true;            &#125;            else if (typeToMatch.hasGenerics() &amp;&amp; containsBeanDefinition(beanName)) &#123;                // 泛型可能只匹配目标类，而不匹配代理…                RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);                Class&lt;?&gt; targetType = mbd.getTargetType();                if (targetType != null &amp;&amp; targetType != ClassUtils.getUserClass(beanInstance) &amp;&amp;                        typeToMatch.isAssignableFrom(targetType)) &#123;                    // 还要检查原始类匹配，确保它在代理上暴露。                    Class&lt;?&gt; classToMatch = typeToMatch.resolve();                    return (classToMatch == null || classToMatch.isInstance(beanInstance));                &#125;            &#125;        &#125;        return false;    &#125;    // 当前 beanName 的 bean 没有被注册过    else if (containsSingleton(beanName) &amp;&amp; !containsBeanDefinition(beanName)) &#123;        // null instance registered        return false;    &#125;    // 没有找到单例实例-&gt;检查bean定义。    BeanFactory parentBeanFactory = getParentBeanFactory();    if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123;        // 在这个 factory 中没有找到 bean definition -&gt; 委托 parent。        return parentBeanFactory.isTypeMatch(originalBeanName(name), typeToMatch);    &#125;    // 检索相应的 bean 定义。    RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);    Class&lt;?&gt; classToMatch = typeToMatch.resolve();    if (classToMatch == null) &#123;        classToMatch = FactoryBean.class;    &#125;    Class&lt;?&gt;[] typesToMatch = (FactoryBean.class == classToMatch ?            new Class&lt;?&gt;[] &#123;classToMatch&#125; : new Class&lt;?&gt;[] &#123;FactoryBean.class, classToMatch&#125;);    // Check decorated bean definition, if any: We assume it&#x27;ll be easier    // to determine the decorated bean&#x27;s type than the proxy&#x27;s type.    // 检查修饰 bean definition(如果有的话):我们假设确定修饰 bean 的类型比确定代理的类型更容易。    BeanDefinitionHolder dbd = mbd.getDecoratedDefinition();    if (dbd != null &amp;&amp; !BeanFactoryUtils.isFactoryDereference(name)) &#123;        RootBeanDefinition tbd = getMergedBeanDefinition(dbd.getBeanName(), dbd.getBeanDefinition(), mbd);        // 预测指定bean的最终bean类型(已处理bean实例的)。由&#123;@link #getType&#125;和&#123;@link #isTypeMatch&#125;调用。不需要专门处理factorybean，因为它只应该操作原始bean类型。        // 这个实现过于简单，因为它不能处理工厂方法和实例化 awarebeanpostprocessors。对于标准bean，它只能正确地预测bean类型。要在子类中重写，应用更复杂的类型检测。        Class&lt;?&gt; targetClass = predictBeanType(dbd.getBeanName(), tbd, typesToMatch);        if (targetClass != null &amp;&amp; !FactoryBean.class.isAssignableFrom(targetClass)) &#123;            return typeToMatch.isAssignableFrom(targetClass);        &#125;    &#125;    // 推断出 beanType    Class&lt;?&gt; beanType = predictBeanType(beanName, mbd, typesToMatch);    if (beanType == null) &#123;        return false;    &#125;        // 检查 bean class 是否是 FactoryBean 类型。本案例就是在这被处理到 返回 false 的    if (FactoryBean.class.isAssignableFrom(beanType)) &#123;        if (!BeanFactoryUtils.isFactoryDereference(name) &amp;&amp; beanInstance == null) &#123;            // 如果它是FactoryBean，我们希望看到它创建了什么（getObject），而不是工厂类。            beanType = getTypeForFactoryBean(beanName, mbd);            if (beanType == null) &#123;                return false;            &#125;        &#125;    &#125;    // 省略 ........&#125;\n\ngetTypeForFactoryBean 方法这个步骤会向尝试从 FactoryBean 的 getObjectType 方法去获取类型，如果拿不到，则调用父类的进行初始化 bean 操作\n123456789101112131415// 省略 其他...if (fb != null) &#123;    // 尝试从实例的这个早期阶段获取 FactoryBean 的对象类型。这里调用的就是 FactoryBean#getObjectType 方法    Class&lt;?&gt; result = getTypeForFactoryBean(fb);    // 本案例中这里返回的是 null, 所以会走到 else    if (result != null) &#123;        return result;    &#125;    else &#123;        // 这里的意思就是没有通过 FactoryBean#getObjectType 快速获取到类型        // 将执行实例当前实例，然后再获取        return super.getTypeForFactoryBean(beanName, mbd);    &#125;&#125;// 省略 其他...\n\nAbstractBeanFactory#getTypeForFactoryBean调用父类的 getTypeForFactoryBean 方法，执行 bean 的初始化\n123456789101112131415@Nullableprotected Class&lt;?&gt; getTypeForFactoryBean(String beanName, RootBeanDefinition mbd) &#123;    if (!mbd.isSingleton()) &#123;        return null;    &#125;    try &#123;        // 这里开始执行 doGetBean，之前的文章里面有提到，bean 实例化的入口就是 getBean 的时候        FactoryBean&lt;?&gt; factoryBean = doGetBean(FACTORY_BEAN_PREFIX + beanName, FactoryBean.class, null, true);        return getTypeForFactoryBean(factoryBean);    &#125;    catch (BeanCreationException ex) &#123;        // 省略日志打印部分        return null;    &#125;&#125;\n\n在 doGetBean 中执行链路中，会在 initializeBean 时给当前 bean 注册 BeanPostProcessor，（applyBeanPostProcessorsBeforeInitialization 方法中) ，这里可以比较清晰的看到 BeanPostProcessor 没有作用于 目标 bean 的。\n\n\n\n\n\n\n\n\n\ndoGetBean -&gt; createBean -&gt; initializeBean -&gt; applyBeanPostProcessorsBeforeInitialization\n\n小结在本篇的案例中，其实比较明显的可以看到测试工程中 GlmapperFactoryBean 的 getObjectType 返回是为 null 的，也正是因为这个原因导致了 BeanPostProcessor 失效。那么如何在实际的开发过程中来规避呢？\n\n1、FactoryBean 的 getObjectType() 不要返回 null\n2、定义 BeanPostProcessor 时，需要特别注意 order\n3、在 创建所有 non-lazy-init bean 之前的 getBeanNamesForType 调用，尽量将 eagerInit 传为 false。\n\n关于第三点，前面提到过 getBeanNamesForType 的调用会触发类型检查，但其实这个方法还有些参数，参考如下：\n1String[] getBeanNamesForType(Class&lt;?&gt; type, boolean includeNonSingletons, boolean allowEagerInit);\n这里有个很重要的参数 allowEagerInit ，可以看到 spring 的注释中对其有非常详细的解释：\n12345* @param allowEagerInit whether to initialize lazy-init singletons and* objects created by FactoryBeans (or by factory methods with a* &quot;factory-bean&quot; reference) for the type check. Note that FactoryBeans need to be* eagerly initialized to determine their type: So be aware that passing in &quot;true&quot;* for this flag will initialize FactoryBeans and &quot;factory-bean&quot; references.\n\n简单来说这个参数能够控制是否允许 FactoryBean 的提前创建，如果是 false，那么也不会引发上述的 类型检测 。可以看到在 Spring 中在获取 BeanFactoryPostProcessor 以及 BeanPostProcessor 时，也都是传入 false 的。\n1234String[] postProcessorNames =        beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);String[] postProcessorNames =     beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);\n当然在一些 @Bean 的方法参数注入、@Autowire 注入等场景下，这个默认都是 true 的，无法改变；但针对平时编码过程中，如果是在比较早期的调用中，可根据情况，尽量传入 false。\n","slug":"spring/spring-series-factory-bean-and-post-processor","date":"2020-06-21T02:52:12.000Z","categories_index":"spring","tags_index":"BeanPostProcessor,bean 生命周期","author_index":"glmapper"},{"id":"a1ba8e53214d9964ec5cbb3342aa4377","title":"解决方案系列-集群选主(基于DB)","content":"一个业务量很小的系统，所有的代码都放在一个项目中，部署在一台服务器上。所有的服务都由这台服务器提供，这就是常说的单机模式；我们知道单机模式的缺点是：1、处理能力有限，2、存在单点问题。单机模式大致如下图所示：\n\n为了解决这些问题，出现了集群模式。\n\n\n\n常见的集群模式方案\n集群主要的使用场景就是为了分担请求的压力，也就是在几个服务器上部署相同的应用程序，来分担客户端请求。集群主要是通过加机器来解决问题，对于问题本身是不会做任何分解的。（PS：分解了就是分布式）。那么常见的集群模式有哪几种呢？\n主备，冷备模式，主写主读\n所有的写请求都由 master 负责处理，如果请求打在 slave 上，则 slave 会将请求转发给 master 处理，架构图如下图所示：\n\n冷备模式主要是在请求量不大，且对于数据状态有要求的情况（比如所有的数据其实都是 master 内存存储），提供一个从机用于备用，在 master 出现问题的时候能够及时顶上去。\n主备，主写从读\n基于冷备模式，衍生出主写从读，也就是 master 会将数据同步给各个 slave，然后就可以分担掉读请求的处理压力，架构图如下图所示：\n\n这种模式算是比较常见的，像数据库的主从模式。\n对等，广播\n这种场景是客户端的请求可能需要指定的集群中的某个 server 来处理，常见的比如配置中心，配置中心客户端会选择与集群中的某个 server 建立连接，当通过管控端推送配置指令下来时，因为没法指定到具体的 server 去推送，所以当请求推到集群的某台机器时，该机器会向集群中的其他机器广播此次请求，谁持有这个客户端的连接，谁去处理。架构图如下图所示：\n\n纯对等（无状态）\n最后一种就是纯对等的，集群中的机器谁处理都行；这种就是广义说的集群模式，通过扩机器解决高并发。\n\n集群选主\n集群选主指是上述提到的主备模式下进行的，也就是有状态的情况，无状态场景不需要进行选主操作。集群选主很容易，困难的是选主之后的操作（比如如何协调和感知集群中的机器状态），还有集群内机器发生变更之后的操作（如如何分配客户端连接，这里就会涉及到一个非常常见的问题：一致性 hash）。本篇主要介绍集群选主，所以对于这两个问题不做过多的探讨。\n集群选主的方式有很多种，本篇只介绍通过 ”争抢锁“ 的选主方式，即在集群中机器启动时会通过争抢某个”非共享“资源，谁抢到谁来当 master。那么基于此，我们可以罗列以下几种常见的”非共享“资源：\n\nDB 的唯一键插入\nzk 的节点创建\nredis 的原子写\n…\n\n基于 DB 的唯一键插入实现选主\n下面以 DB 的唯一键插入 为例来简单介绍下选主的逻辑。\n\n  数据库唯一键：unique key，用来保证对应的字段中的数据唯一。\n\n机器表设计&amp;唯一键设置\n所有集群中的机器启动时都需要将自己的机器信息写到 DB 中。这里创建一个唯一键：uk_master，包括两个字段，分别是 机器状态和一个 master_lock（master 锁）。\n--------------------------------Tablestructureforcluster_servers------------------------------DROPTABLEIFEXISTS`cluster_servers`;CREATETABLE`cluster_servers`(`id`int(11)NOTNULLAUTO_INCREMENTCOMMENT'主键',`host_name`varchar(128)NOTNULLCOMMENT'主机名',`ip`varchar(16)NOTNULLCOMMENT'ip地址',`is_master`int(4)NOTNULLCOMMENT'是否是master',`status`varchar(32)NOTNULLCOMMENT'机器状态',`master_lock`varchar(128)NOTNULLCOMMENT'master锁',`heartbeat`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPONUPDATECURRENT_TIMESTAMPCOMMENT'心跳时间',`gmt_sql_server_time`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'sql执行时间',`gmt_modify`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'修改时间',`gmt_create`timestampNOTNULLDEFAULTCURRENT_TIMESTAMPCOMMENT'创建时间',PRIMARYKEY(`id`),UNIQUEKEY`uk_master`(`status`,`master_lock`)USINGBTREE)ENGINE=InnoDBDEFAULTCHARSET=utf8;\n争抢唯一键\n这里就是谁更新数据状态成功，谁就是 master，没有争抢成功则是 slave。\n&lt;updateid=\"setMaster\"&gt;updatecluster_serverssetis_master=#&#123;isMaster&#125;,master_lock=#&#123;masterLock&#125;,status=#&#123;status&#125;,heartbeat=CURRENT_TIMESTAMP,gmt_modify=CURRENT_TIMESTAMPwherehost_name=#&#123;hostName&#125;&lt;/update&gt;\n集群选主的过程\n基于此，集群选主的大致过程可以通过下图描述：\n\n这里的像 slave 的后置任务，比如开启监听 master 状态，这样在 master 出现问题时就会触发新的选举。master 的后置任务一个是开始监听各个 slave 的状态，如果 slave 出现问题，则可以及时的将此 slave 踢出集群，其他则需要根据具体的业务情况来看。\n总结\n本篇主要介绍了集群的几种基本形态，然后基于需要选主的场景进行了简单分析；最后提供了基于 DB 进行集群选主的一种可行性方案，并介绍了大体的选主流程。需要补充一点，基于 DB 选主和维持心跳本身是比较重的，强依赖 DB 的状态，如果 DB 有问题则集群状态可能会出现一些非预期的情况或者导致集群直接不可用，所以大家在选择具体的方式时，还是要结合业务的具体场景来选择。","slug":"solutions/solution-series-cluster-selector","date":"2020-05-29T10:12:42.000Z","categories_index":"解决方案","tags_index":"架构,Mysql,集群选主","author_index":"glmapper"},{"id":"753168a64d611acbfc5231c389c4fa85","title":"什么是中台？","content":"没有XX台的时代 - 烟囱式的架构在传统IT企业，项目的架构是什么样的呢？无论项目内部的如何复杂，都可简化分为前台和后台两部分，也就是垂直的烟囱式架构（业内人士把见招拆招、垂直化发展、未做足够抽象通用的架构称之为烟囱型架构）。什么是前台？所谓前台即包括各种和消费者用户直接交互的界面业务功能，比如web页面（PC端），手机app（无线端或移动端）。什么是后台？后台是面向运营人员的配置管理系统，比如商品管理、物流管理、结算管理。后台为前台提供业务管理等。前台、后台、用户之间的关系，可以用下图简单表示：\n\n\n\n起初，项目的发展相对稳定，并不需要快速的去迭代，所以垂直的烟囱式结构并没有什么问题。但在互联网快速发展的今天，企业之间的竞争越来越激烈，只有以用户为中心，快速响应用户的需求，不断迭代和试错，才能让企业在竞争当中立于不败。在传统的前台-后台架构中，各个项目相对独立，许多项目都在重复发明同样的轮子（比如用户中心，支付业务等），即让项目本身越来越臃肿，也让开发效率越来越低。这种时候，为提高开发效率，我们有必要整合出一个中间组织，为所有的项目提供一些公共资源。而这个中间组织，就是人们所说的平台。\n垂直烟囱的进化 - 平台化的架构为什么会出现平台化架构，还得从烟囱型架构说起（参考上一节）。但烟囱型架构并非一无是处，在早期业务死活未知的情况下，不过度设计架构，能直接有效的支持到业务。不过，当业务发展起来之后，烟囱越树越多，成长的烦恼就如期而至了。\n​第一个问题是人不够，业务响应慢了下来。我们以一个5人研发团队为例来说明一下这个问题。起初团队一个产品都没有，5个人1个月干出一个简单版本的红包系统；几年之后团队增加到10人，但手头要维护10个系统。那么平均人手一个系统，这时候，又来了2个新业务，团队派出3个人去干，大约要干4个月，严重不符合前端业务的响应预期。\n第二个问题是重复建设，同类烟囱系统中80%的功能是类似的，从数据库模型到主要业务逻辑，都是copy-paste加补丁，一步留神又踩到一个坑。\n第三个问题是维护成本高。日常升级包、咨询支持服务，团队疲惫不堪。基于此，80%甚至90%的共性问题，能不能抽象出来呢？核心领域模型是否可以是稳定的呢？从下图可以看出，这是可以做到的。\n​ 在既要支持不断出现的各种业务，又要支持建设新平台。企业便启动了平台化建设，对前后台业务提供统一的能力露出，由能力组装编排内部服务。研发规则运营、统一后台管理服务等。\n\n总结下来，平台化架构有以下好处：一是快速支撑、响应业务；二是抽象共性，边界清晰。快速支撑，响应业务是以终为始的出发点。架构如果不服务业务，再高大上都是扯淡。技术不是炫技，要服务商业。再谈谈抽象共性的问题，业务平台化要解决业务共性问题，比如天猫、淘宝都有各类营销活动。那么就抽象出一个营销平台来管理营销活动、营销工具的整个的生命周期管理。\n中台的架构思想 - 大中台小前台中台的起源SuperCell SuperCell 是一家芬兰的手机游戏公司，这个名字或许有些陌生，但是说起下面几款游戏，大家一定会很熟悉：部落冲突、海岛奇兵、皇室战争等。SuperCell 公司就像是一个高产的游戏孵化器，在几年内开发出了10款以上的游戏，但是大部分用于试错的游戏都在研发过程中被腰斩了，最终呈献给用户的几款游戏都是经典中的经典。是什么让 SuperCell 公司能够如此高效地试错和迭代呢？他们依靠的是强大的平台资源，支撑起各个游戏开发的小团队。他们开发出的游戏看上去风格迥异，却存在许多共同之处。在业务上，共通的东西包括支付系统、用户系统等等，在技术上，共同的东西包括游戏引擎，内部开发工具等等。而这些共通的资源，都可以由一个强大的“中台”来提供。Supercell 的中台，指的是公司将游戏开发过程中公共和通用的游戏素材和算法整合起来，并积累了非常科学的研发工具和框架体系，构建了一个功能非常强大的中台。这样强大的中台可以支持若干个小团队在短时间内开发出一款新的游戏。\n \n阿里巴巴 马云在2015年的一次欧洲之旅（访问SuperCell公司），将中台的思想结合阿里的现状，提出了大中台、小前台的战略架构，从而将中台架构思想引入国内，开启了中台化热潮。\n \n中台的定义中台是什么？简言之，中台是给业务团队提效为目标的，可复用的技术能力及业务能力的集合。有业务能力说明理解业务，能复用说明能提效。从这个定义可以看出，中台更接近是一个解决方案。\n中台的分类中台 是 可复用的技术能力和业务能力的集合；与此相对应的，中间件、技术框架、技术平台 是 可复用的技术能力的集合；中台和中间件的共同点就是他们都需要被复用才能发挥价值，并不能出去单打独斗。\n​以此类推：业务中台就是可复用的业务技术能力和组织业务能力的集合；数据中台就是可复用的数据技术能力和数据业务能力的集合；算法中台就是可复用的算法技术能力和算法业务能力的集合；\n​但是，技术中台这种说法有点迷，会让人误解里面都是技术复用，而没有任何业务。如果其实是纯粹的技术复用平台，建议大家在平常交流时还是尽量别用技术中台，直接用中间件、技术平台、技术框架的原有概念来沟通即可，没必要赶时髦。\n中台的用户\n电商交易系统，前台的用户是消费者，后台的用户是电商运营，中台的用户是谁？\n\n企业管理系统，前台的用户是员工，后台的用户是企业管理员，中台的用户是谁？\n\n数字政务系统，前台的用户是公务员，后台的用户是政府管理员，中台的用户是谁？\n\n\n大中台，小前台。 这种说法的误导性在于，让人以为中台是为前台服务的。但其实中台可以服务任何业务形态。从 Supercell 这个故事可以看出，中台不会直面消费者或最终用户。中台的作用就是为业务团队服务，让业务团队更好更快的服务最终用户。\n中台是必须？从0到1的阶段没有必要搭建中台。从0到1的创业型公司，首要目的是生存下去，以最快的速度打造出产品，证明自身的市场价值。这个时候，让项目野蛮生长才是最好的选择。如果不慌不忙地先去搭建中台，恐怕中台还没搭建好，公司早就饿死了。\n从1到N的阶段​适合搭建中台。当企业有了一定规模，产品得到了市场的认可，这时候公司的首要目的不再是活下去，而是活的更好。这个时候，趁着项目复杂度还不是特别高，可以考虑把各项目的通用部分下沉，组建中台，以方便后续新项目的尝试和旧项目的迭代。\n从N到N+1的阶段​搭建中台势在必行。当企业已经有了很大的规模，各种产品、服务、部门错综复杂，这时候做架构调整会比较痛苦。但是长痛不如短痛，为了项目的长期发展，还是需要尽早调整架构，实现平台化，以免日后越来越难以维护。\n中台的FAQ中心化&#x2F;平台化&#x2F;中台化异同？中心化-&gt;平台化-&gt;中台化，更像是随着组织规模增大，分布式系统下一种架构思想的演进。在业务最早期，业务既量小又简单，一个业务系统、单机或几台机器就支持了。随着业务快速发展，团队增多，带来诸多的效率和稳定性问题，系统架构升级，开始系统拆分，正式进入分布式系统阶段，并由此开启了一段新的架构演进，如下图所示：\n\n\n中心化重在领域建模，通过对自身领域的抽象建模，对外提供统一标准的数据和服务；\n平台化重在业务抽象和架构开放，“业务抽象解决共性的80%问题，系统架构开放性解决20%的个性化问题”，既能对外提供标准的数据和服务，还能通过平台配置，或实现指定服务接口，或平台内部实现业务逻辑控制等方式支持不同业务的运行；\n中台化重在建立标准和机制，通过建立业务身份、能力、扩展点等业务领域概念标准，能力管控、流程编排等系统运行时标准，使大家能互联互通、共享共建，以统一的标准进行需求分析、技术开发和复用。\n\n总的来说：中心主要负责自身单一领域的建设，而平台要负责对多个业务域的支持，而中台则是要覆盖到所有业务域，建立整个业务域的协同标准和机制。所以中台的技术连通性更强，技术生态性更突出。淘系业务系统的发展正是这个过程，业务上从淘宝时期到三淘（淘宝、天猫、一淘）时期到现在的淘系生态，系统上从商品中心、店铺中心等到商品平台、店铺平台到今天的电商业务中台。\n小前台到底多小才算小呢？小前台只是个代称，并不一定非得是前台团队， 用一个“快速反应团队”代之较为合适。也就是5人、7人、最多十几个人组成的团队，不宜过大（其实是相对“小”，不用刻意追求数量的少）。过大了惯性也会比较大，掉头就比较不容易，不利于快速反应、创新、试错。\n如何下手建设中台化架构？从哪里开始？哪种路径更适合打造一个中台？\n\n直接下手开始做中台，逐步扩展到其他业务\n从最擅长的业务（核心业务）入手，做中台的探索\n\n第一种路径的好处是一开始可以做好中台的规划，技术栈保持一致性。坏处是失败的概率和成本比较高。第二种路径更保险，也是目前来看比较可能结出果实的路径。比如：阿里先有电商业务和互联网金融业务，然后才做了共享业务、星环等中台方案。头条最擅长算法业务，然后才有了算法中台。腾讯在IM领域沉淀了多年，基于IM做中台符合逻辑。\n中台架构到底在学习什么？值得我们学习的不是中台本身，而是 Supercell 模式。Supercell 模式如何实现，马老师已经给了一种路径：大中台，小前台。 但也许这不是唯一路径，但至少是种思路。18年到19年，有种功利化、蹭热度化、浮躁化的氛围，弥漫在中台的圈子里。大家一哄而上，咋咋呼呼的大跃进式的建设大中台，逢人必谈中台，周报写中台，开会说中台，晋升提中台，甚至借中台之名，行平台之实。\n参考资料\n我看中台：https://mp.weixin.qq.com/s/fQ98fe3XH6imxzNhwiNaNA\n漫画：什么是中台：https://mp.weixin.qq.com/s/rF7_xJBq4NJP6CmkW3HPpQ\n掘金： 数据中台：https://juejin.im/search?query=数据中台\n读透《阿里巴巴数据中台实践》，其到底有什么高明之处？：https://juejin.im/post/5d79fedff265da03cd0aac81\n知乎：中台如何做到快速响应：https://www.zhihu.com/search?type=content&amp;q=中台如何做到快速响应\n业务中台探索和实践：软件的根本问题：https://zhuanlan.zhihu.com/p/59867439\n什么是中台？什么不是中台？所有的中台都是业务中台：https://zhuanlan.zhihu.com/p/77097815\n如何建设中台？中台建设的组织、支撑技术和方法论：https://zhuanlan.zhihu.com/p/77362869\n什么是人力资源中台模式？：https://www.zhihu.com/question/332569121/answer/733808658\n中台是什么，到底要解决什么问题？：https://juejin.im/post/5d8093c251882579f24fb9ed\n从平台到中台【上】：https://mp.weixin.qq.com/s/dpkteHsQJ4Rwl6YNl2PVeg?\n从平台到中台【下】：https://mp.weixin.qq.com/s/TirTQfWo0gX9PUw_okdGjQ?\n陈华编著《企业IT架构转型之道：阿里巴巴中台战略思想与架构实战》：https://book.douban.com/subject/27039508/\n\n","slug":"solutions/solution-series-zhongtai","date":"2020-05-19T03:11:01.000Z","categories_index":"解决方案","tags_index":"架构,中台","author_index":"glmapper"},{"id":"44fd65499cadd100c61bae4110f540c9","title":"ClassLoader 类加载-type checking 对类加载的影响","content":"Type CheckingType Checking (类型检测) 的作用是分析程序在编译或者运行期间，其类型表达是否一致的一个过程。举个例子：如果一个变量被声明为 int 类型，那么他就不能被赋值为实际的值（或者字符串类型、或者其他任何类型）。java 语言的类型检测分为两种：\n\n静态类型检测（static checking）: 问题在程序运行之前被自动找到，也就是在编译阶段完成的检查。静态类型检测更多的是关注在”类型“上。\n动态类型检测（dynamic checking）: 问题在运行期间被检测，动态运行检测关注的是在”值“上。\n\n\n\n本文主要介绍静态类型检测。java 语言在编译时会做大量的类型检测，只要你声明了一个变量的类型，编译器将会确保只有相应类型的值可以被赋值给这个变量（或者这个值的类型是变量类型的子类型）。比如，如果你声明了如下变量：\n1int x;\n这里可以确保它只保存 int 值。但是，如果将变量声明为 List，则该变量可能包含列表的子类型，包括 ArrayList、LinkedList 等。\nType Checking 对类加载的影响前面提到静态类型检测主要是对类型的检测，而 java 语言中，类型一致表示的是 类全限定名+ClassLoader 一致，所以在做类型检测时就必定会涉及到某些类的 class load 操作。下面我们就从几个方面来分析下类型检测对于类加载的影响。\n\n\n\n\n\n\n\n\n\n在 jvm 参数中配置 -verbose:class 可以观察类加载过程\n方法的返回类型在下面的例子中， Main 执行过程，check 方法没有被调用，但是该方法返回了一个非 ClassA 的类型，也就是类型 ClassB。那么类型检测就要求就提前加载 ClassA 和 ClassB 类型，加以验证，因此加载顺序如下（ClassA –&gt; ClassB –&gt; ClassC –&gt; ClassD）。\n12345678910111213141516public class ClassA &#123;&#125;public class ClassB extends ClassA&#123;&#125;public class ClassC &#123;&#125;public class ClassD &#123;&#125;public class Main &#123;    static ClassC c;    static &#123;        c = new ClassC();    &#125;    public static void main(String[] args) &#123;        new ClassD();    &#125;    ClassA check(ClassA a) &#123;        return new ClassB();    &#125;&#125;\n\n执行查看类加载顺序如下：\n12345678[Loaded com.glmapper.bridge.boot.methodreturn.Main from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded sun.launcher.LauncherHelper$FXHelper from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded java.lang.Class$MethodArray from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded com.glmapper.bridge.boot.methodreturn.ClassA from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded com.glmapper.bridge.boot.methodreturn.ClassB from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded java.lang.Void from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded com.glmapper.bridge.boot.methodreturn.ClassC from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded com.glmapper.bridge.boot.methodreturn.ClassD from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/]\n从这里可以看到，静态域不一定会比非静态域先加载，这里就是因为静态检测提前出发了类的加载导致。\n方法参数先来看下下面这段代码，大家可以想一下类加载顺序是什么样的\n1234567891011121314public class ClassA &#123;&#125;public class ClassB extends ClassA&#123;&#125;public class ClassC &#123;&#125;public class Main &#123;    static ClassC c;    static  &#123;        c = new ClassC();    &#125;    public static void main(String[] args) &#123;        Main main = new Main();        main.m(new ClassB());    &#125;    void m(ClassA a) &#123;&#125;&#125;\n按照我们惯性理解，Main 加载之后，会加载 ClassC，然后再加载 ClassA 和 ClassB。但是事实是这样吗？通过 -verbose:class 参数执行结果如下：\n12345678[Loaded com.glmapper.bridge.boot.paramscheck.Main from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded sun.launcher.LauncherHelper$FXHelper from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded java.lang.Class$MethodArray from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded com.glmapper.bridge.boot.paramscheck.ClassA from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded com.glmapper.bridge.boot.paramscheck.ClassB from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded java.lang.Void from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded com.glmapper.bridge.boot.paramscheck.ClassC from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/]\n\n但是从这里看到，Main 执行时， ClassA ，ClassB 先于 ClassC 加载了。原因是类型检测过程中，会一行行先行的看你的代码，在这个场景中，它发现有 m(ClassA a) 方法，但是代码中传入了 ClassB 这个类型，那么在真正运行 main 方法之前，在运行 Main 的 static 块之前，先行加载了 ClassA 和 ClassB 两个类型，然后验证它们之间的关系。所以看到的类加载顺序是 ClassA -&gt; ClassB -&gt; ClassC ，而非我们概念中的 ClassC -&gt; ClassA -&gt; ClassB。\n变量赋值最后一种场景是变量赋值，来看下面的代码片段：\n12345678910111213141516171819public class ClassA &#123;&#125;public class ClassB extends ClassA&#123;&#125;public class ClassC &#123;&#125;public class ClassD &#123;    ClassA a;&#125;public class Main &#123;    static ClassC c;    static &#123;        c = new ClassC();    &#125;    public static void main(String[] args) &#123;        ClassD d = new ClassD();        d.a = new ClassB();    &#125;&#125;\n启动 main 方法时，在 jvm 参数中配置 -verbose:class 来观察类型加载顺序；\n123456789[Loaded com.glmapper.bridge.boot.variableassign.Main from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded sun.launcher.LauncherHelper$FXHelper from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded java.lang.Class$MethodArray from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded com.glmapper.bridge.boot.variableassign.ClassA from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded com.glmapper.bridge.boot.variableassign.ClassB from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded java.lang.Void from /Library/Java/JavaVirtualMachines/jdk1.8.0_162.jdk/Contents/Home/jre/lib/rt.jar][Loaded com.glmapper.bridge.boot.variableassign.ClassC from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/][Loaded com.glmapper.bridge.boot.variableassign.ClassD from file:/glmapper/Documents/glmapper/glmapper-blog-samples/glmapper-blog-sample-typecheck/target/classes/]\n\n是不是又有点出乎意料呢？类型检测发现 Main 中包含了 d.a &#x3D; new ClassB() 的语句，其中 d.a 的类型不是 ClassB，因此会先于 main 方法执行以及先于 Main 中的 static 块执行进行加载。 类型检测，将类型 ClassA 和 ClassB 的加载“提前”了。\n小结本文主要介绍了静态类型检测对于 Class Loader 加载类顺序的影响，了解此逻辑对于在考虑多 class loader 场景处理问题非常有用，对于常规的类似 ClassCastExcetion, LinkageError 等异常排查有一定的意义。\n","slug":"jvm/java-base-classloader-typecheck","date":"2020-05-01T07:21:17.000Z","categories_index":"jvm","tags_index":"typecheck,classloader,jvm","author_index":"glmapper"},{"id":"5845178adf5da311babad1f01389aa66","title":"【译】微服务（microservices）","content":"\n\n\n\n\n\n\n\n\n原文链接：https://martinfowler.com/articles/microservices.html\n\n\n目录\n微服务体系结构的特征\n通过服务拆分实现组件化\n围绕业务功能进行组织\n产品不是项目\n智能端点和轻量级通信\n分散治理\n分散的数据管理\n基础设施自动化\n容错设计\n演进式设计\n微服务是未来的趋势吗?\n\nSidebars-扩展\n微服务有多大?\nMicroservices和SOA\n多种语言，多种选择\n经过实战检验的标准和强制执行的标准\n让做正确的事情变得容易\n断路器和可随时上线的代码\n同步调用的弊端\n\n术语\n\n\n术语原词\n释义\n\n\n\nMicroservice Architecture\n微服务架构\n\n\nautomated deployment\n自动部署\n\n\ncentralized management\n集中管理\n\n\ncommunicating\n通信、交互\n\n\nlightweight mechanisms\n轻量级机制\n\n\nmonolithic application\n单体应用&#x2F;集中式应用\n\n\nload-balancer\n负载均衡器\n\n\nmodular structure\n模块化结构\n\n\nComponentization&#x2F;components\n组件化&#x2F;组件\n\n\nphysical world\n客观世界\n\n\nOO programs\n面向对象编程\n\n\nencapsulation\n封装\n\n\nprocesses\n进程\n\n\ncross-team\n跨团队\n\n\nboundaries\n边界\n\n\nbusiness capability\n业务能力\n\n\nbusiness area\n业务领域\n\n\ncross-functional\n跨职能的\n\n\nmessage bus.\n消息总线\n\n\nSmart endpoints\n智能端点\n\n\ndumb pipes\n轻量级通信\n\n\nDecentralized Governance\n去中心化治理\n\n\nInfrastructure Automation\n基础设施自动化\n\n\nDesign for failure\n容错机制设计\n\n\nEvolutionary Design\n演进&#x2F;迭代 设计\n\n\ncoarser-grained\n粗粒度的\n\n\n一个新架构术语的定义\n\n\n\n\n\n\n\n\nThe term “Microservice Architecture” has sprung up over(涌现出了) the last few years to describe a particular(特定的) way of designing software applications as suites of independently deployable services.\n过去几年中出现了“微服务架构”一词，用以描述将软件应用程序设计为可独立部署的服务套件的特定方法。\n\n\n\n\n\n\n\n\n\nWhile there is no precise(精确) definition of this architectural style，there are certain(某些) common characteristics around organization around business capability(业务功能), automated deployment(自动部署), intelligence in the endpoints, and decentralized(分散的，去中心化的) control of languages and data.\n虽然没有对这种架构风格的精确定义，但围绕业务功能的组织，自动部署，端点智能以及在编程语言和数据方面进行去中心化的控制方面存在某些共同特征。\n\n\n\n\n\n\n\n\n\n“Microservices” - yet another new term on the crowded streets of software architecture. Although our natural inclination is to pass such things by with a contemptuous glance, this bit of terminology describes a style of software systems that we are finding more and more appealing.\n“微服务” - 在繁多的软件架构术语中又多了一个新的名词。 虽然我们对于这种新的概念打心底里自然是不削一顾的，但这个术语描述了一种对于我们来说越来越有吸引力的软件系统风格。\n\n\n\n\n\n\n\n\n\nWe’ve seen many projects use this style in the last few years, and results so far have been positive, so much so that for many of our colleagues this is becoming the default style for building enterprise applications.\n我们已经看到许多项目在过去几年中使用了这种架构风格，并且都取得了很不错的结果；以至于对于我们的许多同事来说，这已成为构建企业应用程序的默认架构风格了。\n\n\n\n\n\n\n\n\n\nSadly, however, there’s not much information that outlines what the microservice style is and how to do it.\n然而，遗憾的是，现在还没有太多信息可以概述微服务是什么，以及我们该如何实现微服务架构。\n\n\n\n\n\n\n\n\n\nIn short, the microservice architectural style [1] is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API.\n简单来说，微服务架构风格[1]就是以开发一组小型服务的方式来开发一个独立的应用系统的，每个单体服务都在自己独立的进程中运行，并以HTTP资源API这种轻量级机制进行通信。\n\n\n\n\n\n\n\n\n\nThese services are built around business capabilities and independently deployable by fully automated deployment machinery.\n这些服务围绕业务功能构建，可通过自动化部署机制进行独立部署。\n\n\n\n\n\n\n\n\n\nThere is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies.\n这些服务具有最低限度的集中管理，可以用不同的编程语言编写，也可以使用不同的数据存储技术。\n\n\n\n\n\n\n\n\n\nTo start explaining the microservice style it’s useful to compare it to the monolithic style: a monolithic application built as a single unit.\n在开始介绍微服务风格之前，将它与单体应用进行比较是很有用的。\n\n\n\n\n\n\n\n\n\nEnterprise Applications are often built in three main parts: a client-side user interface (consisting of HTML pages and javascript running in a browser on the user’s machine) a database (consisting of many tables inserted into a common, and usually relational, database management system), and a server-side application.\n企业级应用通常由三个主要部分构成：\n\n客户端用户界面(由在用户机器上的浏览器中运行的HTML页面和javascript组成)\n数据库(由插入到公共(通常是关系)数据库管理系统中的许多表组成)\n服务器端应用程序。\n\n\n\n\n\n\n\n\n\n\nThe server-side application will handle HTTP requests, execute domain logic, retrieve and update data from the database, and select and populate HTML views to be sent to the browser.\n服务器端应用负责处理HTTP请求、执行域逻辑、从数据库检索和更新数据，并选择和填充要发送到浏览器的HTML视图。\n\n\n\n\n\n\n\n\n\nThis server-side application is a monolith - a single logical executable[2]. Any changes to the system involve building and deploying a new version of the server-side application.\n这个服务器端应用是一个整体 - 一个可执行的逻辑程序[2]。 对系统的任何更改都涉及构建和部署新版本的服务器端应用程序。\n\n\n\n\n\n\n\n\n\nSuch a monolithic server is a natural way to approach building such a system.All your logic for handling a request runs in a single process, allowing you to use the basic features of your language to divide up the application into classes, functions, and namespaces.With some care, you can run and test the application on a developer’s laptop, and use a deployment pipeline to ensure that changes are properly tested and deployed into production.\n这种单体服务器是构建上述系统的常规方式。所有请求的逻辑处理都运行在单个进程中，允许使用语言的基本特性将应用程序划分为类、函数和命名空间。通过这样一些设计，你可以在开发人员的笔记本电脑上运行和测试应用程序，并使用部署流程平台来确保变更可以被正确地测试然后再将其部署到生产环境中。\n\n\n\n\n\n\n\n\n\nYou can horizontally scale the monolith by running many instances behind a load-balancer.\n最后，通过负载均衡器运行许多实例，已达到将这个单体应用进行横向扩展的目的。\n\n\n\n\n\n\n\n\n\nMonolithic applications can be successful, but increasingly people are feeling frustrations with them - especially as more applications are being deployed to the cloud .Change cycles are tied together - a change made to a small part of the application, requires the entire monolith to be rebuilt and deployed.\n单体应用架构可以很成功的实现，但是随着越来越多的应用程序被部署到云上时，人们对它们将会越来越感到失望。因为对于单体架构的应用来说，每当对一个小小的功能进行修改时，都会涉及到整个应用的重新构建和部署，实际上这个局部功能的改动是不应该对整个应用造成影响的。\n\n\n\n\n\n\n\n\n\nOver time it’s often hard to keep a good modular structure, making it harder to keep changes that ought to only affect one module within that module. Scaling requires scaling of the entire application rather than parts of it that require greater resource.\n随着时间的推移，单体应用也很难保持一个良好的模块化结构，因为把一个模块的变更影响控制在该模块内将会变得非常困难。当对系统进行扩展时，不得不扩展整个应用系统，而不是对需要更多资源的部分应用程序进行扩展。\n\n\n\n\n\n\n\n\n\n\nThese frustrations have led to the microservice architectural style: building applications as suites of services.\n这一系列的问题导致了微服务架构风格产生：以构建一组服务的方式来构建应用系统。\n\n\n\n\n\n\n\n\n\nAs well as the fact that services are independently deployable and scalable, each service also provides a firm module boundary, even allowing for different services to be written in different programming languages. They can also be managed by different teams .\n除了服务是可独立部署和可伸缩的这一事实之外，每个服务还提供了一个可靠的模块边界，甚至允许用不同的编程语言编写不同的服务。它们也可以由不同的团队管理。\n\n\n\n\n\n\n\n\n\nWe do not claim that the microservice style is novel or innovative, its roots go back at least to the design principles of Unix. But we do think that not enough people consider a microservice architecture and that many software developments would be better off if they used it.\n我们并不认为微服务架构风格是新颖或创新的，它的根源至少可以追溯到Unix的设计原则。但是我们认为目前还没有足够多的人考虑微服务体系架构，如果他们都参与使用这个架构风格的话，许多软件的开发将会变得更好。\nCharacteristics of a Microservice Architecture-微服务架构的特征\n\n\n\n\n\n\n\n\nWe cannot say there is a formal definition of the microservices architectural style, but we can attempt to describe what we see as common characteristics for architectures that fit the label.\n我们不能说微服务体系架构风格有一个正式的定义，但是我们可以尝试去描述我们所看到的符合这个标签的体系结构的一些共同特征。\n\n\n\n\n\n\n\n\n\nAs with any definition that outlines common characteristics, not all microservice architectures have all the characteristics, but we do expect that most microservice architectures exhibit most characteristics.\n与任何概述共同特征的定义一样，并非所有的微服务体系架构都具有所有特征，但我们期望常见的微服务都应该有这些特性。\n\n\n\n\n\n\n\n\n\nWhile we authors have been active members of this rather loose community, our intention is to attempt a description of what we see in our own work and in similar efforts by teams we know of. In particular we are not laying down some definition to conform to.\n虽然我们作者是这个相当松散的社区的活跃成员，但我们的意图是尝试描述我们在自己的工作中看到的内容，以及我们所知道的团队在类似的工作中所做的工作。特别是，我们不依赖于那些已经明确过的定义。\nComponentization via Services-通过服务拆分实现组件化\n\n\n\n\n\n\n\n\nFor as long as we’ve been involved in the software industry, there’s been a desire to build systems by plugging together components, much in the way we see things are made in the physical world.\n只要我们参与到软件行业，就一直希望通过将组件集成在一起来构建系统，就像我们在物理世界中看到事物的方式一样。\n\n\n\n\n\n\n\n\n\nDuring the last couple of decades we’ve seen considerable progress with large compendiums of common libraries that are part of most language platforms.\n在过去的几十年中，我们已经看到了作为大多数语言平台一部分的公共库，已经在大量组合方面取得了相当大的进展。\n\n\n\n\n\n\n\n\n\nWhen talking about components we run into the difficult definition of what makes a component. Our definition is that a component is a unit of software that is independently replaceable and upgradeable.\n在讨论组件时，我们遇到了一个困惑是组件到底是什么。我们的定义是，组件一个可独立替换和升级的软件单元。\n\n\n\n\n\n\n\n\n\nMicroservice architectures will use libraries, but their primary way of componentizing their own software is by breaking down into services.\n微服务架构会使用库，但他们将自己的软件组件化的主要方式是把它拆分成服务\n\n\n\n\n\n\n\n\n\nWe define libraries as components that are linked into a program and called using in-memory function calls, while services are out-of-process components who communicate with a mechanism such as a web service request, or remote procedure call. (This is a different concept to that of a service object in many OO programs [3].)\n我们将库定义为链接到程序并使用内存内函数调用的组件，而服务是进程外组件，它们通过诸如web服务请求或远程过程调用之类的机制进行通信。（这与许多面向对象程序中的服务对象的概念不同[3]。）\n\n\n\n\n\n\n\n\n\nOne main reason for using services as components (rather than libraries) is that services are independently deployable.\n将服务用作组件（而不是库）的一个主要原因是服务可以独立部署。\n\n\n\n\n\n\n\n\n\nIf you have an application  that consists of a multiple libraries in a single process, a change to any single component results in having to redeploy the entire application.\n如果您在单个进程中有一个由多个库组成的应用程序，则对任何单个组件的更改都会导致必须重新部署整个应用程序。\n\n\n\n\n\n\n\n\n\nBut if that application is decomposed into multiple services, you can expect many single service changes to only require that service to be redeployed.\n但是，如果将该应用程序分解为多个服务，那你只需要重新部署那个改变的服务就可以。\n\n\n\n\n\n\n\n\n\nThat’s not an absolute, some changes will change service interfaces resulting in some coordination, but the aim of a good microservice architecture is to minimize these through cohesive service boundaries and evolution mechanisms in the service contracts.\n但是这也不是绝对的，比如一些更改将会更改服务接口，从而导致一些协调问题，但是一个好的微服务体系结构的目标是通过服务契约中的内聚服务边界和演进机制将这些更改最小化。\n\n\n\n\n\n\n\n\n\nAnother consequence of using services as components is a more explicit component interface.Most languages do not have a good mechanism for defining an explicit Published Interface.Often it’s only documentation and discipline that prevents clients breaking a component’s encapsulation, leading to overly-tight coupling between components.Services make it easier to avoid this by using explicit remote call mechanisms.\n将服务用作组件的另一个结果是将拥有更清晰的组件接口。大多数语言都没有定义显式发布接口的良好机制。通常只有文档和规则的说明来防止客户端破坏组件的封装，避免组件之间的耦合过于紧密。但是通过使用显式远程调用机制，则更容易避免这种情况。\n\n\n\n\n\n\n\n\n\nUsing services like this does have downsides. Remote calls are more expensive than in-process calls, and thus remote APIs need to be coarser-grained, which is often more awkward to use.\n但是这种方式也有不足的地方。主要是远程调用比进程内调用更昂贵，因此远程api需要是粗粒度的，但这会比较难用。\n\n\n\n\n\n\n\n\n\nIf you need to change the allocation of responsibilities between components, such movements of behavior are harder to do when you’re crossing process boundaries.\n如果您需要更改组件之间的职责分配，那么当你需要跨进程时，这种行为的迁移将更加困难。\n\n\n\n\n\n\n\n\n\nAt a first approximation, we can observe that services map to runtime processes, but that is only a first approximation.\n一种可能是，我们可以观察到服务映射到运行时进程上，但这只是一种可能。\n\n\n\n\n\n\n\n\n\nA service may consist of multiple processes that will always be developed and deployed together, such as an application process and a database that’s only used by that service.\n服务可以由多个进程组成，这些进程可以同时开发和部署，例如一个应用程序进程和一个只能由这个服务使用的数据库。\nOrganized around Business Capabilities-围绕业务功能组织\n\n\n\n\n\n\n\n\nWhen looking to split a large application into parts, often management focuses on the technology layer, leading to UI teams, server-side logic teams, and database teams.\n当希望将大型应用程序分解为多个模块时，管理通常关注于技术层，重要的包括UI团队、服务器端逻辑团队和数据库团队。\n\n\n\n\n\n\n\n\n\nWhen teams are separated along these lines, even simple changes can lead to a cross-team project taking time and budgetary approval.\n当团队按照这些原则分开时，即使是简单的更改也可能涉及到跨团队沟通，那么这样项目就会需要增加时间和预算审批等成本。\n\n\n\n\n\n\n\n\n\nA smart team will optimise around this and plump for the lesser of two evils - just force the logic into whichever application they have access to. Logic everywhere in other words. This is an example of Conway’s Law[5] in action.\n一个优秀的团队将围绕这一点进行改善，并选择两害相权取其轻——只需将逻辑强制应用到他们能够访问的任何应用程序中。换句话说，逻辑无处不在。这是康威定律5的一个例子。\n\n\n\n\n\n\n\n\n\nAny organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure.任何设计系统(广义定义)的组织都会产生一个结构是组织通信结构副本的设计。 – Melvyn Conway, 1967\n\n\n\n\n\n\n\n\n\n\nThe microservice approach to division is different, splitting up into services organized around business capability.\n划分微服务方法是不同的，但更倾向于围绕业务功能的组织来进行服务划分。\n\n\n\n\n\n\n\n\n\nSuch services take a broad-stack implementation of software for that business area, including user-interface, persistant storage, and any external collaborations.\n这些服务在商业领域软件上有广泛实施，包括用户界面、持久性存储和任何外部协作。\n\n\n\n\n\n\n\n\n\nConsequently the teams are cross-functional, including the full range of skills required for the development: user-experience, database, and project management.\n因此，团队是跨职能的，包括开发所需的全方位技能:用户体验、数据库和项目管理。\n\n\n\n\n\n\n\n\n\n\nOne company organised in this way is www.comparethemarket.com. Cross functional teams are responsible for building and operating each product and each product is split out into a number of individual services communicating via a message bus.\nwww.comparethemarket.com 就是采样这样组织形式的一家公司。跨职能团队负责同时构建和运维每个产品，每个产品都被划分为许多单个服务，服务间再通过消息总线进行通信。\n\n\n\n\n\n\n\n\n\nLarge monolithic applications can always be modularized around business capabilities too, although that’s not the common case.Certainly we would urge a large team building a monolithic application to divide itself along business lines.\n大型集中式应用程序也可以围绕业务功能进行模块划分，尽管这种情况并不常见。当然，我们会敦促构建完整应用程序的大型团队沿着业务线进行自我划分。\n\n\n\n\n\n\n\n\n\nThe main issue we have seen here, is that they tend to be organised around too many contexts.\n我们在这里看到的主要问题是，它们往往围绕太多的上下文背景进行组织（依赖太多，包袱太重）。\n\n\n\n\n\n\n\n\n\nIf the monolith spans many of these modular boundaries it can be difficult for individual members of a team to fit them into their short-term memory.Additionally we see that the modular lines require a great deal of discipline to enforce. The necessarily more explicit separation required by service components makes it easier to keep the team boundaries clear.\n如果整个应用会跨越许多这样的模块边界时，这对于团队中的一些成员来说也很难短期内可以掌握。此外，我们看到模块化开发需要大量的规范来遵守执行。但是对于服务组件这种需要进行明确的业务划分的要求的情况下，可以使得保持团队职能边界清晰变得更加容易。\nProducts not Projects-产品不是项目Most application development efforts that we see use a project model: where the aim is to deliver some piece of software which is then considered to be completed. On completion the software is handed over to a maintenance organization and the project team that built it is disbanded.\n我们看到的大多数应用程序开发工作都使用这样的项目模式：目标是交付一个他们认为完成的软件。接着，软件被移交给运维团队，项目开发团队被解散。\n\n\n\n\n\n\n\n\n\nMicroservice proponents tend to avoid this model, preferring instead the notion that a team should own a product over its full lifetime.\n微服务的支持者倾向于避免这种模式，他们更希望团队应该负责产品的整个生命周期。\n\n\n\n\n\n\n\n\n\nA common inspiration for this is Amazon’s notion of “you build, you run it” where a development team takes full responsibility for the software in production.This brings developers into day-to-day contact with how their software behaves in production and increases contact with their users, as they have to take on at least some of the support burden.\n一个常见的灵感是Amazon的“你构建，你运行它”的概念，在这个概念中，开发团队需要对产品承担全部责任。这使得开发人员能够在日常中关注到软件运行情况，并增加与用户的联系，同时必须承担一些支持工作。\n\n\n\n\n\n\n\n\n\nThe product mentality, ties in with the linkage to business capabilities. Rather than looking at the software as a set of functionality to be completed, there is an on-going relationship where the question is how can software assist its users to enhance the business capability.\n产品的理念，与业务能力联系在一起。与其将软件看作一组要完成的功能，还不如将软件看作是一种持续的关系，在这种关系中，软件是如何帮助用户增强业务能力。\n\n\n\n\n\n\n\n\n\nThere’s no reason why this same approach can’t be taken with monolithic applications, but the smaller granularity of services can make it easier to create the personal relationships between service developers and their users.\n没有理由不能在单体应用程序中采用相同的方法，但是服务粒度越小，就越容易在服务开发人员和用户之间创建个人关系。\nSmart endpoints and dumb pipes-智能端点和轻量级通信\n\n\n\n\n\n\n\n\nWhen building communication structures between different processes, we’ve seen many products and approaches that stress putting significant smarts into the communication mechanism itself.\n在构建不同进程之间的通信结构时，我们看到许多产品和方法都强调在通信机制本身中投入大量的方案。\n\n\n\n\n\n\n\n\n\nA good example of this is the Enterprise Service Bus (ESB), where ESB products often include sophisticated facilities for message routing, choreography, transformation, and applying business rules.\n这方面的一个很好的例子是企业服务总线(ESB)，ESB产品通常包含用于消息路由、编排、转换和应用业务规则的复杂工具。\n\n\n\n\n\n\n\n\n\nThe microservice community favours an alternative approach: smart endpoints and dumb pipes.\n在微服务社区则支持另一种方法:智能端点和轻量级通信。\n\n\n\n\n\n\n\n\n\nApplications built from microservices aim to be as decoupled and as cohesive as possible - they own their own domain logic and act more as filters in the classical Unix sense - receiving a request, applying logic as appropriate and producing a response.\n使用微服务构建的应用程序旨在尽可能地解耦和内聚 - 采用独立的业务逻辑，表现的更像经典Unix意义上的过滤器一样，接受请求、处理业务逻辑，然后返回响应。\n\n\n\n\n\n\n\n\n\nThese are choreographed using simple RESTish protocols rather than complex protocols such as WS-Choreography or BPEL or orchestration by a central tool.\n它们更喜欢简单的REST风格，而不是使用复杂的协议，如WS-Choreography、BPEL或集中式框架。\n\n\n\n\n\n\n\n\n\nThe two protocols used most commonly are HTTP request-response with resource API’s and lightweight messaging[8].\n最常用的两种协议是带有资源API的HTTP请求-响应协议和轻量级消息传递[8]协议。 第一个是最好的描述是:善于利用网络，而不是限制。\n\n\n\n\n\n\n\n\n\nBe of the web, not behind the web– Ian Robinson\n\n\n\n\n\n\n\n\n\nMicroservice teams use the principles and protocols that the world wide web (and to a large extent, Unix) is built on. Often used resources can be cached with very little effort on the part of developers or operations folk.\n微服务团队使用构建在互联网(很大程度上是Unix)上的原则和协议。开发人员或操作人员只需很少的精力就可以缓存经常使用的资源。\n\n\n\n\n\n\n\n\n\nThe second approach in common use is messaging over a lightweight message bus. The infrastructure chosen is typically dumb (dumb as in acts as a message router only) - simple implementations such as RabbitMQ or ZeroMQ don’t do much more than provide a reliable asynchronous fabric - the smarts still live in the end points that are producing and consuming messages; in the services.\n第二种常用的方式是通过轻量级消息总线进行消息传递。所选择的基础设施通常是单一的(只负责消息路由)——像RabbitMQ或者ZeroMQ这样的简单的实现，连可靠的异步机制都没有提供——导致仍然需要依赖产生或者消费消息的终端或者服务来处理这类问题。\n\n\n\n\n\n\n\n\n\nIn a monolith, the components are executing in-process and communication between them is via either method invocation or function call. The biggest issue in changing a monolith into microservices lies in changing the communication pattern. A naive conversion from in-memory method calls to RPC leads to chatty communications which don’t perform well. Instead you need to replace the fine-grained communication with a coarser -grained approach.\n在单体应用中，组件在进程内执行，它们之间的通信要么通过方法调用要么通过回调函数。将单体架构变为微服务架构的最大问题在于改变通信模式。 从内存中的方法调用到RPC调用的简单转换会导致通信性能的下降。因此，你需要用更粗粒度的方法替换细粒度的通信。\nDecentralized Governance-分散治理\n\n\n\n\n\n\n\n\nOne of the consequences of centralised governance is the tendency to standardise on single technology platforms. Experience shows that this approach is constricting - not every problem is a nail and not every solution a hammer. We prefer using the right tool for the job and while monolithic applications can take advantage of different languages to a certain extent, it isn’t that common.\n集中治理的优势在于可以在单一技术平台上实现标准化。经验表明，这种方法是有局限性的——不是每个问题都是很棘手，也不是每个解决方案都是万能的。我们更喜欢使用适合这项工作的工具，虽然单体应用程序可以在一定程度上利用不同的语言，但这种情况并不常见。\n\n\n\n\n\n\n\n\n\nSplitting the monolith’s components out into services we have a choice when building each of them. You want to use Node.js to standup a simple reports page? Go for it. C++ for a particularly gnarly near-real-time component? Fine. You want to swap in a different flavour of database that better suits the read behaviour of one component? We have the technology to rebuild him.\n把整体式框架中的组件，拆分成不同的服务，这样构建它们时就会有更多的选择性。 您想使用Node.js站立一个简单的报告页面吗？ 去吧。 C ++是否适用于特别近乎实时的组件？做吧。 您想要交换不同风格的数据库，以更好地适应一个组件的读取行为？ 我们同样有重构它的技术。\n\n\n\n\n\n\n\n\n\nOf course, just because you can do something, doesn’t mean you should - but partitioning your system in this way means you have the option.\n当然，仅仅因为你可以做一些事情，并不意味着你就应该这么做——但是以这种方式对系统进行划分意味着你可以选择。\n\n\n\n\n\n\n\n\n\nTeams building microservices prefer a different approach to standards too. Rather than use a set of defined standards written down somewhere on paper they prefer the idea of producing useful tools that other developers can use to solve similar problems to the ones they are facing.These tools are usually harvested from implementations and shared with a wider group, sometimes, but not exclusively using an internal open source model. Now that git and github have become the de facto version control system of choice, open source practices are becoming more and more common in-house .\n与其选用一组写在纸上已经定义好的标准，他们更喜欢编写一些有用的工具，来让其他开发者能够使用，以便解决那些和他们所面临的问题相似的问题。这些工具通常源自他们的微服务实施过程，并且被分享到更大规模的组织中，这种分享有时会使用内部开源的模式来进行。现在，git和github已经成为事实上的首选版本控制系统。在企业内部，开源的做法也正在变得越来越普遍。\n\n\n\n\n\n\n\n\n\nNetflix is a good example of an organisation that follows this philosophy. Sharing useful and, above all, battle-tested code as libraries encourages other developers to solve similar problems in similar ways yet leaves the door open to picking a different approach if required. Shared libraries tend to be focused on common problems of data storage, inter-process communication and as we discuss further below, infrastructure automation.\nNetflix公司是遵循上述理念的好例子。将实用且经过实战检验的代码以软件库的形式共享出来，能鼓励其他开发人员以相似的方式来解决相似的问题，当然也为在需要的时候选用不同的方案留了一扇门。共享软件库往往集中在解决这样的常见问题，即数据存储、进程间的通信和下面要进一步讨论的基础设施的自动化。\n\n\n\n\n\n\n\n\n\nFor the microservice community, overheads are particularly unattractive. That isn’t to say that the community doesn’t value service contracts. Quite the opposite, since there tend to be many more of them. It’s just that they are looking at different ways of managing those contracts. Patterns like Tolerant Reader and Consumer-Driven Contracts are often applied to microservices. These aid service contracts in evolving independently. Executing consumer driven contracts as part of your build increases confidence and provides fast feedback on whether your services are functioning. Indeed we know of a team in Australia who drive the build of new services with consumer driven contracts. They use simple tools that allow them to define the contract for a service. This becomes part of the automated build before code for the new service is even written. The service is then built out only to the point where it satisfies the contract - an elegant approach to avoid the ‘YAGNI’9dilemma when building new software. These techniques and the tooling growing up around them, limit the need for central contract management by decreasing the temporal coupling between services.\n对于微服务社区来说，管理费用特别缺乏吸引力。 这并不是说社区不重视服务合同。 恰恰相反，因为往往会有更多。只是他们正在寻找管理这些合同的不同方式。像“容错读取”和“消费者驱动的契约”这样的模式，经常被运用到微服务中。这些都有助于服务契约进行独立演进。将执行“ 消费者驱动的契约 ”做为软件构建的一部分，能增强开发团队的信心，并提供所依赖的服务是否正常工作的快速反馈。实际上，我们了解到一个在澳大利亚的团队就是使用“ 消费者驱动的契约 ”来驱动构建多个新服务的。他们使用了一些简单的工具，来针对每一个服务定义契约。甚至在新服务的代码编写之前，这件事就已经成为自动化构建的一部分了。接下来服务仅被构建到刚好能满足契约的程度——这是一个在构建新软件时避免YAGNI 9 困境的优雅方法。这些技术和工具在契约周边生长出来，由于减少了服务之间在时域(temporal)上的耦合，从而抑制了对中心契约管理的需求。\n\n\n\n\n\n\n\n\n\nPerhaps the apogee of decentralised governance is the build it &#x2F; run it ethos popularised by Amazon. Teams are responsible for all aspects of the software they build including operating the software 24&#x2F;7. Devolution of this level of responsibility is definitely not the norm but we do see more and more companies pushing responsibility to the development teams. Netflix is another organisation that has adopted this ethos11. Being woken up at 3am every night by your pager is certainly a powerful incentive to focus on quality when writing your code. These ideas are about as far away from the traditional centralized governance model as it is possible to be.\n也许分散治理治理技术的极盛时期，就是亚马逊的“你构建，你运行”的理念开始普及的时候。 每个团队负责他们构建的软件的全生命周期，包括持续的软件的运维。 把运维的这种能力放到团队的做法目前还不是主流的，但我们确实看到越来越多的公司将运维的职责推向开发团队。 Netflix是另一个采用这种模式的组织11。 如果你不想每天凌晨3点被喊起来去改bug，那么你就该在编写代码时投入更多的精力和时间。 但是这些想法与传统的集中治理模式相差甚远。\nDecentralized Data Management-分散的数据管理\n\n\n\n\n\n\n\n\nDecentralization of data management presents in a number of different ways. At the most abstract level, it means that the conceptual model of the world will differ between systems. This is a common issue when integrating across a large enterprise, the sales view of a customer will differ from the support view. Some things that are called customers in the sales view may not appear at all in the support view. Those that do may have different attributes and (worse) common attributes with subtly different semantics.\n分散化的数据管理以多种不同的方式呈现。 在最抽象的层面上来看的话，就意味着各个系统对客观世界所构建的概念模型是彼此各不相同的。 这是在大型企业中集成时的常见问题，比如对于客户来说，销售视角和支持视角肯定是不同的。 销售视角中客户的某些内容可能根本不会出现在支持视角中。即使在两个视角中都能看到的事物，那么各自关注的核心信息也是不同的。极端情况下，甚至两个视角中具有相同属性的事物，或许在语义上也会有细的差距。\n\n\n\n\n\n\n\n\n\nThis issue is common between applications, but can also occur _within_applications, particular when that application is divided into separate components. A useful way of thinking about this is the Domain-Driven Design notion of Bounded Context. DDD divides a complex domain up into multiple bounded contexts and maps out the relationships between them. This process is useful for both monolithic and microservice architectures, but there is a natural correlation between service and context boundaries that helps clarify, and as we describe in the section on business capabilities, reinforce the separations.\n上述问题在不同的应用程序之间经常出现，当然应用程序内部也会出现，尤其是当一个应用程序被分成不同组件的情况下。思考这类问题的一个可靠的方法，就是使用领域驱动设计（Domain-Driven Design, DDD）中的“限界上下文”的概念。DDD将一个复杂的领域划分为多个限界上下文，并且将其相互之间的关系用图画出来。这一划分过程对于单体架构和微服务架构两者都是有用的，而且就像前面有关“业务功能”一节中所讨论的那样，在服务和各个限界上下文之间所存在的自然的联动关系，能有助于澄清和强化这种划分。\n\n\n\n\n\n\n\n\n\nAs well as decentralizing decisions about conceptual models, microservices also decentralize data storage decisions. While monolithic applications prefer a single logical database for persistant data, enterprises often prefer a single database across a range of applications - many of these decisions driven through vendor’s commercial models around licensing. Microservices prefer letting each service manage its own database, either different instances of the same database technology, or entirely different database systems - an approach called Polyglot Persistence. You can use polyglot persistence in a monolith, but it appears more frequently with microservices.\n除了关于概念模型的分散决策之外，微服务还分散了数据存储决策。 虽然单体应用程序通常都是使用单个逻辑数据库来存储持久性数据，但企业往往喜欢一系列单体应用共用一个单独的数据库 - 其中许多决策是通过供应商围绕许可的商业模型来实现的（供应商的版权商业模式所驱动）。 微服务体系中更偏向让每个服务实例管理自己的数据库，可以是相同数据库技术的不同实例，也可以是完全不同的数据库系统 – 这种方法称为 Polyglot Persistence（多语言持久化）。在一个单体系统中也能使用多语种持久化，但它在微服务中更常出现。\n\n\n\n\n\n\n\n\n\nDecentralizing responsibility for data across microservices has implications for managing updates. The common approach to dealing with updates has been to use transactions to guarantee consistency when updating multiple resources. This approach is often used within monoliths.\n跨微服务分散数据责任对管理更新具有影响。处理软件更新的常用方法，是当更新多个资源的时候，需要使用事务来保证一致性。这种方法经常在单块系统中被采用。\n\n\n\n\n\n\n\n\n\nUsing transactions like this helps with consistency, but imposes significant temporal coupling, which is problematic across multiple services. Distributed transactions are notoriously difficult to implement and as a consequence microservice architectures emphasize transactionless coordination between services, with explicit recognition that consistency may only be eventual consistency and problems are dealt with by compensating operations.\n通过使用事务，有助于保持数据一致性。但对时间的消耗是严重的，而当在多个服务之间处理事务时也会出现一致性问题。众所周知，分布式事务很难实现，因此微服务架构强调服务间事务协调，明确认识到一致性可能只是最终的一致性及通过补偿操作来处理问题。\n\n\n\n\n\n\n\n\n\nChoosing to manage inconsistencies in this way is a new challenge for many development teams, but it is one that often matches business practice. Often businesses handle a degree of inconsistency in order to respond quickly to demand, while having some kind of reversal process to deal with mistakes. The trade-off is worth it as long as the cost of fixing mistakes is less than the cost of lost business under greater consistency.\n对于许多开发团队来说，选择以这种方式管理数据的“不一致性”问题是一个新的挑战，但是这又是一种非常常见的业务实践场景。为了对需求做出快速反应，企业通常会允许一定程度上的数据“不一致性”，但同时也会采用一些恢复的进程来处理这种错误 。只要业务上处理强一致性成本比处理错误的成本少时，那么这种“ 不一致性”地管理数据的权衡就是值得的。\nInfrastructure Automation-基础设施高度自动化\n\n\n\n\n\n\n\n\nInfrastructure automation techniques have evolved enormously over the last few years - the evolution of the cloud and AWS in particular has reduced the operational complexity of building, deploying and operating microservices.\n在过去几年里，基础设施自动化技术有了很大的发展——云计算和AWS的发展降低了构建、部署和运维微服务的复杂性。\n\n\n\n\n\n\n\n\n\nMany of the products or systems being build with microservices are being built by teams with extensive experience of Continuous Delivery and it’s precursor, Continuous Integration. Teams building software this way make extensive use of infrastructure automation techniques. This is illustrated in the build pipeline shown below.\n许多使用微服务构建的产品或系统都是由具有大量 持续交付与其前身持续集成 经验的团队构建的。以这种方式构建软件的团队广泛使用了基础设施自动化技术。如下图的构建流水线所示：\n\n\n\n\n\n\n\n\n\n\nSince this isn’t an article on Continuous Delivery we will call attention to just a couple of key features here. We want as much confidence as possible that our software is working, so we run lots of automated tests. Promotion of working software ‘up’ the pipeline means we automate deployment to each new environment.\n由于这不是一篇关于持续交付的文章，我们将在这里只关注几个关键特性。我们希望我们的软件能够正常工作，所以我们运行了大量的自动化测试。让可工作的软件达到“晋级”(Promotion)状态从而“推上”流水线，就意味着可以在 每一个新的环境中，对软件进行 自动化部署 。\n\n\n\n\n\n\n\n\n\nA monolithic application will be built, tested and pushed through these environments quite happlily. It turns out that once you have invested in automating the path to production for a monolith, then deploying _more_applications doesn’t seem so scary any more. Remember, one of the aims of CD is to make deployment boring, so whether its one or three applications, as long as its still boring it doesn’t matter12.\n对于单体应用来说，可以轻松的在上述的各个环境中进行构建、测试和发布。其结果是，一旦投入到自动化平台， 那么部署更多的应用系统似乎就不再可怕。记住，持续交付的目的之一，是让“部署”工作变得“无聊”。所以不管是一个还是三个应用系统，只要是部署工作，就依旧很“无聊”，那么就没什么可担心的了 12 。\n\n\n\n\n\n\n\n\n\nAnother area where we see teams using extensive infrastructure automation is when managing microservices in production. In contrast to our assertion above that as long as deployment is boring there isn’t that much difference between monoliths and microservices, the operational landscape for each can be strikingly different.\n另一个方面，我们发现使用微服务的团队更加依赖于基础设施的自动化。与前面我们对比单体系统和微服务所说的正相反，只要部署工作很无聊，那么在这一点上单块系统和微服务就没什么区别。然而，两者在运维领域的情况却截然不同。\n\nDesign for failure-“容错”设计\n\n\n\n\n\n\n\n\nA consequence of using services as components, is that applications need to be designed so that they can tolerate the failure of services. Any service call could fail due to unavailability of the supplier, the client has to respond to this as gracefully as possible. This is a disadvantage compared to a monolithic design as it introduces additional complexity to handle it. The consequence is that microservice teams constantly reflect on how service failures affect the user experience. Netflix’s Simian Army induces failures of services and even datacenters during the working day to test both the application’s resilience and monitoring.\n使用各个微服务来替代组件，其结果是各个应用程序需要设计成能够容忍这些服务所出现的故障。如果服务提供方不可用，那么任何对该服务的调用都会出现故障。客户端要尽可能优雅地应对这种情况。与单体应用设计相比，这是一个劣势。因为这会引人额外的复杂性来处理这种情况。这需要微服务团队要时刻考虑到服务故障情况下的用户体验。Netflix公司所研发的开源测试工具Simian Army，可以为每个应用的服务及数据中心提供日常故障检测和恢复。\n\n\n\n\n\n\n\n\n\nThis kind of automated testing in production would be enough to give most operation groups the kind of shivers usually preceding a week off work. This isn’t to say that monolithic architectural styles aren’t capable of sophisticated monitoring setups - it’s just less common in our experience.\n这种在生产环境中所进行的自动化测试，能足以让大多数运维组织兴奋得浑身颤栗，就像在一周的长假即将到来前那样。这并不是说单体架构风格不能构建先进的监控系统——只是根据我们的经验，这在单体系统中并不常见罢了。\n\n\n\n\n\n\n\n\n\nSince services can fail at any time, it’s important to be able to detect the failures quickly and, if possible, automatically restore service. Microservice applications put a lot of emphasis on real-time monitoring of the application, checking both architectural elements (how many requests per second is the database getting) and business relevant metrics (such as how many orders per minute are received). Semantic monitoring can provide an early warning system of something going wrong that triggers development teams to follow up and investigate.\n因为每个服务都可能在任何时候发生故障，所以下面两件事就变得很重要，即 快速故障检测 和 自动恢复。各个微服务的应用都将大量的精力放到了应用程序的实时监控上，来检查“架构元素指标”（例如数据库每秒收到多少请求）和“业务相关指标”（例如系统每分钟收到多少订单）。当系统某个地方出现问题，监控系统能提供一个预警，来触发开发团队进行后续的跟进和调查工作。\n\n\n\n\n\n\n\n\n\nThis is particularly important to a microservices architecture because the microservice preference towards choreography and event collaboration leads to emergent behavior. While many pundits praise the value of serendipitous emergence, the truth is that emergent behavior can sometimes be a bad thing. Monitoring is vital to spot bad emergent behavior quickly so it can be fixed.\n这对于一个微服务架构是非常重要的，因为微服务之间交互通信随时都可能出现一些紧急的意外情况。尽管许多权威人士对于突发情况的价值持积极态度，但事实上，突发情况有时可能会酿成大的灾难。在能够快速发现有坏处的突发情况并进行修复的方面，监控是至关重要的。\n\n\n\n\n\n\n\n\n\nMonoliths can be built to be as transparent as a microservice - in fact, they should be. The difference is that you absolutely need to know when services running in different processes are disconnected. With libraries within the same process this kind of transparency is less likely to be useful.\n单体系统也能构建像微服务那样来实现透明的一套监控系统——实际上，它们也应该如此。差别是，绝对需要知道那些运行在不同进程中的服务，在何时断掉了。而如果在同一个进程内使用软件库的话，这种透明的监控系统就用处不大了。\n\n\n\n\n\n\n\n\n\nMicroservice teams would expect to see sophisticated monitoring and logging setups for each individual service such as dashboards showing up&#x2F;down status and a variety of operational and business relevant metrics. Details on circuit breaker status, current throughput and latency are other examples we often encounter in the wild.\n微服务团队希望在每一个单独的服务中，都能看到良好的监控和日志记录装置。例如显示“运行&#x2F;宕机”状态的仪表盘，和各种运维和业务相关的指标。另外我们经常在工作中会碰到这样一些细节，即断路器的状态、当前的吞吐率和延迟，以及其他一些例子。\nEvolutionary Design-“演进式”设计\n\n\n\n\n\n\n\n\nMicroservice practitioners, usually have come from an evolutionary design background and see service decomposition as a further tool to enable application developers to control changes in their application without slowing down change. Change control doesn’t necessarily mean change reduction - with the right attitudes and tools you can make frequent, fast, and well-controlled changes to software.\n微服务的从业者们，通常具有演进式设计的背景，他们把服务分解成进一步的工具，以达到可以让应用开发者在不改变速度情况下，控制他们应用的需求变更。变更控制并不一定意味着要减少变化——在正确的方式和工具的帮助下，能在软件中让变更发生得频繁、快速且有良好的控制。\n\n\n\n\n\n\n\n\n\nWhenever you try to break a software system into components, you’re faced with the decision of how to divide up the pieces - what are the principles on which we decide to slice up our application? The key property of a component is the notion of independent replacement and upgradeability13 - which implies we look for points where we can imagine rewriting a component without affecting its collaborators. Indeed many microservice groups take this further by explicitly expecting many services to be scrapped rather than evolved in the longer term.\n每当试图要将软件系统分解为各个组件时，就会面临这样的问题，即如何进行切分——我们决定切分应用系统时应该遵循的原则是什么？首要的因素，组件可以被独立替换和更新的 13 ——这意味着，需要寻找这些点，即想象着能否在其中一个点上重写该组件，而无须影响该组件的其他合作组件。事实上，许多微服务团队考虑的更多的是，如何明确地预期许多服务将来会报废，而不是守着这些服务做长期迭代。\n\n\n\n\n\n\n\n\n\nThe Guardian website is a good example of an application that was designed and built as a monolith, but has been evolving in a microservice direction. The monolith still is the core of the website, but they prefer to add new features by building microservices that use the monolith’s API. This approach is particularly handy for features that are inherently temporary, such as specialized pages to handle a sporting event. Such a part of the website can quickly be put together using rapid development languages, and removed once the event is over. We’ve seen similar approaches at a financial institution where new services are added for a market opportunity and discarded after a few months or even weeks.\nGuardian 网站就是这方面的一个优秀的例子。它初期被设计和构建成一个单体架构应用，然而它已经开始向微服务方向进行迭代演进了。原先的单体系统依旧是该网站的核心，但是在添加新特性时，他们愿意以构建微服务的方式来进行添加，而这些微服务会去调用原先那个单体系统的API。当在开发那些本身就带有临时性特点的新特性时， 这种方法就特别方便，例如开发那些报道一个体育赛事的专门页面。当使用一些快速的开发语言时，像这样的网站页面就能被快速地整合起来。而一旦赛事结束，这样页面就可以被删除。在一个金融机构中，我们已经看到了一些相似的做法，即针对一个市场机会，一些新的服务可以被添加进来。然后在几个月甚至几周之后，这些新服务就作废了。\n\n\n\n\n\n\n\n\n\nThis emphasis on replaceability is a special case of a more general principle of modular design, which is to drive modularity through the pattern of change 14. You want to keep things that change at the same time in the same module. Parts of a system that change rarely should be in different services to those that are currently undergoing lots of churn. If you find yourself repeatedly changing two services together, that’s a sign that they should be merged.\n这种强调可更换性的特点，是模块化设计一般性原则的一个特例，需求变更通过进行模块化的方式实现。大家都愿意将那些能在同时发生变化的东西，放到同一个模块中。系统中那些很少发生变化的部分，应该被放到不同的服务中，以区别于那些当前正在经历大量变动(churn)的部分。如果发现需要同时反复变更两个服务时，这就是它们两个需要被合并的一个信号。\n\n\n\n\n\n\n\n\n\nPutting components into services adds an opportunity for more granular release planning. With a monolith any changes require a full build and deployment of the entire application. With microservices, however, you only need to redeploy the service(s) you modified. This can simplify and speed up the release process. The downside is that you have to worry about changes to one service breaking its consumers. The traditional integration approach is to try to deal with this problem using versioning, but the preference in the microservice world is to only use versioning as a last resort. We can avoid a lot of versioning by designing services to be as tolerant as possible to changes in their suppliers.\n把组件改成服务，增加了作出更加精细的软件发布计划的机会。对于一个单体系统，任何变化都需要做一次整个应用系统的全量构建和部署。然而，对于微服务来说，只需要重新部署修改过的那些服务就够了。这能简化并加快发布过程。但缺点是：必须要考虑当一个服务发生变化时，依赖它并对其进行消费的其他服务可能将无法工作。传统的集成方法是试图使用版本化来解决这个问题。但在微服务世界中，大家更喜欢将版本化作为最后万不得已的手段来使用 。我们需要在设计服务时尽可能的容忍供应商的变更，以避免提供多个版本。\nAre Microservices the Future?-未来的方向是“微服务”吗？\n\n\n\n\n\n\n\n\nOur main aim in writing this article is to explain the major ideas and principles of microservices. By taking the time to do this we clearly think that the microservices architectural style is an important idea - one worth serious consideration for enterprise applications. We have recently built several systems using the style and know of others who have used and favor this approach.\n我们写这篇文章的主要目的是来解释有关微服务的主要思路和原则。在花了一点时间做了这件事后，我们清楚地认识到，微服务架构风格是一个重要的架构方案——在研发企业应用系统时，值得对它进行认真考虑。我们最近已经使用这种风格构建了一些系统，并且了解到其他一些团队也在使用并支持这种方法。\n\n\n\n\n\n\n\n\n\nThose we know about who are in some way pioneering the architectural style include Amazon, Netflix, The Guardian, the UK Government Digital Service, realestate.com.au, Forward and comparethemarket.com. The conference circuit in 2013 was full of examples of companies that are moving to something that would class as microservices - including Travis CI. In addition there are plenty of organizations that have long been doing what we would class as microservices, but without ever using the name. (Often this is labelled as SOA - although, as we’ve said, SOA comes in many contradictory forms. 15)\n我们所了解到的实践先驱包括：亚马逊、Netflix、The Guardian、The UK Government Digital Service、realestate.com.au、Forward和comparethemarket.com。在2013年的技术大会圈子里充满了各种各样的正在转向微服务的公司案例——包括Travis CI。另外还有大量的组织，它们长期以来一直在做着我们可以归类为微服务的产品，却从未使用过这个名字（这通常被标记为SOA—— 尽管正如我们所说，SOA会表现出各种自相矛盾的形式 15 ）。\n\n\n\n\n\n\n\n\n\nDespite these positive experiences, however, we aren’t arguing that we are certain that microservices are the future direction for software architectures. While our experiences so far are positive compared to monolithic applications, we’re conscious of the fact that not enough time has passed for us to make a full judgement.\n尽管有这些正面的经验，然而并不是说我们确信微服务是软件架构的未来的方向。尽管到目前为止，与单体应用系统相比，我们对于所经历过的微服务架构的评价都是积极的，但是我们也意识到这样的事实，即能供我们做出完整判断的时间还不够长。\n\n\n\n\n\n\n\n\n\nOften the true consequences of your architectural decisions are only evident several years after you made them. We have seen projects where a good team, with a strong desire for modularity, has built a monolithic architecture that has decayed over the years. Many people believe that such decay is less likely with microservices, since the service boundaries are explicit and hard to patch around. Yet until we see enough systems with enough age, we can’t truly assess how microservice architectures mature.\n通常，架构决策的真正效果只有在做出这些决策几年之后才会表现出来。我们已经看到由带着强烈的模块化愿望的优秀团队所做的一些项目，最终却构建出一个单体架构，并在几年之内不断腐化。许多人认为，这种腐化不太可能与微服务有关，因为服务的边界是明确的，很难往里面塞新的东西。但是，当我们还没看到足够多的系统运行足够长时间时，我们不能肯定微服务构架是成熟的。\n\n\n\n\n\n\n\n\n\nThere are certainly reasons why one might expect microservices to mature poorly. In any effort at componentization, success depends on how well the software fits into components. It’s hard to figure out exactly where the component boundaries should lie. Evolutionary design recognizes the difficulties of getting boundaries right and thus the importance of it being easy to refactor them. But when your components are services with remote communications, then refactoring is much harder than with in-process libraries. Moving code is difficult across service boundaries, any interface changes need to be coordinated between participants, layers of backwards compatibility need to be added, and testing is made more complicated.\n有人觉得微服务或许很难成熟起来，这当然是有原因的。在组件化上所做的任何工作的是否有效，取决于软件与组件的匹配程度。要想准确地搞清楚某个组件的边界的位置是一件困难的事情。 演进式设计承认难以对边界进行正确定位，所以它将工作的重点放到了易于重构上。但是当各个组件成为各个进行远程通信的服务后，比起在单一进程内进行各个软件库之间的调用，重构就变得更加困难。跨服务边界的代码迁移也会变得困难起来。接口的任何变更，都需要在其各个参与者之间进行协调，向后兼容的层次也需要被添加进来，测试也会变得更加复杂。\n\n\n\n\n\n\n\n\n\nAnother issue is If the components do not compose cleanly, then all you are doing is shifting complexity from inside a component to the connections between components. Not just does this just move complexity around, it moves it to a place that’s less explicit and harder to control. It’s easy to think things are better when you are looking at the inside of a small, simple component, while missing messy connections between services.\n另一个问题在于，如果组件并没有清晰的划分，那么这项工作的复杂性将会从组件内部转向组件间。后果是，不仅仅是将复杂性搬了家，它还将复杂性变得不可控。在一个小的、简单的组件内部考虑事情是很容易的，但也不能忽视了服务之间复杂的连接。\n\n\n\n\n\n\n\n\n\nFinally, there is the factor of team skill. New techniques tend to be adopted by more skillful teams. But a technique that is more effective for a more skillful team isn’t necessarily going to work for less skillful teams. We’ve seen plenty of cases of less skillful teams building messy monolithic architectures, but it takes time to see what happens when this kind of mess occurs with microservices. A poor team will always create a poor system - it’s very hard to tell if microservices reduce the mess in this case or make it worse.\n最后，对于团队技能也是一个因素。新的技术倾向于被掌握更多的技能的团队使用。适用于技术背景好的团队的技术，不一定适用于一个技术薄弱的团队。我们已经看到大量这样的案例，那些技术薄弱的团队构建出了杂乱的单体架构。当这种杂乱发生到微服务身上时，会出现什么情况？这需要花时间来观察 。一个糟糕的团队，总会构建一个糟糕的系统——在这种情况下，很难讲微服务究竟是减少了杂乱，还是让事情变得更糟。\n\n\n\n\n\n\n\n\n\nOne reasonable argument we’ve heard is that you shouldn’t start with a microservices architecture. Instead begin with a monolith, keep it modular, and split it into microservices once the monolith becomes a problem. (Although this advice isn’t ideal, since a good in-process interface is usually not a good service interface.)\n我们听到一个合理的说法，是说不要一上来就以微服务架构做为起点。相反，要用一个单体系统做为起点，并保持其模块化。当这个单体系统出现了问题后，再将其分解为微服务。（尽管这个建议并不理想，因为一个良好的单一进程内的接口，通常不是一个良好的服务接口）\n\n\n\n\n\n\n\n\n\nSo we write this with cautious optimism. So far, we’ve seen enough about the microservice style to feel that it can be a worthwhile road to tread. We can’t say for sure where we’ll end up, but one of the challenges of software development is that you can only make decisions based on the imperfect information that you currently have to hand.\n因此，我们持谨慎乐观的态度来撰写此文。到目前为止，我们已经看到足够多的有关微服务风格的项目，并且觉得这是一条值得去探索的道路。我们不能肯定地说，道路的尽头在哪里。但是，软件开发的挑战之一，就是只能基于 “目前手上拥有但还不够完善” 的信息来做出决策。\nTIPSTips1 : How big is a microservice?-一个微服务应该有多大？\n\n\n\n\n\n\n\n\nAlthough “microservice” has become a popular name for this architectural style, its name does lead to an unfortunate focus on the size of service, and arguments about what constitutes “micro”. In our conversations with microservice practitioners, we see a range of sizes of services. The largest sizes reported follow Amazon’s notion of the Two Pizza Team (i.e. the whole team can be fed by two pizzas), meaning no more than a dozen people. On the smaller size scale we’ve seen setups where a team of half-a-dozen would support half-a-dozen services.\n尽管“微服务”已经成为一个流行的名字，但是这个名字确实会不幸地导致大家对服务规模的关注，并且产生了有关什么是“微”的争论。在与微服务从业者的交谈中，我们看到了有关服务的一系列规模。所听到的最大的一个服务的规模，是遵循了亚马逊的“两个比萨团队”（即一个团队可以被两个比萨所喂饱）的理念，这意味着这个团队不会多于12人。对于规模较小的服务，我们已经看到一个6人的团队在支持6个服务。\n\n\n\n\n\n\n\n\n\nThis leads to the question of whether there are sufficiently large differences within this size range that the service-per-dozen-people and service-per-person sizes shouldn’t be lumped under one microservices label. At the moment we think it’s better to group them together, but it’s certainly possible that we’ll change our mind as we explore this style further.\n这引出了一个问题，即“每12人做一个服务”和“每人做一个服务”这样有关服务规模的差距，是否已经大到不能将两者都纳入微服务之下？此时，我们认为最好还是把它们归为一类，但是随着进一步探索这种架构风格，绝对有可能我们会在将来改变主意。\nTips2 : Microservices and SOA-微服务与SOA\n\n\n\n\n\n\n\n\nWhen we’ve talked about microservices a common question is whether this is just Service Oriented Architecture (SOA) that we saw a decade ago. There is merit to this point, because the microservice style is very similar to what some advocates of SOA have been in favor of. The problem, however, is that SOA means too many different things, and that most of the time that we come across something called “SOA” it’s significantly different to the style we’re describing here, usually due to a focus on ESBs used to integrate monolithic applications.\n当我们谈起微服务时，一个常见的问题就会出现：是否微服务仅仅是十多年前所看到的“面向服务的架构”(Service Oriented Architecture, SOA)？这样问是有道理的，因为微服务风格非常类似于一些支持SOA的人所赞成的观点。然而，问题在于SOA这个词儿意味着太多不同的东西。而且大多数时候，我们所遇到的某些被称作”SOA”的事物，明显不同于本文所描述的风格。这通常由于它们专注于ESB，来集成各个单体应用。\n\n\n\n\n\n\n\n\n\nIn particular we have seen so many botched implementations of service orientation - from the tendency to hide complexity away in ESB’s 6, to failed multi-year initiatives that cost millions and deliver no value, to centralised governance models that actively inhibit change, that it is sometimes difficult to see past these problems.\n特别地，我们已经看到如此之多的面向服务的拙劣实现——从将系统复杂性隐藏于ESB中的趋势 6 ，到花费数百万进行多年却没有交付任何价值的失败项目，到顽固抑制变化发生的中心化技术治理模型——以至于有时觉得其所造成的种种问题真的不堪回首。\n\n\n\n\n\n\n\n\n\nCertainly, many of the techniques in use in the microservice community have grown from the experiences of developers integrating services in large organisations. The Tolerant Reader pattern is an example of this. Efforts to use the web have contributed, using simple protocols is another approach derived from these experiences - a reaction away from central standards that have reached a complexity that is, frankly, breathtaking. (Any time you need an ontology to manage your ontologies you know you are in deep trouble.)\n当然，在微服务社区投入使用的许多技术，源自各个开发人员将各种服务集成到各个大型组织的经验。“容错读取”(Tolerant Reader)模式就是这样一个例子。对于Web的广泛使用，使得人们不再使用一些中心化的标准，而使用一些简单的协议。坦率地说，这些中心化的标准，其复杂性已经达到令人吃惊的程度。（任何时候，如果需要一个本体（ontology）来管理其他各个本体，那么麻烦就大了）\n\n\n\n\n\n\n\n\n\nThis common manifestation of SOA has led some microservice advocates to reject the SOA label entirely, although others consider microservices to be one form of SOA 7, perhaps service orientation done right. Either way, the fact that SOA means such different things means it’s valuable to have a term that more crisply defines this architectural style.\n这种常见的SOA的表现，已使得一些微服务的倡导者完全拒绝将自己贴上SOA的标签。尽管其他人会将微服务看作是SOA的 一种形式 7 ，也许微服务就是以正确的形式来实现面向服务的SOA 。不管是哪种情况，SOA意味着很多的不同事物，这表明用一个更加干净利落的术语来命名这种架构风格是很有价值的。\nTips3 : Many languages, many options-多种编程语言，多种选择可能\n\n\n\n\n\n\n\n\nThe growth of JVM as a platform is just the latest example of mixing languages within a common platform. It’s been common practice to shell-out to a higher level language to take advantage of higher level abstractions for decades. As is dropping down to the metal and writing performance sensitive code in a lower level one. However, many monoliths don’t need this level of performance optimisation nor are DSL’s and higher level abstractions that common (to our dismay). Instead monoliths are usually single language and the tendency is to limit the number of technologies in use [10].\n做为一个平台，JVM的发展仅仅是一个将各种编程语言混合到一个通用平台的最新例证。近十年以来，在平台外层实现更高层次的编程语言，来利用更高层次的抽象，已经成为一个普遍做法。同样，在平台底层以更低层次的编程语言编写性能敏感的代码也很普遍。然而，许多单体系统并不需要这种级别的性能优化，另外DSL和更高层次的抽象也不常用（这令我们感到失望）。相反，许多单体应用通常就使用单一编程语言，并且有对所使用的技术数量进行 限制 的趋势 [10] 。\nTips4 : Battle-tested standards and enforced standards-”实战检验”的标准与“强制执行”的标准\n\n\n\n\n\n\n\n\nIt’s a bit of a dichotomy that microservice teams tend to eschew the kind of rigid enforced standards laid down by enterprise architecture groups but will happily use and even evangelise the use of open standards such as HTTP, ATOM and other microformats.\n微服务的某些做法有点泾渭分明的味道，即他们趋向于避开被那些企业架构组织所制定的硬性实施的标准，而愉快地使用甚至传播一些开放标准，比如 HTTP、ATOM和其他微格式的协议。\n\n\n\n\n\n\n\n\n\nThe key difference is how the standards are developed and how they are enforced. Standards managed by groups such as the IETF only become standards when there are several live implementations of them in the wider world and which often grow from successful open-source projects.\n这里的关键区别是，这些标准是如何被制定以及如何被实施的。像诸如IETF这样的组织所管理的各种标准，只有达到某些条件才能称为标准，即该标准在全球更广阔的地区有一些正在运行的实现案例，而且这些标准经常源自一些成功的开源项目。\n\n\n\n\n\n\n\n\n\nThese standards are a world apart from many in a corporate world, which are often developed by groups that have little recent programming experience or overly influenced by vendors.\n这些标准组成了一个世界，它区别于来自企业世界的许多标准。企业世界中的标准，经常由这样特点的组织来开发，即缺乏用较新技术进行编程的经验，或受到供应商的过度影响。\nTips5 : Make it easy to do the right thing-让做正确的事情变得容易\n\n\n\n\n\n\n\n\nOne side effect we have found of increased automation as a consequence of continuous delivery and deployment is the creation of useful tools to help developers and operations folk. Tooling for creating artefacts, managing codebases, standing up simple services or for adding standard monitoring and logging are pretty common now. The best example on the web is probably Netflix’s set of open source tools, but there are others including Dropwizard which we have used extensively.\n那些因实现持续交付和持续集成所增加的自动化工作的副产品，是创建一些对开发和运维人员有用的工具。现在，能完成下面工作的工具已经相当常见了：即创建工件(artefacts)、管理代码库、启动一些简单的服务、或增加标准的监控和日志功能。Web上最好的例子可能是Netflix提供的一套开源工具集，但也有其他一些好工具，包括我们已经广泛使用的Dropwizard。\nTips6 : The circuit breaker and production ready code-“断路器”与“可随时上线的代码”\n\n\n\n\n\n\n\n\nCircuit Breaker appears in Release It!alongside other patterns such as Bulkhead and Timeout. Implemented together, these patterns are crucially important when building communicating applications. This Netflix blog entry does a great job of explaining their application of them.\n“断路器”(Circuit Breaker )一词与其他一些模式一起出现在《发布！》(Release It! )一书中，例如隔板(Bulkhead)和超时(Timeout)。当构建彼此通信的应用系统时，将这些模式加以综合运用就变得至关重要。Netflix公司的这篇很精彩的博客解释了这些模式是如何应用的。\nTips7 : Synchronous calls considered harmful-同步调用的弊端\n\n\n\n\n\n\n\n\nAny time you have a number of synchronous calls between services you will encounter the multiplicative effect of downtime. Simply, this is when the downtime of your system becomes the product of the downtimes of the individual components. You face a choice, making your calls asynchronous or managing the downtime. At www.guardian.co.uk they have implemented a simple rule on the new platform - one synchronous call per user request while at Netflix, their platform API redesign has built asynchronicity into the API fabric.\n一旦在一些服务之间进行多个同步调用，就会遇到宕机的乘法效应。简而言之，这意味着整个系统的宕机时间，是每一个单独模块各自宕机时间的乘积。此时面临着一个选择：是让模块之间的调用异步，还是去管理宕机时间？在www.guardian.co.uk网站，他们在新平台上实现了一个简单的规则——每一个用户请求都对应一个同步调用。然而在Netflix公司，他们重新设计的平台API将异步性构建到API的机制(fabric)中。\n参考\nhttps://www.aliyun.com/jiaocheng/292444.html\n\n","slug":"solutions/solution-series-microservices","date":"2020-04-12T07:36:06.000Z","categories_index":"解决方案","tags_index":"架构,微服务,microservices","author_index":"glmapper"},{"id":"007a95c44a187f79d860d68b5fd58832","title":"SpringBoot 实践系列-集成 RocketMQ","content":"RocketMQ 快速开始RocketMQ 简介：Apache RocketMQ是一个分布式消息传递和流媒体平台，具有低延迟、高性能和可靠性、万亿级容量和灵活的可伸缩性。它提供了多种功能，具体参考: https://github.com/apache/rocketmq 。\n\n\n官方指导手册快速开始中提到，RocketMQ 安装需要具体以下条件：\n\n64bit OS, 推荐使用 Linux&#x2F;Unix&#x2F;Mac \n64bit JDK 1.8+\nMaven 3.2.x\n4g+ free disk for Broker server （这个需要特别关注下）\n\n下载安装和编译12345wget https://archive.apache.org/dist/rocketmq/4.7.0/rocketmq-all-4.7.0-source-release.zipunzip rocketmq-all-4.7.0-source-release.zipcd rocketmq-all-4.7.0/mvn -Prelease-all -DskipTests clean install -Ucd distribution/target/rocketmq-4.7.0/rocketmq-4.7.0\n\n1、启动 Name Server\n123&gt; nohup sh bin/mqnamesrv &amp;&gt; tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success...\n\n2、启动 Broker\n1234&gt; nohup sh bin/mqbroker -n localhost:9876 &amp;# nohup sh bin/mqbroker -n localhost:9876 autoCreateTopicEnable=true &amp;&gt; tail -f ~/logs/rocketmqlogs/broker.log The broker[%s, 172.30.30.233:10911] boot success...\n\n\n\n\n\n\n\n\n\nautoCreateTopicEnable：使用 RocketMQ 进行发消息时，必须要指定 topic，对于 topic 的设置有一个开关 autoCreateTopicEnable，一般在开发测试环境中会使用默认设置 autoCreateTopicEnable &#x3D; true，但是这样就会导致 topic 的设置不容易规范管理，没有统一的审核等等，所以在正式环境中会在 Broker 启动时设置参数 autoCreateTopicEnable &#x3D; false。这样当需要增加 topic 时就需要在 web 管理界面上或者通过 admin tools 添加即可\nSpringBoot 集成RocketMQ 目前没有提供集成 SpringBoot 的 starter，因此现在接入都是通过引入客户端进行编程。下面来看下 SpringBoot 集成 RocketMQ 的过程。\n引入 RocketMQ 客户端依赖github 上目前更新的最新版本是 4.7.0 版本，这里就使用最新版本：\n12345&lt;dependency&gt;    &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt;    &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt;    &lt;version&gt;4.7.0&lt;/version&gt;&lt;/dependency&gt;\n\n提供生产者的自动配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * @author: guolei.sgl (glmapper_2018@163.com) 2020/4/5 5:17 PM * @since: **/@Configurationpublic class MQProducerConfiguration &#123;    public static final Logger LOGGER = LoggerFactory.getLogger(MQProducerConfiguration.class);    @Value(&quot;$&#123;rocketmq.producer.groupName&#125;&quot;)    private String             groupName;    @Value(&quot;$&#123;rocketmq.producer.namesrvAddr&#125;&quot;)    private String             namesrvAddr;    @Value(&quot;$&#123;rocketmq.producer.maxMessageSize&#125;&quot;)    private Integer            maxMessageSize;    @Value(&quot;$&#123;rocketmq.producer.sendMsgTimeout&#125;&quot;)    private Integer            sendMsgTimeout;    @Value(&quot;$&#123;rocketmq.producer.retryTimesWhenSendFailed&#125;&quot;)    private Integer            retryTimesWhenSendFailed;    @Bean    @ConditionalOnMissingBean    public DefaultMQProducer defaultMQProducer() throws RuntimeException &#123;        DefaultMQProducer producer = new DefaultMQProducer(this.groupName);        producer.setNamesrvAddr(this.namesrvAddr);        producer.setCreateTopicKey(&quot;AUTO_CREATE_TOPIC_KEY&quot;);        //如果需要同一个 jvm 中不同的 producer 往不同的 mq 集群发送消息，需要设置不同的 instanceName        //producer.setInstanceName(instanceName);        //如果发送消息的最大限制        producer.setMaxMessageSize(this.maxMessageSize);        //如果发送消息超时时间        producer.setSendMsgTimeout(this.sendMsgTimeout);        //如果发送消息失败，设置重试次数，默认为 2 次        producer.setRetryTimesWhenSendFailed(this.retryTimesWhenSendFailed);        try &#123;            producer.start();            LOGGER.info(&quot;producer is started. groupName:&#123;&#125;, namesrvAddr: &#123;&#125;&quot;, groupName, namesrvAddr);        &#125; catch (MQClientException e) &#123;            LOGGER.error(&quot;failed to start producer.&quot;, e);            throw new RuntimeException(e);        &#125;        return producer;    &#125;&#125;\n\n\ngroupName: 发送同一类消息的设置为同一个 group，保证唯一， 默认不需要设置，rocketmq 会使用 ip@pid(pid代表jvm名字) 作为唯一标示。\nnamesrvAddr：Name Server 地址\nmaxMessageSize：消息最大限制，默认 4M\nsendMsgTimeout：消息发送超时时间，默认 3 秒\nretryTimesWhenSendFailed：消息发送失败重试次数，默认 2 次\n\n提供消费者的自动配置类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Configurationpublic class MQConsumerConfiguration &#123;    public static final Logger  LOGGER = LoggerFactory.getLogger(MQConsumerConfiguration.class);    @Value(&quot;$&#123;rocketmq.consumer.namesrvAddr&#125;&quot;)    private String                        namesrvAddr;    @Value(&quot;$&#123;rocketmq.consumer.groupName&#125;&quot;)    private String                        groupName;    @Value(&quot;$&#123;rocketmq.consumer.consumeThreadMin&#125;&quot;)    private int                           consumeThreadMin;    @Value(&quot;$&#123;rocketmq.consumer.consumeThreadMax&#125;&quot;)    private int                           consumeThreadMax;    // 订阅指定的 topic     @Value(&quot;$&#123;rocketmq.consumer.topics&#125;&quot;)    private String                        topics;    @Value(&quot;$&#123;rocketmq.consumer.consumeMessageBatchMaxSize&#125;&quot;)    private int                           consumeMessageBatchMaxSize;    @Autowired    private MessageListenerHandler mqMessageListenerProcessor;    @Bean    @ConditionalOnMissingBean    public DefaultMQPushConsumer defaultMQPushConsumer() throws RuntimeException &#123;        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(groupName);        consumer.setNamesrvAddr(namesrvAddr);        consumer.setConsumeThreadMin(consumeThreadMin);        consumer.setConsumeThreadMax(consumeThreadMax);        consumer.registerMessageListener(mqMessageListenerProcessor);        // 设置 consumer 第一次启动是从队列头部开始消费还是队列尾部开始消费        // 如果非第一次启动，那么按照上次消费的位置继续消费        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);        // 设置消费模型，集群还是广播，默认为集群        consumer.setMessageModel(MessageModel.CLUSTERING);        // 设置一次消费消息的条数，默认为 1 条        consumer.setConsumeMessageBatchMaxSize(consumeMessageBatchMaxSize);        try &#123;            // 设置该消费者订阅的主题和tag，如果是订阅该主题下的所有tag，使用*；            consumer.subscribe(topics, &quot;*&quot;);            // 启动消费            consumer.start();            LOGGER.info(&quot;consumer is started. groupName:&#123;&#125;, topics:&#123;&#125;, namesrvAddr:&#123;&#125;&quot;,groupName,topics,namesrvAddr);        &#125; catch (Exception e) &#123;            LOGGER.error(&quot;failed to start consumer . groupName:&#123;&#125;, topics:&#123;&#125;, namesrvAddr:&#123;&#125;&quot;,groupName,topics,namesrvAddr,e);            throw new RuntimeException(e);        &#125;        return consumer;    &#125;&#125;\n参数参考上述生产者部分。这里配置只是启动的消费端的监听，具体的消费需要再实现一个 MessageListenerConcurrently 接口。\n1234567891011121314151617181920212223242526272829/** * @author: guolei.sgl (glmapper_2018@163.com) 2020/4/5 5:21 PM * @since: **/@Componentpublic class MessageListenerHandler implements MessageListenerConcurrently &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(MessageListenerHandler.class);    private static String TOPIC = &quot;DemoTopic&quot;;    @Override    public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs,                                                    ConsumeConcurrentlyContext context) &#123;        if (CollectionUtils.isEmpty(msgs)) &#123;            LOGGER.info(&quot;receive blank msgs...&quot;);            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;        &#125;        MessageExt messageExt = msgs.get(0);        String msg = new String(messageExt.getBody());        if (messageExt.getTopic().equals(TOPIC)) &#123;            // mock 消费逻辑            mockConsume(msg);        &#125;        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;    &#125;    private void mockConsume(String msg)&#123;        LOGGER.info(&quot;receive msg: &#123;&#125;.&quot;, msg);    &#125;&#125;\n\n使用客户端发送消息使用客户端发送消息的逻辑比较简单，就是拿到 DefaultMQProducer 对象，调用 send 方法，支持同步、异步、oneway 等多种调用方式。\n1234567891011121314151617181920@RestControllerpublic class TestController &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(TestController.class);    private static String TOPIC = &quot;DemoTopic&quot;;    private static String TAGS = &quot;glmapperTags&quot;;    @Autowired    private DefaultMQProducer defaultMQProducer;    @RequestMapping(&quot;send&quot;)    public String test() throws Throwable &#123;        Message msg = new Message(TOPIC, TAGS, (&quot;Say Hello RocketMQ to Glmapper&quot;).getBytes(RemotingHelper.DEFAULT_CHARSET));        // 调用客户端发送消息        SendResult sendResult = defaultMQProducer.send(msg);        LOGGER.info(&quot;sendResult: &#123;&#125;.&quot;,sendResult);        return &quot;SUCCESS&quot;;    &#125;&#125;\n\n测试这里的测试应用是将生产端和消费端放在一起的，所以配置如下：\n123456789101112131415161718spring.application.name=test-rocketserver.port=8008#producerrocketmq.producer.isOnOff=on #该应用是否启用生产者rocketmq.producer.groupName=$&#123;spring.application.name&#125;rocketmq.producer.namesrvAddr=sofa.cloud.alipay.net:9876rocketmq.producer.maxMessageSize=4096rocketmq.producer.sendMsgTimeout=3000rocketmq.producer.retryTimesWhenSendFailed=2#consumerrocketmq.consumer.isOnOff=on #该应用是否启用消费者rocketmq.consumer.groupName=$&#123;spring.application.name&#125;rocketmq.consumer.namesrvAddr=sofa.cloud.alipay.net:9876rocketmq.consumer.topics=DemoTopicrocketmq.consumer.consumeThreadMin=20rocketmq.consumer.consumeThreadMax=64rocketmq.consumer.consumeMessageBatchMaxSize=1\n\n启动程序，查看日志输出:\n122020-04-05 22:53:15.141  INFO 46817 --- [           main] c.g.b.b.c.MQProducerConfiguration        : producer is started. groupName:test-rocket, namesrvAddr: sofa.cloud.alipay.net:98762020-04-05 22:53:15.577  INFO 46817 --- [           main] c.g.b.b.c.MQConsumerConfiguration        : consumer is started. groupName:test-rocket, topics:DemoTopic, namesrvAddr:sofa.cloud.alipay.net:9876\n这里看到，生产者和消费者自动配置已经生效并启动完成。通过 curl localhost:8008&#x2F;send 来触发消息发送:\n122020-04-05 22:54:21.654  INFO 46817 --- [nio-8008-exec-1] c.g.b.boot.controller.TestController     : sendResult: SendResult [sendStatus=SEND_OK, msgId=1E0FC3A2B6E118B4AAC21983B3C50000, offsetMsgId=64583D7C00002A9F0000000000011788, messageQueue=MessageQueue [topic=DemoTopic, brokerName=sofa.cloud.alipay.net, queueId=6], queueOffset=50].2020-04-05 22:54:21.658  INFO 46817 --- [MessageThread_1] c.g.b.b.p.MessageListenerHandler         : receive msg: Say Hello RocketMQ to Glmapper.\n看到发送消息的日志和接受消息的日志。\n使用 hook 拦截消息RocKetMQ 中提供了两个 hook 接口：SendMessageHook 和 ConsumeMessageHook 接口，可以用于在消息发送之前、之后，消息消费之前、之后对消息进行拦截，官方文档中并没有关于这部分的描述，那么这里我们就来看下如何使用这两个 hook 接口来搞点事情。\nSendMessageHook自定义一个 ProducerTestHook ，代码如下：\n12345678910111213141516171819public class ProducerTestHook implements SendMessageHook &#123;    public static final Logger LOGGER = LoggerFactory.getLogger(ProducerTestHook.class);    @Override    public String hookName() &#123;        return ProducerTestHook.class.getName();    &#125;    @Override    public void sendMessageBefore(SendMessageContext sendMessageContext) &#123;        LOGGER.info(&quot;execute sendMessageBefore. sendMessageContext:&#123;&#125;&quot;, sendMessageContext);    &#125;    @Override    public void sendMessageAfter(SendMessageContext sendMessageContext) &#123;        LOGGER.info(&quot;execute sendMessageAfter. sendMessageContext:&#123;&#125;&quot;, sendMessageContext);    &#125;&#125;\n在上面生产者的自动配置类中，将 ProducerTestHook 注册给 producer。\n12// 注册 SendMessageHookproducer.getDefaultMQProducerImpl().registerSendMessageHook(new ProducerTestHook());\n\nConsumeMessageHook自定义一个 ConsumerTestHook ，代码如下：\n12345678910111213141516171819public class ConsumerTestHook implements ConsumeMessageHook &#123;    public static final Logger LOGGER = LoggerFactory.getLogger(ConsumerTestHook.class);    @Override    public String hookName() &#123;        return ConsumerTestHook.class.getName();    &#125;    @Override    public void consumeMessageBefore(ConsumeMessageContext consumeMessageContext) &#123;        LOGGER.info(&quot;execute consumeMessageBefore. consumeMessageContext: &#123;&#125;&quot;,consumeMessageContext);    &#125;    @Override    public void consumeMessageAfter(ConsumeMessageContext consumeMessageContext) &#123;        LOGGER.info(&quot;execute consumeMessageAfter. consumeMessageContext: &#123;&#125;&quot;,consumeMessageContext);    &#125;&#125;\n\n在上面消费者的自动配置类中，将 ConsumerTestHook 注册给 consumer\n12// 注册 ConsumeMessageHookconsumer.getDefaultMQPushConsumerImpl().registerConsumeMessageHook(new ConsumerTestHook());\n\n执行结果如下：\n123456execute sendMessageBefore. sendMessageContext:org.apache.rocketmq.client.hook.SendMessageContext@a50ea34execute sendMessageAfter. sendMessageContext:org.apache.rocketmq.client.hook.SendMessageContext@a50ea34sendResult: SendResult [sendStatus=SEND_OK, msgId=0A0FE8F8C02F18B4AAC21C1275FB0000, offsetMsgId=64583D7C00002A9F0000000000011850, messageQueue=MessageQueue [topic=DemoTopic, brokerName=sofa.cloud.alipay.net, queueId=5], queueOffset=50].execute consumeMessageBefore. consumeMessageContext: org.apache.rocketmq.client.hook.ConsumeMessageContext@6482209areceive msg: Say Hello RocketMQ to Glmapper.execute consumeMessageAfter. consumeMessageContext: org.apache.rocketmq.client.hook.ConsumeMessageContext@6482209a\n遇到的一些问题集成过程中遇到几个问题记录如下：\n1、Broker 启动失败。\n我在测试时遇到的情况是，在 Name Server 启动之后，再启动 Boker 时，ssh 连接会直接提示 connect conversation fail. 通过 dmesg | egrep -i -B100 &#39;killed process&#39; 查看进程被 kill 的记录，得到如下日志：\n123456[2257026.030741] Memory cgroup out of memory: Kill process 110719 (systemd) score 0 or sacrifice child[2257026.031888] Killed process 100735 (sh) total-vm:15708kB, anon-rss:176kB, file-rss:1800kB, shmem-rss:0kB[2257026.133506] Memory cgroup out of memory: Kill process 110719 (systemd) score 0 or sacrifice child[2257026.133539] Killed process 100745 (vsar) total-vm:172560kB, anon-rss:22936kB, file-rss:1360kB, shmem-rss:0kB[2257026.206872] Memory cgroup out of memory: Kill process 104617 (java) score 3 or sacrifice child[2257026.207742] Killed process 104617 (java) total-vm:9092924kB, anon-rss:4188528kB, file-rss:496kB, shmem-rss:0kB\n那这里看到的结论是发生了 OOM，这里是启动时没哟分配到足够的空间导致的(默认配置文件初始内存设置的太大了)。解决办法是：进入到编译之后的 distribution&#x2F;target&#x2F;apache-rocketmq&#x2F;bin 目录，找到 runbroker.sh 和 runserver.sh 两个脚本文件，这两个脚本理解启动时默认指定的参数是非常大的（4g&#x2F;8g&#x2F;2g），我线下测试机器总共才 1c2g，所以适当的调整了下参数:\n\nrunserver.sh\n\n1JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms128m -Xmx256m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;\n\nrunbroker.sh\n\n1JAVA_OPT=&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m&quot;\n\n修改后重新启动 namesrv 和 broker ，正常了\n1234$ jps98633 Jps55689 BrokerStartup54906 NamesrvStartup\n2、No Topic Route Info，xxx\n这个在官方的 FAQ 里面有提到，说明遇到的频次一定是很高的。官方给出的方案可以详解这里 http://rocketmq.apache.org/docs/faq/ 第4条。我是通过 If you can’t find this topic, create it on a broker via admin tools command updateTopic or web console.  这个解决的:\n12345sh mqadmin updateTopic -b localhost:10911 -n localhost:9876 -t DemoTopic # 执行此指令，创建 DemoTopicRocketMQLog:WARN No appenders could be found for logger (io.netty.util.internal.PlatformDependent0).RocketMQLog:WARN Please initialize the logger system properly.create topic to localhost:10911 success.TopicConfig [topicName=DemoTopic, readQueueNums=8, writeQueueNums=8, perm=RW-, topicFilterType=SINGLE_TAG, topicSysFlag=0, order=false]\n\n总结之前在做 SOFATracer 集成消息组件时有看过 RocketMQ 的部分代码，但是在实际操作时还是饶了不少弯路。总体来看，SpringBoot 集成 RocketMQ 还是比较简单的，在此记录一下。如果文中有描述有误的地方，还请各位大佬留言指正。\n参考文档\nhttp://rocketmq.apache.org/docs/quick-start/\nhttps://blog.csdn.net/ph3636/article/details/79528638\n\n","slug":"springboot/springboot-series-rocketmq","date":"2020-04-05T08:09:25.000Z","categories_index":"SpringBoot","tags_index":"微服务,SpringBoot,消息,RocketMQ","author_index":"glmapper"},{"id":"29bf6d756e74758621dce6f471f701c6","title":"解决方案系列-基于 SOFAArk 实现应用的动态装载和卸载","content":"\n\n\n\n\n\n\n\n\n原文链接：解决方案系列-基于 SOFAArk 实现应用的动态装载和卸载\n本篇主要来看下蚂蚁金服开源的 SOFAArk 这个产品。SOFAArk 是一款基于 Java 实现的轻量级类隔离容器，主要提供类隔离和应用(模块)合并部署能力；本文主要基于 telnet 指令的方式进行应用 Biz 的装载和卸载操作。去年在上海 KubeCon 大会上有分享过 《SOFABoot 动态模块实践》，主要是通过 SOFADashboard 来下发指令的，基于 SOFABoot 3.1.4 和 SOFAArk 0.6.0 版本；目前 SOFABoot 已经发布到 3.3.x+ ，SOFAARK 1.1.1 版本，其中 ，SOFAARK 提供了很多新的特性，包括全生命周期的事件机制、卸载优化等。\n\n\n\n由于 SOFABoot 3.3.0 版本中部分代码的重构，导致无法兼容 runtime plugin，所以本文是基于修复版的 SOFABoot 3.3.0-poc-ark-SNAPSHOT 来完成，案例工程kc-sofastack-dynamic-demo 分支 support-3.3.0 。\n案例描述\n先看下官方文档里面对于动态部署的描述，是通过变更/监听 zk 节点数据来实现运维命令的下发和接收：\n\n本篇精简一下，使用 telnet 指令直接进行运维操作；案例描述如下：对于一个运行期的一个应用 A，将另外一个应用 B 动态的装载到 A 上（实际是 A 所在的 Ark 容器上），大体描述如下图所示：\n\n下面两张图是具体的运行结果图：\n\n默认 master 运行、无动态 biz 运行时的运行结果\n动态安装 biz 之后运行结果\n\n操作步骤\n1、构建 SOFABoot 3.3.0-poc-ark-SNAPSHOT 版本，安装到本地仓库\ngitclonehttps://github.com/glmapper/sofa-boot.gitgitcheckout3.3.0-poc-ark-SNAPSHOTmvncleaninstall-DskipTest\n2、下载 kc-sofastack-dynamic-demo 案例工程，打包\ngitclonehttps://github.com/sofastack-guides/kc-sofastack-dynamic-demo.gitgitcheckoutsupport-3.3.0mvncleanpackage-DskipTest\n3、完成打包之后，案例工程根目录 target 目录下有两个包，dynamic-stock-mng-1.0.0-ark-biz.jar 和 dynamic-provider-1.0.0-ark-biz.jar。dynamic-stock-mng-1.0.0-ark-biz.jar 是 master biz + ark 容器，dynamic-provider-1.0.0-ark-biz.jar 是动态 biz\n4、执行 java -jar dynamic-stock-mng-1.0.0-ark-biz.jar，浏览器输入 http://localhost:8080/，运行结果\n这里看到的 SUPPORT BY: DEFAULT BIZ 是默认的 BIZ ，也就是 master BIZ\n5、通过 telnet 指令安装 动态 biz\ntelnetlocalhost1234sofa-ark&gt;biz-ifile://xxxxx/dynamic-provider-1.0.0-ark-biz.jar#这里的文件路径根据你自己本地实际的包路径修改\n通过 biz -a 查看安装结果：\nsofa-ark&gt;biz-aprovide:1.0.0:activatedstock-mng:1.0.0:activatedbizcount=2\n在次通过浏览器输入 http://localhost:8080/，运行结果\n\n这里 SUPPORT BY 是刚刚安装的 动态 BIZ 所提供的。\n原理\n\n  来自官网\n\nSOFAArk 包含三个概念，Ark Container, Ark Plugin 和 Ark Biz; 运行时逻辑结构图如下:\n\n概念解释： \n\nArk Container: SOFAArk 容器，负责 Ark 包启动运行时的管理；Ark Plugin 和 Ark Biz 运行在 SOFAArk 容器之上；容器具备管理插件和应用的功能；容器启动成功后，会自动解析 classpath 包含的 Ark Plugin 和 Ark Biz 依赖，完成隔离加载并按优先级依次启动之；\nArk Plugin: Ark 插件，满足特定目录格式要求的 Fat Jar，使用官方提供的 Maven 插件 sofa-ark-plugin-maven-plugin 可以将一个或多个普通的 Java jar 打包成一个标准格式的 Ark Plugin；Ark Plugin 会包含一份配置文件，通常包括插件类导入导出配置、资源导入导出配置、插件启动优先级等；运行时，SOFAArk 容器会使用独立的 PluginClassLoader加载插件，并根据插件配置构建类加载索引表、资源加载索引表，使插件和插件之间、插件和应用之间相互隔离；\nArk Biz: Ark 应用模块，满足特定目录格式要求的 Fat Jar，使用官方提供的 Maven 插件 sofa-ark-maven-plugin 可以将工程应用打包成一个标准格式的 Ark Biz；Ark Biz 是工程应用以及其依赖包的组织单元，包含应用启动所需的所有依赖和配置；一个 Ark 包中可以包含多个 Ark Biz 包，按优先级依次启动，Biz 之间通过 JVM 服务交互；\n\n运行 Ark 包，Ark Container 优先启动，容器自动解析 Ark 包中含有的 Ark Plugin 和 Ark Biz，并读取他们的配置信息，构建类和资源的加载索引表；然后使用独立的 ClassLoader 加载并按优先级配置依次启动。","slug":"solutions/solution-series-dynamic-module","date":"2020-04-03T08:12:22.000Z","categories_index":"解决方案","tags_index":"ClassLoader,SOFAArk,架构,SOFAStack","author_index":"glmapper"},{"id":"90702231598ae749367712a968e7c7e3","title":"聊一聊 CopyOnWriteArraySet 的迭代删除","content":"上周在工程中涉及到一个清理 Set 集合的操作，将满足设定条件的项从 Set 中删除掉。简化版本代码如下：\n123456789101112public static void main(String[] args) &#123;    Set&lt;String&gt; sets = new CopyOnWriteArraySet&lt;&gt;();    sets.add(&quot;1&quot;);    sets.add(&quot;3&quot;);    sets.add(&quot;3&quot;);    sets.add(&quot;4&quot;);    Iterator&lt;String&gt; iterator = sets.iterator();    while (iterator.hasNext())&#123;        iterator.remove();    &#125;    System.out.println(sets);    &#125;\n这个看起来是个很常规的问题，没有验证就直接发了线下环境，然后就收到了业务方反馈的服务无法正常使用的问题了。\n\n\n问题现象先来看下上述代码所抛出的异常：\n123Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException\tat java.util.concurrent.CopyOnWriteArrayList$COWIterator.remove(CopyOnWriteArrayList.java:1178)\tat com.glmapper.bridge.boot.TestMain.main(TestMain.java:21)\n\n关于 UnsupportedOperationException 这个异常没有什么好说的，在集合操作中经常出现，网上也有很多关于这个异常的说明，这里不再赘述。这里我比较关注的是，我使用的是 CopyOnWriteArraySet，迭代器也是 sets 的，但是异常中居然出现了CopyOnWriteArrayList，查看了 CopyOnWriteArraySet 的类继承关系，和 CopyOnWriteArrayList 也没啥关系。\n排查&amp;结果通过查看了 CopyOnWriteArraySet 的代码，发现 CopyOnWriteArraySet 内部其实是持有了一个 CopyOnWriteArrayList 的对象实例，其内部的所有操作都是基于 CopyOnWriteArrayList 这个对象来进行的。\n123456789101112public class CopyOnWriteArraySet&lt;E&gt; extends AbstractSet&lt;E&gt;        implements java.io.Serializable &#123;    // 省略其他代码    private final CopyOnWriteArrayList&lt;E&gt; al;    /**        * Creates an empty set.        */    public CopyOnWriteArraySet() &#123;        al = new CopyOnWriteArrayList&lt;E&gt;();    &#125;    // 省略其他代码&#125;\n关于 CopyOnWriteArrayList 的操作写操作\n在 CopyOnWriteArrayList 里处理写操作（包括 add、remove、set 等）是先将原始的数据通过 JDK1.6 的 Arrays.copyof() 来生成一份新的数组。add 的代码如下：\n123456789101112131415public boolean add(E e) &#123;    final ReentrantLock lock = this.lock;    lock.lock();    try &#123;        Object[] elements = getArray();        int len = elements.length;        // 这里是生产新的数组        Object[] newElements = Arrays.copyOf(elements, len + 1);        newElements[len] = e;        setArray(newElements);        return true;    &#125; finally &#123;        lock.unlock();    &#125;&#125;\n\n后续的操作都是在新的数据对象上进行写，写完后再将原来的引用指向到当前这个数据对象，这样保证了每次写都是在新的对象上（因为要保证写的一致性，这里要对各种写操作要加一把锁，JDK1.6 在这里用了重入锁），\n读操作\n读的时候就是在引用的当前对象上进行读（包括 get，iterator 等），不存在加锁和阻塞，针对 iterator 使用了一个叫 COWIterator 的简化版迭代器，因为不支持写操作，当获取 CopyOnWriteArrayList 的迭代器时，是将迭代器里的数据引用指向当前引用指向的数据对象，无论未来发生什么写操作，都不会再更改迭代器里的数据对象引用，所以迭代器也很安全。\n结论因为 CopyOnWriteArraySet 的内部操作都是基于 CopyOnWriteArrayList 的，从异常来看：\n1java.util.concurrent.CopyOnWriteArrayList$COWIterator.remove(CopyOnWriteArrayList.java:1178)\nCOWIterator 是 CopyOnWriteArrayList 内部提供的一个简化版的迭代器。所以异常里面出现这个就理所应当了。在来看下 COWIterator 这里简化版的迭代器的 remove 方法：\n12345678/*** Not supported. Always throws UnsupportedOperationException.* @throws UnsupportedOperationException always; &#123;@code remove&#125;*         is not supported by this iterator.*/public void remove() &#123;    throw new UnsupportedOperationException();&#125;\n\n这里实际上是直接就会抛出异常的，另外这里在多补充一个关于 HashSet 的迭代器移除，HashSet 其实内部是持有的 HashMap 实例，因此它的迭代器是 HashMap 内部提供的 HashIterator：\n1234567891011public final void remove() &#123;    Node&lt;K,V&gt; p = current;    if (p == null)        throw new IllegalStateException();    if (modCount != expectedModCount)        throw new ConcurrentModificationException();    current = null;    K key = p.key;    removeNode(hash(key), key, null, false, false);    expectedModCount = modCount;&#125;\n这里其实也可以看到，在对非安全的集合做 remove 操作时会经常遇到的 ConcurrentModificationException 这个异常。\n","slug":"java/java-base-iterator-of-set","date":"2020-03-16T08:20:38.000Z","categories_index":"JAVA","tags_index":"set,迭代器,CopyOnWriteArraySet","author_index":"glmapper"},{"id":"0df03a60d15d7b7ab424fe228bc8cf70","title":"SpringBoot 实践系列-Filter 中的异常处理和 Controller 中的异常处理","content":"本篇主要是记录如何使用 SpringBoot 所提供的 ErrorController 这个接口能力；其内置了一个 BasicErrorController 对异常进行统一的处理，当在 Controller 发生异常的时候会自动把请求 forward 到 /error 这个请求 path 下(/error 是 SpringBoot 提供的一个默认的mapping)。BasicErrorController 提供两种返回错误：1、页面返回；2、json 返回。\n\n\n\n背景\n开发中遇到的一个问题：项目中所有的 rest 请求均是通过 json 形式返回，且自定义了一个统一的数据结构对象，如下：\npublicclassResponse&lt;T&gt;&#123;//数据privateTdata;//success标记privatebooleansuccess;//异常信息privateStringerror;//省略getset&#125;\n这个结构非常常见，相信很多开发者都这么玩过。项目中 rest 请求返回的所有结果都是以 Response 对象形式返回，如下：\n@RequestMapping(\"test\")publicResponse&lt;String&gt;testApi()&#123;Response&lt;String&gt;result=newResponse&lt;&gt;();result.setData(\"thisisglmapperblog\");result.setSuccess(true);returnresult;&#125;\n这基本是最简化版的一个模型；出于安全考虑，现在有个需求是需要对每个请求做校验，比如校验请求中是否携带 token 这种。思路很简单就是通过拦截器或者过滤器的方式来对请求做拦截检验。\n其实不管是拦截器还是过滤器，需要考虑的一个问题是，在校验不通过或者校验时产生异常的情况下，怎么把异常信息以项目中规定的统一数据格式返回，即返回 Response。\n直接将 Response 写回去\n利用 ServletResponse 中提供的 PrintWriter，将 Response 以 json 格式直接 print 回去。大概代码如下：\n@OverridepublicvoiddoFilter(ServletRequestservletRequest,ServletResponseservletResponse,FilterChainchain)throwsIOException,ServletException&#123;HttpServletRequestrequest=(HttpServletRequest)servletRequest;StringrequestURI=request.getRequestURI();//mock测试异常请求if(requestURI.contains(\"testTokenError\"))&#123;Response&lt;String&gt;response=newResponse&lt;&gt;();response.setError(\"tokenvalidationfails\");//回写异常信息returnResponse((HttpServletResponse)servletResponse,JSONObject.toJSONString(response));//返回return;&#125;chain.doFilter(servletRequest,servletResponse);&#125;privatevoidreturnResponse(HttpServletResponseresponse,Stringdata)&#123;PrintWriterwriter=null;response.setCharacterEncoding(\"UTF-8\");response.setContentType(\"text/html;charset=utf-8\");try&#123;writer=response.getWriter();//通过PrintWriter将data数据直接print回去writer.print(data);&#125;catch(IOExceptione)&#123;&#125;finally&#123;if(writer!=null)writer.close();&#125;&#125;\n这种方式比较简单和直接，print 异常数据之后直接 return，不再继续过滤器链。\n抛出异常，通过 BasicErrorController 方式处理\n这种方式是利用了 SpringBoot 本身提供的能力，可以更优雅的处理错误信息。代码大致如下：\n1、是在 Filter 中就直接抛出一个异常\n@OverridepublicvoiddoFilter(ServletRequestservletRequest,ServletResponseservletResponse,FilterChainchain)throwsIOException,ServletException&#123;HttpServletRequestrequest=(HttpServletRequest)servletRequest;StringrequestURI=request.getRequestURI();//mock测试异常请求if(requestURI.contains(\"testTokenError\"))&#123;//直接返回一个自定义的异常thrownewValidationException(\"tokenvalidationfails\");&#125;chain.doFilter(servletRequest,servletResponse);&#125;\n2、定义一个异常处理的 Controller\n这里定义一个 TokenErrorController ，继承自 SpringBoot 提供的 BasicErrorController 这个类，然后重写 error 这个方法（如果是页面的话，重写 errorHtml 这个方法），用于返回自定义的 Response 数据。代码如下：\n@RestControllerpublicclassTokenErrorControllerextendsBasicErrorController&#123;//重写error方法@Override@RequestMapping(produces=&#123;MediaType.APPLICATION_JSON_VALUE&#125;)publicResponseEntity&lt;Map&lt;String,Object&gt;&gt;error(HttpServletRequestrequest)&#123;Map&lt;String,Object&gt;body=getErrorAttributes(request,isIncludeStackTrace(request,MediaType.ALL));HttpStatusstatus=getStatus(request);//拿到body中的异常messageStringmessage=body.get(\"message\").toString();//构建Response对象Responseresponse=newResponse();//将message的设置到responseresponse.setError(message);//返回returnnewResponseEntity(response,status);&#125;//省略其他无关代码&#125;\n这样就可以实现在不改动之前工程任何代码的情况下只处理额外 Filter 中抛出的异常了。需要注意的是，上述是通过 BasicErrorController 来接受了 Filter 抛出的异常信息，然后再通过 BasicErrorController 将异常信息进行包装并且返回。为什么要提一下这个呢？主要是为了和 SpringBoot 中基于 REST 请求层所提供的两个用于处理全局异常的注解区分，这两个注解分别是 @ControllerAdvice 和 @RestControllerAdvice，通过注解的名字其实就能看出，SpringBoot 中，可以通过这两个注解来实现对 @Controller 和  @RestController 标注的类进行全局拦截，因为是 Controller 层面的 AOP 拦截，所以对于 Filter 中抛出的异常，通过 @ControllerAdvice 和 @RestControllerAdvice 两个注解定义的全局异常处理器是没法处理的。\n下面就简单介绍下 @ControllerAdvice 和 @RestControllerAdvice 这两个注解的使用。\n全局异常处理\n自定义一个 OtherExcepetion ，然后再使用基于 @RestControllerAdvice 注解编写一个全局异常处理器。\n@RestControllerAdvicepublicclassOtherExceptionHandler&#123;//这里只处理OtherException异常类型@ExceptionHandler(value=OtherException.class)publicResponse&lt;String&gt;otherExceptionHandler(HttpServletRequestreq,OtherExceptione)&#123;Responseresponse=newResponse();response.setError(e.getMessage());returnresponse;&#125;//当然你也可以定义处理其他异常的@ExceptionHandler&#125;\n这种方式是没法处理 Filter 中异常的，只能处理 Controller 里面抛出的异常。\n小结\n本篇主要记录了在 SpringBoot 中如何保证 Filter 中抛出的异常能和业务一样以指定类型的对象返回，并对 SpringBoot 中提供的基于 Controller 层异常捕获处理进行简单介绍。两者处理异常的思路是不同的：\n\nBasicErrorController：接受来自 /error 的异常请求处理，Filter 中抛出的异常先 forward 到 /error，然后处理。\n@RestControllerAdvice：通过对于所有 @Controller 注解所标注的类进行 AOP 拦截，能够根据异常类型匹配具体的 ExceptionHandler 进行处理。\n\n\n\n\n\n\n\n\n\n\n\n水平有限，文章如果表述错误的地方，希望各位大佬给予指正~\n","slug":"springboot/springboot-series-filter-exception","date":"2020-02-12T08:24:11.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,Exception","author_index":"glmapper"},{"id":"8594734a788b611179d7e2206570ce2a","title":"一文详解蚂蚁金服分布式链路组件 SOFATracer 的埋点机制","content":"\n\n\n\n\n\n\n\n\n原文链接 一文详解蚂蚁金服分布式链路组件 SOFATracer 的埋点机制\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 TraceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的，这些链路数据可用于故障的快速发现，服务治理等。\n\n  GITHUB 地址：https://github.com/sofastack/sofa-tracer/pulls （欢迎 star）官方文件地址：https://www.sofastack.tech/projects/sofa-tracer/overview/\n\n2018 年末时至 2019 年初，SOFA 团队发起过 剖析-sofatracer-框架 的源码解析系列文章。这个系列中，基本对 SOFATracer 所提供的能力及实现原理都做了比较全面的分析，有兴趣的同学可以看下。\n\n\n\n从官方文档及 PR 来看，目前 SOFATracer 已经支持了对以下开源组件的埋点支持：\n\nSpring MVC\nRestTemplate\nHttpClient\nOkHttp3\nJDBC \nDubbo(2.6/2.7)\nSOFARPC\nRedis\nMongoDB\nSpring Message\nSpring Cloud Stream (基于 Spring Message 的埋点)\nRocketMQ\nSpring Cloud FeignClient\nHystrix\n\n\n  大多数能力提供在 3.x 版本，2.x 版本从官方 issue 中可以看到后续将不在继续提供新的功能更新；这也是和 SpringBoot 宣布不在继续维护 1.x 版本有关系。\n\n本文将从插件的角度来分析，SOFATracer 是如何实现对上述组件进行埋点的；通过本文，除了了解 SOFATracer 的埋点机制之外，也可以对上述组件的基本扩展机制以及基本原理有一点学习。\n标准 Servlet 规范埋点原理\nSOFATracer 支持对标准 Servlet 规范的 web mvc 埋点，包括普通的 servlet 和 Springmvc 等；基本原理就是基于 Servelt 规范所提供的 javax.servlet.Filter 过滤器接口扩展实现。\n\n  过滤器位于 client 和 web 应用程序之间，用于检查和修改两者之间流过的请求和响应信息。在请求到达 Servlet 之前，过滤器截获请求。在响应送给客户端之前，过滤器截获响应。多个过滤器形成一个 FilterChain，FilterChain 中不同过滤器的先后顺序由部署文件 web.xml 中过滤器映射的顺序决定。最先截获客户端请求的过滤器将最后截获 Servlet 的响应信息。\n\nweb 应用程序一般作为请求的接收方，在 Tracer 中应用是作为 server 存在的，其在解析 SpanContext 时所对应的事件为 sr (server receive)。\nSOFATracer 在 sofa-tracer-springmvc-plugin 插件中解析及产生 span 的过程大致如下：\n\nServlet Filter 拦截到 request 请求\n从请求中解析 SpanContext \n通过 SpanContext 构建当前 MVC 的 span \n给当前 span 设置 tag、log。\n在 filter 处理的最后，结束 span。\n\n当然这里面还会设计到其他很多细节，比如给 span 设置哪些 tag 属性、如果处理异步线程透传等等。本篇不展开细节探讨，有兴趣的同学可以自行阅读代码或者和我交流。\nDubbo 埋点原理\nDubbo 埋点在 SOFATracer 中实际上提供了两个插件，分别用于支持 Dubbo 2.6.x 和 Dubbo 2.7.x；Duddo 埋点也是基于 Filter ，此Filter 是 Dubbo 提供的 SPI 扩展-调用拦截扩展 机制实现。\n像 Dubbo 或者 SOFARpc 等 rpc 框架的埋点，通常需要考虑的点比较多，首先是 rpc 框架分客户端和服务端，所以在埋点时 rpc 的客户端和服务端必须要有所区分；再者就是 rpc 的调用方式包括很多种，如常见的同步调用、异步调用、oneway 等等，调用方式不同，所对应的 span 的结束时机也不同，重要是的基本所有的 rpc 框架都会使用线程池用来发起和处理请求，那么如何保证 tracer 在多线程环境下不串也很重要。\n另外 Dubbo 2.6.x 和 Dubbo 2.7.x 在异步回调处理上差异比较大，Dubbo 2.7.x 中提供了 onResponse 方法（后面又升级为 Listener，包括 onResponse 和 onError 两个方法）；而 Dubbo 2.6.x 中则并未提供相应的机制，只能通过对 future 的硬编码处理来完成埋点和上报。\n\n  这个问题 zipkin brave 对 Dubbo 2.6.x 的埋点时其实也没有考虑到，在做 SOFATracer 支持 Dubbo 2.6.x 时发现了这个 bug，并做了修复。\n\nSOFATracer 中提供的 DubboSofaTracerFilter 类： \n@Activate(group=&#123;CommonConstants.PROVIDER,CommonConstants.CONSUMER&#125;,value=\"dubboSofaTracerFilter\",order=1)publicclassDubboSofaTracerFilterimplementsFilter&#123;//todotrace&#125;\nSOFATracer 中用于处理 Dubbo 2.6.x 版本中异步回调处理的核心代码：\n\n  Dubbo 异步处理依赖 ResponseFuture 接口，但是 ResponseFuture 在核心链路上并非是以数据或者 list 的形式存在，所以在链路上只会存在一个 ResponseFuture，因此如果我自定义一个类来实现 ResponseFuture 接口是没法达到预期目的的，因为运行期会存在覆盖 ResponseFuture 的问题。所以在设计上，SOFATracer 会通过 ResponseFuture 构建一个新的 FutureAdapter出来用于传递。\n\nbooleanensureSpanFinishes(Future&lt;Object&gt;future,Invocationinvocation,Invoker&lt;?&gt;invoker)&#123;booleandeferFinish=false;if(futureinstanceofFutureAdapter)&#123;deferFinish=true;ResponseFutureoriginal=((FutureAdapter&lt;Object&gt;)future).getFuture();ResponseFuturewrapped=newAsyncResponseFutureDelegate(invocation,invoker,original);//Ensuresevenifnocallbackaddedlater,forexamplewhenaconsumer,wefinishthespanwrapped.setCallback(null);RpcContext.getContext().setFuture(newFutureAdapter&lt;&gt;(wrapped));&#125;returndeferFinish;&#125;\nhttp 客户端埋点原理\nhttp 客户端埋点包括 HttpClient、OkHttp、RestTemplate 等，此类埋点一般都是基于拦截器机制来实现的，如 HttpClient 使用的 HttpRequestInterceptor、HttpResponseInterceptor；OkHttp 使用的 okhttp3.Interceptor；RestTemplate 使用的 ClientHttpRequestInterceptor。\n以 OkHttp 为例，简单分析下 http 客户端埋点的实现原理：\n@OverridepublicResponseintercept(Chainchain)throwsIOException&#123;//获取请求Requestrequest=chain.request();//解析出SpanContext，然后构建SpanSofaTracerSpansofaTracerSpan=okHttpTracer.clientSend(request.method());//发起具体的调用Responseresponse=chain.proceed(appendOkHttpRequestSpanTags(request,sofaTracerSpan));//结束spanokHttpTracer.clientReceive(String.valueOf(response.code()));returnresponse;&#125;\nDatasource 埋点原理\n和标准 servlet 规范实现一样，所有基于 javax.sql.DataSource 实现的 DataSource 均可以使用 SOFATracer 进行埋点。因为 DataSource 并没有提供像 Servlet 那样的过滤器或者拦截器，所以 SOFATracer 中没法直接通过常规的方式（Filter/SPI扩展拦截/拦截器等）进行埋点，而是使用了代理模式的方式来实现的。\n\n上图为 SOFATracer 中 DataSource 代理类实现的类继承结构体系；可以看出，SOFATracer 中自定义了一个 BaseDataSource 抽象类，该抽象类继承 javax.sql.DataSource 接口，SmartDataSource 作为 BaseDataSource 的唯一子类，也就是 SOFATracer 中所使用的 代理类。所以如果你使用了 sofa-tracer-datasource-plugin 插件的话，可以看到最终运行时的 Datasource 类型是 com.alipay.sofa.tracer.plugins.datasource.SmartDataSource。\npublicabstractclassBaseDataSourceimplementsDataSource&#123;//实际被代理的datasourceprotectedDataSourcedelegate;//sofatracer中自定义的拦截器，用于对连接操作、db操作等进行拦截埋点protectedList&lt;Interceptor&gt;interceptors;protectedList&lt;Interceptor&gt;dataSourceInterceptors;&#125;\nInterceptor 主要包括以下三种类型：\n\n以 StatementTracerInterceptor 为例 StatementTracerInterceptor 将将会拦截到所有 PreparedStatement 接口的方法，代码如下：\npublicclassStatementTracerInterceptorimplementsInterceptor&#123;//tracer类型为clientprivateDataSourceClientTracerclientTracer;publicvoidsetClientTracer(DataSourceClientTracerclientTracer)&#123;//tracer对象实例this.clientTracer=clientTracer;&#125;@OverridepublicObjectintercept(Chainchain)throwsException&#123;//记录当前系统时间longstart=System.currentTimeMillis();StringresultCode=SofaTracerConstant.RESULT_SUCCESS;try&#123;//开始一个spanclientTracer.startTrace(chain.getOriginalSql());//执行returnchain.proceed();&#125;catch(Exceptione)&#123;resultCode=SofaTracerConstant.RESULT_FAILED;throwe;&#125;finally&#123;//这里计算执行时间System.currentTimeMillis()-start//结束一个spanclientTracer.endTrace(System.currentTimeMillis()-start,resultCode);&#125;&#125;&#125;\n总体思路是，Datasource 通过组合的方式自定义一个代理类（实际上也可以理解为适配器模式中的对象适配模型方式），对所有目标对象的方式进行代理拦截，在执行具体的 sql 或者连接操作之前创建 datasource 的 span，在操作结束之后结束 span，并进行上报。\n消息埋点\n消息框架组件包括很多，像常见的 RocketMQ、Kafka 等；处理各个组件自己提供的客户端之外，像 Spring 就提供了很多消息组件的封装，包括Spring Cloud Stream、Spring Integration、Spring Message 等等。SOFATracer 基于 Spring Message 标准实现了对常见消息组件和 Spring Cloud Stream 的埋点支持，同时也提供了基于 RocketMQ 客户端模式的埋点实现。\nSpring Messaging 埋点实现原理\nspring-messaging 模块为集成 messaging api 和消息协议提供支持。这里我们先看一个 pipes-and-filters 架构模型：\n\nspring-messaging 的 support 模块中提供了各种不同的 MessageChannel 实现和 channel interceptor 支持，因此在对 spring-messaging 进行埋点时我们自然就会想到去使用 channel interceptor。\n//SOFATracer实现的基于spring-messaging消息拦截器publicclassSofaTracerChannelInterceptorimplementsChannelInterceptor,ExecutorChannelInterceptor&#123;//todotrace&#125;//THISISChannelInterceptorpublicinterfaceChannelInterceptor&#123;//发送之前@NullabledefaultMessage&lt;?&gt;preSend(Message&lt;?&gt;message,MessageChannelchannel)&#123;returnmessage;&#125;//发送后defaultvoidpostSend(Message&lt;?&gt;message,MessageChannelchannel,booleansent)&#123;&#125;//完成发送之后defaultvoidafterSendCompletion(Message&lt;?&gt;message,MessageChannelchannel,booleansent,@NullableExceptionex)&#123;&#125;//接收消息之前defaultbooleanpreReceive(MessageChannelchannel)&#123;returntrue;&#125;//接收后@NullabledefaultMessage&lt;?&gt;postReceive(Message&lt;?&gt;message,MessageChannelchannel)&#123;returnmessage;&#125;//完成接收消息之后defaultvoidafterReceiveCompletion(@NullableMessage&lt;?&gt;message,MessageChannelchannel,@NullableExceptionex)&#123;&#125;&#125;\n可以看到 ChannelInterceptor 实现了消息传递全生命周期的管控，通过暴露出来的方法，可以轻松的实现各个阶段的扩展埋点。\nRocketMQ 埋点实现原理\nRocketMQ 本身是提供了对 Opentracing 规范支持的，由于其支持的版本较高，与 SOFATracer 所实现的 Opentracing 版本不一致，所以在一定程度上不兼容；因此 SOFATracer（opentracing 0.22.0 版本）自身又单独提供了 RocketMQ  的插件。\nRocketMQ 埋点其实是通过两个 hook 接口来完成，实际上在 RocketMQ 的官方文档中貌似并没有提到这两个点。\n//RocketMQ消息消费端hook接口埋点实现类publicclassSofaTracerConsumeMessageHookimplementsConsumeMessageHook&#123;&#125;//RocketMQ消息发送端hook接口埋点实现类publicclassSofaTracerSendMessageHookimplementsSendMessageHook&#123;&#125;\n首先是 SendMessageHook 接口，SendMessageHook 接口提供了两个方法，sendMessageBefore 和 sendMessageAfter，SOFATracer 在实现埋点时，sendMessageBefore 中用来解析和构建 span，sendMessageAfter 中用于拿到结果然后结束 span。\n同样的，ConsumeMessageHook 中也提供了两个方法（consumeMessageBefore和consumeMessageAfter），可以提供给 SOFATracer 来从消息中解析出透传的 tracer 信息然后再将 tracer 信息透传到下游链路中去。\nredis 埋点原理\nSOFATracer 中的 redis 埋点是基于 spring data redis 实现的，没有针对具体的 redis 客户端来埋点。另外 redis 埋点部分参考的是开源社区opentracing-spring-cloud-redis-starter中的实现逻辑。\nredis 的埋点实现与 Datasource 的锚点实现基本思路是一致的，都是通过一层代理来是实现的拦截。sofa-tracer-redis-plugin 中对所有的 redis 操作都通过 RedisActionWrapperHelper 进行了一层包装，在执行具体的命令前后通过 SOFATracer 自己提供的 API 进行埋点操作。代码如下：\npublic&lt;T&gt;TdoInScope(Stringcommand,Supplier&lt;T&gt;supplier)&#123;//构建spanSpanspan=buildSpan(command);returnactivateAndCloseSpan(span,supplier);&#125;//在span的生命周期内执行具体命令private&lt;T&gt;TactivateAndCloseSpan(Spanspan,Supplier&lt;T&gt;supplier)&#123;ThrowablecandidateThrowable=null;try&#123;//执行命令returnsupplier.get();&#125;catch(Throwablet)&#123;candidateThrowable=t;throwt;&#125;finally&#123;if(candidateThrowable!=null)&#123;//...&#125;else&#123;//...&#125;//通过tracerapi结束一个spanredisSofaTracer.clientReceiveTagFinish((SofaTracerSpan)span,\"00\");&#125;&#125;\n除此之后 mongodb 的埋点也是基于 spring data 实现，埋点的实现思路和 redis 基本相同，这里就不在单独分析。\n总结\n本文对蚂蚁金服分布式链路组件 SOFATracer 的埋点机制做了简要的介绍；从各个组件的埋点机制来看，整体思路就是对组件操作进行包装，在请求或者命令执行的前后进行 span 构建和上报。目前一些主流的链路跟踪组件像 brave 也是基于此思路，区别在于 brave 并非是直接基于 opentracing 规范进行编码，而是其自己封装了一整套 api ，然后通过面向 opentracing api 进行一层适配；另外一个非常流行的 skywalking 则是基于 java agent 实现，埋点实现的机制上与 SOFATracer 和 brave 不同。\n参考\n\nSOFATracer\nspring源码分析之spring-messaging模块详解\n","slug":"sofa/sofa-tracer-integration-analysis","date":"2020-01-20T08:27:53.000Z","categories_index":"SOFA","tags_index":"分布式链路跟踪,Tracer,OpenTracing","author_index":"glmapper"},{"id":"e42097f5a6c0cf4efef189a5728220a9","title":"SpringBoot 源码系列-自动配置及 starter 机制解析","content":"\n\n\n\n\n\n\n\n\n一家之言，如有任何错误，请批评指出，不胜感激\n本篇主要来讨论研究两个问题：1、什么自动配置，2、如何编写自动配置\n在使用 Spring 作为项目开发框架的过程中，当需要集成某个组件时，通常需要大量的 xml 配置才可以让项目工程 run 起来，下面先以 mybatis 为例，来看下如何使用 mybatis-Spring 模块，需要哪些必不可少的依赖和配置。\n\n\n使用 mybatis-spring任何组件的集成都绕不过两个问题：依赖和配置，关于配置在这篇文章中介绍了配置的一些点，有兴趣的可以看下。\n依赖从 mybatis 的官方文当可以了解到，要使用 MyBatis-Spring 模块，需要在类路径下包含 mybatis-spring.jar 文件和相关依赖（如：mysql-connector-java）即可。如果使用 Maven 作为构建工具，则在 pom.xml 中加入以下代码即可：\n12345&lt;dependency&gt;  &lt;groupId&gt;org.mybatis&lt;/groupId&gt;  &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;  &lt;version&gt;$&#123;latest.version&#125;&lt;/version&gt;&lt;/dependency&gt;\n\nbean 配置Spirng 集成 mybatis 通常需要以下 bean 配置：\n1.dataSource\n1234&lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot;    init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt;    // 省略其他配置&lt;/bean&gt;\n2.sqlSessionFactory\n123&lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;  &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;\n3.其他：包扫描和事务配置\n1234567891011&lt;!-- DAO 接口所在包名，Spring 会自动查找其下的类，并将其定义为一个 Spring Bean --&gt;&lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt;    &lt;property name=&quot;basePackage&quot; value=&quot;com.glmapper.bridge.boot.dao&quot; /&gt;    &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- (事务管理)transaction manager --&gt;&lt;bean id=&quot;transactionManager&quot;        class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;\n\n这些个 bean 是在 Spring 中使用 mybatis 框架时基本必不可少的配置。那么在 SpringBoot 中呢？\nSpringBoot 中如何集成 mybatis 的SpringBoot 集成 mybatis 非常简单，加一下下面的 starter ，再在 application.properties 配置下数据库连接配置即可；不需要配置 datasource，sqlSessionFactory 等这些 bean。\n12345&lt;dependency&gt;    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n\n\n\n\n\n\n官方文档：https://mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/\nmybatis starter 是如何规避 bean 配置的引用 mybatis-spring-boot-starter 既然可以不用在 xml 中配置 bean ，那肯定是这些 bean 是在 mybatis-spring-boot-starter 中通过某种方式被创建了。\n在 SpringBoot 官方文档的描述中，starter 只是用来管理依赖的，一般不会有代码，自动配置的代码一般在 xxxx-autoconfigure 中。mybatis 的自动配置相关代码是在 mybatis-spring-boot-autoconfigure 中。\nmybatis-spring-boot-autoconfigure 这依赖中只有简单的几个类，其中最核心的就是 MybatisAutoConfiguration 这个配置类。另外一个 MybatisProperties 是 mybatis spring boot 的属性配置类，就是常见的 mybatis.xxxx。\nMybatisAutoConfiguration 自动配置类MybatisAutoConfiguration 的定义及其生效条件：\n\n1.当前 classpath 下必须有 SqlSessionFactory 和 SqlSessionFactoryBean 这两个类\n2.存在 DataSource bean 实例\n3.有配置类 MybatisProperties 实例\n4.在 DataSourceAutoConfiguration 和 MybatisLanguageDriverAutoConfiguration 两个自动配置类之后刷新\n\n123456789101112131415161718@ConditionalOnClass(&#123; SqlSessionFactory.class, SqlSessionFactoryBean.class &#125;)@ConditionalOnSingleCandidate(DataSource.class)@EnableConfigurationProperties(MybatisProperties.class)@AutoConfigureAfter(&#123; DataSourceAutoConfiguration.class, MybatisLanguageDriverAutoConfiguration.class &#125;)public class MybatisAutoConfiguration implements InitializingBean &#123;    // 定义 SqlSessionFactory bean    @Bean    @ConditionalOnMissingBean    public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception &#123;        //     &#125;    // check    @Override    public void afterPropertiesSet() &#123;    checkConfigFileExists();    &#125;    // 省略其他code&#125;\n\n从上面的代码片段大体可以知道 MybatisAutoConfiguration 所做的事情主要包括以下几点：\n\n1、刷新 SqlSessionFactory 和 SqlSessionFactoryBean 两个 bean；\n2、afterPropertiesSet 中做一些准备或者检验工作（这里就是 check 了 mybatis 的配置文件是否配置了）\n\n关于 DataSource 的 bean ，则是由 DataSourceAutoConfiguration 这个配置类中来定义。\n\n\n\n\n\n\n\n\n\n具体代码有兴趣的读者可以自己查阅相关源码，这里就不展开了。\n所以整体看来， MybatisAutoConfiguration 及其所依赖的 xxxConfiguration 会帮助用户定义 bean 和解析配置。\nmybatis 自动配置的 bean 是如何生效的上面分析到 MybatisAutoConfiguration 及其依赖的配置自动类会帮助创建运行时所需要的 bean，那么这些 bean 是如何被 SpringBoot 框架感知并加载的呢？\n其实一般的项目工程中，如果我们在一个类上打了 @Configuration 注解的话，Spring 会直接能够加载到的（前提是这个类所在的包在启动类的子包下）。但是在框架层面，项目的包和所引入的组件包的包路径肯定是有差异的，所以在一些情况下会刷不到依赖中的 bean。\nSpringBoot 中提供了一种类似于 SPI 机制的方式来帮忙加载 EnableAutoConfiguration、ApplicationListner、ApplicationContextInitializer 等类型的 bean。比如 mybatis 自动配置的配置如下：\n1234# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.mybatis.spring.boot.autoconfigure.MybatisLanguageDriverAutoConfiguration,\\org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration\n\n其处理逻辑在 SpringApplication 类中，具体解析方法如下：\n12345678910111213141516171819private &lt;T&gt; List&lt;T&gt; createSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes,\t\t\tClassLoader classLoader, Object[] args, Set&lt;String&gt; names) &#123;    List&lt;T&gt; instances = new ArrayList&lt;&gt;(names.size());    for (String name : names) &#123;        try &#123;            Class&lt;?&gt; instanceClass = ClassUtils.forName(name, classLoader);            Assert.isAssignable(type, instanceClass);            // 反射拿到构造函数            Constructor&lt;?&gt; constructor = instanceClass.getDeclaredConstructor(parameterTypes);            // 创建 bean             T instance = (T) BeanUtils.instantiateClass(constructor, args);            instances.add(instance);        &#125;        catch (Throwable ex) &#123;            throw new IllegalArgumentException(&quot;Cannot instantiate &quot; + type + &quot; : &quot; + name, ex);        &#125;    &#125;    return instances;&#125;\n\n如何编写自己的 starter本小节将结合上面的描述，自定义一个 starter，让你的项目和 xml bean 配置说再见。\n场景描述：有两个 bean,一个 parentBean，一个 childBean，parentBean 需要依赖 childBean，parentBean 中又要依赖 http 包\n原来的 xml 配置：\n1234&lt;bean id=&quot;parentBean&quot; class=&quot;com.glmapper.bridge.boot.service.impl.ParentBean&quot;&gt;    &lt;property name=&quot;childBean&quot; ref=&quot;childBean&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;childBean&quot; class=&quot;com.glmapper.bridge.boot.service.impl.ChildBean&quot;/&gt;\n\n下面考虑的是将这些 bean 作为公共组件提供给其他项目工程用，从框架角度来看，最佳实践是：\n\n提供一个 autoconfigure 模块用于编写自动配置类代码\n提供一个 starter，用于提供给外部用户使用\n\n编写 autoconfigure\n自动配置类\n123456789101112131415161718@Configuration// parentBean 依赖 HttpClient，所以如果没有 HttpClient 则不会刷新当前自动配置类@ConditionalOnClass(HttpClient.class)public class GlmpperAutoConfiguration &#123;    // ParentBean bean 定义    @Bean    @ConditionalOnMissingBean   // 如果当前 Spring 容器中已经存在 parentBean则不会再创建    public ParentBean parentBean()&#123;        return new ParentBean();    &#125;    // ChildBean bean 定义    @Bean    @ConditionalOnMissingBean    public ChildBean childBean()&#123;        return new ChildBean();    &#125;&#125;\n\n依赖 scope 使用 provided，不直接打在 autoconfigure 依赖中\n12345678&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;        &lt;artifactId&gt;httpclient&lt;/artifactId&gt;        &lt;version&gt;4.5.6&lt;/version&gt;        &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n编写 spring.factories，在 resources&#x2F;META-INF&#x2F; 新建一个 spring.factories 文件，配置如下：\n123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\  com.glmapper.bridge.boot.autoconfigure.GlmpperAutoConfiguration\n\n编写 starterstarter 里面没有代码，只做依赖管控\n1234567891011&lt;dependency&gt;    &lt;groupId&gt;com.glmapper.bridge.boot&lt;/groupId&gt;    &lt;artifactId&gt;guides-autoconfigure&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;    &lt;artifactId&gt;httpclient&lt;/artifactId&gt;    &lt;version&gt;4.5.6&lt;/version&gt;&lt;/dependency&gt;\nstarter 里面包括了自动配置的依赖和 httpclient 的依赖，所以用户在引入 starter 之后所有生效条件都满足了，就会在启动时直接刷新。\n\n\n\n\n\n\n\n\n\n示例工程: https://github.com/glmapper/springboot-series-guides.git（`guides-autoconfigure` 模块和 guides-starter 模块）\n小结本篇以 mybatis 为例，对 spring 环境和 SpringBoot 环境下的使用方式做了简单对比；以此为切入点，介绍了 SpringBoot 中的自动配置及 starter 最佳实践。\n","slug":"springboot/springboot-series-auto-configure","date":"2020-01-05T08:36:19.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,自动配置,starter 机制","author_index":"glmapper"},{"id":"33c355c4c6e9a75658b222c024ba6de3","title":"SpringBoot 实践系列-外部化配置优先级问题","content":"本文主要针对 spring.profiles.active、spring.config.location 以及 spring.config.additional-location 的作用机制及优先级问题进行实践对比。\n\n\n\n\n\n\n\n\n\n\n\n本文案例工程已上传 github 仓库：https://github.com/glmapper/springboot-series-guides/tree/master/guides-properties\nspring.profiles.active除了 application.properties 文件之外，profile-specific 配置也可以通过以下命名方式来定义:application-&#123;profile&#125;.properties。在没有使用 active 指定 profiles 的情况下，Environment 会指定一组默认的 profiles（默认情况下是[default])，换句话说就是，如果没有显示的激活 profiles 配置文件，则默认加载的是 application-default.properties 配置文件。\nprofile-specific 配置文件的属性与标准 application.properties 从相同的位置加载（一般是 classpath 下）；profile-specific 指定的 properties 配置文件始终覆盖默认配置。\n在案例工程中(guides-properties)，resources 下面包括 application.properties 和 application-dev.properties \n\napplication.properties 文件配置\n12spring.application.name=appNameInnertestKey=key-default\n\napplication-dev.properties 文件配置\n1testKey=key-dev\n\n通过以下代码在启动时将配置值输出：\n123456789@Value(&quot;$&#123;testKey&#125;&quot;)private String testKey;@PostConstructprivate void init()&#123;    System.out.println(&quot;-------------------------------&quot;);    System.out.println(testKey);    System.out.println(&quot;-------------------------------&quot;);&#125;\n\n不指定 spring.profiles.active 时通过 java -jar guides-properties/target/guides-properties-0.0.1-SNAPSHOT.jar 启动工程，console 输出如下：\n12342020-01-04 00:08:47.279  INFO 11050 --- [           main] com.glmapper.bridge.boot.BootStrap       : No active profile set, falling back to default profiles: default-------------------------------key-default-------------------------------\n\n结论是，如果不显示指定 profiles，则使用默认的。\n指定 spring.profiles.active 时通过 java -jar -Dspring.profiles.active=dev guides-properties/target/guides-properties-0.0.1-SNAPSHOT.jar 启动工程，console 输出如下：\n12342020-01-04 00:08:14.426  INFO 11040 --- [           main] com.glmapper.bridge.boot.BootStrap       : The following profiles are active: dev-------------------------------key-dev-------------------------------\n结论是，在显示指定 profiles 的情况下，会覆盖默认 application.properties 中的配置值。\nspring.config.location在 SpringBoot 2.x 中 spring.config.location 的语义发生了变更(此项配置会导致 classpath 中的 application.properties 不再生效)。原因如下：\n12345678910private Set&lt;String&gt; getSearchLocations() &#123;    // spring.config.location 直接使用此份文件，不会再处理其他配置文件    if (this.environment.containsProperty(CONFIG_LOCATION_PROPERTY)) &#123;        return getSearchLocations(CONFIG_LOCATION_PROPERTY);    &#125;    Set&lt;String&gt; locations = getSearchLocations(CONFIG_ADDITIONAL_LOCATION_PROPERTY);    locations.addAll(            asResolvedSet(ConfigFileApplicationListener.this.searchLocations, DEFAULT_SEARCH_LOCATIONS));    return locations;&#125;\n\n在工程的根目录的 conf 目录下新建一个 application-conf.properties 配置文件，内容如下：\n1testKey=key-spring.config.location\n\n通过 java -jar -Dspring.config.location=conf/application-conf.properties guides-properties/target/guides-properties-0.0.1-SNAPSHOT.jar 启动工程，发现启动报错，原因是因为 application-conf.properties 中没有 配置 spring.application.name，而 spring.application.name 是在 resources 目录下的 application.properties 中的，所以也间接说明前面提到的，会使 classpath 下的配置失效。新增 spring.application.name 之后，重新启动工程，\n12spring.application.name=guides-propertiestestKey=key-spring.config.location\n\n输出结果如下：\n12342020-01-04 00:19:12.225  INFO 11147 --- [           main] com.glmapper.bridge.boot.BootStrap       : No active profile set, falling back to default profiles: default-------------------------------key-spring.config.location-------------------------------\n\n所以在使用 spring.config.location 指定外部配置文件时，需要此份配置文件需全量满足当前工程运行时所需，因为它不会去与 resources 目录下的配置文件去做 merge 操作。\nspring.config.additional-location在使用 spring.config.additional-location 这种方式自定义 locations 时，除了默认 locations 之外，还会使用 spring.config.additional-location 指定的。\n\n\n\n\n\n\n\n\n\nadditional-location：言外之意就是增量的配置在工程的根目录的 conf 目录下新建一个 application-addition.properties 配置文件，内容如下：\n1testKey=key-addition\n通过 java -jar -Dspring.config.additional-location=conf/application-addition.properties guides-properties/target/guides-properties-0.0.1-SNAPSHOT.jar 启动工程，输出结果如下：\n12342020-01-04 00:28:30.048  INFO 11384 --- [           main] com.glmapper.bridge.boot.BootStrap       : No active profile set, falling back to default profiles: default-------------------------------key-addition-------------------------------\n结论是，会覆盖默认 application.properties 中的配置值。\nspring.config.additional-location 与 spring.profiles.active 配置加载关系spring.config.location 不用多说，它就是独立的一份，使用它就不能使用其它的。所以这里只分析 spring.config.additional-location 与 spring.profiles.active 配置加载关系。\n同时指定两个配置通过 java -jar -Dspring.profiles.active=dev -Dspring.config.additional-location=conf/application-addition.properties guides-properties/target/guides-properties-0.0.1-SNAPSHOT.jar 启动工程，输出如下：\n12342020-01-04 00:32:59.044  INFO 11451 --- [           main] com.glmapper.bridge.boot.BootStrap       : The following profiles are active: dev-------------------------------key-dev-------------------------------\n\n为了排除与 -D 参数顺序有关，也使用如下方式再执行一次：java -jar -Dspring.config.additional-location=conf/application-addition.properties -Dspring.profiles.active=dev guides-properties/target/guides-properties-0.0.1-SNAPSHOT.jar，输出结果与前面相同，所以可以得出，spring.profiles.active 的优先级比spring.config.additional-location要高。\nspring.config.additional-location 指定差异增量配置在 spring.config.additional-location 中增加 additionKey\n12testKey=key-additionadditionKey=testAddition\n使用 java -jar -Dspring.config.additional-location=conf/application-addition.properties -Dspring.profiles.active=dev guides-properties/target/guides-properties-0.0.1-SNAPSHOT.jar 启动工程，输出如下：\n123452020-01-04 11:44:42.227  INFO 12821 --- [           main] com.glmapper.bridge.boot.BootStrap       : The following profiles are active: dev-------------------------------key-devtestAddition-------------------------------\n\n结论是 spring.config.additional-location 可以用于提供出 profiles 机制或者默认方式之外的增量配置。\n小结在使用外部化配置文件时，执行顺序为：\n\n\n\n\n\n\n\n\n\nspring.config.location &gt; spring.profiles.active &gt; spring.config.additional-location &gt; 默认的 application.proerties。\n其中通过 spring.profiles.active 和 spring.config.additional-location 指定的配置文件会与 默认的 application.proerties merge 作为最终的配置，spring.config.location 则不会。\n","slug":"springboot/springboot-series-externalize-prop","date":"2020-01-03T08:52:36.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,配置","author_index":"glmapper"},{"id":"6d8a07de9a2b43faff9f51b0d1189aec","title":"SpringBoot 源码系列-配置解析","content":"\n  注：本文基于 SpringBoot 2.1.11 版本\n\n说到配置，你能想到的是什么？ \n在日常的开发和运维过程中，可以说配置都是及其重要的，因为它可能影响到应用的正常启动或者正常运行。相信在之前 Spring xml 时代，很多人都会被一堆 xml 配置折腾的够呛，除此之外，还有像数据库连接配置、缓存配置、注册中心配置、消息配置等等，这些相信大家都不会陌生。\n配置对于开发人员或者运维人员来说可以比喻成一把”钥匙“，可以通过这把”钥匙“让我们的程序 run 起来，可以通过这把 ”钥匙“ 开启或者关闭应用程序的某一个功能。那么为什么会需要配置，对于一个应用来说，配置的意义又是什么呢？\n\n\n\n配置对于框架组件和应用程序的意义 \n配置对于框架组件和应用程序的意义是什么？我的理解是可以让框架组件和应用程序变得灵活，通过配置可以使得一个框架组件或者一个应用程序在不需要做任何自身代码变更的情况下跑在不同的环境、不同的场景下。例如 Dubbo ，用户可以通过配置使得 Dubbo 将服务注册到不同的注册中心，nacos、zookeeper、SOFARegistry 等等；再比如，我有一个应用程序，在 dev 环境和生产环境需要连接不同的数据库，但是我又不想去在代码里面去做修改来适配不同的环境，那么同样我也可以使用配置的方式来做控制。配置可以让框架组件和应用程序变得灵活、不强耦合在某一个场景或者环境下，它可以有很多种存在形态，如常见的是存在文件中、配置中心中、系统环境变量中，对于 JAVA 程序来说还可以是命令行参数或者 -D 参数。可以说任何优秀的框架或者应用，都离不开配置。\n那么作为 Java 语言生态里面最优秀的框架， Spring 是如何管理和使用配置的呢？本篇将以 SpringBoot 中的配置为切入点，来进行详细的剖析。\nSpringBoot 中的配置 \nSpring Boot 官方文章中使用了单独的章节和大量的篇幅对配置进行了描述，可以见得，配置对于 SpringBoot 来说，是相当重要的。 Spring Boot 允许用户将配置外部化，以便可以在不同的环境中使用相同的应用程序代码，用户可以使用 properties 文件、YAML 文件、环境变量和命令行参数来具体化配置。属性值可以通过使用 @Value 注释直接注入 bean，可以通过 Spring 的环境抽象访问，也可以通过 @ConfigurationProperties 绑定到结构化对象。\n在日常的开发中，对于 SpringBoot 中的配置，可能直接想到的就是 application.properties，实际上，从 SpringBoot 官方文档可以看到，SpringBoot 获取配置的方式有多达 17 种；同时 Spring Boot 也提供了一种非常特殊的 PropertyOrder，来允许用户可以在适当的场景下覆盖某些属性值，下面就是官方文档中描述的属性优先加载顺序:\n\n1.在主目录（当 devtools 被激活，则为 ~/.spring-boot-devtools.properties ）中的 Devtools 全局设置属性。\n2.在测试中使用到的 @TestPropertySource 注解。\n3.在测试中使用到的 properties 属性，可以是 @SpringBootTest 和用于测试应用程序某部分的测试注解。\n4.命令行参数。\n5.来自 SPRING_APPLICATION_JSON 的属性（嵌入在环境变量或者系统属性【system propert】中的内联 JSON）\n6.ServletConfig 初始化参数。\n7.ServletContext 初始化参数。\n8.来自 java:comp/env 的 JNDI 属性。\n9.Java 系统属性（System.getProperties()）。\n10.操作系统环境变量。\n11.只有 random.* 属性的 RandomValuePropertySource。\n12.在已打包的 fatjar 外部的指定 profile 的应用属性文件（application-{profile}.properties 和 YAML 变量）。\n13.在已打包的 fatjar 内部的指定 profile 的应用属性文件（application-{profile}.properties 和 YAML 变量）。\n14.在已打包的 fatjar 外部的应用属性文件（application.properties 和 YAML 变量）。\n15.在已打包的 fatjar 内部的应用属性文件（application.properties 和 YAML 变量）。\n16.在 @Configuration 类上的 @PropertySource 注解。\n17.默认属性（使用 SpringApplication.setDefaultProperties 指定）。\n\n相信绝大多数都是你不曾用过的，不用纠结，其实用不到也很正常，但是我们还是需要能够知道它提供的方式有哪些，以便于在适当的场景下掏出来镇楼！\nSpring 中对于配置最终都是交给 Environment 对象来管理，也就是我们常说的 Spring 环境。比如可以通过以下方式从 Environment 中获取配置值：\nConfigurableEnvironmentenvironment=context.getEnvironment();environment.getProperty(\"key\");\n那么 Environment 是如何被构建的呢？Environment 与配置的关系又是什么？\nEnviroemnt 构建 \nEnvironment 的构建发生在 prepareEnvironment 中，关于 SpringBoot 启动过程想了解更多，可以参考这篇 SpringBoot系列-启动过程分析。\nprivateConfigurableEnvironmentgetOrCreateEnvironment()&#123;if(this.environment!=null)&#123;returnthis.environment;&#125;switch(this.webApplicationType)&#123;//标准的web应用caseSERVLET:returnnewStandardServletEnvironment();//webflux应用caseREACTIVE:returnnewStandardReactiveWebEnvironment();//非web应用default:returnnewStandardEnvironment();&#125;&#125;\n\n  本篇基于非 web 应用分析，所有主要围绕 StandardEnvironment 这个类展开分析。\n\nEnvironment 类继承结构体系：\n\nsystemProperties &amp; systemEnvironment \n在构建 StandardEnvironment 对象的过程中，会初始化 systemProperties &amp; systemEnvironment 两个 PropertySource。其触发时机是在其父类 AbstractEnvironment 的构造函数中。customizePropertySources 方法在 AbstractEnvironment 中并没有具体的实现，其依赖子类完成，如下：\npublicAbstractEnvironment()&#123;customizePropertySources(this.propertySources);&#125;//子类StandardEnvironment中的实现逻辑@OverrideprotectedvoidcustomizePropertySources(MutablePropertySourcespropertySources)&#123;//构建systemProperties配置propertySources.addLast(newPropertiesPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME,getSystemProperties()));////构建systemEnvironment配置propertySources.addLast(newSystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME,getSystemEnvironment()));&#125;\n以我本机为例，来分别看下 systemProperties 和 systemEnvironment 主要是哪些东西\n\nsystemProperties\n\n\n\nsystemEnvironment\n\n\ndefaultProperties &amp; commandLineArgs \n在构建完默认的 Environment 完成之后就是配置 Environment ，这里主要就包括默认的 defaultProperties 和命令行参数两个部分。defaultProperties 可以通过以下方式设置:\nMap&lt;String,Object&gt;defaultProperties=newHashMap&lt;&gt;();defaultProperties.put(\"defaultKey\",\"defaultValue\");SpringApplicationspringApplication=newSpringApplication(BootStrap.class);springApplication.setDefaultProperties(defaultProperties);springApplication.run(args);\n配置 defaultProperties 和命令行参数过程的代码如下：\nprotectedvoidconfigurePropertySources(ConfigurableEnvironmentenvironment,String[]args)&#123;MutablePropertySourcessources=environment.getPropertySources();//如果springApplication设置了则构建defaultProperties，没有就算了if(this.defaultProperties!=null&amp;&amp;!this.defaultProperties.isEmpty())&#123;sources.addLast(newMapPropertySource(\"defaultProperties\",this.defaultProperties));&#125;//命令行参数if(this.addCommandLineProperties&amp;&amp;args.length&gt;0)&#123;//PropertySource名为commandLineArgsStringname=CommandLinePropertySource.COMMAND_LINE_PROPERTY_SOURCE_NAME;if(sources.contains(name))&#123;PropertySource&lt;?&gt;source=sources.get(name);CompositePropertySourcecomposite=newCompositePropertySource(name);composite.addPropertySource(newSimpleCommandLinePropertySource(\"springApplicationCommandLineArgs\",args));composite.addPropertySource(source);sources.replace(name,composite);&#125;else&#123;sources.addFirst(newSimpleCommandLinePropertySource(args));&#125;&#125;&#125;\nSpringBoot 打成 fatjar 包后通过命令行传入的参数 包括以下 3 种实现方式\n\njava -jar xxx.jar  a b c : 通过 main 方法的参数获取，即 args \njava -jar xxx.jar -Dp1=a -Dp2=b -Dp3=c : -D 参数方式，会被设置到系统参数中\njava -jar xxx.jar --p1=a --p2=b --p3=c : SpringBoot 规范方式，可以通过 @Value(\"${p1}\"） 获取\n\n配置 Profiles \n为 application enviroment 配置哪些配置文件是 active 的(或者默认情况下是 active)。在配置文件处理期间，可以通过 spring.profiles.active 配置属性来激活其他配置文件。主要包括两种：\n\n通过 spring.profiles.active 配置\n\nprotectedSet&lt;String&gt;doGetActiveProfiles()&#123;synchronized(this.activeProfiles)&#123;if(this.activeProfiles.isEmpty())&#123;//获取spring.profiles.active配置值//如：spring.profiles.active=local，profiles为local//如：spring.profiles.active=local,dev，profiles为local,devStringprofiles=getProperty(ACTIVE_PROFILES_PROPERTY_NAME);if(StringUtils.hasText(profiles))&#123;//按，分割成String[]数组setActiveProfiles(StringUtils.commaDelimitedListToStringArray(StringUtils.trimAllWhitespace(profiles)));&#125;&#125;//返回，这里还没有解析和merge配置returnthis.activeProfiles;&#125;&#125;\n\n通过 SpringApplication 对象 setAdditionalProfiles 配置\n\nSpringApplicationspringApplication=newSpringApplication(BootStrap.class);//设置devspringApplication.setAdditionalProfiles(\"dev\");springApplication.run(args);\n以上两种方式设置的 profiles 会作为最后生效的 activeProfiles。\nconfigurationProperties \n将 ConfigurationPropertySource 支持附加到指定的 Environment。将 Environment 管理的每个 PropertySource 调整为 ConfigurationPropertySource 类型，并允许 PropertySourcesPropertyResolver 使用 ConfigurationPropertyName 调用解析。附加的解析器将动态跟踪任何来自基础环境属性源的添加或删除（这个也是 SpringCloud Config 的底层支持原理）。\npublicstaticvoidattach(Environmentenvironment)&#123;//类型检查Assert.isInstanceOf(ConfigurableEnvironment.class,environment);MutablePropertySourcessources=((ConfigurableEnvironment)environment).getPropertySources();//获取名为configurationProperties的PropertySourcePropertySource&lt;?&gt;attached=sources.get(ATTACHED_PROPERTY_SOURCE_NAME);//如果存在先移除，保证每次都是最新的PropertySourceif(attached!=null&amp;&amp;attached.getSource()!=sources)&#123;sources.remove(ATTACHED_PROPERTY_SOURCE_NAME);attached=null;&#125;if(attached==null)&#123;//重新将名为configurationProperties的PropertySource放到属性源中sources.addFirst(newConfigurationPropertySourcesPropertySource(ATTACHED_PROPERTY_SOURCE_NAME,newSpringConfigurationPropertySources(sources)));&#125;&#125;\n绑定 Environment 到 SpringApplication \n在 Spring Boot 2.0 中，用于绑定 Environment 属性的机制 @ConfigurationProperties 已经完全彻底修改; 所以相信很多人在迁移 SpringBoot 从 1.x 到 2.x 系列时，或者或少都会踩这块的坑。\n新的 API 可以使得 @ConfigurationProperties 直接在你自己的代码之外使用。绑定规则可以参考：Relaxed-Binding-2.0。这里简单演示下：\n//绑定CustomPropList&lt;CustomProp&gt;props=Binder.get(run.getEnvironment()).bind(\"glmapper.property\",Bindable.listOf(CustomProp.class)).orElseThrow(IllegalStateException::new);//配置类@ConfigurationProperties(prefix=\"glmapper.property\")publicclassCustomProp&#123;privateStringname;privateintage;//省略get&amp;set&#125;\n属性配置：\nglmapper:property:-name:glmapperage:26-name:slgage:26\n从上面整个构建过程来看，Enviroment 对象构建实际就是 MutablePropertySources 对象填充的过程。Environment 的静态属性和存储容器都是在AbstractEnvironment 中定义的，ConfigurableWebEnvironment 接口提供的 getPropertySources() 方法可以获取到返回的 MutablePropertySources 实例，然后添加额外的 PropertySource。实际上，Environment 的存储容器就是 PropertySource 的子类集合，而 AbstractEnvironment 中使用的实例就是 MutablePropertySources。\n那么到这里相比 Environment 与配置的关系就非常清楚了，一句话概括就是：Environment 是所有配置的管理器，是 Spring 对提供配置的统一接口。前面提到 Environment 管理了所有 Spring 的环境配置，这些配置最终是以 MutablePropertySources 对象的形态存在 Environment  中。下图为 MutablePropertySources 类的继承体系：\n\n下面继续来看 PropertySources。\nPropertySource &amp; PropertySources \n从名字就能直观看出，PropertySources 是持有一个或者多个 PropertySource 的类。PropertySources 提供了一组基本管理 PropertySource 的方法。\nPropertySource \n下面看下 PropertySource 的源码：\npublicabstractclassPropertySource&lt;T&gt;&#123;protectedfinalLoglogger=LogFactory.getLog(getClass());//属性名protectedfinalStringname;//属性源protectedfinalTsource;//根据指定name和source构建publicPropertySource(Stringname,Tsource)&#123;Assert.hasText(name,\"Propertysourcenamemustcontainatleastonecharacter\");Assert.notNull(source,\"Propertysourcemustnotbenull\");this.name=name;this.source=source;&#125;//根据指定name构建，source默认为Object类型@SuppressWarnings(\"unchecked\")publicPropertySource(Stringname)&#123;this(name,(T)newObject());&#125;//返回当前PropertySource的namepublicStringgetName()&#123;returnthis.name;&#125;//返回当前PropertySource的sourcepublicTgetSource()&#123;returnthis.source;&#125;publicbooleancontainsProperty(Stringname)&#123;return(getProperty(name)!=null);&#125;@NullablepublicabstractObjectgetProperty(Stringname);//返回用于集合比较目的的PropertySource实现(ComparisonPropertySource)。publicstaticPropertySource&lt;?&gt;named(Stringname)&#123;returnnewComparisonPropertySource(name);&#125;//省略其他两个内部类实现，无实际意义&#125;\n一个 PropertySource 实例对应一个 name，例如 systemProperties、enviromentProperties 等。 PropertySource 包括多种类型的实现，主要包括：\n\n1、AnsiPropertySource：Ansi.*，包括 AnsiStyle、AnsiColor、AnsiBackground 等\n2、StubPropertySource：在实际的属性源不能在 application context 创建时立即初始化的情况下用作占位符。例如，基于 ServletContext 的属性源必须等待，直到  ServletContext 对象对其封装的 ApplicationContext 可用。在这种情况下，应该使用存根来保存属性源的默认位置/顺序，然后在上下文刷新期间替换存根。\nComparisonPropertySource：继承自 StubPropertySource ，所有属性访问方法强制抛出异常，作用就是一个不可访问属性的空实现。\n3、EnumerablePropertySource：可枚举的 PropertySource，在其父类的基础上扩展了 getPropertyNames 方法\nCompositePropertySource：source 为组合类型的 PropertySource 实现\nCommandLinePropertySource：source 为命令行参数类型的 PropertySource 实现，包括两种命令行参数和 java opts 参数两种。\nMapPropertySource：source 为 Map 类型的 PropertySource 实现\nPropertiesPropertySource：内部的 Map 实例由 Properties 实例转换而来\nJsonPropertySource：内部的 Map 实例由 Json 实例转换而来\nSystemEnvironmentPropertySource：内部的 Map 实例由 system env 获取\n\n其他还有 ServletConfigPropertySource、ServletContextPropertySource、AnnotationsPropertySource 等，均可根据名字知晓其 source 来源。\nPropertySources \nPropertySources 接口比较简单，如下所示：\npublicinterfacePropertySourcesextendsIterable&lt;PropertySource&lt;?&gt;&gt;&#123;//从5.1版本才提供的defaultStream&lt;PropertySource&lt;?&gt;&gt;stream()&#123;returnStreamSupport.stream(spliterator(),false);&#125;//checkname为「name」的数据源是否存在booleancontains(Stringname);//根据name」获取数据源@NullablePropertySource&lt;?&gt;get(Stringname);&#125;\n前面在分析 Enviroment 构建中，可以看到整个过程都是以填充 MutablePropertySources 为主线。MutablePropertySources 是 PropertySources 的默认实现，它允许对包含的属性源进行操作，并提供了一个构造函数用于复制现有的 PropertySources 实例。此外，其内部在 addFirst 和 addLast 等方法中提到了 precedence（优先顺序） ，这些将会影响 PropertyResolver 解析给定属性时搜索属性源的顺序。\nMutablePropertySources 内部就是对 propertySourceList 的一系列管理操作（增删改成等），propertySourceList 其实就是整个配置系统最底层的存储容器，所以就很好理解，配置解析为什么都是在填充 MutablePropertySources 这个对象了。\n//配置最终都被塞到这里了privatefinalList&lt;PropertySource&lt;?&gt;&gt;propertySourceList=newCopyOnWriteArrayList&lt;&gt;();\n最后我们再来看下，Spring 中 Environment 属性是如何被访问的。\nEnvironment 属性访问\n单从 Environment 代码来看，其内部并没有提供访问属性的方法，这些访问属性的方法都由其父类接口 PropertyResolver 提供。\npublicinterfacePropertyResolver&#123;//判断属性是否存在booleancontainsProperty(Stringkey);//获取属性@NullableStringgetProperty(Stringkey);//获取属性，如果没有则提供默认值StringgetProperty(Stringkey,StringdefaultValue);@Nullable&lt;T&gt;TgetProperty(Stringkey,Class&lt;T&gt;targetType);&lt;T&gt;TgetProperty(Stringkey,Class&lt;T&gt;targetType,TdefaultValue);//获取Required属性StringgetRequiredProperty(Stringkey)throwsIllegalStateException;&lt;T&gt;TgetRequiredProperty(Stringkey,Class&lt;T&gt;targetType)throwsIllegalStateException;//解析占位符StringresolvePlaceholders(Stringtext);//解析Required占位符StringresolveRequiredPlaceholders(Stringtext)throwsIllegalArgumentException;&#125;\nEnvironment 中提供默认访问属性的对象实现是 PropertySourcesPropertyResolver，其定义在 AbstractEnvironment 这个抽象类中：\nprivatefinalConfigurablePropertyResolverpropertyResolver=newPropertySourcesPropertyResolver(this.propertySources);\n那文章最后就来看下 PropertySourcesPropertyResolver 是如何访问配置属性的吧。\nprotected&lt;T&gt;TgetProperty(Stringkey,Class&lt;T&gt;targetValueType,booleanresolveNestedPlaceholders)&#123;if(this.propertySources!=null)&#123;//遍历所有的PropertySourcefor(PropertySource&lt;?&gt;propertySource:this.propertySources)&#123;//省略日志//从propertySource中根据指定的key获取值Objectvalue=propertySource.getProperty(key);//如果值不为空-&gt;选用第一个不为null的匹配key的属性值if(value!=null)&#123;//解析占位符替换,如$&#123;server.port&#125;，底层委托到PropertyPlaceholderHelper完成if(resolveNestedPlaceholders&amp;&amp;valueinstanceofString)&#123;value=resolveNestedPlaceholders((String)value);&#125;logKeyFound(key,propertySource,value);//进行一次类型转换，具体由DefaultConversionService处理returnconvertValueIfNecessary(value,targetValueType);&#125;&#125;&#125;//省略日志...//没有的话就返回nullreturnnull;&#125;\n这里有一点需要注意，就是如果出现多个 PropertySource 中存在同名的 key，则只会返回第一个 PropertySource 对应 key 的属性值。在实际的业务开发中，如果需要自定义一些环境属性，最好要对各个 PropertySource 的顺序有足够的掌握。\n小结 \n整体看来，Spring 中对于配置的管理还是比较简单的，从 Environment 到 PropertySource 整个过程没有那么绕，就是单纯的把来自各个地方的配置统一塞到 MutablePropertySources 中，对外又通过 Environment 接口对外提供接口访问。\n\n\n\n\n\n\n\n\n\n\n最后感谢大家一年来的关注和支持，和 2019 说声再见，和 2020 说声你好！ 祝大家元旦快乐。\n","slug":"springboot/springboot-series-propertysource","date":"2019-12-29T09:10:24.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,配置,PropertySource","author_index":"glmapper"},{"id":"be22db7a82eb7ce306e739c568aa9990","title":"git ssh 配置及使用","content":"配置使用 ssh 方式来提交和克隆代码大概可以分为以下几个步骤：\n\n设置 Git 的 user name 和 email：(如果是第一次的话)\n检查是否已经有 SSH Key。\n生成密钥\n添加密钥到 ssh-agent\n登陆 github, 添加 ssh\n\n\n\n设置 Git 的 user name 和 email1234# 用户名替换成自己的用户名git config --global user.name &quot;your name&quot;# 邮箱替换换成自己的邮箱git config --global user.email  &quot;your email&quot;\n\n检查是否已经有 SSH Key12# 到 .ssh 目录下cd ~/.ssh\n\nls 列出所有文件，看是否存在 id_isa 和 id_isa.pub 文件（也可以是别的文件名，只要 yourName 和 yourName.pub 成对存在），如果存在的话，证明已经存在 ssh key 了，可以直接跳过 生成密钥 这一步骤\n1alipaynet_rsa      alipaynet_rsa.pub  config             id_rsa             id_rsa.pub         known_hosts        ssh-rsa-bridge     ssh-rsa-bridge.pub\n\n生成秘钥上述因为我已经配置过了，如果没有的话，可参考本节进行相关操作\n12# 生成秘钥ssh-keygen -t rsa -C &quot;your email&quot;\n\n如果不需要密码的话，上述执行过程可以一直回车跳过；执行完成之后将会得到两个文件：id_rsa 和 id_rsa.pub。windows 下默认的路径是 C:\\Users\\Administrator\\.ssh , Mac&#x2F;Linux 默认是 ~/.ssh。\n添加密钥到 ssh-agent确保 ssh-agent 是可用的。ssh-agent 是一种控制用来保存公钥身份验证所使用的私钥的程序，ssh-agent 就是一个密钥管理器，运行 ssh-agent 以后，使用 ssh-add 将私钥交给 ssh-agent 保管，其他程序需要身份验证的时候可以将验证申请交给 ssh-agent 来完成整个认证过程。\n12# start the ssh-agent in the backgroundeval &quot;$(ssh-agent -s)&quot;\n\n执行完之后将会输出如下信息：\n1Agent pid 64345   #  64345 为agent 的进程号\n\n添加生成的 SSH key 到 ssh-agent：\n1ssh-add ~/.ssh/id_rsa\n\n登陆 Github， 添加 sshhttps://github.com/settings/keys 添加 SSH key，把 id_rsa.pub 文件里的内容复制到这里即可。\n","slug":"git/git-ssh-config","date":"2019-12-20T10:05:05.000Z","categories_index":"git","tags_index":"git,ssh","author_index":"glmapper"},{"id":"f4c2cd21dea87d9615be25c2ed29dd31","title":"SpringBoot 源码系列-Bean 的生命周期与扩展","content":"继续承接上一篇 SpringBoot 系列-启动过程分析，本篇围绕一个 bean 的生命周期，对 bean 进行一些修改和扩展。\n\n\n本篇将涉及到以下主要内容：\n\n阅读之前\nBeanDefinition 解析时机和过程\ninvokeBeanFactoryPostProcessors 执行过程分析\ninvokeBeanDefinitionRegistryPostProcessors 执行过程分析\n\n\nBeanFactoryPostProcessor 对 BeanDefinition 的修改\n案例工程中 BeanFactoryPostProcessor 的实现\n\n\n通过监听 ApplicationEnvironmentPreparedEvent 事件修改属性值\n@Value 注入 &amp; @Autowired 注入\nBean 属性注入发生的时机\nBean 属性注入发生的过程\n\n\nBean 的实例化过程\nBeanPostProcessor 的处理时机\n使用 BeanPostProcessor 修改 Bean\n使用 InitializingBean\n指定 Bean 的 init-method 方法\n\n\n总结\nBeanFactoryPostProcessor 对于 init-method 的影响\n附：案例工程地址及参考\n\n\n\n阅读之前下面是本篇文章的“主人公” TestBeanService ，定义如下：\n12345678910111213141516public class TestBeanService &#123;    /**     * 依赖注入     */    @Autowired    private InjectBeanService injectBeanService;    /**     * 属性注入     */    @Value(&quot;$&#123;spring.application.name&#125;&quot;)    private String appName;    public String test() &#123;        return injectBeanService.testInject();    &#125;&#125;\n\nTestBeanService 里面包括两个属性，一个是 injectBeanService ，另外一个是 appName，分别通过 @Autowired 和 @Value 注入值。本篇最终希望完成的目标是能够完成了解 Bean 属性注入的过程，以及 Bean 的实例化过程；除此之外，从 Spring 扩展的角度，来对 BeanFactoryPostProcess、BeanPostProcess、ApplicationListener、InitializingBean 以及 initMethod 的执行时机和作用进行分析。\nTestBeanService 被解析成 BeanDifinition 的时机与过程\n\n\n\n\n\n\n\n\nSpring 容器刷新流程非常复杂，当我们想 debug BeanDifinition 加载过程时可能没法很快找到入口，这里可以直接面向 BeanDifinition 的最终去向来 debug。我们知道 BeanFactory 接口本身是不具体注册 BeanDifinition 能力的，这个能力是由 BeanDefinitionRegistry 接口提供。那么就看下 BeanDefinitionRegistry 的 registerBeanDefinition 方法有几个具体的实现，然后在这几个实现出打上断点，执行找到具体的处理入口。\n我们将断点打在 DefaultListableBeanFactory#registerBeanDefinition 这个方法入口处，debug 模式运行工程，可以看到断点进入时的情况如下图所示：\n\n这里通过执行堆栈逆向找到 BeanDifinition 的加载入口是容器刷新阶段的 invokeBeanFactoryPostProcessors 方法；这里就详细分析下 testBeanService 这个 beandifition 是怎么被注册到容器中的。\ninvokeBeanFactoryPostProcessors 执行过程分析invokeBeanFactoryPostProcessors 这个方法实现非常长，但是基本处理过程很简单，存在很多重复的步骤。为了方便理解整个过程，这里还是有必要贴一下代码，代码中会详细标注所做的事情是什么，这个过程是构建 BeanFactory 非常重要一步。掌握这个过程，就可以随意玩转 BeanFactoryPostProcessor 了。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141public static void invokeBeanFactoryPostProcessors(\t\t\tConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123;    // Invoke BeanDefinitionRegistryPostProcessors first, if any.    Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;();    // 当前 beanFactory 是否是 BeanDefinitionRegistry 类型    // 只有是 BeanDefinitionRegistry 类型，才具备注册 beanDefinition 的能力    if (beanFactory instanceof BeanDefinitionRegistry) &#123;        BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;        // 普通的 BeanFactoryPostProcessor 集合        List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;();        // BeanDefinitionRegistryPostProcessor 类型处理器集合        List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;();        // 这里 beanFactoryPostProcessors 是在 SharedMetadataReaderFactoryContextInitializer 中加进来的，是 Spring 自己的处理器        for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123;            // 如果是 BeanDefinitionRegistryPostProcessor 类型，就加到 registryProcessors            if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123;                BeanDefinitionRegistryPostProcessor registryProcessor =                        (BeanDefinitionRegistryPostProcessor) postProcessor;                // 执行 BeanDefinitionRegistryPostProcessor 后置处理                registryProcessor.postProcessBeanDefinitionRegistry(registry);                registryProcessors.add(registryProcessor);            &#125;            else &#123;                // 否则就放到 regularPostProcessors                regularPostProcessors.add(postProcessor);            &#125;        &#125;        // 不要在这里初始化 FactoryBeans：需要保留所有未初始化的常规bean，以使 beanFacotryPostProcessor 对其处理！        // 分离实现 PriorityOrdered，Ordered和其余优先级的 BeanDefinitionRegistryPostProcessor。        List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;();        // 首先，调用实现 PriorityOrdered 的 BeanDefinitionRegistryPostProcessors。        String[] postProcessorNames =                beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);        // 遍历 BeanDefinitionRegistryPostProcessors        for (String ppName : postProcessorNames) &#123;            // 只处理实现 PriorityOrdered 接口的 BeanDefinitionRegistryPostProcessor            if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;                // 符合上述条件的 BeanDefinitionRegistryPostProcessor 放到 currentRegistryProcessors 中，供后面使用                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                // 标记当前 postProcessor 已经处理过了                processedBeans.add(ppName);            &#125;        &#125;        // 排序        sortPostProcessors(currentRegistryProcessors, beanFactory);        registryProcessors.addAll(currentRegistryProcessors);        // 调用 BeanDefinitionRegistryPostProcessor 后置处理器        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);        currentRegistryProcessors.clear();        // 接下来，调用实现 Ordered的BeanDefinitionRegistryPostProcessors        postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);        for (String ppName : postProcessorNames) &#123;            if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;                currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                processedBeans.add(ppName);            &#125;        &#125;        sortPostProcessors(currentRegistryProcessors, beanFactory);        registryProcessors.addAll(currentRegistryProcessors);        invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);        currentRegistryProcessors.clear();        // 最后，调用所有其他 BeanDefinitionRegistryPostProcessor，直到不再出现（保证全部处理完）。        boolean reiterate = true;        while (reiterate) &#123;            reiterate = false;            postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);            for (String ppName : postProcessorNames) &#123;                if (!processedBeans.contains(ppName)) &#123;                    currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                    processedBeans.add(ppName);                    reiterate = true;                &#125;            &#125;            sortPostProcessors(currentRegistryProcessors, beanFactory);            registryProcessors.addAll(currentRegistryProcessors);            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);            currentRegistryProcessors.clear();        &#125;        // 现在，调用到目前为止已处理的所有处理器的 postProcessBeanFactory 回调。        invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);        invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);    &#125;    else &#123;        // 调用在上下文实例中注册的工厂处理器。就是前面提到的 SharedMetadataReaderFactoryContextInitializer 中注册的        invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);    &#125;    // 这里再次拿到所有的 BeanFactoryPostProcessor    String[] postProcessorNames =            beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);    // 同样将实现 PriorityOrdered、Order 和普通的 BeanFactoryPostProcessor 分离开    List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();    List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;();    List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;();    for (String ppName : postProcessorNames) &#123;        if (processedBeans.contains(ppName)) &#123;            // 跳过-已在上述第一阶段处理过        &#125;        else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;            priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));        &#125;        else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;            orderedPostProcessorNames.add(ppName);        &#125;        else &#123;            nonOrderedPostProcessorNames.add(ppName);        &#125;    &#125;    // 首先，调用实现PriorityOrdered的BeanFactoryPostProcessors。    sortPostProcessors(priorityOrderedPostProcessors, beanFactory);    // 优先执行实现 PriorityOrdered 接口的 BeanFactoryPostProcessor    invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);    // 接下来，调用实现Ordered的BeanFactoryPostProcessors。    List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;(orderedPostProcessorNames.size());    for (String postProcessorName : orderedPostProcessorNames) &#123;        orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));    &#125;    sortPostProcessors(orderedPostProcessors, beanFactory);    // 执行实现 Ordered 接口的 BeanFactoryPostProcessor    invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);    // 最后，调用所有其他 BeanFactoryPostProcessor    List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;(nonOrderedPostProcessorNames.size());    for (String postProcessorName : nonOrderedPostProcessorNames) &#123;        nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));    &#125;    // 执行其他没有实现任何优先级接口的 BeanFactoryPostProcessor    invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);    // 清除缓存的合并 beanDefinition，因为后处理器可能已经修改了原始元数据    beanFactory.clearMetadataCache();&#125;\n\n上面代码段中大体就是，先处理 BeanDefinitionRegistryPostProcessor 类型的 BeanFactoryPostProcessor ，然后再处理普通的 BeanFactoryPostProcessor；在这里处理过程中，会根据一些排序规则来调整各个 BeanFactoryPostProcessor 的执行顺序。\n这里先处理 BeanDefinitionRegistryPostProcessor 类型的 BeanFactoryPostProcessor 是一定的，因为需要在这个阶段去注册 BeanDefinition。在 classpath 下的所有 BeanDefinition 都被注册之后，再执行普通 BeanFactoryPostProcessor 的后置回调，这样就可以覆盖所有的 BeanDefinition。\ninvokeBeanDefinitionRegistryPostProcessors 执行过程分析在第一次调用 invokeBeanDefinitionRegistryPostProcessors 时，当前的 BeanDefinitionRegistryPostProcessor 只有一个，就是 org.springframework.context.annotation.ConfigurationClassPostProcessor 。\n\n\n\n\n\n\n\n\n\n在 ConfigurationClassPostProcessor 类中，会解析 @Configuration、@ComponentScan、@ComponentScans、@Import 等注解。ConfigurationClassPostProcessor 实现了 BeanDefinitionRegistryPostProcessor 接口，而 BeanDefinitionRegistryPostProcessor 接口继承了 BeanFactoryPostProcessor 接口，所以 ConfigurationClassPostProcessor 中需要重写 postProcessBeanDefinitionRegistry() 方法和 postProcessBeanFactory() 方法。而 ConfigurationClassPostProcessor 类的作用就是通过这两个方法去实现的。更多细节可以参考 ConfigurationClassPostProcessor源码解析 这篇文章，写的非常 nice。\ninvokeBeanDefinitionRegistryPostProcessors 处理的核心过程如下：\n\n1、ConfigurationClassPostProcessor#postProcessBeanDefinitionRegistry：BeanDefinition 触发加载的入口\n2、ConfigurationClassPostProcessor#processConfigBeanDefinitions：解析配置类，在此处会解析配置类上的注解(ComponentScan扫描出的类，@Import注册的类，以及@Bean方法定义的类)\n3、ComponentScanAnnotationParser#parse：根据注解的属性值来过滤加载 classpath 下的 beanDefinition（默认条件就是 basePackages，默认的 basePackages 为当前启动类的根包）\n4、ClassPathBeanDefinitionScanner#doScan：处理 basePackages 下所以的 beanDefinition，被打了 @Service、@Compoment 等注解的类都会被解析到\n5、DefaultListableBeanFactory#registerBeanDefinition：将 beanDefinition 注册到 BeanFactory 中（beanDefinitionMap 中）\n\n那么到这里 TestBeanService 的 BeanDefinition 就被注册到 BeanFactory 中了。\nBeanFactoryPostProcessor 对 BeanDefinition 的修改在本篇文章所对应的案例工程中，也实现了一个 BeanFactoryPostProcessor ，没有实现任何排序接口。这个 TestBeanServiceBeanFactoryPostProcessor 的作用是将原来的 TestBeanService 修改为 ProxyTestBeanService。代码如下：\n1234567891011121314151617181920212223242526272829public class TestBeanServiceBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123;    @Override    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123;        // 根据类型拿到所有的 beanNames        Iterable&lt;String&gt; beanNames = getBeanNames(beanFactory, TestBeanService.class);        // 这里因为只有一个 TestBeanService ，所以只处理第一个        beanNames.forEach(beanName -&gt; &#123;            System.out.println(&quot;begin to execute BeanFactoryPostProcessor...&quot;);            BeanDefinitionRegistry beanDefinitionRegistry = (BeanDefinitionRegistry) beanFactory;            // 先从工程中拿到原始 beanDefinition            BeanDefinition beanDefinition = beanFactory.getBeanDefinition(beanName);            // 这里构建一个新的 BeanDefinition，类型为 ProxyTestBeanService，ProxyTestBeanService 是 TestBeanService 的子类            RootBeanDefinition proxy = new RootBeanDefinition(ProxyTestBeanService.class);            // 这里设置指定的initMethod            proxy.setInitMethodName(beanDefinition.getInitMethodName());            // 设置一些属性            proxy.setPropertyValues(beanDefinition.getPropertyValues());            proxy.setPrimary(beanDefinition.isPrimary());            proxy.setRole(BeanDefinition.ROLE_APPLICATION);            // 将原始 beanDefinition 移除掉            beanDefinitionRegistry.removeBeanDefinition(beanName);            // 将代理的新的 beanDefinition 注册进去            beanDefinitionRegistry.registerBeanDefinition(beanName,proxy);            System.out.println(&quot;current bean type is : &quot; + proxy.getBeanClass().getTypeName());            return;        &#125;);    &#125;&#125;\n在 invokeBeanFactoryPostProcessors 执行过程分析中已经分析了 BeanFactoryPostProcessor 执行的时机和过程，这里不再赘述。TestBeanServiceBeanFactoryPostProcessor 的作用就是先将原始的 TestBeanService 的 Beandefinition 从容器中移除掉，然后构建一个 ProxyTestBeanService 的 Beandefinition，然后注册到容器中，beanName 没有变，所以通过 BeanFactoryPostProcessor 可以修改最原始的 Bean 信息，也可以通过 BeanFactoryPostProcessor 来动态注册一个新的 Bean。\n通过监听 ApplicationEnvironmentPreparedEvent 事件修改属性值上面完成了对 TestBeanService 的 BeanDefinition 的修改，将 TestBeanService 对象换成了 ProxyTestBeanService。前面提到 TestBeanService 中有两个需要注入的值，一个是通过 @Autowired 注入，一个是通过 @Value 注入，先来看 @Value 注入。@Value 注入的值来自 Enviroment，这里关于 Enviroment 和配置解析及构建不多说，本篇中关注的是如何将 @Value 注入的值改变掉。\nApplicationEnvironmentPreparedEvent 事件是在环境准备完成时发送的事件，此时 Enviroment 已经准备好，可以随时为容器刷新提供环境变量支持。那么既然此时容器中的 Enviroment 对象已经 ready ，说明配置的 application.properties、系统参数等均已经被解析好了，而此时目标 Bean 还没有被刷新，其内部需要被注入的属性值还没有被注入，那么此时就可以通过监听这个事件，来对 Enviroment 中已经准备好的值进行修改，以改变实际被注入的值。代码如下：\n12345678910111213141516public class ChangeAppNameListener implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) &#123;        ConfigurableEnvironment environment = event.getEnvironment();        // 获取原始 spring.application.name 的值        String applicationName = environment.getProperty(&quot;spring.application.name&quot;);        System.out.println(&quot;origin applicationName is : &quot; + applicationName);        // 修改 spring.application.name        Properties props = new Properties();        props.put(&quot;spring.application.name&quot;, &quot;updateAppName&quot;);        environment.getPropertySources().addFirst(new PropertiesPropertySource(&quot;decrypted_properties&quot;, props));        applicationName = environment.getProperty(&quot;spring.application.name&quot;);        System.out.println(&quot;updated applicationName is : &quot; + applicationName);    &#125;&#125;\n\n@Value 注入 &amp; @Autowired 注入在 Spring 中，无论是 @Value 注入还是 @Autowired 注入，都是由 AutowiredAnnotationBeanPostProcessor 这个后置处理器处理的。\n\n\n\n\n\n\n\n\n\n在很多开源的框架中，其内部自定义的注解也大都是通过 BeanPostProcessor 这个后置处理器来处理的。\nAutowiredAnnotationBeanPostProcessor 中有个 AutowiredFieldElement 内部类，这个内部类的作用就是注入目标 bean 的属性值的。这里就包括 @Value 的注入和 @Autowired 注入。\nBean 属性注入发生的时机容器刷新及属性注入调用堆栈如下：\n\n从堆栈看出，在容器刷新的最后阶段，会通过 finishBeanFactoryInitialization 这个方法实例化所有剩余的（非延迟初始化）单例 bean；这个过程就是绝大多数 bean 实例化的过程。这个过程中会涉及到以下两个比较重要的点：1、BeanPostProcessor 处理，2、依赖注入。从上面其实也可以看出，依赖注入的发生就是通过 BeanPostProcessor 处理完成的。下图为遍历所有目标属性，依次注入属性的过程：\n\nBean 属性注入发生的过程这里以 @Autowired 注入为例，@Value 注入和 @Autowired 注入过程基本是一样的。@Autowired 注入相比于 @Value 注入，会涉及到初始化另外一个 Bean 的过程。\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 构建一个依赖描述符对象DependencyDescriptor desc = new DependencyDescriptor(field, this.required);// 设置包含此依赖项的具体类desc.setContainingClass(bean.getClass());// 初始化一个注入的 beanName 集合，用于后面注册到容器中// 这里实际上只有一个，如果有多个实例 bean 存在，则需要通过 Qualifier 指定了Set&lt;String&gt; autowiredBeanNames = new LinkedHashSet&lt;&gt;(1);Assert.state(beanFactory != null, &quot;No BeanFactory available&quot;);TypeConverter typeConverter = beanFactory.getTypeConverter();try &#123;    // 解析依赖，依赖注入    value = beanFactory.resolveDependency(desc, beanName, autowiredBeanNames, typeConverter);&#125;catch (BeansException ex) &#123;    // 抛出注入失败异常    throw new UnsatisfiedDependencyException(null, beanName, new InjectionPoint(field), ex);&#125;synchronized (this) &#123;    if (!this.cached) &#123;        if (value != null || this.required) &#123;            this.cachedFieldValue = desc;            // 注册依赖的 bean            registerDependentBeans(beanName, autowiredBeanNames);            if (autowiredBeanNames.size() == 1) &#123;                String autowiredBeanName = autowiredBeanNames.iterator().next();                // 判断容器中是否存在此依赖 bean,并且校验 bean 的类型是否匹配                if (beanFactory.containsBean(autowiredBeanName) &amp;&amp;                        beanFactory.isTypeMatch(autowiredBeanName, field.getType())) &#123;                    // 缓存注入值                    this.cachedFieldValue = new ShortcutDependencyDescriptor(                            desc, autowiredBeanName, field.getType());                &#125;            &#125;        &#125;        else &#123;            // 没有找到 依赖bean 实例，且 required 为 false             this.cachedFieldValue = null;        &#125;        this.cached = true;    &#125;&#125;// value 为解析到的属性值，如果不为空，则通过反射设置给目标 Bean，完成属性的注入if (value != null) &#123;    ReflectionUtils.makeAccessible(field);    field.set(bean, value);&#125;\n\n属性注入发生在 populateBean（填充 Bean）的过程，在 Bean 属性填充完成之后就是 Bean 的实例化过程。\nBean 的实例化过程这里截取 AbstractAutowireCapableBeanFactory#doCreateBean 方法中的一小段代码，来承接上下文：\n1234567891011// 初始化bean实例。Object exposedObject = bean;try &#123;    // 填充 Bean    populateBean(beanName, mbd, instanceWrapper);    // 实例化 Bean    exposedObject = initializeBean(beanName, exposedObject, mbd);&#125;catch (Throwable ex) &#123;    // 省略异常处理&#125;\n\n这里通过代码就很好的和上一小节的内容关联起来了，即填充 Bean -&gt; 实例化 Bean 。在 Bean 的实例化阶段会涉及到两个比较重要的扩展：1、BeanPostProcessor，2、InitializingBean。\nBeanPostProcessor 的处理时机BeanPostProcessor 有两个抽象方法，一个是实例化之前调用，一个是实例化之后调用。InitializingBean 接口只有一个 afterPropertiesSet 方法，afterPropertiesSet 方法的执行介于实例化之前实例化之后调用之间。BeanPostProcessor 的处理时机是在调用 initializeBean 方法中触发的，下面为 initializeBean 方法中的部分代码片段： \n123456789101112131415161718Object wrappedBean = bean;if (mbd == null || !mbd.isSynthetic()) &#123;    // 实例化之前调用    wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);&#125;try &#123;    // 调用 InitializingBean 和指定的 init-method 方法    invokeInitMethods(beanName, wrappedBean, mbd);&#125;catch (Throwable ex) &#123;    throw new BeanCreationException(            (mbd != null ? mbd.getResourceDescription() : null),            beanName, &quot;Invocation of init method failed&quot;, ex);&#125;if (mbd == null || !mbd.isSynthetic()) &#123;    // 实例化之后调用    wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);&#125;\n\n\n\n\n\n\n\n\n\n\n这里的 bean 对象实际上已经是完整的 bean 了，postProcessBeforeInitialization 和 postProcessAfterInitialization 是相对于是否执行 InitializingBean 的 afterPropertiesSet 和执行 Bean 指定的 initMethod 方法而言的。\n使用 BeanPostProcessor 修改 Bean从 initializeBean 方法中可以看出，了，postProcessBeforeInitialization 和 postProcessAfterInitialization 两处回调返回放回的是 wrappedBean，也就意味着我们可以在这两个方法中对容器中的原始 Bean 做一些处理，比如代理一层原始的 Bean，或者修改 Bean 中的一些属性等。\n在案例工程中提供了一个 TestBeanServiceProcessor ，其作用是对 TestBeanService 类型的 Bean 做一层代理，使得在执行 TestBeanService 中方法的前后做一些埋点。\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// TestBeanServiceProcessorpublic class TestBeanServiceProcessor implements BeanPostProcessor &#123;    @Override    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        // 如果 bean 的类型是 TestBeanService，则将其包装成 TestBeanWrapperService 并返回        if (bean instanceof TestBeanService)&#123;            System.out.println(&quot;begin to execute postProcessBeforeInitialization.&quot;);            TestBeanWrapperService testBeanService = new TestBeanWrapperService((TestBeanService)bean);            return testBeanService;        &#125;        return bean;    &#125;    @Override    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;        if (bean instanceof TestBeanService)&#123;            System.out.println(&quot;begin to execute postProcessAfterInitialization.&quot;);        &#125;        return bean;    &#125;&#125;// 代理类 TestBeanWrapperService，注意这里代理类也应该是 TestBeanService 类型，否在是后面使用时就会找不到 Bean 实例public class TestBeanWrapperService extends TestBeanService &#123;    private final TestBeanService delegate;    public TestBeanWrapperService(TestBeanService delegate)&#123;        this.delegate = delegate;    &#125;    /**     * 实现对 test 方法执行前后进行拦截     **/    @Override    public String test() &#123;        try &#123;            before();            return delegate.test();        &#125; finally &#123;            after();        &#125;    &#125;    private void before()&#123;        System.out.println(&quot;before execute test.&quot;);    &#125;    private void after()&#123;        System.out.println(&quot;after execute test.&quot;);    &#125;&#125;\n\n使用 InitializingBean如果一个 bean 集成了 InitializingBean 接口，那么就需要重写其 afterPropertiesSet 方法。这里感觉有点漏洞，afterPropertiesSet 动作其实早就完成了，另外因为 afterPropertiesSet  是在 postProcessAfterInitialization 方法之前调用，所以还是可以在 postProcessAfterInitialization 对属性做修改。实际使用过程中需要关注下这个点，一般情况下，我们会在 afterPropertiesSet 中做一些初始化动作，比如启动连接 Zookeeper。\n1234567public class TestBeanService implements InitializingBean &#123;    // 省略其他代码    @Override    public void afterPropertiesSet() throws Exception &#123;        System.out.println(&quot;begin to execute afterPropertiesSet...&quot;);    &#125;&#125;\n\n指定 Bean 的 init-method 方法init-method 方法只能通过 @Bean 或者 xml 方式指定，如果是使用 @Component 或者 @Service 注解标准的 Bean ，则可以通过 @PostConstruct 注解标注方法，对应的是 destroy-method 和 @PreDestroy 。\n12345678910111213public class TestBeanService implements InitializingBean&#123;    // 省略其他代码    // init 方法    public void init()&#123;        System.out.println(&quot;begin to execute init...&quot;);    &#125;&#125;// 在自动配置类或者 xml 文件中指定 initMethod@Bean(initMethod = &quot;init&quot;)public TestBeanService testBeanService()&#123;    return new TestBeanService();&#125;\n\n总结本篇围绕 TestBeanService 这个 Bean 展开，对其生命周期，及其生命周期各个阶段扩展点进行了介绍，包括修改注入的属性值、修改其 BeanDefinition、修改 Bean 实例等等，从扩展点的视角来洞悉一个 Bean 的生命周期。\nBeanFactoryPostProcessor 对于 init-method 的影响因为 init-method 这个点是后面想起来加上去的，在实际测试过程中，发现 TestBeanService 中指定的 init 方法没有被执行（正常情况下是在 afterPropertiesSet 之后就会执行的）；对于这个 TestBeanService 在案例工程中有两处对其进行了修改，一个是修改其 BeanDefinition ，一个是修改 其 Bean 实例；最终拿到的 bean 的类型是 TestBeanWrapperService，在此之前 Bean 的类型是 ProxyTestBeanService ，无论是TestBeanWrapperService 还是 ProxyTestBeanService 都是 TestBeanService 的子类，init 方法又是 public 的，所以从这个角度来看，不可能不生效。所以基本可以排除因为访问权限问题导致。最后 debug 下面代码发现，mbd.getInitMethodName() 返回的是 null， mbd 是 RootBeanDefinition；\n\n\n\n\n\n\n\n\n\nPS: BeanDefinition 中 getInitMethodName 方法是在 Spring 5.1 版本之后才有的，之前版本都是 在 AbstractBeanDefinition 这个抽象类中定义。\n123456789if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) &#123;    // 从当前 bean  的 BeanDefinition 对象中获取 initMethod 方法名    String initMethodName = mbd.getInitMethodName();    if (StringUtils.hasLength(initMethodName) &amp;&amp;            !(isInitializingBean &amp;&amp; &quot;afterPropertiesSet&quot;.equals(initMethodName)) &amp;&amp;            !mbd.isExternallyManagedInitMethod(initMethodName)) &#123;        invokeCustomInitMethod(beanName, bean, mbd);    &#125;&#125;\n问题出在这里，在 TestBeanServiceBeanFactoryPostProcessor 处理时，没有将原始 BeanDefinition 的 initMethod 给新的 ProxyTestBeanService，所以导致后面所有基于此实例化的 bean 的 BeanDefinition 都没有 initMethod 方法。在TestBeanServiceBeanFactoryPostProcessor#postProcessBeanFactory 方法中补充设置 InitMethodName 之后问题解决。\n12// 这里设置指定的initMethodproxy.setInitMethodName(beanDefinition.getInitMethodName());\n\n附：案例工程地址及参考\n工程地址：glmapper-blog-bean-lifecycle\n参考文档：ConfigurationClassPostProcessor源码解析\n\n","slug":"springboot/springboot-series-bean-life","date":"2019-12-14T09:20:43.000Z","categories_index":"SpringBoot","tags_index":"bean 生命周期,SpringBoot,bean 扩展机制","author_index":"glmapper"},{"id":"f5d3246c456264d1eef61369dbcbbbab","title":"SpringBoot 源码系列-日志详解","content":"Spring Boot 使用 Commons Logging 进行所有内部日志记录，但保留底层日志实现。为 Java Util Logging、Log4J2 和 Logback 提供了默认配置。在每种情况下，loggers 都预先配置为使用 console 输出，并且也提供可选的文件输出。\n默认情况下，如果使用 “starters”，则使用 Logback 进行日志记录。还包括适当的 Logback 路由，以确保使用 Java Util 日志记录、Commons 日志记录、Log4J 或 SLF4J 的依赖库都能正常工作。\n\n\n下面先来看一个最简单的 SpringBoot demo 工程的日志输出，以此来展开日志格式、控制台输出、日志颜色、日志文件配置、日志体系解析等几个方面的介绍。\n新建一个 SpringBoot 工程，默认在什么都不加的情况下直接启动，其启动日志大概如下：\n123456782019-12-24 20:41:31.866  INFO 87851 --- [           main] com.glmapper.bridge.boot.BootStrap       : No active profile set, falling back to default profiles: default2019-12-24 20:41:32.003  INFO 87851 --- [           main] s.c.a.AnnotationConfigApplicationContext : Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@314c508a: startup date [Tue Dec 24 20:41:31 CST 2019]; root of context hierarchy2019-12-24 20:41:32.556  INFO 87851 --- [           main] o.s.j.e.a.AnnotationMBeanExporter        : Registering beans for JMX exposure on startup2019-12-24 20:41:32.568  INFO 87851 --- [           main] com.glmapper.bridge.boot.BootStrap       : Started BootStrap in 1.035 seconds (JVM running for 2.13)2019-12-24 20:41:32.569  INFO 87851 --- [       Thread-4] s.c.a.AnnotationConfigApplicationContext : Closing org.springframework.context.annotation.AnnotationConfigApplicationContext@314c508a: startup date [Tue Dec 24 20:41:31 CST 2019]; root of context hierarchy2019-12-24 20:41:32.571  INFO 87851 --- [       Thread-4] o.s.j.e.a.AnnotationMBeanExporter        : Unregistering JMX-exposed beans on shutdownProcess finished with exit code 0\n\n日志格式上面是 Spring Boot 的默认日志输出，从日志格式来看，主要包括以下几项：\n\n日期时间: 例如 2019-12-24 20:41:31.866 (毫秒精度)\n日志级别: 例如 INFO (ERROR, WARN, INFO, DEBUG, or TRACE.)\n当前进程: 例如 87851\n— 分隔符，用于区分实际日志消息的开头。\n线程名称: 例如 Thread-4 (用方括号括起来(为了控制台输出可能被截断)).\n日志名称: 这通常是源类名(通常是缩写)。\n日志信息: 具体的日志消息\n\n比如这条记录：\n12019-12-24 20:41:31.866  INFO 87851 --- [           main] com.glmapper.bridge.boot.BootStrap       : No active profile set, falling back to default profiles: default\n\n是在 org.springframework.boot.SpringApplication#logStartupProfileInfo 方法中打印的，日志级别为 INFO。\n\nConsole 输出SpringBoot 默认会将日志输出到 Console，默认情况下，会记录 error 级别、warn 级别和 info 级别的消息。还可以通过使用 —-debug 参数启动应用程序来使用 “debug” 级别。\n1java -jar myapp.jar --debug\n\n\n\n\n\n\n\n\n\n\n也可以在 application.properties 中指定 debug&#x3D;true 来启用 debug 级别\n当启用 debug 级别时，将配置一系列核心日志记录器(嵌入式容器、Hibernate 和 Spring Boot) 以输出更多信息。启用 debug 模式并不会将应用程序配置为记录所有具有 debug 级别的消息。同样的，也可以使用 —-trace 标记来启动 trace 级别模式来启动应用程序。\n彩色编码输出如果你的终端支持 ANSI，你可以通过设置 “spring.output.ansi.enable“ 配置项值来指定颜色（前提是官方已经支持的颜色）。颜色编码是通过使用 %clr 转换字来配置的，最简单的就是根据日志级别对输出的日志进行着色，如下面的示例所示:\n1%clr(%5p)\n\n下表是官方提供的描述日志级别到颜色的映射关系表:\n\n\n\nLevel\nColor\n\n\n\nFATAL\nRed\n\n\nERROR\nRed\n\n\nWARN\nYellow\n\n\nINFO\nGreen\n\n\nDEBUG\nGreen\n\n\nTRACE\nGreen\n\n\n如果你想要使文本变成黄色，可以使用以下设置:\n1%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;yellow&#125;\n\n目前支持的颜色和样式包括 : blue、cyan、faint、green、magenta、red、yellow。\n文件输出默认情况下，Spring 引导日志只输出到 Console，不会写入到日志文件中。如果希望在 Console 输出之外还写入到日志文件，则需要设置 logging.file 和 logging.path 属性(在 application.properties 中)。下表显示了 logging.* 属性如何一起使用:\n\n\n\nlogging.file\nlogging.path\nExample\nDescription\n\n\n\nnone\nnone\n\n控制台日志\n\n\n指定文件\nnone\nmy.log\n写入指定的日志文件，名称可以是精确位置或相对于当前目录。\n\n\nnone\n指定文件\n&#x2F;var&#x2F;log\n将 spring.log 写入指定的目录，名称可以是精确位置或相对于当前目录。\n\n\n日志文件在达到 10 MB 时会进行 Rolling，与 Console 输出一样，默认情况下会记录 ERROR 级别、WARN 级别和 INFO 级别的消息。可以使用 logging.file.max-size 属性更改大小限制。除非已设置 logging.file.max-history 属性，否则以前 Rolling 的文件将无限期归档。\n\n\n\n\n\n\n\n\n\n日志系统在应用程序生命周期的早期初始化。因此，在通过 @PropertySource 注释加载的属性文件中是找不到日志属性的。另外，logging 属性独立于实际的logging 基础结构。所以，Spring Boot 不会管理特定的配置密钥（例如 Logback 的 logback.configurationFile）。\n日志级别SpringBoot 中所支持的日志系统都可以通过 logging.level.&lt;logger-name&gt;=&lt;level&gt; 在 Spring 环境中设置日志的级别(比如在application.properties 中)。日志级别主要包括 TRACE, DEBUG, INFO, WARN, ERROR, FATAL 和 OFF 几种。除此之外，还可以使用  logging.level.root 配置 root logger 的日志级别。下面的示例展示了如何在 application.properties 中配置日志级别:\n123logging.level.root=warnlogging.level.org.springframework.web=debuglogging.level.org.hibernate=error\n\n除了 application.properties 之外，也可以使用环境变量设置日志级别。例如，LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_WEB&#x3D;DEBUG 将 org.springframework.web 包下的日志打印级别设置为 DEBUG。\n\n\n\n\n\n\n\n\n\n上面的方法只适用于包级别的日志记录。由于 Relaxed Binding 总是将环境变量转换为小写形式，因此不可能以这种方式为单个类配置日志记录。如果需要为一个类配置日志记录，可以使用 SPRING_APPLICATION_JSON 变量。\n日志 Groups将相关的 loggers 分组在一起通常很有用，这样就可以同时对它们进行配置，Spring Boot 允许在 Spring 环境中定义日志组。例如将 “tomcat” 组添加到 application.properties。\n1logging.group.tomcat=org.apache.catalina, org.apache.coyote, org.apache.tomcat\n\n这样，我们就可以通过一行配置来设置一组日志的日志级别：\n1logging.level.tomcat=TRACE\n\nSpring Boot 包含以下可以开箱即用的预定义日志组:\n\n\n\nName\nLoggers\n\n\n\nweb\norg.springframework.core.codec, org.springframework.http, org.springframework.web, org.springframework.boot.actuate.endpoint.web, org.springframework.boot.web.servlet.ServletContextInitializerBeans\n\n\nsql\norg.springframework.jdbc.core, org.hibernate.SQL\n\n\n自定义日志配置可以通过在类路径中包含适当的库来激活各种日志系统，还可以通过在类路径的根目录中提供适当的配置文件或在 Spring 环境的 logging.config 属性指定的位置提供适当的配置文件来进一步定制日志系统。\n比如可以使用 org.springframework.boot.logging.LoggingSystem 配置属性强制 Spring 引导使用指定的日志系统。该值应该是 LoggingSystem 实现的完全限定类名；如果配置为 none 的话，则表示完全禁用 Spring Boot 的日志配置。下表描述了 SpringBoot 中日志系统所对应的日志配置文件：\n\n\n\nLogging System\nCustomization\n\n\n\nLogback\nlogback-spring.xml, logback-spring.groovy, logback.xml, or logback.groovy\n\n\nLog4j2\norg.springframework.jdbc.core, org.hibernate.SQL\n\n\nJDK (Java Util Logging)\nlogging.properties\n\n\n\n\n\n\n\n\n\n\n\nSpringBoot 官方建议在日志配置中使用 -spring 的配置方式(例如，使用 logback-spring.xml 而不是 logback.xml)。如果使用标准配置位置，Spring 无法完全控制日志初始化。\n\n\n\n\n\n\n\n\n\n另外官方文档中有明确提到，JUL(ava Util Logging) 在 FATJAR 场景下存在一些已知的类加载问题，所以要尽量避免在 FATJAR 场景下使用 JUL。\n为了辅助对日志系统进行定制，Spring 会将环境变量属性设置成系统属性，如下表所示:\n\n\n\nSpring Environment\nSystem Property\nComments\n\n\n\nlogging.exception-conversion-word\nLOG_EXCEPTION_CONVERSION_WORD\n记录异常时使用的 conversion word\n\n\nlogging.file\nLOG_FILE\n如果已定义，则在默认日志配置中使用。\n\n\nlogging.file.max-size\nLOG_FILE_MAX_SIZE\n最大日志文件大小(如果启用了LOG_FILE)。(只支持默认的Logback设置)\n\n\nlogging.file.max-history\nLOG_FILE_MAX_HISTORY\n要保留的归档日志文件的最大数量(如果启用了LOG_FILE)。(只支持默认的Logback设置。)\n\n\nlogging.path\nLOG_PATH\n如果已定义，则在默认日志配置中使用。\n\n\nlogging.pattern.console\nCONSOLE_LOG_PATTERN\n要在控制台(stdout)上使用的日志模式。(只支持默认的Logback设置。)\n\n\nlogging.pattern.dateformat\nLOG_DATEFORMAT_PATTERN\n日志日期格式的附加模式。(只支持默认的 Logback 设置。)\n\n\nlogging.pattern.file\nFILE_LOG_PATTERN\n最大日志文件大小(如果启用了LOG_FILE)。(只支持默认的Logback设置)\n\n\nlogging.pattern.level\nLOG_LEVEL_PATTERN\n呈现日志级别时使用的格式(默认%5p)。(只支持默认的Logback设置。)\n\n\nPID\nPID\n当前进程ID\n\n\n所有支持的日志系统在解析配置文件时都可以参考系统属性进行配置解析。\n\n\n\n\n\n\n\n\n\n如果希望在日志属性中使用占位符，应该使用 SpringBoot 的语法，而不是底层框架的语法。需要注意的是，如果使用 Logback，应该使用:作为属性名及其默认值之间的分隔符，而不是使用:-。\nspringProfile 配置  允许用户根据激活的 Spring profiles 选择包含或排除配置部分。profile 文件部分在  元素的任何地方都受支持。可以使用 name 属性指定哪个配置文件接受配置。 可以包含简单的 profile 文件名称(例如 dev )或 profile 文件表达式。profile 文件表达式允许一些比较复杂的 profile 文件逻辑，例如: “production &amp; (eu-central | eu-west)”。下面的显示了三个配置文件示例:\n 1234567891011 &lt;springProfile name=&quot;dev&quot;&gt;\t&lt;!-- 激活 dev 环境的配置 --&gt;&lt;/springProfile&gt;&lt;springProfile name=&quot;dev | pre&quot;&gt;\t&lt;!-- 激活 dev 和 pre 的环境变量 --&gt;&lt;/springProfile&gt;&lt;springProfile name=&quot;!prod&quot;&gt;\t&lt;!-- 所有非 prod 环境的都激活 --&gt;&lt;/springProfile&gt;\n\n环境属性  标记允许用户传递 Spring Environment 中的属性，以便在 Logback 中使用。比如在 Logback 配置中访问 application.properties 文件中的值。 的作用机制与 Logback 的标准  标签类似。但是，不是指定直接 value，而是指定属性的 source（来自Environment）。如果需要将属性存储在 local 范围以外的其他位置，则可以使用 scope 属性来控制。如果需要默认值（如果未在 Environment 中设置该属性），则可以使用 defaultValue 属性配置。以下示例描述了如何传递在 Logback 中使用的属性：\n 123456&lt;springProperty scope=&quot;context&quot; name=&quot;fluentHost&quot; source=&quot;myapp.fluentd.host&quot;\t\tdefaultValue=&quot;localhost&quot;/&gt;&lt;appender name=&quot;FLUENT&quot; class=&quot;ch.qos.logback.more.appenders.DataFluentAppender&quot;&gt;\t&lt;remoteHost&gt;$&#123;fluentHost&#125;&lt;/remoteHost&gt;\t...&lt;/appender&gt;\n\n前面基于 SpringBoot 官方文档对于 Logger 的支持描述做了简单的介绍，下面将通过分析源码来深入的掌握上述这些特性。本文以 log4j2 为例进行分析。\n在 SpringBoot 系列-事件机制详解 文章中其实有提到过 logging 初始化的时机。这里简单回顾下：\n12345# Application Listenersorg.springframework.context.ApplicationListener=\\// 省略其他org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\org.springframework.boot.context.logging.LoggingApplicationListener,\\\n这两个 logging 的监听器中，主要作用的是 LoggingApplicationListener ，这个监听器就是 SpringBoot 中日志初始化的入口。\n日志初始化入口LoggingApplicationListener 继承了 GenericApplicationListener 这个接口，其父接口是 ApplicationListener，GenericApplicationListener 中扩展了对于事件类型的支持判断。这里主要关心的是 onApplicationEvent 这个回调方法，关于这个方法中所提到的几个事件类型，可以参考 SpringBoot 系列-事件机制详解 这篇文章的介绍。\n123456789101112131415161718192021222324@Overridepublic void onApplicationEvent(ApplicationEvent event) &#123;    // ApplicationStartingEvent     if (event instanceof ApplicationStartingEvent) &#123;        onApplicationStartingEvent((ApplicationStartingEvent) event);    &#125;    // ApplicationEnvironmentPreparedEvent     else if (event instanceof ApplicationEnvironmentPreparedEvent) &#123;        onApplicationEnvironmentPreparedEvent((ApplicationEnvironmentPreparedEvent) event);    &#125;    // ApplicationPreparedEvent    else if (event instanceof ApplicationPreparedEvent) &#123;        onApplicationPreparedEvent((ApplicationPreparedEvent) event);    &#125;    // ContextClosedEvent    else if (event instanceof ContextClosedEvent            &amp;&amp; ((ContextClosedEvent) event).getApplicationContext().getParent() == null) &#123;        onContextClosedEvent();    &#125;    // ApplicationFailedEvent    else if (event instanceof ApplicationFailedEvent) &#123;        onApplicationFailedEvent();    &#125;&#125;\n\nApplicationStartingEvent 阶段的处理在收到 ApplicationStartingEvent 事件时，SpringBoot 将通过当前应用的 classloader 来构建一个 loggingSystem 对象，然后执行初始化之前的一些准备工作。\n123456private void onApplicationStartingEvent(ApplicationStartingEvent event) &#123;    // 通过当前应用的 classloader 构建 loggingSystem 对象    this.loggingSystem = LoggingSystem.get(event.getSpringApplication().getClassLoader());    // loggingSystem 初始化之前准备    this.loggingSystem.beforeInitialize();&#125;\n\n这里可以来看下 loggingSystem 是如何被构建出来的，这个过程可以使得我们非常清楚的了解到，为什么通过引入日志框架依赖或者使用 org.springframework.boot.logging.LoggingSystem 配置能够自动的完成日志框架的选择。\n123456789101112131415161718public static LoggingSystem get(ClassLoader classLoader) &#123;    // SYSTEM_PROPERTY=org.springframework.boot.logging.LoggingSystem    // 这里先从系统变量中获取下 org.springframework.boot.logging.LoggingSystem，看下是否用户自己指定了 LoggingSystem 的类型    String loggingSystem = System.getProperty(SYSTEM_PROPERTY);    // 如果 org.springframework.boot.logging.LoggingSystem=xx 有配置值     if (StringUtils.hasLength(loggingSystem)) &#123;        // 是否配置的是 none        if (NONE.equals(loggingSystem)) &#123;            // 如果配置的是 none ，则返回 NoOpLoggingSystem            return new NoOpLoggingSystem();        &#125;        // 根据指定的日志类型通过反射创建 loggingSystem 对象        return get(classLoader, loggingSystem);    &#125;    return SYSTEMS.entrySet().stream().filter((entry) -&gt; ClassUtils.isPresent(entry.getKey(), classLoader))            .map((entry) -&gt; get(classLoader, entry.getValue())).findFirst()            .orElseThrow(() -&gt; new IllegalStateException(&quot;No suitable logging system located&quot;));&#125;\n上面代码的最后基于 SYSTEMS 一个 Map 结构的数据进行一系列的处理，主要就是通过判断 entry.getKey() 是否在当前 classpath 中存在，如果存在则通过反射构建类型为 entry.getValue() 的对象；SYSTEMS 是 LoggingSystem 抽象类中的一个静态的 MAP 结构变量，其初始化是在静态代码块中完成的：\n1234567891011static &#123;    Map&lt;String, String&gt; systems = new LinkedHashMap&lt;&gt;();    // 添加 logback 的 LoggingSystem    systems.put(&quot;ch.qos.logback.core.Appender&quot;, &quot;org.springframework.boot.logging.logback.LogbackLoggingSystem&quot;);、     // 添加 log4j2 的 LoggingSystem    systems.put(&quot;org.apache.logging.log4j.core.impl.Log4jContextFactory&quot;,            &quot;org.springframework.boot.logging.log4j2.Log4J2LoggingSystem&quot;);    // 添加 JUL 的 LoggingSystem    systems.put(&quot;java.util.logging.LogManager&quot;, &quot;org.springframework.boot.logging.java.JavaLoggingSystem&quot;);    SYSTEMS = Collections.unmodifiableMap(systems);&#125;\n这样看来就比较清晰，如果当前 classpath 中存在 logback、log4j2 或者 JUL 的依赖，则就构建对应的 LoggingSystem 对象。LoggingSystem 对象构建之后还会调用 beforeInitialize 方法，假设引入的是 log4j2 的依赖，则最后构建的 LoggingSystem 就是 Log4J2LoggingSystem 。beforeInitialize 是 LoggingSystem 提供的抽象方法，其具体实现是由子类实现。下面在源码分析部分会展开分析。\nApplicationEnvironmentPreparedEvent 阶段的处理接收到 ApplicationEnvironmentPreparedEvent 事件说明 Environment 对象已经构建完成，环境变量都已经初始化完成了。所以这里主要的工作就是初始化日志框架。\n123456789101112131415161718192021222324252627private void onApplicationEnvironmentPreparedEvent(ApplicationEnvironmentPreparedEvent event) &#123;    // 这里会再 check 一次loggingSystem 是否已经被创建    if (this.loggingSystem == null) &#123;        this.loggingSystem = LoggingSystem.get(event.getSpringApplication().getClassLoader());    &#125;    // 通过环境和类路径表达的首选项初始化日志系统。    initialize(event.getEnvironment(), event.getSpringApplication().getClassLoader());&#125;// initializeprotected void initialize(ConfigurableEnvironment environment, ClassLoader classLoader) &#123;    // Spring 环境转移到系统属性    new LoggingSystemProperties(environment).apply();    // 解析得到 logFile，依赖 logging.file 和 loggin.path 两个配置值    this.logFile = LogFile.get(environment);    if (this.logFile != null) &#123;        //设置logging.file-&gt;LOG_FILE        // loggin.path -&gt; LOG_PATH        this.logFile.applyToSystemProperties();    &#125;    initializeEarlyLoggingLevel(environment);    // 根据 log 的配置文件初始化 日志    initializeSystem(environment, this.loggingSystem, this.logFile);    // 绑定 logging.group , 设置 logging.level    initializeFinalLoggingLevels(environment, this.loggingSystem);    // 注册 logging.register-shutdown-hook 配置的 钩子    registerShutdownHookIfNecessary(environment, this.loggingSystem);&#125;\n这个阶段就是根据我们配置的日志相关的属性和配置文件对日志进行一系列的初始化工作，这里所涉及到的属性和配置在文章前面部分均有提及到。\nApplicationPreparedEvent 阶段的处理接收到 ApplicationPreparedEvent 事件表示应用程序已经准备好，这里会注册两个 bean ， 一个是 springBootLoggingSystem，一个是 pringBootLogFile 。\n1234567891011private void onApplicationPreparedEvent(ApplicationPreparedEvent event) &#123;    ConfigurableListableBeanFactory beanFactory = event.getApplicationContext().getBeanFactory();    // 注册 springBootLoggingSystem bean     if (!beanFactory.containsBean(LOGGING_SYSTEM_BEAN_NAME)) &#123;        beanFactory.registerSingleton(LOGGING_SYSTEM_BEAN_NAME, this.loggingSystem);    &#125;    // 注册 pringBootLogFile bean    if (this.logFile != null &amp;&amp; !beanFactory.containsBean(LOGFILE_BEAN_NAME)) &#123;        beanFactory.registerSingleton(LOGFILE_BEAN_NAME, this.logFile);    &#125;&#125;\n\nContextClosedEvent 和 ApplicationFailedEventContextClosedEvent 事件是 Spring 容器关闭时发送的事件，这里主要就是在 Spring 容器关闭时对日志系统做的一些清理操作；ApplicationFailedEvent 是应用启动失败发送的事件，这里也会对日志系统做清理操作。清理方法由各个子 LoggingSystem 提供具体的实现，以 log4j2 为例，log4j2 的清理主要包括注销桥接处理器（前面初始化阶段有提到）、LogContext 置为null、移除 FILTER，基本上就是初始化阶段的逆过程。\nLoggingSystem 分析LoggingSystem 是 SpringBoot 对日志框架进行的一层抽象封装，LoggingSystem 使得我们可以很方便地使用一些日志框架，只需要定义对应日志框架的配置文件，比如 Logback、Log4j、Log4j2 等，代码内部便可以直接使用。\n\n上图为 LoggingSystem 的类继承结构，可以看到 LoggingSystem 的实现子类有 Logback（LogbackLoggingSystem）、Log4j2（Log4J2LoggingSystem）以及 JDK 内置的 Log (JavaLoggingSystem)。LoggingSystem 是个抽象类，内部有这几个方法：\n\nbeforeInitialize：日志系统初始化之前需要处理的事情\ninitialize：初始化日志系统\ncleanUp：日志系统的清除工作\ngetShutdownHandler：返回一个 Runnable 用于当 jvm 退出的时候处理日志系统关闭后需要进行的操作，默认返回 null\nsetLogLevel：设置 logger 的级别\n\n这几个方法在上面分析启动入口和日志初始化时都有看到，上述几个方法在 LoggingSystem 要么是抽象方法，要么是空实现，均需要有具体的子类来完成的具体日志框架的处理。从类继承结构图看到有一个 AbstractLoggingSystem，日志实现子类都是继承自这个类，而这个类也是一个抽象类，它又是 LoggingSystem 的子类。所以下面就分别看下 AbstractLoggingSystem 和 Log4J2LoggingSystem 两个类是怎么重写上述几个方法的，这也是 SpringBoot 中日志框架处理的核心逻辑。\nAbstractLoggingSystem 处理逻辑beforeInitialize 在 AbstractLoggingSystem 中没有具体的处理逻辑，是个空方法，所以主要是看下 initialize 这个方法.\n12345678910111213141516171819202122232425262728293031323334353637383940@Overridepublic void initialize(LoggingInitializationContext initializationContext, String configLocation, LogFile logFile) &#123;    // 如果指定了日志配置文件，则通过此配置文件进行初始化    if (StringUtils.hasLength(configLocation)) &#123;        initializeWithSpecificConfig(initializationContext, configLocation, logFile);        return;    &#125;    // 没有指定配置文件，则使用默认的方式查找配置文件并加载    initializeWithConventions(initializationContext, logFile);&#125;// 通过指定的配置文件初始化private void initializeWithSpecificConfig(LoggingInitializationContext initializationContext, String configLocation,\t\t\tLogFile logFile) &#123;    // 这里会处理日志配置文件中的占位符    configLocation = SystemPropertyUtils.resolvePlaceholders(configLocation);    // 抽象方法，由具体子类实现（不同的日志框架处理配置文件的方式由其自身决定）    loadConfiguration(initializationContext, configLocation, logFile);&#125;// 通过默认方式查找配置文件并初始化private void initializeWithConventions(LoggingInitializationContext initializationContext, LogFile logFile) &#123;    // 查找配置文件，以 log4j2 为例，默认会在 classpath 下查找文件名为     // log4j2.properties、log4j2.yaml, log4j2.yml、log4j2.json，log4j2.jsn，log4j2.xml 的文件    String config = getSelfInitializationConfig();    if (config != null &amp;&amp; logFile == null) &#123;        // 发生了自初始化，在属性发生变化时重新初始化        reinitialize(initializationContext);        return;    &#125;    if (config == null) &#123;        // 查找 Spring 规则方式的配置，        // log4j2-spring.properties、log4j2-spring.xml 等        config = getSpringInitializationConfig();    &#125;    if (config != null) &#123;        loadConfiguration(initializationContext, config, logFile);        return;    &#125;    // 抽象方法，由具体的日志系统实现    loadDefaults(initializationContext, logFile);&#125;\n\ninitialize 里主要就是找配置文件，然后通过配置文件进行日志系统的初始化，如果找不到就使用日志系统提供的默认方式进行初始化。上面代码中关于如何 load 配置文件和 load 默认都是在子类中实现的。所以下面就看下在 log4j2 的情况下，是怎么玩的。\nLog4J2LoggingSystem 处理逻辑Log4J2LoggingSystem 并非是 AbstractLoggingSystem 的直接子类，而是 Slf4JLoggingSystem 的直接子类，Slf4JLoggingSystem 这个抽象类从代码来看其实就是为了做一些桥接处理，这里不展开分析。\nbeforeInitialize 在 Log4J2LoggingSystem 中的实现12345678910111213@Overridepublic void beforeInitialize() &#123;    // 创建、获取 LoggerContext 对象    LoggerContext loggerContext = getLoggerContext();    // 判断当前 LoggerContext 是否已经初始化过了，如果已经初始化过了则直接返回    if (isAlreadyInitialized(loggerContext)) &#123;        return;    &#125;    // 调用父类 Slf4JLoggingSystem 的 beforeInitialize 的方法，父类这个方法主要就是配置JDK Logging 的桥接处理器    super.beforeInitialize();    // 给 loggerContext 添加默认的 FILTER    loggerContext.getConfiguration().addFilter(FILTER);&#125;\n\n\n\n\n\n\n\n\n\n\ngetLoggerContext 是 log4j2 自己构建 LoggerContext 的过程，此处就先 pass。\ninitialize 在 Log4J2LoggingSystem 中的实现123456789101112131415@Overridepublic void initialize(LoggingInitializationContext initializationContext, String configLocation, LogFile logFile) &#123;    // 拿到当前 loggerContext    LoggerContext loggerContext = getLoggerContext();    // 判断下是否已经初始化过了    if (isAlreadyInitialized(loggerContext)) &#123;        return;    &#125;    // 移除默认的 FILTER    loggerContext.getConfiguration().removeFilter(FILTER);    // 调用父类 initialize，就是在找日志配置文件并且初始化    super.initialize(initializationContext, configLocation, logFile);    // 标记已经完成初始化    markAsInitialized(loggerContext);&#125;\n这里核心 initialize方法 还是使用的父类的处理逻辑，前面也提到 initialize 在 AbstractLoggingSystem 中最核心的是 load 配置配置文件的过程（loadConfiguration&#x2F;loadDefaults），而这个 load 的过程是子类实现的。所以下面就看下 log4j2 中 load 配置文件的过程。\n\nloadConfiguration：有配置文件的情况\n\n1234567891011121314151617protected void loadConfiguration(String location, LogFile logFile) &#123;    Assert.notNull(location, &quot;Location must not be null&quot;);    try &#123;        LoggerContext ctx = getLoggerContext();        // 拿到资源url        URL url = ResourceUtils.getURL(location);        // 构建 ConfigurationSource 对象        ConfigurationSource source = getConfigurationSource(url);        // 这里会根据配置的类型选择不同的解析器来解析配置文件,比如        // XmlConfigurationFactory、PropertiesConfigurationFactory...        // 以指定的 configuration 启动        ctx.start(ConfigurationFactory.getInstance().getConfiguration(ctx, source));    &#125;    catch (Exception ex) &#123;        throw new IllegalStateException(&quot;Could not initialize Log4J2 logging from &quot; + location, ex);    &#125;&#125;\n\n简单概括：通过指定的配置文件地址构建 ConfigurationSource 配置资源对象，然后根据配置资源的文件类型选择不同的 ConfigurationFactory 来解析配置文件，最后日志框架根据此配置文件初始化日志系统。\n\nloadDefaults：没有配置文件的情况\n\n1234567891011@Overrideprotected void loadDefaults(LoggingInitializationContext initializationContext, LogFile logFile) &#123;    if (logFile != null) &#123;        // 使用 classpath:org/springframework/boot/logging/log4j2/log4j2-file.xml        loadConfiguration(getPackagedConfigFile(&quot;log4j2-file.xml&quot;), logFile);    &#125;    else &#123;        // 使用 classpath:org/springframework/boot/logging/log4j2/log4j2.xml        loadConfiguration(getPackagedConfigFile(&quot;log4j2.xml&quot;), logFile);    &#125;&#125;\n简单概括：在没有指定日志配置文件或者没有在 classpath 下找到符合指定日志系统的配置文件时，则使用 SpringBoot 提供的默认的配置文件进行初始化。\n日志系统的清理逻辑cleanUp 方法也是由具体的 LoggingSystem 实现，主要作用就是清理 LoggingSystem 资源。\n12345678910@Overridepublic void cleanUp() &#123;    // 调用父类，移除桥接器    super.cleanUp();    LoggerContext loggerContext = getLoggerContext();    // 标记loggerContext为未初始化状态，并将内部的 externalContext 置为 null    markAsUninitialized(loggerContext);    // 移除默认的 FILTER    loggerContext.getConfiguration().removeFilter(FILTER);&#125;\n一些场景分析这里面包括日常开发工作中使用日志的一些常见场景，比如项目中没有任何日志配置的情况、在 resources 目录下配置日志配置文件的情况、已经使用 SpringBoot 无法识别的日志篇日志文件的情况。\n没有任何配置文件没有任何配置，通过前面的分析可知，initialize 方法执行时，是找不到任何资源的，所以会走默认的 loadDefaults 方法进行加载，LogbackLoggingSystem 的loadDefaults 方法，由于 logFile 为 null，所以会使用 classpath:org/springframework/boot/logging/log4j2/log4j2.xml 这份配置文件:\n123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot;&gt;\t&lt;Properties&gt;\t\t&lt;Property name=&quot;PID&quot;&gt;????&lt;/Property&gt;\t\t&lt;Property name=&quot;LOG_EXCEPTION_CONVERSION_WORD&quot;&gt;%xwEx&lt;/Property&gt;\t\t&lt;Property name=&quot;LOG_LEVEL_PATTERN&quot;&gt;%5p&lt;/Property&gt;\t\t&lt;Property name=&quot;LOG_DATEFORMAT_PATTERN&quot;&gt;yyyy-MM-dd HH:mm:ss.SSS&lt;/Property&gt;\t\t&lt;Property name=&quot;CONSOLE_LOG_PATTERN&quot;&gt;%clr&#123;%d&#123;$&#123;LOG_DATEFORMAT_PATTERN&#125;&#125;&#125;&#123;faint&#125; %clr&#123;$&#123;LOG_LEVEL_PATTERN&#125;&#125; %clr&#123;$&#123;sys:PID&#125;&#125;&#123;magenta&#125; %clr&#123;---&#125;&#123;faint&#125; %clr&#123;[%15.15t]&#125;&#123;faint&#125; %clr&#123;%-40.40c&#123;1.&#125;&#125;&#123;cyan&#125; %clr&#123;:&#125;&#123;faint&#125; %m%n$&#123;sys:LOG_EXCEPTION_CONVERSION_WORD&#125;&lt;/Property&gt;\t\t&lt;Property name=&quot;FILE_LOG_PATTERN&quot;&gt;%d&#123;$&#123;LOG_DATEFORMAT_PATTERN&#125;&#125; $&#123;LOG_LEVEL_PATTERN&#125; $&#123;sys:PID&#125; --- [%t] %-40.40c&#123;1.&#125; : %m%n$&#123;sys:LOG_EXCEPTION_CONVERSION_WORD&#125;&lt;/Property&gt;\t&lt;/Properties&gt;\t&lt;Appenders&gt;        // 打在控制台\t\t&lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot; follow=&quot;true&quot;&gt;\t\t\t&lt;PatternLayout pattern=&quot;$&#123;sys:CONSOLE_LOG_PATTERN&#125;&quot; /&gt;\t\t&lt;/Console&gt;\t&lt;/Appenders&gt;\t&lt;Loggers&gt;\t\t&lt;Logger name=&quot;org.apache.catalina.startup.DigesterFactory&quot; level=&quot;error&quot; /&gt;\t\t&lt;Logger name=&quot;org.apache.catalina.util.LifecycleBase&quot; level=&quot;error&quot; /&gt;\t\t&lt;Logger name=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; level=&quot;warn&quot; /&gt;\t\t&lt;logger name=&quot;org.apache.sshd.common.util.SecurityUtils&quot; level=&quot;warn&quot;/&gt;\t\t&lt;Logger name=&quot;org.apache.tomcat.util.net.NioSelectorPool&quot; level=&quot;warn&quot; /&gt;\t\t&lt;Logger name=&quot;org.eclipse.jetty.util.component.AbstractLifeCycle&quot; level=&quot;error&quot; /&gt;\t\t&lt;Logger name=&quot;org.hibernate.validator.internal.util.Version&quot; level=&quot;warn&quot; /&gt;\t\t&lt;logger name=&quot;org.springframework.boot.actuate.endpoint.jmx&quot; level=&quot;warn&quot;/&gt;\t\t&lt;Root level=&quot;info&quot;&gt;\t\t\t&lt;AppenderRef ref=&quot;Console&quot; /&gt;\t\t&lt;/Root&gt;\t&lt;/Loggers&gt;&lt;/Configuration&gt;\n这份配置文件中值有一个  Appender，就是默认的 Console，所以没有配置任何日志配置文件时，日志会被打在控制台。\n在 resources 目录下配置 log4j2.xml这份配置文件是能够被 SpringBoot 识别的，所以在初始化日志时会使用此份配置文件来进行日志系统的初始化。下面这份配置文件为每种日志级别都配置了一个 appender，所以在使用时，会根据日志级别将日志打在不同的日志目录下。（PS:关于能够识别的日志配置文件参考前面的分析）\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration status=&quot;OFF&quot;&gt;    &lt;Properties&gt;        &lt;Property name=&quot;logging.path&quot;&gt;./logs&lt;/Property&gt;    &lt;/Properties&gt;    &lt;appenders&gt;        &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt;            &lt;!--只接受程序中 INFO 级别的日志进行处理 --&gt;            &lt;ThresholdFilter level=&quot;INFO&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot; /&gt;            &lt;PatternLayout pattern=&quot;[%d&#123;HH:mm:ss.SSS&#125;] %-5level %class&#123;36&#125; %L %M - %msg%xEx%n&quot; /&gt;        &lt;/Console&gt;        &lt;!--处理DEBUG级别的日志，并把该日志放到logs/debug.log文件中--&gt;        &lt;!--打印出DEBUG级别日志，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档--&gt;        &lt;RollingFile name=&quot;RollingFileDebug&quot; fileName=&quot;$&#123;logging.path&#125;/debug.log&quot;                     filePattern=&quot;logs/$$&#123;date:yyyy-MM&#125;/debug-%d&#123;yyyy-MM-dd&#125;-%i.log.gz&quot;&gt;            &lt;Filters&gt;                &lt;ThresholdFilter level=&quot;DEBUG&quot;/&gt;                &lt;ThresholdFilter level=&quot;INFO&quot; onMatch=&quot;DENY&quot; onMismatch=&quot;NEUTRAL&quot;/&gt;            &lt;/Filters&gt;            &lt;PatternLayout                    pattern=&quot;[%d&#123;yyyy-MM-dd HH:mm:ss&#125;] %-5level %class&#123;36&#125; %L %M - %msg%xEx%n&quot;/&gt;            &lt;Policies&gt;                &lt;SizeBasedTriggeringPolicy size=&quot;500 MB&quot;/&gt;                &lt;TimeBasedTriggeringPolicy/&gt;            &lt;/Policies&gt;        &lt;/RollingFile&gt;        &lt;!--处理INFO级别的日志，并把该日志放到logs/info.log文件中--&gt;        &lt;RollingFile name=&quot;RollingFileInfo&quot; fileName=&quot;$&#123;logging.path&#125;/info.log&quot;                     filePattern=&quot;logs/$$&#123;date:yyyy-MM&#125;/info-%d&#123;yyyy-MM-dd&#125;-%i.log.gz&quot;&gt;            &lt;Filters&gt;                &lt;!--只接受INFO级别的日志，其余的全部拒绝处理--&gt;                &lt;ThresholdFilter level=&quot;INFO&quot;/&gt;                &lt;ThresholdFilter level=&quot;WARN&quot; onMatch=&quot;DENY&quot; onMismatch=&quot;NEUTRAL&quot;/&gt;            &lt;/Filters&gt;            &lt;PatternLayout                    pattern=&quot;[%d&#123;yyyy-MM-dd HH:mm:ss&#125;] %-5level %class&#123;36&#125; %L %M - %msg%xEx%n&quot;/&gt;            &lt;Policies&gt;                &lt;SizeBasedTriggeringPolicy size=&quot;500 MB&quot;/&gt;                &lt;TimeBasedTriggeringPolicy/&gt;            &lt;/Policies&gt;        &lt;/RollingFile&gt;        &lt;!--处理WARN级别的日志，并把该日志放到logs/warn.log文件中--&gt;        &lt;RollingFile name=&quot;RollingFileWarn&quot; fileName=&quot;$&#123;logging.path&#125;/warn.log&quot;                     filePattern=&quot;logs/$$&#123;date:yyyy-MM&#125;/warn-%d&#123;yyyy-MM-dd&#125;-%i.log.gz&quot;&gt;            &lt;Filters&gt;                &lt;ThresholdFilter level=&quot;WARN&quot;/&gt;                &lt;ThresholdFilter level=&quot;ERROR&quot; onMatch=&quot;DENY&quot; onMismatch=&quot;NEUTRAL&quot;/&gt;            &lt;/Filters&gt;            &lt;PatternLayout                    pattern=&quot;[%d&#123;yyyy-MM-dd HH:mm:ss&#125;] %-5level %class&#123;36&#125; %L %M - %msg%xEx%n&quot;/&gt;            &lt;Policies&gt;                &lt;SizeBasedTriggeringPolicy size=&quot;500 MB&quot;/&gt;                &lt;TimeBasedTriggeringPolicy/&gt;            &lt;/Policies&gt;        &lt;/RollingFile&gt;        &lt;!--处理error级别的日志，并把该日志放到logs/error.log文件中--&gt;        &lt;RollingFile name=&quot;RollingFileError&quot; fileName=&quot;$&#123;logging.path&#125;/error.log&quot;                     filePattern=&quot;logs/$$&#123;date:yyyy-MM&#125;/error-%d&#123;yyyy-MM-dd&#125;-%i.log.gz&quot;&gt;            &lt;ThresholdFilter level=&quot;ERROR&quot;/&gt;            &lt;PatternLayout                    pattern=&quot;[%d&#123;yyyy-MM-dd HH:mm:ss&#125;] %-5level %class&#123;36&#125; %L %M - %msg%xEx%n&quot;/&gt;            &lt;Policies&gt;                &lt;SizeBasedTriggeringPolicy size=&quot;500 MB&quot;/&gt;                &lt;TimeBasedTriggeringPolicy/&gt;            &lt;/Policies&gt;        &lt;/RollingFile&gt;    &lt;/appenders&gt;    &lt;loggers&gt;        &lt;root level=&quot;DEBUG&quot;&gt;            &lt;appender-ref ref=&quot;Console&quot;/&gt;            &lt;appender-ref ref=&quot;RollingFileInfo&quot;/&gt;            &lt;appender-ref ref=&quot;RollingFileWarn&quot;/&gt;            &lt;appender-ref ref=&quot;RollingFileError&quot;/&gt;            &lt;appender-ref ref=&quot;RollingFileDebug&quot;/&gt;        &lt;/root&gt;        &lt;!--log4j2 自带过滤日志--&gt;        &lt;Logger name=&quot;org.apache.catalina.startup.DigesterFactory&quot; level=&quot;error&quot; /&gt;        &lt;Logger name=&quot;org.apache.catalina.util.LifecycleBase&quot; level=&quot;error&quot; /&gt;        &lt;Logger name=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; level=&quot;warn&quot; /&gt;        &lt;logger name=&quot;org.apache.sshd.common.util.SecurityUtils&quot; level=&quot;warn&quot;/&gt;        &lt;Logger name=&quot;org.apache.tomcat.util.net.NioSelectorPool&quot; level=&quot;warn&quot; /&gt;        &lt;Logger name=&quot;org.crsh.plugin&quot; level=&quot;warn&quot; /&gt;        &lt;logger name=&quot;org.crsh.ssh&quot; level=&quot;warn&quot;/&gt;        &lt;Logger name=&quot;org.eclipse.jetty.util.component.AbstractLifeCycle&quot; level=&quot;error&quot; /&gt;        &lt;Logger name=&quot;org.hibernate.validator.internal.util.Version&quot; level=&quot;warn&quot; /&gt;        &lt;logger name=&quot;org.thymeleaf&quot; level=&quot;warn&quot;/&gt;        &lt;Logger name=&quot;org.springframework&quot; level=&quot;warn&quot;/&gt;    &lt;/loggers&gt;&lt;/configuration&gt;\n\n在 resources 下配置一个 log4j2-glmapper.xml将上面的配置文件重命名为 log4j2-glmapper.xml ，因为这个命名规则是 SpringBoot 无法默认识别的，所以在日志配置文件加载时和场景一是一样的。如果希望这份配置文件能够被识别，可以使用 logging.config 来指定。\n1logging.config=classpath:log4j2-glmapper.xml\n小结本篇对 SpringBoot 中的日志进行了系统的介绍和分析，文章主要是了解 SpringBoot 中对于日志系统的处理，所以不会太关注日志系统自身的一些处理逻辑，有兴趣的读者可以自行研究或者联系作者一起沟通。\n","slug":"springboot/springboot-series-log","date":"2019-12-14T09:18:07.000Z","categories_index":"SpringBoot","tags_index":"log,SpringBoot","author_index":"glmapper"},{"id":"5f271418dba5b05b4849df36b7771e2b","title":"SpringBoot 实践系列-资源访问","content":"简介当我们创建一个 SpringBoot web 应用时，有时候需要从 classpath 去加载一些文件，这里记录下在 war 和 jar 两种不同文件格式下加载文件的解决方案\n\nThe ResourceLoader在 Java 中 ，我们可以使用当前线程的 classLoader 去尝试加载文件，但是 Spring Framework 为我们提供了更加优雅的解决方案，例如 ResourceLoader。\n使用 ResourceLoader 时，我们只需要使用 @Autowire 自动注入 ResourceLoader，然后调用 getResource(“somePath”) 方法即可。\n在Spring Boot（WAR）中从资源目录&#x2F;类路径加载文件的示例12345678910111213141516171819202122232425262728293031323334353637@Service(&quot;geolocationservice&quot;)public class GeoLocationServiceImpl implements GeoLocationService &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(GeoLocationServiceImpl.class);    private static DatabaseReader reader = null;    private ResourceLoader resourceLoader;    @Autowired    public GeoLocationServiceImpl(ResourceLoader resourceLoader) &#123;        this.resourceLoader = resourceLoader;    &#125;    @PostConstruct    public void init() &#123;        try &#123;            LOGGER.info(&quot;GeoLocationServiceImpl: Trying to load GeoLite2-Country database...&quot;);            Resource resource = resourceLoader.getResource(&quot;classpath:GeoLite2-Country.mmdb&quot;);            File dbAsFile = resource.getFile();            // Initialize the reader            reader = new DatabaseReader                        .Builder(dbAsFile)                        .fileMode(Reader.FileMode.MEMORY)                        .build();            LOGGER.info(&quot;GeoLocationServiceImpl: Database was loaded successfully.&quot;);        &#125; catch (IOException | NullPointerException e) &#123;            LOGGER.error(&quot;Database reader cound not be initialized. &quot;, e);        &#125;    &#125;    @PreDestroy    public void preDestroy() &#123;        if (reader != null) &#123;            try &#123;                reader.close();            &#125; catch (IOException e) &#123;                LOGGER.error(&quot;Failed to close the reader.&quot;);            &#125;        &#125;    &#125;&#125;\n\n从 SpringBoot FatJar 中加载资源如果我们想从 Spring Boot JAR 中的类路径加载文件，则必须使用 resource.getInputStream() 方法将其作为 InputStream 检索。 如果尝试使用resource.getFile()，则会收到错误消息，因为 Spring 尝试访问文件系统路径，但它无法访问 JAR 中的路径。\n123456789101112131415161718192021222324252627282930313233343536373839@Service(&quot;geolocationservice&quot;)public class GeoLocationServiceImpl implements GeoLocationService &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(GeoLocationServiceImpl.class);    private static DatabaseReader reader = null;    private ResourceLoader resourceLoader;    @Inject    public GeoLocationServiceImpl(ResourceLoader resourceLoader) &#123;        this.resourceLoader = resourceLoader;    &#125;    @PostConstruct    public void init() &#123;        try &#123;            LOGGER.info(&quot;GeoLocationServiceImpl: Trying to load GeoLite2-Country database...&quot;);            Resource resource = resourceLoader.getResource(&quot;classpath:GeoLite2-Country.mmdb&quot;);            InputStream dbAsStream = resource.getInputStream(); // &lt;-- this is the difference            // Initialize the reader            reader = new DatabaseReader                        .Builder(dbAsStream)                        .fileMode(Reader.FileMode.MEMORY)                        .build();            LOGGER.info(&quot;GeoLocationServiceImpl: Database was loaded successfully.&quot;);        &#125; catch (IOException | NullPointerException e) &#123;            LOGGER.error(&quot;Database reader cound not be initialized. &quot;, e);        &#125;    &#125;    @PreDestroy    public void preDestroy() &#123;        if (reader != null) &#123;            try &#123;                reader.close();            &#125; catch (IOException e) &#123;                LOGGER.error(&quot;Failed to close the reader.&quot;);            &#125;        &#125;    &#125;&#125;","slug":"springboot/springboot-series-access-resource","date":"2019-12-09T09:38:26.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,ResourceLoader","author_index":"glmapper"},{"id":"fb1d63795354398f9ac651e5b767f565","title":"SpringBoot 源码系列-启动过程分析","content":"SpringBoot 作为目前非常流行的微服务框架，它使得构建独立的 Spring 生产级应用变得非常简单，因此受到很多互联网企业的青睐。\n最近在写 SOFATracer 集成 Spring Cloud Stream RocketMQ 的过程中，遇到了一些问题，比如：BeanPostProcessor 不生效，如何在 BeanPostProcessor 不生效的情况下去修改一个 Bean 等，这些问题其实都是和 Bean 的生命周期有关系的，当然也和容器启动的过程有关系。SpringBoot 的启动过程对于我来说其实不算陌生，也可以说是比较熟悉，但是之前没有完整的梳理过这一块的东西，在实际的应用过程成难免再去踩一些坑。另外想到之前也写过一篇 SpringBoot系列- FatJar 启动原理，刚好承接上篇，继续来探索 SpringBoot 中的一些知识点。\n\n\n\n\n\n\n\n\n\n\n\n注：本篇基于 SpringBoot 2.1.0.RELEASE 版本，SpringBoot 各个版本之间可能存在差异，不过大体流程基本差不多，所以各位看官在实际的工作过程中也\n从一份配置文件开始说起Spring 的启动过程实际上就是 Ioc 容器初始化以及载入 Bean 的过程；SpringBoot 的启动过程最核心的容器刷新流程也是复用了  Spring 容器刷新的逻辑。在分析 SpringBoot 启动过程之前，我们先来简单回顾下 Spring web 应用基于 tomcat 容器部署的启动过程。这就需要从一个大家都熟悉的配置文件开始说起：\n1234567&lt;listener&gt;       &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;  &lt;/listener&gt; &lt;context-param&gt;      &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;      &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;  &lt;/context-param&gt;\n\n在一般的传统 WEB 项目中，项目的启动一般是从 web.xml 文件的载入开始，如果我们的项目中使用了Spring，那么你肯定会在你的 web.xml 文件中看到上面的配置。Spring 正是通过 ContextLoaderListener 监听器作为容器初始化入口的。\nContextLoaderListener 继承了 ContextLoader 类和 ServletContextListener 接口，并且重写了 ServletContextListener 中的contextInitialized 和 contextDestroyed 方法。在 contextInitialized 中，通过调用父类（ContextLoader）的 initWebApplicationContext 方法进行容器创建：\n1234@Overridepublic void contextInitialized(ServletContextEvent event) &#123;    initWebApplicationContext(event.getServletContext());&#125;\n\n对于上述 Spring 容器引导刷新大概可以分为两个点来做简单的归纳：\n\n1、通过监听 ServletContextEvent 事件，为 web 容器提供一个全局的 ServletContext 上下文环境，并作为后面 spring 容器的宿主环境\n\n2、在 contextInitialized 方法被调用时，spring 开始初始化一个上下文，这个上下文被称为根上下文，也就是 WebApplicationContext（实际的实现类是 XmlWebApplicationContext ）。这个 WebApplicationContext 就是 spring 的 IoC 容器，其对应的 Bean 定义的配置文件由 web.xml 中的 context-param 指定。\n\n\n关于依赖监听 ServletContextEvent 事件来引导启动的过程大致可以描述为一下过程：\n\n相对于通过监听 ServletContextEvent 事件方式引导刷新 Spring 上下文，SpringBoot 给我的感觉是回归了 java 的本源，即通过 main 方法方式引导启动。由于 SpringBoot 中对于 web 容器也是使用了嵌入式+自动配置的方式，所以在启动入口上差异还是比较大的，当然 SpringBoot 除了支持 fatjar 方式之外，也提供了 war 包方式来保持对原有 Spring 工程的兼容。\n本篇文章将承接上一篇《SpringBoot FatJar 启动原理》，来分析下 SpringBoot 的启动过程。希望通过本篇文章，能够让大家了解到与传统基于 servlet 事件引导启动和基于 main 方式启动的不同，从而对 SpringBoot 的整体启动过程有比较清楚的认识。\n启动入口在这篇 SpringBoot系列- FatJar 启动原理  文章中介绍得到，JarLaunch 最后是构建了一个 MainMethodRunner 实例对象，然后通过反射的方式调用了 BootStrap 类中的 main 方法，这里的 ’BootStrap 类中的 main 方法‘ 实际上就是 SpringBoot 的业务入口，也就是常见的下面的代码片段：\n123456@SpringBootApplicationpublic class GlmapperApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(GlmapperApplication.class, args);    &#125;&#125;\n\n从代码可以非常直观的了解到，启动是通过调用 SpringApplication 的静态方法 run；这个 run 方法内部其实是会构造一个 SpringApplication 的实例，然后再调用这里实例的 run 方法来启动 SpringBoot 的。\n1234567891011/*** Static helper that can be used to run a &#123;@link SpringApplication&#125; from the* specified sources using default settings and user supplied arguments.* @param primarySources the primary sources to load* @param args the application arguments (usually passed from a Java main method)* @return the running &#123;@link ApplicationContext&#125;*/public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources,    String[] args) &#123;    return new SpringApplication(primarySources).run(args);&#125;\n\n因此，如果要分析 SpringBoot 的启动过程，我们需要熟悉 SpringApplication 的构造过程以及 SpringApplication 的 run 方法执行过程即可。\nSpringApplication 实例的构建篇幅原因，我们只分析核心的构建流程。\n12345678910111213141516public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123;    // 资源加载器，默认是 null    this.resourceLoader = resourceLoader;    // 启动类 bean     Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;);    this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));    // 是否是 web 应用    this.webApplicationType = WebApplicationType.deduceFromClasspath();    // 设置了 ApplicationContextInitializer    setInitializers((Collection) getSpringFactoriesInstances(            ApplicationContextInitializer.class));    // 设置 ApplicationListener    setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));    // 启动类    this.mainApplicationClass = deduceMainApplicationClass();&#125;\n\n上面代码段中，需要关注两个点：\n\n1、初始化 ApplicationContextInitializer；\n2、初始化 ApplicationListener\n\n要注意的是这里的实例化，并非是通过注解和扫包完成，而是通过一种不依赖 Spring 上下文的加载方法；这种做法是为了能够使得在 Spring 完成启动前做各种配置。Spring 的解决方法是以接口的全限定名作为 key，实现类的全限定名作为 value 记录在项目的 META-INF&#x2F;spring.factories 文件中，然后通过SpringFactoriesLoader 工具类提供静态方法进行类加载并缓存下来，spring.factories 是 SpringBoot 的核心配置文件。SpringFactoriesLoader 可以理解为 Spring 自己提供的一种 spi 扩展实现。SpringBoot 中提供的默认的 spring.factories 配置如下：\n123456789101112131415161718192021222324# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\\// ..省略# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\// ..省略# Error Reportersorg.springframework.boot.SpringBootExceptionReporter=\\// ..省略# Application Context Initializersorg.springframework.context.ApplicationContextInitializer=\\/// ..省略# Application Listenersorg.springframework.context.ApplicationListener=\\// ..省略# Environment Post Processorsorg.springframework.boot.env.EnvironmentPostProcessor=\\// ..省略# Failure Analyzersorg.springframework.boot.diagnostics.FailureAnalyzer=\\// ..省略# FailureAnalysisReportersorg.springframework.boot.diagnostics.FailureAnalysisReporter=\\// ..省略\n\n关于 SpringFactoriesLoader  如何加载这些资源这里就不过多分析，有兴趣的读者可以自行查看相关源码。org.springframework.core.io.support.SpringFactoriesLoader#loadSpringFactories\nrun 方法主流程SpringApplication 的 run 方法 SpringBoot 进行 Spring 容器刷新的实际入口方法，这个方法中包括了很多 SpringBoot 自己扩展出来的一些特性机制，比如 SpringApplicationRunListener、打印启动 Banner、统一的异常处理扩展等等。下面就直观的看下代码，然后再逐个分析各个流程的具体细节：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public ConfigurableApplicationContext run(String... args) &#123;    // 开启容器启动计时    StopWatch stopWatch = new StopWatch();    stopWatch.start();    ConfigurableApplicationContext context = null;    // SpringBootExceptionReporter 列表，SpringBoot 允许自定义 Reporter    Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;();    // 设置java.awt.headless属性为true还是false    // 可详见解释：https://blog.csdn.net/michaelgo/article/details/81634017    configureHeadlessProperty();    // 获取所有 SpringApplicationRunListener ，也是通过 SpringFactoriesLoader 来获取的    SpringApplicationRunListeners listeners = getRunListeners(args);    // 发布 starting 事件，在首次启动 run方法时立即调用，可用于非常早的初始化，注意此时容器上下文还没有刷新    listeners.starting();    try &#123;        // 构建 ApplicationArguments 对象        ApplicationArguments applicationArguments = new DefaultApplicationArguments(                args);        // 准备上下文刷新需要的环境属性 -- 详见 prepareEnvironment 过程分析        ConfigurableEnvironment environment = prepareEnvironment(listeners,                applicationArguments);        // spring.beaninfo.ignore，如果为空设置为true        configureIgnoreBeanInfo(environment);        // 打印 SpringBoot 启动 Banner        Banner printedBanner = printBanner(environment);        // 创建上下文，这里会根据 webApplicationType 类型来创建不同的 ApplicationContext        context = createApplicationContext();        // 加载获取 exceptionReporters        exceptionReporters = getSpringFactoriesInstances(                SpringBootExceptionReporter.class,                new Class[] &#123; ConfigurableApplicationContext.class &#125;, context);        // 上下文刷新之前的准备工作 -- 详见 prepareContext 过程分析        prepareContext(context, environment, listeners, applicationArguments,                printedBanner);        // 刷新上下文 -- 详见 refreshContext 过程分析        refreshContext(context);        // 刷新之后回调，SpringBoot 中这个方法是空实现，可以自行扩展        afterRefresh(context, applicationArguments);        // 停止计时        stopWatch.stop();        if (this.logStartupInfo) &#123;            new StartupInfoLogger(this.mainApplicationClass)                    .logStarted(getApplicationLog(), stopWatch);        &#125;        // 发布 started 事件         listeners.started(context);        // ApplicationRunner 和 CommandLineRunner 调用        callRunners(context, applicationArguments);    &#125;    catch (Throwable ex) &#123;        // 异常处理        handleRunFailure(context, ex, exceptionReporters, listeners);        throw new IllegalStateException(ex);    &#125;    try &#123;        // 发布 running 事件         listeners.running(context);    &#125;    catch (Throwable ex) &#123;        // 异常处理        handleRunFailure(context, ex, exceptionReporters, null);        throw new IllegalStateException(ex);    &#125;    return context;&#125;\n\n上面对代码基本都做了一些详细的注释，有几个需要关注的点：\n\n1、prepareEnvironment 的处理过程\n2、prepareContext 的处理过程\n3、refreshContext 的处理过程\n4、listeners 执行时机及顺序\n5、异常处理逻辑\n\n关于 Listeners 执行时机及顺序在之前的文章中有做过非常详细的分析，详见：SpringBoot 系列-事件机制详解。下面就对其他的 4 个点做下详细的分析。\n\n\n\n\n\n\n\n\n\n分析启动过程，本质上是对其整个容器生命周期有个了解，包括 listeners 执行各个事件的时机、PostProcessor 执行的时机，Enviroment Ready 的时机等等。掌握这些扩展和时机，可以在实际的业务开发中来做很多事情。\nprepareEnvironment 的处理过程prepareEnvironment 过程相对来说是比较早的，这里主要就是为上下文刷新提供 Environment。\n123456789101112131415161718192021private ConfigurableEnvironment prepareEnvironment(\t\t\tSpringApplicationRunListeners listeners,\t\t\tApplicationArguments applicationArguments) &#123;    // Create and configure the environment    ConfigurableEnvironment environment = getOrCreateEnvironment();    // 配置 PropertySources 和 Profiles    // 1、将参数和一些默认的属性配置到 environment    // 2、激活 profiles     configureEnvironment(environment, applicationArguments.getSourceArgs());    // 发布 ApplicationEnvironmentPreparedEvent 事件    listeners.environmentPrepared(environment);    // 绑定 SpringApplication 环境    bindToSpringApplication(environment);    if (!this.isCustomEnvironment) &#123;        environment = new EnvironmentConverter(getClassLoader())                .convertEnvironmentIfNecessary(environment, deduceEnvironmentClass());    &#125;    // 附加的解析器将动态跟踪底层 Environment 属性源的任何添加或删除    ConfigurationPropertySources.attach(environment);    return environment;&#125;\n这里面做的事情就是将我们的配置，包括系统配置、application.properties、-D 参数等等统统打包给 environment。在 Spring 中，我们最常见的 xml 中使用的 ${xxx} 或者代码中使用的 @Value(“${xxxx}”) 等，最后都是从 environment 中拿值的。\n这里需要关注的一个比较重要的点是发布 ApplicationEnvironmentPreparedEvent 事件，我们可以通过监听这个事件来修改 environment。这里可以参考下 SOFATracer 中 SofaTracerConfigurationListener 是如何利用这个事件来做环境配置处理的。\nprepareContext 的处理过程prepareContext 的处理过程中可以利用的点是非常多的，比如 ApplicationContextInitializer 的执行、ApplicationContextInitializedEvent 和 ApplicationPreparedEvent 事件发布。\n123456789101112131415161718192021222324252627282930313233private void prepareContext(ConfigurableApplicationContext context,\t\t\tConfigurableEnvironment environment, SpringApplicationRunListeners listeners,\t\t\tApplicationArguments applicationArguments, Banner printedBanner) &#123;    // 设置 environment 给 context，所以需要注意的是，在此之前拿到的 context 中，environment 是没有的。    context.setEnvironment(environment);    // 对 ApplicationContext 的后置处理，比如注册 BeanNameGenerator 和 ResourceLoader    postProcessApplicationContext(context);    // 这里开始执行所有的 ApplicationContextInitializer    applyInitializers(context);    // 发布 ApplicationContextInitializedEvent 事件    listeners.contextPrepared(context);    if (this.logStartupInfo) &#123;        logStartupInfo(context.getParent() == null);        logStartupProfileInfo(context);    &#125;    // Add boot specific singleton beans    ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();    beanFactory.registerSingleton(&quot;springApplicationArguments&quot;, applicationArguments);    if (printedBanner != null) &#123;        beanFactory.registerSingleton(&quot;springBootBanner&quot;, printedBanner);    &#125;    if (beanFactory instanceof DefaultListableBeanFactory) &#123;        // 是否允许 bean 覆盖，这里如果是 false ,则可能会导致 BeanDefinitionOverrideException 异常        ((DefaultListableBeanFactory) beanFactory)                .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding);    &#125;    // Load the sources    Set&lt;Object&gt; sources = getAllSources();    Assert.notEmpty(sources, &quot;Sources must not be empty&quot;);    load(context, sources.toArray(new Object[0]));    // 发布 ApplicationPreparedEvent 事件    listeners.contextLoaded(context);&#125;\nApplicationContextInitializer 是 spring 容器刷新之前初始化 Spring ConfigurableApplicationContext 的回调接口，ApplicationContextInitializer 的 initialize 方法执行之前，context 是还没有刷新的。可以看到在 applyInitializers 之后紧接着发布了 ApplicationContextInitializedEvent 事件。其实这两个点都可以对 context 搞一些事情，ApplicationContextInitializer 更纯粹些，它只关注 context；而 ApplicationContextInitializedEvent 事件源中除了 context 之外，还有 springApplication 对象和参数 args。\nprepareContext 最后阶段是发布了 ApplicationPreparedEvent 事件，表示上下文已经准备好了，可以随时执行 refresh 了。\nrefreshContext 的处理过程refreshContext 是 Spring 上下文刷新的过程，这里实际调用的是 AbstractApplicationContext 的 refresh 方法；所以 SpringBoot 也是复用了 Spring 上下文刷新的过程。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Overridepublic void refresh() throws BeansException, IllegalStateException &#123;    // 加锁处理    synchronized (this.startupShutdownMonitor) &#123;        // 准备刷新此上下文。主要包括占位符的替换及验证所有的 properties        prepareRefresh();        // 这里做了很多事情：        // 1、让子类刷新内部beanFactory ，创建IoC容器（DefaultListableBeanFactory--ConfigurableListableBeanFactory 的实现类）        // 2、加载解析XML文件（最终存储到Document对象中）        // 3、读取Document对象，并完成BeanDefinition的加载和注册工作        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();        // 对 beanFactory 进行一些预处理（设置一些公共属性）        prepareBeanFactory(beanFactory);        try &#123;            // 允许在 AbstractApplicationContext的子类中对 BeanFactory 进行后置处理，postProcessBeanFactory()这个方法是个空实现。            postProcessBeanFactory(beanFactory);            // 调用 BeanFactoryPostProcessor 后置处理器处理 BeanFactory 实例（BeanDefinition）            invokeBeanFactoryPostProcessors(beanFactory);            // 注册BeanPostProcessor后置处理器，BeanPostProcessors后置处理器用于拦截bean的创建            // 用于对创建后的bean实例进行处理            registerBeanPostProcessors(beanFactory);            // 初始化消息资源            initMessageSource();            //  初始化应用事件广播器            initApplicationEventMulticaster();            // 初始化特殊的bean，这个方法是空实现，让AbstractApplicationContext的子类重写            onRefresh();            // 注册监听器（ApplicationListener）            registerListeners();            // 实例化剩余的单例bean（非懒加载方式）， Bean的 IoC、DI 和 AOP 都是发生在此步骤            finishBeanFactoryInitialization(beanFactory);            // 完成刷新            // 1、发布 ContextRefreshedEvent 事件            // 2、处理 LifecycleProcessor            finishRefresh();        &#125;        catch (BeansException ex) &#123;            if (logger.isWarnEnabled()) &#123;                logger.warn(&quot;Exception encountered during context initialization - &quot; +                        &quot;cancelling refresh attempt: &quot; + ex);            &#125;            // 销毁已经创建的单例以避免资源悬空。            destroyBeans();            // 重置 ”active“ 标记            cancelRefresh(ex);            throw ex;        &#125;        finally &#123;            // 重置Spring内核中的常用自检缓存，清空单例bean内缓存            resetCommonCaches();        &#125;    &#125;&#125;\n这个过程涉及到的东西非常多，可扩展的点也非常多，包括 BeanFactoryPostProcessor 处理、BeanPostProcessor 处理、LifecycleProcessor 处理已经 发布 ContextRefreshedEvent 事件等。到这里容器刷新已经完成，容器已经 ready，DI 和 AOP 也已经完成。\nBeanFactoryPostProcessor 处理 BeanFactoryPostProcessor 可以对我们的 beanFactory 内所有的 beandefinition（未实例化）数据进行修改，这个过程是在 bean 还没有实例化之前做的。所以在这，我们通过自己去注册一些 beandefinition ，也可以对 beandefinition 做一些修改。关于 BeanFactoryPostProcessor 的用法在很多框架中都有体现，这里以 SOFATracer 中修改 Datasource 为例来说明下。\n\n\n\n\n\n\n\n\n\nSOFATracer 中为了对有所基于 jdbc 规范的数据源进行埋点，提供了一个 DataSourceBeanFactoryPostProcessor，用于修改原生 DataSource 来实现一层代理。代码详见：com.alipay.sofa.tracer.boot.datasource.processor.DataSourceBeanFactoryPostProcessor\n 这里只看核心代码部分，在 postProcessBeanFactory 方法中会根据 Datasource 的类型来创建不同的 DataSourceProxy；创建 DataSourceProxy 的过程就是修改原生 Datasource 的过程。\n 123456789101112131415161718192021222324252627282930313233343536private void createDataSourceProxy(ConfigurableListableBeanFactory beanFactory,                                      String beanName, BeanDefinition originDataSource,                                      String jdbcUrl) &#123;   // re-register origin datasource bean   BeanDefinitionRegistry beanDefinitionRegistry = (BeanDefinitionRegistry) beanFactory;   // 先把之前已经存在的 Datasource 的 BeanDefinition 移除   beanDefinitionRegistry.removeBeanDefinition(beanName);   boolean isPrimary = originDataSource.isPrimary();   originDataSource.setPrimary(false);   // 换个 beanName ,重新注册到容器中   beanDefinitionRegistry.registerBeanDefinition(transformDatasourceBeanName(beanName),       originDataSource);   // 构建代理的 datasource BeanDefinition，类型为 SmartDataSource   RootBeanDefinition proxiedBeanDefinition = new RootBeanDefinition(SmartDataSource.class);   // 设置 BeanDefinition 相关属性   proxiedBeanDefinition.setRole(BeanDefinition.ROLE_APPLICATION);   proxiedBeanDefinition.setPrimary(isPrimary);   proxiedBeanDefinition.setInitMethodName(&quot;init&quot;);   proxiedBeanDefinition.setDependsOn(transformDatasourceBeanName(beanName));   // 获取原生 datasource 的属性值   MutablePropertyValues originValues = originDataSource.getPropertyValues();   MutablePropertyValues values = new MutablePropertyValues();   String appName = environment.getProperty(TRACER_APPNAME_KEY);   // 修改和新增属性   Assert.isTrue(!StringUtils.isBlank(appName), TRACER_APPNAME_KEY + &quot; must be configured!&quot;);   values.add(&quot;appName&quot;, appName);   values.add(&quot;delegate&quot;, new RuntimeBeanReference(transformDatasourceBeanName(beanName)));   values.add(&quot;dbType&quot;,       DataSourceUtils.resolveDbTypeFromUrl(unwrapPropertyValue(originValues.get(jdbcUrl))));   values.add(&quot;database&quot;,       DataSourceUtils.resolveDatabaseFromUrl(unwrapPropertyValue(originValues.get(jdbcUrl))));   // 将新的 values 设置给代理 BeanDefinition   proxiedBeanDefinition.setPropertyValues(values);   // 将代理的 datasource BeanDefinition 注册到容器中   beanDefinitionRegistry.registerBeanDefinition(beanName, proxiedBeanDefinition);&#125;\n\n上面这段代码就是 BeanFactoryPostProcessor 一种典型的应用场景，就是修改 BeanDefinition。\nBeanFactoryPostProcessor 处理过程代码比较长，这里就不在具体分析处理的流程。需要关注的点是：1、BeanFactoryPostProcessor 的作用，它能做哪些事情；2、它是在容器启动的哪个阶段执行的。\nregisterBeanPostProcessors 的处理过程registerBeanPostProcessors 是用于注册 BeanPostProcessor 的。BeanPostProcessor 的作用时机相对于 BeanFactoryPostProcessor 来说要晚一些，BeanFactoryPostProcessor 处理的是 BeanDefinition，Bean 还没有实例化；BeanPostProcessor 处理的是 Bean，BeanPostProcessor 包括两个方法，分别用于在 Bean 实例化之前和实例化之后回调。\n开篇有提到，在某些场景下会出现 BeanPostProcessor 不生效。对于 Spring 来说，BeanPostProcessor 本身也会被注册成一个 Bean，那么自然就可能会出现，BeanPostProcessor  处理的 bean 在 BeanPostProcessor 本身初始化之前就已经完成了的情况。\nregisterBeanPostProcessors 大体分为以下几个部分：\n\n注册 BeanPostProcessorChecker。（当一个 bean 在 BeanPostProcessor 实例化过程中被创建时，即当一个bean没有资格被所有 BeanPostProcessor 处理时，它记录一个信息消息）\n实现优先排序、排序和其他操作的 BeanPostProcessor 之间进行排序\n注册实现 PriorityOrdered 的 BeanPostProcessor\n注册实现 Ordered 的 \n注册所有常规的 BeanPostProcessor\n重新注册所有的内部 BeanPostProcessor\n将后处理器注册为用于检测内部 bean 的 applicationlistener，将其移动到处理器链的末端(用于获取代理等)。\n\n\n\n\n\n\n\n\n\n\n这里还是以扩展时机为主线，Bean 的 IoC、DI 和 AOP 初始化过程不细究。\nLifecycleProcessor 的处理过程LifecycleProcessor 的处理过程是在 finishRefresh 方法中执行，下面先看下 finishRefresh 方法：\n123456789101112protected void finishRefresh() &#123;    // 清除上下文级的资源缓存(比如扫描的ASM元数据)。    clearResourceCaches();    // 为此上下文初始化 LifecycleProcessor。    initLifecycleProcessor();    // 首先将 refresh 传播到 LifecycleProcessor。    getLifecycleProcessor().onRefresh();    // 发布 ContextRefreshedEvent 事件    publishEvent(new ContextRefreshedEvent(this));    // Participate in LiveBeansView MBean, if active.    LiveBeansView.registerApplicationContext(this);&#125;\n\n初始化 initLifecycleProcessor 是从容器中拿到所有的 LifecycleProcessor ，如果业务代码中没有实现 LifecycleProcessor 接口的 bean ，则使用默认的 DefaultLifecycleProcessor。\nonRefresh 过程是 最后会调用到 Lifecycle 接口的 start 方法。LifeCycle 定义 Spring 容器对象的生命周期，任何 spring 管理对象都可以实现该接口。然后，当 ApplicationContext 本身接收启动和停止信号(例如在运行时停止&#x2F;重启场景)时，spring 容器将在容器上下文中找出所有实现了 LifeCycle 及其子类接口的类，并一一调用它们实现的类。spring 是通过委托给生命周期处理器 LifecycleProcessor 来实现这一点的。Lifecycle 接口定义如下：\n123456789101112131415161718192021public interface Lifecycle &#123;    /**     * 启动当前组件     * 1、如果组件已经在运行，不应该抛出异常     * 2、对于容器，这将把开始信号传播到应用的所有组件     */    void start();    /**     * 通常以同步方式停止该组件，当该方法执行完成后,该组件会被完全停止。当需要异步停止行为时，考虑实现 SmartLifecycle 和它的 stop     * (Runnable) 方法变体。注意，此停止通知在销毁前不能保证到达:在常规关闭时，&#123;@code Lifecycle&#125; bean将首先收到一个停止通知，然后才传播     * 常规销毁回调;然而，在上下文的生命周期内的热刷新或中止的刷新尝试上，只调用销毁方法。对于容器，这将把停止信号传播到应用的所有组件     */    void stop();    /**      *  检查此组件是否正在运行。      *  1. 只有该方法返回 false 时，start方法才会被执行。      *  2. 只有该方法返回 true 时，stop(Runnable callback) 或 stop() 方法才会被执行。      */    boolean isRunning();&#125;\n\n至此，容器刷新其实已经就完成了。可以看到 Spring 或者 SpringBoot 在整个启动过程中，有非常多的口子暴露出来，供用户使用，非常灵活。\n异常处理逻辑与正常流程类似，异常处理流程同样作为 SpringBoot 生命周期的一个环节，在异常发生时，会通过一些机制来处理收尾过程。异常处理部分 SpringBoot 1.x 版本和 SpringBoot 2.x 版本差异还是比较大的。这里只分析 SpringBoot 2.x 的处理过程。这里直接贴一段代码：\n1234567891011121314151617181920212223242526private void handleRunFailure(ConfigurableApplicationContext context,\t\t\tThrowable exception,\t\t\tCollection&lt;SpringBootExceptionReporter&gt; exceptionReporters,\t\t\tSpringApplicationRunListeners listeners) &#123;    try &#123;        try &#123;            // exitCode            handleExitCode(context, exception);            if (listeners != null) &#123;                // failed                listeners.failed(context, exception);            &#125;        &#125;        finally &#123;            // 这里也是扩展的口子            reportFailure(exceptionReporters, exception);            if (context != null) &#123;                context.close();            &#125;        &#125;    &#125;    catch (Exception ex) &#123;        logger.warn(&quot;Unable to close ApplicationContext&quot;, ex);    &#125;    ReflectionUtils.rethrowRuntimeException(exception);&#125;\n上述代码片段主要做了以下几件事：\n\nhandleExitCode： 这里会拿到异常的 exitCode，随后发布一个 ExitCodeEvent 事件，最后交由 SpringBootExceptionHandler 处理。\nSpringApplicationRunListeners#failed： 循环遍历调用所有 SpringApplicationRunListener 的 failed 方法\nreportFailure：用户可以自定义扩展 SpringBootExceptionReporter 接口来实现定制化的异常上报逻辑\n\n在 SpringApplicationRunListeners#failed 中，业务产生的异常将直接被抛出，而不会影响异常处理的主流程。\n总结至此，SpringBoot 启动的主流程已经全部分析完成了。从扩展和扩展时机的角度来看，整个过程中，SpringBoot 提供了非常多的扩展口子，让用户可以在容器启动的各个阶段（无论是启动，环境准备，容器刷新等等）做一些定制化的操作。用户可以利用这些扩展接口来修改 bean 、修改环境变量，给用户极大的空间。\n","slug":"springboot/springboot-series-started","date":"2019-12-07T09:41:01.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot","author_index":"glmapper"},{"id":"ab9e1ff6883aee9623d9698a3a7669a7","title":"SpringBoot 源码系列-FatJar 启动原理","content":"之前有写过一篇文章来介绍 JAR 文件和 MENIFEST.MF 文件，详见：聊一聊 JAR 文件和 MANIFEST.MF，在这篇文章中介绍了 JAR 文件的内部结构。本篇将继续延续前面的节奏，来介绍下，在 SpringBoot 中，是如何将一个 FatJar 运行起来的。\n\n\nFatJar 解压之后的文件目录从 Spring 官网 或者通过 Idea 创建一个新的 SpringBoot 工程，方便起见，建议什么依赖都不加，默认带入的空的 SpringBoot 工程即可。\n通过 maven 命令进行打包，打包成功之后得到的构建产物截图如下：\n\n在前面的文章中有提到，jar 包是zip 包的一种变种，因此也可以通过 unzip 来解压\n1unzip -q guides-for-jarlaunch-0.0.1-SNAPSHOT.jar -d mock\n解压的 mock 目录，使用 tree 指令，看到整个解压之后的 FatJar 的目录结构如下（部分省略）：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748.├── BOOT-INF│   ├── classes│   │   ├── application.properties  # 用户-配置文件│   │   └── com│   │       └── glmapper│   │           └── bridge│   │               └── boot│   │                   └── BootStrap.class  # 用户-启动类│   └── lib│       ├── jakarta.annotation-api-1.3.5.jar│       ├── jul-to-slf4j-1.7.28.jar│       ├── log4j-xxx.jar # 表示 log4j 相关的依赖简写│       ├── logback-xxx.jar # 表示 logback 相关的依赖简写│       ├── slf4j-api-1.7.28.jar│       ├── snakeyaml-1.25.jar│       ├── spring-xxx.jar   # 表示 spring 相关的依赖简写├── META-INF│   ├── MANIFEST.MF│   └── maven│       └── com.glmapper.bridge.boot│           └── guides-for-jarlaunch│               ├── pom.properties│               └── pom.xml└── org    └── springframework        └── boot            └── loader                ├── ExecutableArchiveLauncher.class                ├── JarLauncher.class                ├── LaunchedURLClassLoader$UseFastConnectionExceptionsEnumeration.class                ├── LaunchedURLClassLoader.class                ├── Launcher.class                ├── MainMethodRunner.class                ├── PropertiesLauncher$1.class                ├── PropertiesLauncher$ArchiveEntryFilter.class                ├── PropertiesLauncher$PrefixMatchingArchiveFilter.class                ├── PropertiesLauncher.class                ├── WarLauncher.class                ├── archive                │   ├── # 省略                ├── data                │   ├── # 省略                ├── jar                │   ├── # 省略                └── util                    └── SystemPropertyUtils.class\n\n简单来看，FatJar 解压之后包括三个文件夹：\n12345678├── BOOT-INF # 存放的是业务相关的，包括业务开发的类和配置文件，以及依赖的jar│   ├── classes│   └── lib├── META-INF # 包括 MANIFEST.MF 描述文件和 maven 的构建信息│   ├── MANIFEST.MF│   └── maven└── org # SpringBoot 相关的类    └── springframework\n\n我们平时在 debug SpringBoot 工程的启动流程时，一般都是从 SpringApplication#run 方法开始\n1234567@SpringBootApplicationpublic class BootStrap &#123;    public static void main(String[] args) &#123;        // 入口        SpringApplication.run(BootStrap.class,args);    &#125;&#125;\n对于 java 程序来说，我们知道启动入口必须有 main 函数，这里看起来是符合条件的，但是有一点就是，通过 java 指令执行一个带有 main 函数的类时，是不需要有 -jar 参数的，比如新建一个 BootStrap.java 文件，内容为：\n12345public class BootStrap &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;Hello World&quot;);    &#125;&#125;\n\n通过 javac 编译此文件：\n1javac BootStrap.java\n然后就可以得到编译之后的 .class 文件 BootStrap.class ，此时可以通过 java 指令直接执行：\n1java BootStrap  # 输出 Hello World\n\n那么对于 java -jar 呢？这个其实在 java 的官方文档 中是有明确描述的：\n\n-jar filename\n\n\n\n\n\n\n\n\n\n\nExecutes a program encapsulated in a JAR file. The filename argument is the name of a JAR file with a manifest that contains a line in the form Main-Class:classname that defines the class with the public static void main(String[] args) method that serves as your application’s starting point.\n\n\n\n\n\n\n\n\n\nWhen you use the -jar option, the specified JAR file is the source of all user classes, and other class path settings are ignored.\n简单说就是，java -jar 命令引导的具体启动类必须配置在 MANIFEST.MF 资源的 Main-Class 属性中。\n那回过头再去看下之前打包好、解压之后的文件目录，找到 &#x2F;META-INF&#x2F;MANIFEST.MF 文件，看下元数据：\n1234567891011Manifest-Version: 1.0Implementation-Title: guides-for-jarlaunchImplementation-Version: 0.0.1-SNAPSHOTStart-Class: com.glmapper.bridge.boot.BootStrapSpring-Boot-Classes: BOOT-INF/classes/Spring-Boot-Lib: BOOT-INF/lib/Build-Jdk-Spec: 1.8Spring-Boot-Version: 2.2.0.RELEASECreated-By: Maven Archiver 3.4.0# Main-Class 在这里，指向的是 JarLauncherMain-Class: org.springframework.boot.loader.JarLauncher\n\norg.springframework.boot.loader.JarLauncher 类存放在 org&#x2F;springframework&#x2F;boot&#x2F;loader 下面：\n12345└── boot    └── loader        ├── ExecutableArchiveLauncher.class        ├── JarLauncher.class  # JarLauncher        ├── # 省略\n这样就基本理清楚了， FatJar 中，org.springframework.boot.loader 下面的类负责引导启动 SpringBoot 工程，作为入口，BOOT-INF 中存放业务代码和依赖，META-INF 下存在元数据描述。\nJarLaunch - FatJar 的启动器在分析 JarLaunch 之前，这里插一下，org.springframework.boot.loader 下的这些类是如何被打包在 FatJar 里面的\nspring-boot-maven-plugin 打包 spring-boot-loader 过程因为在新建的空的 SpringBoot 工程中并没有任何地方显示的引入或者编写相关的类。实际上，对于每个新建的 SpringBoot 工程，可以在其 pom.xml 文件中看到如下插件：\n12345678&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n这个是 SpringBoot 官方提供的用于打包 FatJar 的插件，org.springframework.boot.loader 下的类其实就是通过这个插件打进去的；\n下面是此插件将 loader 相关类打入 FatJar 的一个执行流程：\n\n\n\n\n\n\n\n\n\norg.springframework.boot.maven#execute-&gt;org.springframework.boot.maven#repackage -&gt; org.springframework.boot.loader.tools.Repackager#repackage-&gt;org.springframework.boot.loader.tools.Repackager#writeLoaderClasses-&gt;org.springframework.boot.loader.tools.JarWriter#writeLoaderClasses\n最终的执行方法就是下面这个方法，通过注释可以看出，该方法的作用就是将 spring-boot-loader 的classes 写入到 FatJar 中。\n12345678/** * Write the required spring-boot-loader classes to the JAR. * @throws IOException if the classes cannot be written */@Overridepublic void writeLoaderClasses() throws IOException &#123;\twriteLoaderClasses(NESTED_LOADER_JAR);&#125;\n\nJarLaunch 基本原理基于前面的分析，这里考虑一个问题，能否直接通过 java BootStrap 来直接运行 SpringBoot 工程呢？这样在不需要 -jar 参数和 JarLaunch 引导的情况下，直接使用最原始的 java 指令理论上是不是也可以，因为有 main 方法。\n通过 java BootStrap 方式启动BootStrap 类的如下：\n123456@SpringBootApplicationpublic class BootStrap &#123;    public static void main(String[] args) &#123;        SpringApplication.run(BootStrap.class,args);    &#125;&#125;\n\n编译之后，执行 java com.glmapper.bridge.boot.BootStrap，然后抛出异常了：\n12345678Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/springframework/boot/SpringApplication        at com.glmapper.bridge.boot.BootStrap.main(BootStrap.java:13)Caused by: java.lang.ClassNotFoundException: org.springframework.boot.SpringApplication        at java.net.URLClassLoader.findClass(URLClassLoader.java:381)        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:338)        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)        ... 1 more\n从异常堆栈来看，是因为找不到 SpringApplication 这个类；这里其实还是比较好理解的，BootStrap 类中引入了 SpringApplication，但是这个类是在 BOOT-INF&#x2F;lib 下的，而 java 指令在启动时也没有指定 class path 。\n\n\n\n\n\n\n\n\n\n这里不再赘述，通过 -classpath + -Xbootclasspath 的方式尝试了下，貌似也不行，如果有通过 java 指令直接运行成功的，欢迎留言沟通。\n通过 java JarLaunch 启动再通过 java org.springframework.boot.loader.JarLauncher 方式启动，可以看到是可以的。\n\n那这里基本可以猜到，JarLauncher 方式启动时，一定会通过某种方式将所需要依赖的 JAR 文件作为 BootStrap 的依赖引入进来。下面就来简单分析下 JarLauncher 启动时，作为启动引导类，它做了哪些事情。\n基本原理分析JarLaunch 类的定义如下：\n123456789101112131415161718192021222324252627public class JarLauncher extends ExecutableArchiveLauncher &#123;    // BOOT-INF/classes/    static final String BOOT_INF_CLASSES = &quot;BOOT-INF/classes/&quot;;    // BOOT-INF/lib/    static final String BOOT_INF_LIB = &quot;BOOT-INF/lib/&quot;;    // 空构造函数    public JarLauncher() &#123;    &#125;    // 带有指定 Archive 的构造函数    protected JarLauncher(Archive archive) &#123;    \tsuper(archive);    &#125;    // 是否是可嵌套的对象    @Override    protected boolean isNestedArchive(Archive.Entry entry) &#123;    \tif (entry.isDirectory()) &#123;    \t\treturn entry.getName().equals(BOOT_INF_CLASSES);    \t&#125;    \treturn entry.getName().startsWith(BOOT_INF_LIB);    &#125;        // main 函数    public static void main(String[] args) throws Exception &#123;    \tnew JarLauncher().launch(args);    &#125;&#125;\n通过代码，我们很明显可以看到几个关键的信息点：\n\nBOOT_INF_CLASSES 和 BOOT_INF_LIB  两个常量对应的是前面解压之后的两个文件目录\nJarLaunch 中包含一个 main 函数，作为启动入口\n\n但是单从 main 来看，只是构造了一个 JarLaunch 对象，然后执行其 launch 方法，并没有我们期望看到的构建所需依赖的地方。实际上这部分是在 JarLaunch 的父类 ExecutableArchiveLauncher 的构造函数中来完成的。\n12345678910111213141516171819202122232425262728public ExecutableArchiveLauncher() &#123;    try &#123;        // 构建 archive     \tthis.archive = createArchive();    &#125;    catch (Exception ex) &#123;    \tthrow new IllegalStateException(ex);    &#125;&#125;// 构建 Archiveprotected final Archive createArchive() throws Exception &#123;    ProtectionDomain protectionDomain = getClass().getProtectionDomain();    CodeSource codeSource = protectionDomain.getCodeSource();    URI location = (codeSource != null) ? codeSource.getLocation().toURI() : null;    // 这里就是拿到当前的 classpath     // /Users/xxx/Documents/test/glmapper-springboot-study-guides/guides-for-jarlaunch/target/mock/    String path = (location != null) ? location.getSchemeSpecificPart() : null;    if (path == null) &#123;    \tthrow new IllegalStateException(&quot;Unable to determine code source archive&quot;);    &#125;    File root = new File(path);    if (!root.exists()) &#123;    \tthrow new IllegalStateException(&quot;Unable to determine code source archive from &quot; + root);    &#125;    // 构建 Archive     return (root.isDirectory() ? new ExplodedArchive(root) : new JarFileArchive(root));&#125;\n\n\n\n\n\n\n\n\n\nPS: 关于 Archive 的概念这里由于篇幅有限，不再展开说明。\n通过上面构建了一个 Archive ，然后继续执行 launch 方法：\n123456789protected void launch(String[] args) throws Exception &#123;    // 注册协议，利用了 java.net.URLStreamHandler 的扩展机制，SpringBoot    // 扩展出了一种可以解析 jar in jar 的协议    JarFile.registerUrlProtocolHandler();    // 通过 classpath 来构建一个 ClassLoader    ClassLoader classLoader = createClassLoader(getClassPathArchives());    // launch     launch(args, getMainClass(), classLoader);&#125;\n\n下面值需要关注下 getMainClass() 方法即可，这里就是获取 MENIFEST.MF 中指定的 Start-Class ，实际上就是我们的工程里面的 BootStrap 类：\n12345678910111213141516@Overrideprotected String getMainClass() throws Exception &#123;    // 从 archive 中拿到 Manifest    Manifest manifest = this.archive.getManifest();    String mainClass = null;    if (manifest != null) &#123;        // 获取 Start-Class    \tmainClass = manifest.getMainAttributes().getValue(&quot;Start-Class&quot;);    &#125;    if (mainClass == null) &#123;    \tthrow new IllegalStateException(    \t\t\t&quot;No &#x27;Start-Class&#x27; manifest entry specified in &quot; + this);    &#125;    // 返回 mainClass    return mainClass;&#125;\n\n最终是通过构建了一个 MainMethodRunner 实例对象，然后通过反射的方式调用了 BootStrap 类中的 main 方法：\n\n小结本文主要从 JarLaunch 的角度分析了下 SpringBoot 的启动方式，对常规 java 方式和 java -jar 等启动方式进行了简单的演示；同时简单阐述了下 JarLaunch 启动的基本工作原理。对于其中 构建 Archive 、自定义协议 Handler 等未做深入探究，后面也会针对相关点再做单独分析。\n","slug":"springboot/springboot-series-fatjar","date":"2019-10-13T09:46:09.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,FatJar","author_index":"glmapper"},{"id":"beab21777c0d79f5d1291c48820f6305","title":"SpringBoot 源码系列-内嵌 Tomcat 的实现原理解析","content":"对于一个 SpringBoot web 工程来说，一个主要的依赖标志就是有 spring-boot-starter-web 这个 starter ，spring-boot-starter-web 模块在 spring boot 中其实并没有代码存在，只是在 pom.xml 中携带了一些依赖，包括 web、webmvc、tomcat 等：\n\n\n1234567891011121314151617181920212223242526&lt;dependencies&gt;    &lt;dependency&gt;    \t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    \t&lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;    \t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    \t&lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;    \t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    \t&lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;    \t&lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt;    \t&lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;    \t&lt;groupId&gt;org.springframework&lt;/groupId&gt;    \t&lt;artifactId&gt;spring-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;    \t&lt;groupId&gt;org.springframework&lt;/groupId&gt;    \t&lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n\n\n\n\n\n\n\n\n\nSpring Boot 默认的 web 服务容器是 tomcat ，如果想使用 Jetty 等来替换 Tomcat ，可以自行参考官方文档来解决。\nweb、webmvc、tomcat 等提供了 web 应用的运行环境，那 spring-boot-starter 则是让这些运行环境工作的开关（因为 spring-boot-starter 中会间接引入 spring-boot-autoconfigure ）。\nWebServer 自动配置在 spring-boot-autoconfigure 模块中，有处理关于 WebServer 的自动配置类 ServletWebServerFactoryAutoConfiguration 。\nServletWebServerFactoryAutoConfiguration代码片段如下：\n12345678910@Configuration@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@ConditionalOnClass(ServletRequest.class)@ConditionalOnWebApplication(type = Type.SERVLET)@EnableConfigurationProperties(ServerProperties.class)@Import(&#123; ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class,\t\tServletWebServerFactoryConfiguration.EmbeddedTomcat.class,\t\tServletWebServerFactoryConfiguration.EmbeddedJetty.class,\t\tServletWebServerFactoryConfiguration.EmbeddedUndertow.class &#125;)public class ServletWebServerFactoryAutoConfiguration\n\n\n两个 Condition 表示当前运行环境是基于 servlet 标准规范的 web 服务：\n\nConditionalOnClass(ServletRequest.class) ： 表示当前必须有 servlet-api 依赖存在\nConditionalOnWebApplication(type &#x3D; Type.SERVLET) ：仅基于servlet的Web应用程序\n\n@EnableConfigurationProperties(ServerProperties.class)：ServerProperties 配置中包括了常见的 server.port 等配置属性。\n通过 @Import 导入嵌入式容器相关的自动配置类，有 EmbeddedTomcat、EmbeddedJetty 和EmbeddedUndertow。\n综合来看，ServletWebServerFactoryAutoConfiguration 自动配置类中主要做了以下几件事情：\n\n导入了内部类 BeanPostProcessorsRegistrar，它实现了 ImportBeanDefinitionRegistrar，可以实现ImportBeanDefinitionRegistrar 来注册额外的 BeanDefinition。\n导入了 ServletWebServerFactoryConfiguration.EmbeddedTomcat 等嵌入容器先关配置（我们主要关注tomcat 相关的配置）。\n注册了ServletWebServerFactoryCustomizer、TomcatServletWebServerFactoryCustomizer 两个WebServerFactoryCustomizer 类型的 bean。\n\n下面就针对这几个点，做下详细的分析。\nBeanPostProcessorsRegistrarBeanPostProcessorsRegistrar 这个内部类的代码如下(省略了部分代码)：\n1234567891011121314151617181920public static class BeanPostProcessorsRegistrar    implements ImportBeanDefinitionRegistrar, BeanFactoryAware &#123;    // 省略代码    @Override    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata,                                        BeanDefinitionRegistry registry) &#123;        if (this.beanFactory == null) &#123;            return;        &#125;        // 注册 WebServerFactoryCustomizerBeanPostProcessor        registerSyntheticBeanIfMissing(registry,                                       &quot;webServerFactoryCustomizerBeanPostProcessor&quot;,                                       WebServerFactoryCustomizerBeanPostProcessor.class);        // 注册 errorPageRegistrarBeanPostProcessor        registerSyntheticBeanIfMissing(registry,                                       &quot;errorPageRegistrarBeanPostProcessor&quot;,                                       ErrorPageRegistrarBeanPostProcessor.class);    &#125;    // 省略代码&#125;\n\n上面这段代码中，注册了两个 bean，一个 WebServerFactoryCustomizerBeanPostProcessor，一个 errorPageRegistrarBeanPostProcessor；这两个都实现类 BeanPostProcessor 接口，属于 bean 的后置处理器，作用是在 bean 初始化前后加一些自己的逻辑处理。\n\nWebServerFactoryCustomizerBeanPostProcessor：作用是在 WebServerFactory 初始化时调用上面自动配置类注入的那些 WebServerFactoryCustomizer ，然后调用 WebServerFactoryCustomizer 中的 customize 方法来 处理 WebServerFactory。\nerrorPageRegistrarBeanPostProcessor：和上面的作用差不多，不过这个是处理 ErrorPageRegistrar 的。\n\n下面简单看下 WebServerFactoryCustomizerBeanPostProcessor 中的代码：\n12345678910111213141516171819202122232425public class WebServerFactoryCustomizerBeanPostProcessor\t\timplements BeanPostProcessor, BeanFactoryAware &#123;    // 省略部分代码        // 在 postProcessBeforeInitialization 方法中，如果当前 bean 是 WebServerFactory，则进行    // 一些后置处理    @Override\tpublic Object postProcessBeforeInitialization(Object bean, String beanName)\t\t\tthrows BeansException &#123;\t\tif (bean instanceof WebServerFactory) &#123;\t\t\tpostProcessBeforeInitialization((WebServerFactory) bean);\t\t&#125;\t\treturn bean;\t&#125;    // 这段代码就是拿到所有的 Customizers ，然后遍历调用这些 Customizers 的 customize 方法    private void postProcessBeforeInitialization(WebServerFactory webServerFactory) &#123;\t\tLambdaSafe\t\t\t\t.callbacks(WebServerFactoryCustomizer.class, getCustomizers(),\t\t\t\t\t\twebServerFactory)\t\t\t\t.withLogger(WebServerFactoryCustomizerBeanPostProcessor.class)\t\t\t\t.invoke((customizer) -&gt; customizer.customize(webServerFactory));\t&#125;        // 省略部分代码&#125;\n\n自动配置类中注册的两个 Customizer Bean这两个 Customizer 实际上就是去处理一些配置值，然后绑定到 各自的工厂类的。\nWebServerFactoryCustomizer将 serverProperties 配置值绑定给 ConfigurableServletWebServerFactory 对象实例上。\n1234567891011121314151617181920212223242526272829@Overridepublic void customize(ConfigurableServletWebServerFactory factory) &#123;    PropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull();    // 端口    map.from(this.serverProperties::getPort).to(factory::setPort);    // address    map.from(this.serverProperties::getAddress).to(factory::setAddress);    // contextPath    map.from(this.serverProperties.getServlet()::getContextPath)        .to(factory::setContextPath);    // displayName    map.from(this.serverProperties.getServlet()::getApplicationDisplayName)        .to(factory::setDisplayName);    // session 配置    map.from(this.serverProperties.getServlet()::getSession).to(factory::setSession);    // ssl    map.from(this.serverProperties::getSsl).to(factory::setSsl);    // jsp    map.from(this.serverProperties.getServlet()::getJsp).to(factory::setJsp);    // 压缩配置策略实现    map.from(this.serverProperties::getCompression).to(factory::setCompression);    // http2     map.from(this.serverProperties::getHttp2).to(factory::setHttp2);    // serverHeader    map.from(this.serverProperties::getServerHeader).to(factory::setServerHeader);    // contextParameters    map.from(this.serverProperties.getServlet()::getContextParameters)        .to(factory::setInitParameters);&#125;\n\nTomcatServletWebServerFactoryCustomizer相比于上面那个，这个 customizer 主要处理 Tomcat 相关的配置值\n1234567891011121314151617181920@Overridepublic void customize(TomcatServletWebServerFactory factory) &#123;    // 拿到 tomcat 相关的配置    ServerProperties.Tomcat tomcatProperties = this.serverProperties.getTomcat();    // server.tomcat.additional-tld-skip-patterns    if (!ObjectUtils.isEmpty(tomcatProperties.getAdditionalTldSkipPatterns())) &#123;        factory.getTldSkipPatterns()            .addAll(tomcatProperties.getAdditionalTldSkipPatterns());    &#125;    // server.redirectContextRoot    if (tomcatProperties.getRedirectContextRoot() != null) &#123;        customizeRedirectContextRoot(factory,                                     tomcatProperties.getRedirectContextRoot());    &#125;    // server.useRelativeRedirects    if (tomcatProperties.getUseRelativeRedirects() != null) &#123;        customizeUseRelativeRedirects(factory,                                      tomcatProperties.getUseRelativeRedirects());    &#125;&#125;\n\nWebServerFactory用于创建 WebServer 的工厂的标记接口。\n类体系结构\n上图为 WebServerFactory -&gt; TomcatServletWebServerFactory 的整个类结构关系。\nTomcatServletWebServerFactoryTomcatServletWebServerFactory 是用于获取 Tomcat 作为 WebServer 的工厂类实现，其中最核心的方法就是 getWebServer，获取一个 WebServer 对象实例。\n1234567891011121314151617181920212223242526@Overridepublic WebServer getWebServer(ServletContextInitializer... initializers) &#123;    // 创建一个 Tomcat 实例    Tomcat tomcat = new Tomcat();    // 创建一个 Tomcat 实例工作空间目录    File baseDir = (this.baseDirectory != null) ? this.baseDirectory        : createTempDir(&quot;tomcat&quot;);    tomcat.setBaseDir(baseDir.getAbsolutePath());    // 创建连接对象    Connector connector = new Connector(this.protocol);    tomcat.getService().addConnector(connector);    // 1    customizeConnector(connector);    tomcat.setConnector(connector);    tomcat.getHost().setAutoDeploy(false);    // 配置 Engine，没有什么实质性的操作，可忽略    configureEngine(tomcat.getEngine());    // 一些附加链接，默认是 0 个    for (Connector additionalConnector : this.additionalTomcatConnectors) &#123;        tomcat.getService().addConnector(additionalConnector);    &#125;    // 2    prepareContext(tomcat.getHost(), initializers);    // 返回 webServer    return getTomcatWebServer(tomcat);&#125;\n\n\n\n1、customizeConnector ： 给 Connector 设置 port、protocolHandler、uriEncoding 等。Connector 构造的逻辑主要是在NIO和APR选择中选择一个协议，然后反射创建实例并强转为 ProtocolHandler\n2、prepareContext 这里并不是说准备当前 Tomcat 运行环境的上下文信息，而是准备一个 StandardContext ，也就是准备一个 web app。\n\n准备 Web App Context 容器对于 Tomcat 来说，每个 context 就是映射到 一个 web app 的，所以 prepareContext 做的事情就是将 web 应用映射到一个 TomcatEmbeddedContext ，然后加入到 Host 中。\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061protected void prepareContext(Host host, ServletContextInitializer[] initializers) &#123;    File documentRoot = getValidDocumentRoot();    // 创建一个 TomcatEmbeddedContext 对象    TomcatEmbeddedContext context = new TomcatEmbeddedContext();    if (documentRoot != null) &#123;        context.setResources(new LoaderHidingResourceRoot(context));    &#125;    // 设置描述此容器的名称字符串。在属于特定父项的子容器集内，容器名称必须唯一。    context.setName(getContextPath());    // 设置此Web应用程序的显示名称。    context.setDisplayName(getDisplayName());    // 设置 webContextPath  默认是   /    context.setPath(getContextPath());    File docBase = (documentRoot != null) ? documentRoot        : createTempDir(&quot;tomcat-docbase&quot;);    context.setDocBase(docBase.getAbsolutePath());    // 注册一个FixContextListener监听，这个监听用于设置context的配置状态以及是否加入登录验证的逻辑    context.addLifecycleListener(new FixContextListener());    // 设置 父 ClassLoader    context.setParentClassLoader(        (this.resourceLoader != null) ? this.resourceLoader.getClassLoader()        : ClassUtils.getDefaultClassLoader());    // 覆盖Tomcat的默认语言环境映射以与其他服务器对齐。    resetDefaultLocaleMapping(context);    // 添加区域设置编码映射（请参阅Servlet规范2.4的5.4节）    addLocaleMappings(context);    // 设置是否使用相对地址重定向    context.setUseRelativeRedirects(false);    try &#123;        context.setCreateUploadTargets(true);    &#125;    catch (NoSuchMethodError ex) &#123;        // Tomcat is &lt; 8.5.39. Continue.    &#125;    configureTldSkipPatterns(context);    // 设置 WebappLoader ，并且将 父 classLoader 作为构建参数    WebappLoader loader = new WebappLoader(context.getParentClassLoader());    // 设置 WebappLoader 的 loaderClass 值    loader.setLoaderClass(TomcatEmbeddedWebappClassLoader.class.getName());    // 会将加载类向上委托    loader.setDelegate(true);    context.setLoader(loader);    if (isRegisterDefaultServlet()) &#123;        addDefaultServlet(context);    &#125;    // 是否注册 jspServlet    if (shouldRegisterJspServlet()) &#123;        addJspServlet(context);        addJasperInitializer(context);    &#125;    context.addLifecycleListener(new StaticResourceConfigurer(context));    ServletContextInitializer[] initializersToUse = mergeInitializers(initializers);    // 在 host 中 加入一个 context 容器    // add时给context注册了个内存泄漏跟踪的监听MemoryLeakTrackingListener,详见 addChild 方法    host.addChild(context);    //对context做了些设置工作，包括TomcatStarter(实例化并set给context),    // LifecycleListener,contextValue,errorpage,Mime,session超时持久化等以及一些自定义工作    configureContext(context, initializersToUse);    // postProcessContext 方法是空的，留给子类重写用的    postProcessContext(context);&#125;\n\n从上面可以看下，WebappLoader 可以通过 setLoaderClass 和 getLoaderClass 这两个方法可以更改loaderClass 的值。所以也就意味着，我们可以自己定义一个继承 webappClassLoader 的类，来更换系统自带的默认实现。\n初始化 TomcatWebServer在 getWebServer 方法的最后就是构建一个 TomcatWebServer。\n12345678910111213// org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactoryprotected TomcatWebServer getTomcatWebServer(Tomcat tomcat) &#123;    // new 一个 TomcatWebServer    return new TomcatWebServer(tomcat, getPort() &gt;= 0);&#125;// org.springframework.boot.web.embedded.tomcat.TomcatWebServerpublic TomcatWebServer(Tomcat tomcat, boolean autoStart) &#123;    Assert.notNull(tomcat, &quot;Tomcat Server must not be null&quot;);    this.tomcat = tomcat;    this.autoStart = autoStart;    // 初始化    initialize();&#125;\n\n这里主要是 initialize 这个方法，这个方法中将会启动 tomcat 服务\n12345678910111213141516171819202122232425262728293031323334353637383940414243private void initialize() throws WebServerException &#123;    logger.info(&quot;Tomcat initialized with port(s): &quot; + getPortsDescription(false));    synchronized (this.monitor) &#123;        try &#123;            // 对全局原子变量 containerCounter+1，由于初始值是-1，    // 所以 addInstanceIdToEngineName 方法内后续的获取引擎并设置名字的逻辑不会执行            addInstanceIdToEngineName();\t\t\t// 获取 Context             Context context = findContext();            // 给 Context 对象实例生命周期监听器            context.addLifecycleListener((event) -&gt; &#123;                if (context.equals(event.getSource())                    &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) &#123;                    // 将上面new的connection以service（这里是StandardService[Tomcat]）做key保存到                    // serviceConnectors中，并将 StandardService 中的connectors 与 service 解绑(connector.setService((Service)null);)，                    // 解绑后下面利用LifecycleBase启动容器就不会启动到Connector了                    removeServiceConnectors();                &#125;            &#125;);            // 启动服务器以触发初始化监听器            this.tomcat.start();            // 这个方法检查初始化过程中的异常，如果有直接在主线程抛出，            // 检查方法是TomcatStarter中的 startUpException，这个值是在 Context 启动过程中记录的            rethrowDeferredStartupExceptions();            try &#123;                // 绑定命名的上下文和classloader，                ContextBindings.bindClassLoader(context, context.getNamingToken(),                                                getClass().getClassLoader());            &#125;            catch (NamingException ex) &#123;                // 设置失败不需要关心            &#125;\t\t\t// ：与Jetty不同，Tomcat所有的线程都是守护线程，所以创建一个非守护线程            // （例：Thread[container-0,5,main]）来避免服务到这就shutdown了            startDaemonAwaitThread();        &#125;        catch (Exception ex) &#123;            stopSilently();            throw new WebServerException(&quot;Unable to start embedded Tomcat&quot;, ex);        &#125;    &#125;&#125;\n\n查找 Context ，实际上就是查找一个Tomcat 中的一个 web 应用，SpringBoot 中默认启动一个 Tomcat ，并且一个 Tomcat 中只有一个 Web 应用（FATJAR 模式下，应用与 Tomcat 是 1：1 关系），所有在遍历 Host 下的 Container 时，如果 Container 类型是 Context ，就直接返回了。\n12345678private Context findContext() &#123;    for (Container child : this.tomcat.getHost().findChildren()) &#123;        if (child instanceof Context) &#123;            return (Context) child;        &#125;    &#125;    throw new IllegalStateException(&quot;The host does not contain a Context&quot;);&#125;\n\nTomcat 启动过程在 TomcatWebServer 的 initialize 方法中会执行 tomcat 的启动。\n12// Start the server to trigger initialization listenersthis.tomcat.start();\n\norg.apache.catalina.startup.Tomcat 的 start 方法：\n123456public void start() throws LifecycleException &#123;    // 初始化 server    getServer();    // 启动 server    server.start();&#125;\n\n初始化 Server初始化 server 实际上就是构建一个 StandardServer 对象实例，关于 Tomcat 中的 Server 可以参考附件中的说明。\n12345678910111213141516171819202122public Server getServer() &#123;\t// 如果已经存在的话就直接返回    if (server != null) &#123;        return server;    &#125;\t// 设置系统属性 catalina.useNaming    System.setProperty(&quot;catalina.useNaming&quot;, &quot;false&quot;);\t// 直接 new 一个 StandardServer    server = new StandardServer();\t// 初始化 baseDir （catalina.base、catalina.home、 ~/tomcat.&#123;port&#125;）    initBaseDir();    // Set configuration source    ConfigFileLoader.setSource(new CatalinaBaseConfigurationSource(new File(basedir), null));    server.setPort( -1 );    Service service = new StandardService();    service.setName(&quot;Tomcat&quot;);    server.addService(service);    return server;&#125;\n小结上面对 SpringBoot 中内嵌 Tomcat 的过程做了分析，这个过程实际上并不复杂，就是在刷新 Spring 上下文的过程中将 Tomcat 容器启动起来，并且将当前应用绑定到一个 Context ，然后添加了 Host。下图是程序的执行堆栈和执行内嵌 Tomcat 初始化和启动的时机。\n\n下面总结下整个过程：\n\n通过自定配置注册相关的 Bean ，包括一些 Factory 和 后置处理器等\n上下文刷新阶段，执行创建 WebServer，这里需要用到前一个阶段所注册的 Bean \n包括创建 ServletContext\n实例化 webServer\n\n\n创建 Tomcat 实例、创建 Connector 连接器\n绑定 应用到 ServletContext，并添加相关的生命周期范畴内的监听器，然后将 Context 添加到 host 中\n实例化 webServer 并且启动 Tomcat 服务\n\nSpringBoot 的 Fatjar 方式没有提供共享 Tomcat 的实现逻辑，就是两个 FATJAT 启动可以只实例化一个 Tomcat 实例（包括 Connector 和 Host ），从前面的分析知道，每个 web 应用（一个 FATJAT 对应的应用）实例上就是映射到一个 Context ；而对于 war 方式，一个 Host 下面是可以挂载多个 Context 的。\n附：Tomcat 组件说明\n\n\n组件名称\n说明\n\n\n\nServer\n表示整个Servlet 容器，因此 Tomcat 运行环境中只有唯一一个 Server 实例\n\n\nService\nService 表示一个或者多个 Connector 的集合，这些 Connector 共享同一个 Container 来处理其请求。在同一个 Tomcat 实例内可以包含任意多个 Service 实例，他们彼此独立。\n\n\nConnector\nTomcat 连接器，用于监听和转化 Socket 请求，同时将读取的 Socket 请求交由 Container 处理，支持不同协议以及不同的 I&#x2F;O 方式。\n\n\nContainer\nContainer 表示能够执行客户端请求并返回响应的一类对象，在 Tomcat 中存在不同级别的容器：Engine、Host、Context、Wrapper\n\n\nEngine\nEngine 表示整个 Servlet 引擎。在 Tomcat 中，Engine 为最高层级的容器对象，虽然 Engine 不是直接处理请求的容器，确是获取目标容器的入口\n\n\nHost\nHost 作为一类容器，表示 Servlet 引擎（即Engine）中的虚拟机，与一个服务器的网络名有关，如域名等。客户端可以使用这个网络名连接服务器，这个名称必须要在 DNS 服务器上注册\n\n\nContext\nContext 作为一类容器，用于表示 ServletContext，在 Servlet 规范中，一个 ServletContext 即表示一个独立的 web 应用\n\n\nWrapper\nWrapper 作为一类容器，用于表示 Web 应用中定义的 Servlet\n\n\nExecutor\n表示 Tomcat 组件间可以共享的线程池\n\n\n","slug":"springboot/springboot-series-server-tomcat","date":"2019-10-06T09:48:43.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,tomcat,Embedded Tomcat","author_index":"glmapper"},{"id":"965065d167bea41b1f08335d6ffae271","title":"ARK 插件基本规则及注意事项","content":"SOFAARK 是一个轻量级的类隔离框架，其有两个基本的能力：解决依赖包冲突和多应用(模块)合并部署。本篇将从解决依赖角度来说明下 SOFARK 插件的基本使用规则。\n下图是官方文档中提供的用于描述依赖包冲突的一个场景：\n\n\n这里通过一个工程来模拟这种场景，然后通过将其中一个打包成插件的方式来解决。\n案例工程12345├── ark-main-project├── dependency-one├── dependency-two├── dependency-two-plugin\n\n\nark-main-project 为一个 简单的springboot 工程\ndependency-one 依赖1，可以对应到图中的 dependency A\ndependency-two 依赖2，可以对应到图中的 dependency B\ndependency-two-plugin ，dependency-two 的插件包\n\n另外还有一个 dependency-incompatible 工程，用于描述冲突的依赖。\ndependency-incompatibledependency-incompatible 有两个版本 1.0 和 2.0 ，1.0 和 2.0 是不兼容的。\n1.0 版本中提供了两个方法：\n123456789public class IncompatibleUtil &#123;    public static String test1()&#123;        return &quot;test1&quot;;    &#125;    public static String test2()&#123;        return &quot;test2&quot;;    &#125;&#125;\n\n2.0 版本中提供了两个方法：\n1234567891011121314public static String test1()&#123;        return &quot;test1&quot;;    &#125;    public static String test3()&#123;        return Incompatible.test();    &#125;    public static class Incompatible &#123;        public static String test() &#123;            return &quot;test&quot;;        &#125;    &#125;&#125;\n\ndependency-one12345public class TestOneUtil &#123;    public String testOne()&#123;        return IncompatibleUtil.test1()+IncompatibleUtil.test2();    &#125;&#125;\n\ndependency-two12345678910// import org.springframework.util.StringUtils;public class TestTwoUtil &#123;    public String testTwo(String param)&#123;        if (StringUtils.isEmpty(param))&#123;            return IncompatibleUtil.test1() + IncompatibleUtil.test3();        &#125; else &#123;            return IncompatibleUtil.test1() + IncompatibleUtil.test3();        &#125;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n这里引入 spring 的依赖查看是否会引入异常\nark-main-projectark-main-project 引入了 dependency-one 和 dependency-two 两个依赖，然后在启动类中分别调用 dependency-one 和 dependency-two 中提供的 api 。\n12345678910111213141516171819@SpringBootApplicationpublic class MainApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(MainApplication.class,args);        test(&quot;test&quot;);    &#125;    public static void test(String param) &#123;        if (!StringUtils.isEmpty(param))&#123;            TestOneUtil testOneUtil = new TestOneUtil();            System.out.println(testOneUtil.testOne());            TestTwoUtil testTwoUtil = new TestTwoUtil();            System.out.println(testTwoUtil.testTwo(param));        &#125;        else &#123;            System.out.println(&quot;no params&quot;);        &#125;    &#125;&#125;\n\n由于 dependency-one 和 dependency-two 底层都都依赖了 dependency-incompatible ，且 dependency-incompatible 的两个版本不兼容，所以在启动时会报错。\ndependency-two 插件改造根据文档前面那张图的描述，这里需要将其中一个改造成插件的方式，使用独立的 classloader 来加载，从而达到版本兼容。这里改造 dependency-two 。\n新建一个 dependency-two-plugin 模块，然后引入 dependency-two 依赖，并且将 冲突的 api 包导出\n12345678910111213141516171819202122232425262728293031323334&lt;dependencies&gt;        &lt;dependency&gt;            &lt;artifactId&gt;dependency-two&lt;/artifactId&gt;            &lt;groupId&gt;com.glmapper.bridge.boot&lt;/groupId&gt;            &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;                &lt;artifactId&gt;sofa-ark-plugin-maven-plugin&lt;/artifactId&gt;                &lt;version&gt;0.6.0&lt;/version&gt;                &lt;executions&gt;                    &lt;execution&gt;                        &lt;id&gt;default-cli&lt;/id&gt;                        &lt;goals&gt;                            &lt;goal&gt;ark-plugin&lt;/goal&gt;                        &lt;/goals&gt;                        &lt;configuration&gt;                            &lt;exported&gt;                                &lt;packages&gt;                                \t&lt;!--导出冲突的 api --&gt;                                    &lt;package&gt;com.glmapper.bridge.boot.two&lt;/package&gt;                                &lt;/packages&gt;                            &lt;/exported&gt;                        &lt;/configuration&gt;                    &lt;/execution&gt;                &lt;/executions&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;\n关于插件的导出，对于 dependency-two 中，ark-main-projet 中使用到的是 TestTwoUtil 这里类，因此仅需要将这个类导出即可。mvn clean install 安装到本地仓库，然后在 ark-main-project 中引用。\n将 ark-main-project 中的 dependency-two 依赖修改为 dependency-two-plugin 。\n12345&lt;dependency&gt;  &lt;groupId&gt;com.glmapper.bridge.boot&lt;/groupId&gt;  &lt;artifactId&gt;dependency-two-plugin&lt;/artifactId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;\n因为插件是运行在容器上的，所以也需要将 ark-main-project 改造成 ark 工程，具体可以参考官方文档。改造完成之后，打包 ark-main-project 工程，然后通过 java -jar 启动，运行结果如下，实现了类隔离。\nNoClassDefFoundError 异常的发生关于上面 SpringUtils 工具类在插件中和 BIZ 中均加载并且不会报错的解释是，SpringUtils 虽然在插件中和 BIZ 中都被加载了，但是没有报错，是因为没有触发 java 的 type check 机制。\n那么还有一种情况会导致出现 java.lang.NoClassDefFoundError 异常，这种情况是在插件中将 spring 相关的包指定不打入插件了，配置如下：\n12345678910111213&lt;configuration&gt;    &lt;exported&gt;      &lt;packages&gt;       \t&lt;package&gt;com.glmapper.bridge.boot.two.*&lt;/package&gt;      &lt;/packages&gt;    &lt;/exported&gt;    &lt;!--不将 spring 的包打进去--&gt;    &lt;excludeGroupIds&gt;        &lt;excludeGroupId&gt;org.springframework&lt;/excludeGroupId&gt;        &lt;excludeGroupId&gt;org.springframework.boot&lt;/excludeGroupId&gt;        &lt;excludeGroupId&gt;org.apache.tomcat.embed&lt;/excludeGroupId&gt;    &lt;/excludeGroupIds&gt;&lt;/configuration&gt;\n那么这样打出的包实际上包的大小会非常小，但是问题在于运行时，插件从当前 &#x2F;iib 目录下找不到 spring 相关的依赖，就会报 java.lang.NoClassDefFoundError 。\n\nLinkageError 异常的发生ark-main-project 中\ndependency-two 中\n重新打包，然后执行\n没有报错。此时插件中的类和 biz 中的类完全都是独立的。但是会存在一种情况，比如插件中有一个日志工具类，然后在 Biz 使用了这个工具类，则会报错。\n在 dependency-two 中增加一个 LoggerUtil 的类，\n123456789public class LoggerUtil &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(LoggerUtil.class);    public void info(String message)&#123;        LOGGER.info(message);    &#125;    public static Logger getLogger()&#123;        return LOGGER;    &#125;&#125;\n\n然后在 ark-main-project 中这样使用\n12345678910111213141516171819202122public class MainApplication &#123;\t// 使用 LoggerUtil 获取日志对象实例    private static final Logger LOGGER = LoggerUtil.getLogger();    public static void main(String[] args) &#123;        SpringApplication.run(MainApplication.class,args);        test(&quot;test&quot;);    &#125;    public static void test(String param) &#123;\t\t// 记录日志        LOGGER.info(&quot;test in biz.&quot;);        if (!StringUtils.isEmpty(param))&#123;            TestOneUtil testOneUtil = new TestOneUtil();            System.out.println(testOneUtil.testOne());            TestTwoUtil testTwoUtil = new TestTwoUtil();            System.out.println(testTwoUtil.testTwo(param));        &#125;        else &#123;            System.out.println(&quot;no params&quot;);        &#125;    &#125;&#125;\n这种情况下就会导致报错: Caused by: java.lang.LinkageError: loader constraint violation: loader (instance of com&#x2F;alipay&#x2F;sofa&#x2F;ark&#x2F;container&#x2F;service&#x2F;classloader&#x2F;BizClassLoader) previously initiated loading for a different type with name “org&#x2F;slf4j&#x2F;Logger\n1private static final Logger LOGGER = LoggerUtil.getLogger();\n单从这段代码来看，报错的原因在于，Logger LOGGER 的对象加载是被 BizClassLoader 加载的，但是 LoggerUtil.getLogger() 返回的对象是由 PluginClassLoader 加载的。\n所以在构建插件时，需要尽可能的去规避可能出现引起类型检查的地方：\n\n方法参数检验\n变量赋值\n方法返回值\n\n","slug":"sofa/sofa-ark-plugin-rule","date":"2019-08-28T10:53:53.000Z","categories_index":"SOFA","tags_index":"ClassLoader,SOFAArk,类加载","author_index":"glmapper"},{"id":"df38c18caf16ba3a0d7fecc5c412ad01","title":"响应式编程 Reactor","content":"从响应式编程说起响应式编程是一种关注于数据流（data streams）和变化传递（propagation of change）的异步编程方式。 这意味着它可以用既有的编程语言表达静态（如数组）或动态（如事件源）的数据流。\n在响应式编程方面，微软跨出了第一步，它在 .NET 生态中创建了响应式扩展库（Reactive Extensions library, Rx）。接着 RxJava 在 JVM 上实现了响应式编程。后来，在 JVM 平台出现了一套标准的响应式 编程规范，它定义了一系列标准接口和交互规范。并整合到 Java 9 中（Flow 类）。\n\n\n响应式编程通常作为面向对象编程中的“观察者模式”（Observer design pattern）的一种扩展。 响应式流（reactive streams）与“迭代子模式”（Iterator design pattern）也有相通之处， 因为其中也有 Iterable-Iterator 这样的对应关系。主要的区别在于，Iterator 是基于 “拉取”（pull）方式的，而响应式流是基于“推送”（push）方式的。\n\niterator 是一种“命令式”（imperative）编程范式，即使访问元素的方法是 Iterable 的唯一职责。关键在于，什么时候执行 next() 获取元素取决于开发者。\n响应式流中，相对应的角色是 Publisher-Subscriber，但是当有新的值到来的时候 ，却反过来由发布者（Publisher） 通知订阅者（Subscriber），这种“推送”模式是响应式的关键\n\n此外，对推送来的数据的操作是通过一种声明式（declaratively）而不是命令式（imperatively）的方式表达的：开发者通过描述“控制流程”来定义对数据流的处理逻辑。\n除了数据推送，对错误处理（error handling）和完成（completion）信号的定义也很完善。一个 Publisher 可以推送新的值到它的 Subscriber（调用 onNext 方法）， 同样也可以推送错误（调用 onError 方法）和完成（调用 onComplete 方法）信号。 错误和完成信号都可以终止响应式流。可以用下边的表达式描述：\n1onNext x 0..N [onError | onComplete]\n\n这种方式非常灵活，无论是有&#x2F;没有值，还是 n 个值（包括有无限个值的流，比如时钟的持续读秒），都可处理。\n\n\n\n\n\n\n\n\n\n以上来自 https://projectreactor.io/docs/core/release/reference/ 翻译\nReactive StreamsReactive Streams 是上面提到的一套标准的响应式编程规范。它由四个核心概念构成：\n\n消息发布者：只有一个 subscribe 接口，是订阅者调用的，用来订阅发布者的消息。发布者在订阅者调用 request 之后把消息 push 给订阅者。123public interface Publisher&lt;T&gt; &#123;    public void subscribe(Subscriber&lt;? super T&gt; s);&#125;\n订阅者：订阅者包括四个接口，这些接口都由 Publisher 触发调用的。onSubscribe 告诉订阅者订阅成功，并返回了一个 Subscription ；通过 Subscription 订阅者可以告诉发布者发送指定数量的消息（request 完成） ；onNext 是发布者有消息时，调用订阅者这个接口来达到发布消息的目的；onError 通知订阅者，发布者出现了错误；onComplete 通知订阅者消息发送完毕。123456public interface Subscriber&lt;T&gt; &#123;    public void onSubscribe(Subscription s);    public void onNext(T t);    public void onError(Throwable t);    public void onComplete();&#125;\n订阅：包括两个接口，请求 n 个消息和取消此次订阅。123456789public interface Subscription &#123;    // request(n)用来发起请求数据,其中n表示请求数据的数量,它必须大于0,    // 否则会抛出IllegalArgumentException,并触发onError,request的调用会    // 累加,如果没有终止,最后会触发相应次数的onNext方法.    public void request(long n);    // cancel相当于取消订阅,调用之后,后续不会再收到订阅,onError 和     // onComplete也不会被触发    public void cancel();&#125;\n处理器：Processor 同时继承了 Subscriber 和 Publisher；其代表一个处理阶段。12public interface Processor&lt;T, R&gt; extends Subscriber&lt;T&gt;, Publisher&lt;R&gt; &#123;&#125;\n\nReactive Streams 通过上面的四个核心概念和相关的函数，对响应式流进行了一个框架性的约定，它没有具体实现。简单来说，它只提供通用的、合适的解决方案，大家都按照这个规约来实现就好了。\nJava 的 Reactive Programming 类库主要有三个，分别是 Akka-Streams ，RxJava 和 Project Reactor。Spring 5 开始支持 Reactive Programming，其底层使用的是 Project Reactor。本篇主要是对 Project Reactor 中的一些点进行学习总结。\nProject ReactorProject Reactor 是一个基于 Java 8 的实现了响应式流规范 （Reactive Streams specification）的响应式库。\nReactor 引入了实现 Publisher 的响应式类 Flux 和 Mono，以及丰富的操作方式。 一个 Flux 对象代表一个包含 0..N 个元素的响应式序列，而一个 Mono 对象代表一个包含零或者一个（0..1）元素的结果。\nFlux 和 MonoFlux 是生产者，即我们上面提到的 Publisher，它代表的是一个包含 0-N 个元素的异步序列，Mono可以看做 Flux 的有一个特例，代表 0-1 个元素，如果不需要生产任何元素，只是需要一个完成任务的信号，可以使用 Mono。\nFlux-包含 0-N 个元素的异步序列\n先来看这张图，这里是直接从官方文档上贴过来的。就这张图做下说明，先来关注几个点：\n\n从左到右的时间序列轴\n1-6 为 Flux enitted（发射）的元素\n上面 6 后面的竖线标识已经成功完成了\n下面的 1-3 表示转换的结果\n❌  表示出现了error，对应的是执行了onError\noperator : 操作符，声明式的可组装的响应式方法，其组装成的链称为“操作链”\n\n那整体来看就是 Flux 产生元数据，通过一系列 operator 操作得到转换结果，正常成功就是 onCompleted，出现错误就是 onError。看下面的一个小例子：\n123456789101112131415161718192021Flux.just(&quot;glmapper&quot;,&quot;leishu&quot;).subscribe(new Subscriber&lt;String&gt;() &#123;    @Override    public void onSubscribe(Subscription subscription) &#123;        // subscription 表示订阅关系        System.out.println(&quot;onSubscribe,&quot;+ subscription.getClass());        // subscription 通过 request 来触发 onNext        subscription.request(2);    &#125;    @Override    public void onNext(String s) &#123;        System.out.println(&quot;currrent value is = &quot; + s);    &#125;    @Override    public void onError(Throwable throwable) &#123;        System.out.println(&quot;it&#x27;s error.&quot;);    &#125;    @Override    public void onComplete() &#123;        System.out.println(&quot;it&#x27;s completed.&quot;);    &#125;&#125;);\n执行结果:\n1234onSubscribe,class reactor.core.publisher.StrictSubscribercurrrent value is = glmappercurrrent value is = leishuit&#x27;s completed.\n\n如果在 onSubscribe 方法中我们不执行 request，则不会有后续任何操作。关于 request 下面看。\n\n\n\n\n\n\n\n\n\nFlux 是一个能够发出 0 到 N 个元素的标准的 Publisher，它会被一个 “error”  或 “completion” 信号终止。因此，一个 Flux 的结果可能是一个 value、completion 或 error。 就像在响应式流规范中规定的那样，这三种类型的信号被翻译为面向下游的 onNext，onComplete和onError方法。\nMono-异步的 0-1 结果\n这张图也来自官方文档，和上面 Flux 的区别就是，Mono 最多只能 emitted 一个元素。\n1Mono.just(&quot;glmapper&quot;).subscribe(System.out::println);\n\n小结通过上面两段小的代码来看，最直观的感受是，Flux 相当于一个 List，Mono 相当于 Optional。其实在编程中所有的结果我们都可以用 List 来 表示，但是当只返回一个或者没有结果时，用 Optional 可能会更精确些。\n\n\n\n\n\n\n\n\n\nOptional 相关概念可自行搜索 jdk Optional\n另外，Mono 和 Flux 都提供了一些工厂方法，用于创建相关的实例，这里简单罗列一下：\n123456789101112131415161718192021// 可以指定序列中包含的全部元素。创建出来的 Flux // 序列在发布这些元素之后会自动结束。Flux.just(&quot;glmapper&quot;, &quot;leishu&quot;);// 从一个Iterable 对象中创建 Flux 对象,当然还可以是数组、Stream对象等Flux.fromIterable(Arrays.asList(&quot;glmapper&quot;,&quot;leishu&quot;));// 创建一个只包含错误消息的序列。Flux.error(new IllegalStateException());// 创建一个包含了从 0 开始递增的 Long 对象的序列。其中包含的元素按照指定的间// 隔来发布。除了间隔时间之外，还可以指定起始元素发布之前的延迟时间。Flux.interval(Duration.ofMillis(100)).take(10);// 创建一个不包含任何消息通知的序列。Flux.never();// 创建一个不包含任何元素，只发布结束消息的序列。Flux.empty(); // 创建包含从 start 起始的 count 个数量的 Integer 对象的序列Flux.range(int start, int count);// Mono 同上Mono.empty();Mono.never();Mono.just(&quot;glmapper&quot;);Mono.error(new IllegalStateException());\n\n上面的这些静态方法适合于简单的序列生成，当序列的生成需要复杂的逻辑时，则应该使用 generate() 或 create() 方法。\n一些概念\nOperator：Operator 是一系列函数式的便捷操作，可以链式调用。所有函数调用基本都 是 Reactor 的 Operator ，比如 just，map，flatMap，filter 等。\nProcessor：上面从 Processor 的接口定义可以看出，它既是一个 Subscriber，又是一个 Publisher；Processor 夹在第一个 Publisher 和最后一个 Subscriber 中间，对数据进行处理。有点类似 stream 里的 map，filter 等方法。具体在数据流转中， Processor 以 Subscriber 的身份订阅 Publisher 接受数据，又以 Publisher 的方式接受其它 Subscriber 的订阅，它从自己订阅的 Publisher 收到数据后，做一些处理，然后转发给订阅它的 Subscriber。\nback pressure：背压。对 MQ 有了解的应该清楚，消息积压一般是在消费端，也就是说生产端只负责生产，并不会关心消费端的消费能力，这样就到导致 pressure 积压在消费端，这个是正向的。从上面对 Reactor 中的一些了解，Subscriber 是主动向 Publisher 请求的，这样当消费端消费的速度没有生产者快时，这些消息还是积压在生产端；这种好处就是生产者可以根据实际情况适当的调整生产消息的速度。\nHot VS Cold ：参考 Hot VS Cold\n\n核心调用过程Reactor 的核心调用过程大致可以分为图中的几个阶段\n\n声明：无论是使用 just 或者其他什么方式创建反应式流，这个过程都可以称之为声明，因为此时这些代码不会被实际的执行。\nsubscribe：当调用 subscribe 时，整个执行过程便进入 subscribe 阶段，经过一系列的调用之后，subscribe 动作会代理给具体的 Flux 来实现。\nonSubscribe：onSubscribe 阶段指的是 Subscriber#onSubscribe 方法被依次调用的阶段。这个阶段会让各 Subscriber 知道 subscribe 方法已被触发，真正的处理流程马上就要开始。\nrequest：onSubscribe 阶段是表示订阅动作的方式，让各 Subscriber 知悉，准备开始处理数据。当最终的 Subscriber 做好处理数据的准备之后，它便会调用 Subscription 的 request 方法请求数据。\nonNext：通过调用 Subscriber 的 onNext 方法，进行真正的响应式的数据处理。\nonComplete：成功的终端状态，没有进一步的事件将被发送。\nonError：错误的终端状态（和 onComplete 一样，当发生时，后面的将不会在继续执行）。\n\n消息处理当需要处理 Flux 或 Mono 中的消息时，可以通过 subscribe 方法来添加相应的订阅逻辑。在调用 subscribe 方法时可以指定需要处理的消息类型。可以只处理其中包含的正常消息，也可以同时处理错误消息和完成消息。\n通过 subscribe() 方法处理正常和错误消息123Flux.just(1, 2)   .concatWith(Mono.error(new IllegalStateException()))   .subscribe(System.out::println, System.err::println);\n结果：\n12312java.lang.IllegalStateException\n正常的消息处理相对简单。当出现错误时，有多种不同的处理策略:\n\n通过 onErrorReturn() 方法返回一个默认值1234Flux.just(1, 2)    .concatWith(Mono.error(new IllegalStateException()))    .onErrorReturn(0)    .subscribe(System.out::println);\n\n结果：\n123120\n\n通过 onErrorResume()方法来根据不同的异常类型来选择要使用的产生元素的流12345678910Flux.just(1, 2)       .concatWith(Mono.error(new IllegalArgumentException()))       .onErrorResume(e -&gt; &#123;           if (e instanceof IllegalStateException) &#123;               return Mono.just(0);           &#125; else if (e instanceof IllegalArgumentException) &#123;               return Mono.just(-1);           &#125;           return Mono.empty();           &#125;).subscribe(System.out::println);\n结果：12312-1\n通过 retry 操作符来进行重试，重试的动作是通过重新订阅序列来实现的。在使用 retry 操作符时可以指定重试的次数。1234Flux.just(1, 2)    .concatWith(Mono.error(new IllegalStateException()))    .retry(1)    .subscribe(System.out::println);\n结果：123456781212Exception in thread &quot;main&quot; reactor.core.Exceptions$ErrorCallbackNotImplemented: java.lang.IllegalStateExceptionCaused by: java.lang.IllegalStateException\tat com.glmapper.bridge.boot.reactor.SimpleTest.testFluxSub(SimpleTest.java:75)\tat com.glmapper.bridge.boot.reactor.SimpleTest.main(SimpleTest.java:23)\n\n调度器 Scheduler在 Reactor 中，执行模式以及执行过程取决于所使用的 Scheduler，Scheduler 是一个拥有广泛实现类的抽象接口，Schedulers 类提供的静态方法用于达成如下的执行环境：\n\n当前线程（Schedulers.immediate()）12345Schedulers.immediate().schedule(()-&gt;&#123;   System.out.println(Thread.currentThread().getName()+&quot;-&quot;+11);&#125;);// main-11\n可重用的单线程（Schedulers.single()）。注意，这个方法对所有调用者都提供同一个线程来使用， 直到该调度器（Scheduler）被废弃。如果你想使用专一的线程，就对每一个调用使用 Schedulers.newSingle()。12345Schedulers.single().schedule(()-&gt;&#123;    System.out.println(Thread.currentThread().getName()+&quot;-&quot;+11);&#125;);// single-1-11\n弹性线程池（Schedulers.elastic()。它根据需要创建一个线程池，重用空闲线程。线程池如果空闲时间过长 （默认为 60s）就会被废弃。对于 I&#x2F;O 阻塞的场景比较适用。 Schedulers.elastic() 能够方便地给一个阻塞 的任务分配它自己的线程，从而不会妨碍其他任务和资源。12345Schedulers.elastic().schedule(()-&gt;&#123;    System.out.println(Thread.currentThread().getName()+&quot;-&quot;+11);&#125;);// elastic-2-11\n固定大小线程池（Schedulers.parallel()）。所创建线程池的大小与 CPU 个数等同12345Schedulers.parallel().schedule(()-&gt;&#123;    System.out.println(Thread.currentThread().getName()+&quot;-&quot;+11);&#125;);// parallel-1-11\n基于现有的 ExecutorService 创建 Scheduler123456ExecutorService executorService = Executors.newSingleThreadExecutor();Schedulers.fromExecutorService(executorService).schedule(()-&gt;&#123;    System.out.println(Thread.currentThread().getName()+&quot;-&quot;+11);&#125;);        // pool-4-thread-1-11\n基于 newXXX 方法来创建调度器12345Schedulers.newElastic(&quot;test-elastic&quot;).schedule(()-&gt;&#123;    System.out.println(Thread.currentThread().getName()+&quot;-&quot;+11);&#125;);// test-elastic-4-11\n\n一些操作符默认会使用一个指定的调度器（通常也允许开发者调整为其他调度器）例如， 通过工厂方法 Flux.interval(Duration.ofMillis(100)) 生成的每 100ms 打点一次的 Flux， 默认情况下使用的是 Schedulers.parallel()，下边的代码演示了如何将其装换为 Schedulers.single()\n1234Flux&lt;String&gt; intervalResult = Flux.interval(Duration.ofMillis(100),        Schedulers.newSingle(&quot;test&quot;))        .map(i -&gt; Thread.currentThread().getName() +&quot;@&quot;+i);        intervalResult.subscribe(System.out::println);\n结果：\n123456test-1@0test-1@1test-1@2test-1@3test-1@4// 省略\n\npublishOn 和 subscribeOnReactor 提供了两种在响应式链中调整调度器 Scheduler 的方法：publishOn 和 subscribeOn。 它们都接受一个 Scheduler 作为参数，从而可以改变调度器。但是 publishOn 在链中出现的位置是有讲究的，而 subscribeOn 则无所谓。\n\npublishOn 的用法和处于订阅链（subscriber chain）中的其他操作符一样。它将上游 信号传给下游，同时执行指定的调度器 Scheduler 的某个工作线程上的回调。 它会 改变后续的操作符的执行所在线程 （直到下一个 publishOn 出现在这个链上）\nsubscribeOn 用于订阅（subscription）过程，作用于那个向上的订阅链（发布者在被订阅 时才激活，订阅的传递方向是向上游的）。所以，无论你把 subscribeOn 至于操作链的什么位置， 它都会影响到源头的线程执行环境（context）。 但是，它不会影响到后续的 publishOn，后者仍能够切换其后操作符的线程执行环境。\n\n1234567891011Flux.create(sink -&gt; &#123;        sink.next(Thread.currentThread().getName());        sink.complete();    &#125;)    .publishOn(Schedulers.single())    .map(x -&gt; String.format(&quot;[%s] %s&quot;, Thread.currentThread().getName(), x))    .publishOn(Schedulers.elastic())    .map(x -&gt; String.format(&quot;[%s] %s&quot;, Thread.currentThread().getName(), x))    .subscribeOn(Schedulers.parallel())    .toStream()    .forEach(System.out::println);\n结果：\n1[elastic-2] [single-1] parallel-1\n上面这段代码使用 create() 方法创建一个新的 Flux 对象，其中包含唯一的元素是当前线程的名称。\n接着是两对 publishOn() 和 map()方法，其作用是先切换执行时的调度器，再把当前的线程名称作为前缀添加。\n最后通过 subscribeOn()方法来改变流产生时的执行方式。\n最内层的线程名字 parallel-1 来自产生流中元素时使用的 Schedulers.parallel()调度器，中间的线程名称 single-1 来自第一个 map 操作之前的 Schedulers.single() 调度器，最外层的线程名字 elastic-2 来自第二个 map 操作之前的 Schedulers.elastic()调度器。\n\n\n\n\n\n\n\n\n\n先到这里，剩下的想到再补充…\n参考\nhttps://projectreactor.io/docs/core/release/reference/\nhttps://htmlpreview.github.io/?https://github.com/get-set/reactor-core/blob/master-zh/src/docs/index.html#about-doc\nhttps://www.ibm.com/developerworks/cn/java/j-cn-with-reactor-response-encode/index.html?lnk=hmhm\n\n","slug":"java/java-base-reactor-intro","date":"2019-08-24T10:48:19.000Z","categories_index":"JAVA","tags_index":"java,reactor","author_index":"glmapper"},{"id":"099cbe91c3412d78be7c6de51de68c1a","title":"聊一聊-JAVA 泛型中的通配符 T，E，K，V，？","content":"前言Java 泛型（generics）是 JDK 5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许开发者在编译时检测到非法的类型。\n泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。\n\n\n\n泛型带来的好处在没有泛型的情况的下，通过对类型 Object 的引用来实现参数的“任意化”，“任意化”带来的缺点是要做显式的强制类型转换，而这种转换是要求开发者对实际参数类型可以预知的情况下进行的。对于强制类型转换错误的情况，编译器可能不提示错误，在运行的时候才出现异常，这是本身就是一个安全隐患。\n那么泛型的好处就是在编译的时候能够检查类型安全，并且所有的强制转换都是自动和隐式的。\n12345678910111213141516171819202122232425262728293031public class GlmapperGeneric&lt;T&gt; &#123;\t\tprivate T t;    public void set(T t) &#123; this.t = t; &#125;    public T get() &#123; return t; &#125;      public static void main(String[] args) &#123;        // do nothing    &#125;  /**    * 不指定类型    */  public void noSpecifyType()&#123;    GlmapperGeneric glmapperGeneric = new GlmapperGeneric();    glmapperGeneric.set(&quot;test&quot;);    // 需要强制类型转换    String test = (String) glmapperGeneric.get();    System.out.println(test);  &#125;  /**    * 指定类型    */  public void specifyType()&#123;    GlmapperGeneric&lt;String&gt; glmapperGeneric = new GlmapperGeneric();    glmapperGeneric.set(&quot;test&quot;);    // 不需要强制类型转换    String test = glmapperGeneric.get();    System.out.println(test);  &#125;&#125;\n\n\n上面这段代码中的 specifyType 方法中 省去了强制转换，可以在编译时候检查类型安全，可以用在类，方法，接口上。\n泛型中通配符我们在定义泛型类，泛型方法，泛型接口的时候经常会碰见很多不同的通配符，比如 T，E，K，V 等等，这些通配符又都是什么意思呢？\n常用的 T，E，K，V，？本质上这些个都是通配符，没啥区别，只不过是编码时的一种约定俗成的东西。比如上述代码中的 T ，我们可以换成 A-Z 之间的任何一个 字母都可以，并不会影响程序的正常运行，但是如果换成其他的字母代替 T ，在可读性上可能会弱一些。通常情况下，T，E，K，V，？ 是这样约定的：\n\n？ 表示不确定的 java 类型\nT (type) 表示具体的一个java类型\nK V (key value) 分别代表java键值中的Key Value\nE (element) 代表Element\n\n？ 无界通配符先从一个小例子看起，原文在 这里 。\n我有一个父类 Animal 和几个子类，如狗、猫等，现在我需要一个动物的列表，我的第一个想法是像这样的：\n1List&lt;Animal&gt; listAnimals\n\n但是老板的想法确实这样的：\n1List&lt;? extends Animal&gt; listAnimals\n\n为什么要使用通配符而不是简单的泛型呢？通配符其实在声明局部变量时是没有什么意义的，但是当你为一个方法声明一个参数时，它是非常重要的。\n12345678910111213141516171819202122232425static int countLegs (List&lt;? extends Animal &gt; animals ) &#123;    int retVal = 0;    for ( Animal animal : animals )    &#123;        retVal += animal.countLegs();    &#125;    return retVal;&#125;static int countLegs1 (List&lt; Animal &gt; animals )&#123;    int retVal = 0;    for ( Animal animal : animals )    &#123;        retVal += animal.countLegs();    &#125;    return retVal;&#125;public static void main(String[] args) &#123;    List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;(); \t// 不会报错    countLegs( dogs );\t// 报错    countLegs1(dogs);&#125;\n\n当调用 countLegs1 时，就会飘红，提示的错误信息如下：\n\n所以，对于不确定或者不关心实际要操作的类型，可以使用无限制通配符（尖括号里一个问号，即 &lt;?&gt; ），表示可以持有任何类型。像 countLegs 方法中，限定了上届，但是不关心具体类型是什么，所以对于传入的 Animal 的所有子类都可以支持，并且不会报错。而 countLegs1 就不行。\n上界通配符 &lt; ? extends E&gt;\n\n\n\n\n\n\n\n\n上届：用 extends 关键字声明，表示参数化的类型可能是所指定的类型，或者是此类型的子类。\n在类型参数中使用 extends 表示这个泛型中的参数必须是 E 或者 E 的子类，这样有两个好处：\n\n如果传入的类型不是 E 或者 E 的子类，编译不成功\n泛型中可以使用 E 的方法，要不然还得强转成 E 才能使用\n\n123456private &lt;K extends A, E extends B&gt; E test(K arg1, E arg2)&#123;    E result = arg2;    arg2.compareTo(arg1);    //.....    return result;&#125;\n\n\n\n\n\n\n\n\n\n\n类型参数列表中如果有多个类型参数上限，用逗号分开\n下界通配符 &lt; ? super E&gt;\n\n\n\n\n\n\n\n\n下界: 用 super 进行声明，表示参数化的类型可能是所指定的类型，或者是此类型的父类型，直至 Object\n在类型参数中使用 super 表示这个泛型中的参数必须是 E 或者 E 的父类。\n123456789101112131415private &lt;T&gt; void test(List&lt;? super T&gt; dst, List&lt;T&gt; src)&#123;    for (T t : src) &#123;        dst.add(t);    &#125;&#125;public static void main(String[] args) &#123;    List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;();    List&lt;Animal&gt; animals = new ArrayList&lt;&gt;();    new Test3().test(animals,dogs);&#125;// Dog 是 Animal 的子类class Dog extends Animal &#123;&#125;\n\ndst 类型 “大于等于” src 的类型，这里的“大于等于”是指 dst 表示的范围比 src 要大，因此装得下 dst 的容器也就能装 src 。\n？ 和 T 的区别\n？和 T 都表示不确定的类型，区别在于我们可以对 T 进行操作，但是对 ？ 不行，比如如下这种 ：\n12345// 可以T t = operate();// 不可以？ car = operate();\n\n简单总结下：\nT 是一个 确定的 类型，通常用于泛型类和泛型方法的定义，？是一个 不确定 的类型，通常用于泛型方法的调用代码和形参，不能用于定义类和泛型方法。\n区别1：通过 T 来 确保 泛型参数的一致性1234567// 通过 T 来 确保 泛型参数的一致性public &lt;T extends Number&gt; voidtest(List&lt;T&gt; dest, List&lt;T&gt; src)//通配符是 不确定的，所以这个方法不能保证两个 List 具有相同的元素类型public voidtest(List&lt;? extends Number&gt; dest, List&lt;? extends Number&gt; src)\n\n像下面的代码中，约定的 T 是 Number 的子类才可以，但是申明时是用的 String ，所以就会飘红报错。\n\n不能保证两个 List 具有相同的元素类型的情况\n1234GlmapperGeneric&lt;String&gt; glmapperGeneric = new GlmapperGeneric&lt;&gt;();List&lt;String&gt; dest = new ArrayList&lt;&gt;();List&lt;Number&gt; src = new ArrayList&lt;&gt;();glmapperGeneric.testNon(dest,src);\n\n上面的代码在编译器并不会报错，但是当进入到 testNon 方法内部操作时（比如赋值），对于 dest 和 src 而言，就还是需要进行类型转换。\n区别2：类型参数可以多重限定而通配符不行\n使用 &amp; 符号设定多重边界（Multi Bounds)，指定泛型类型 T 必须是 MultiLimitInterfaceA 和 MultiLimitInterfaceB 的共有子类型，此时变量 t 就具有了所有限定的方法和属性。对于通配符来说，因为它不是一个确定的类型，所以不能进行多重限定。\n区别3：通配符可以使用超类限定而类型参数不行类型参数 T 只具有 一种 类型限定方式：\n1T extends A\n\n但是通配符 ? 可以进行 两种限定：\n12? extends A? super A\n\nClass&lt;T&gt; 和 Class&lt;?&gt; 区别前面介绍了 ？ 和 T 的区别，那么对于，Class&lt;T&gt; 和 &lt;Class&lt;?&gt; 又有什么区别呢？Class&lt;T&gt; 和 Class&lt;?&gt;\n最常见的是在反射场景下的使用，这里以用一段发射的代码来说明下。\n1234// 通过反射的方式生成  multiLimit // 对象，这里比较明显的是，我们需要使用强制类型转换MultiLimit multiLimit = (MultiLimit)Class.forName(&quot;com.glmapper.bridge.boot.generic.MultiLimit&quot;).newInstance();\n\n对于上述代码，在运行期，如果反射的类型不是 MultiLimit 类，那么一定会报 java.lang.ClassCastException 错误。\n对于这种情况，则可以使用下面的代码来代替，使得在在编译期就能直接 检查到类型的问题：\n\nClass&lt;T&gt; 在实例化的时候，T 要替换成具体类。Class&lt;?&gt; 它是个通配泛型，? 可以代表任何类型，所以主要用于声明时的限制情况。比如，我们可以这样做申明：\n1234// 可以public Class&lt;?&gt; clazz;// 不可以，因为 T 需要指定类型public Class&lt;T&gt; clazzT;\n\n所以当不知道定声明什么类型的 Class 的时候可以定义一 个Class&lt;?&gt;。\n\n那如果也想 public Class&lt;T&gt; clazzT; 这样的话，就必须让当前的类也指定 T ，\n1234public class Test3&lt;T&gt; &#123;    public Class&lt;?&gt; clazz;    // 不会报错    public Class&lt;T&gt; clazzT;\n\n小结本文零碎整理了下 JAVA 泛型中的一些点，不是很全，仅供参考。如果文中有不当的地方，欢迎指正。\n参考\nJAVA泛型通配符T，E，K，V区别，网友回复：一文秒懂\n\n","slug":"java/java-base-generic-wildcard","date":"2019-08-19T10:13:57.000Z","categories_index":"JAVA","tags_index":"泛型,java","author_index":"glmapper"},{"id":"d490357e7c00b784e454d21c1c78f619","title":"一个 maven 插件打包问题的排查","content":"最近研究 sofa-ark 的插件机制时，发现当执行完 maven clean install -DskipTests 时，打在 target 目录下的 xxx.jar 与安装到本地仓库的 xxx.jar 大小不一致。\n\n\n\ntarget 目录下的插件大小  \n\n.m2 下的插件大小\n  \n\n\n其实一开始看到这种现象也是懵逼，同一个工程，同一次命令执行，但是得到的两个 jar 包大小差距巨大。那么对于这种问题，我想到的有两点：\n\ndebug 打包插件执行过程\n了解 maven 插件的生命周期\n\ndebug 打包插件执行过程这里需要借助 IDEA 中的远程 debug 能力来完成。目前有两个工程，一个是我们的主工程，工程名为上面截图中的 mq-client-ark-plugin ，另一个是打包插件的源码工程，如下图所示：\n\n那么下面就一步一步来完成远程 debug 的配置。\n1、使用 mvnDebug 命令开启 debug 模式在主工程 mq-client-ark-plugin 的根目录下执行  mvnDebug install（当然除了 install 之外，也可以是 compile、package、test、deploy 等）。\n\n当执行完 mvnDebug install 后，可以看到这个阻塞监听 8000 端口了。\n2、源码工程配置远程 debug在 idea 主界面找下下图的工具菜单，选择 Edit Configurations...打开配置面板之后，左上角 + 选择 Remote填写相关远程 debug 参数\n\n\nHost : 远程目标主机地址，因为之前 主工程也是本地启动的，所以这里就是 localhost\nPort : 远程目标主机开启的远程 debug 端口\n开启远程 debug 参数：-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=8000\n\n配置完成之后，执行 debug ，可以看下已经连接到了目标机器：\n\n在来看主工程这里，在源码工程没有执行上面的 debug 按钮之前，一直都是阻塞的，执行之后 maven 执行的生命周期开始了:\n如上图，因为在源码工程中打了断点，所以当执行到 sofa-ark-maven-plugin 插件时阻塞了。\n从 maven 执行的生命周期找出问题根源上面已经搞定了对目标插件源码的 debug 模式的开启，那么下面就是对插件代码进行 debug 操作。节省篇幅，这里直接将断点放在目标代码行位置：\n\n分析这段代码\n\n\n1、获取到项目的 Artifact ,此时 Artifact 的 file 为：\n2、重新设置的 File\n3、重新设置了 artifact\n\n\n如果单从上面 debug 来看，其实很难解释开篇的那个问题。那么这里在回过头来看下 主工程的 maven 执行日志：\n\n如上图中圈红的部分，代表 maven install 所经历的所有阶段。可以看到 sofa-ark-plugin-maven-plugin 是在  maven-install-plugin 后面，那这意味着什么呢？\n我们知道在 target 目录下得到的 xxx.jar 是打包阶段的产物，而 .m2 下面的是 install 的产物。\n\n\n\n\n\n\n\n\n\n当然这里没有涉及到 deploy ，deploy 是 install 之后的操作，比如发布到远程仓库。\n现在再来看，因为 sofa-ark-plugin-maven-plugin 在执行 install 插件之前将 目标文件给替换了，所以导致打包生成的 target 目录下的 xxx.jar 和 安装到本地仓库的 xxx.jar 不一致。\n小结本文记录了日常的一个问题排查过程，包括两个小点，一个是如何去 debug maven 的插件，另外一个是简单了解下 maven 打包的生命周期。\n\n\n\n\n\n\n\n\n\n关于 maven 打包的生命周期的代码没有具体研究过，不过这里可以大概猜测下，就是 maven 在执行命令时，有个类似于中央控制器的东西，通过解析 maven 命令得到一个 LifeCycle 或者 一个 Pipeline （LifeCycle 或者 Pipeline 实际上就是组装了一系列的插件）。然后 LifeCycle 或者 Pipeline 启动执行，遍历插件，依次执行插件的 execute 方法。\n","slug":"maven/maven-plugin-debug-problem","date":"2019-07-23T10:22:50.000Z","categories_index":"maven","tags_index":"maven,maven plugin,maven debug","author_index":"glmapper"},{"id":"e78ea5ad7948adf87206a77ac7badf59","title":"聊一聊 JAR 文件和 MANIFEST.MF","content":"在 JAVA 语言这个圈子里面摸爬滚打，除了对于语言层面和框架层面的学习之外，有一些东西它一直存在，但是确没有对它们有足够的重视，因为都觉得它是理所当然，比如 JAR 是个什么？\n提到 JAR，最先可能想到的就是依赖，比如 fastjson.jar ，它可以作为依赖在项目中来引用，但是不能通过 java -jar 来执行，这种就是非可执行的 JAR。另外一种，比如我们项目打包之后生成的 JAR （当然也可能是 war），我们可以通过 java -jar 来运行程序，我们把它称之为可执行的 JAR。\n\n\nJAR 作用大体可以分为以下几种：\n\n用于发布和使用类库\n作为应用程序和扩展的构建单元\n作为组件、applet 或者插件程序的部署单位\n用于打包与组件相关联的辅助资源\n\n基本概念JAR 文件是一种归档文件，以 ZIP 格式构建，以 .jar 为文件扩展名。用户可以使用 JDK 自带的 jar 命令创建或提取 JAR 文件。也可以使用其他 zip 压缩工具，不过压缩时 zip 文件头里的条目顺序很重要，因为 MANIFEST 文件常需放在首位。JAR 文件内的文件名是 Unicode 文本。\nJAR 文件（Java 归档，英语：Java Archive）是一种软件包文件格式，通常用于聚合大量的 Java 类文件、相关的元数据和资源（文本、图片等）文件到一个文件，以便分发 Java 平台应用软件或库。\n\n\n\n\n\n\n\n\n\n以上来自维基百科 \nJAR 文件格式提供了许多优势和功能，其中很多是传统的压缩格式如 ZIP 或者 TAR 所没有提供的。它们包括：\n\n安全性：可以对 JAR 文件内容加上数字化签名。这样，能够识别签名的工具就可以有选择地为您授予软件安全特权，这是其他文件做不到的，它还可以检测代码是否被篡改过。\n减少下载时间：如果一个 applet 捆绑到一个 JAR 文件中，那么浏览器就可以在一个 HTTP 事务中下载这个 applet 的类文件和相关的资源，而不是对每一个文件打开一个新连接。\n压缩：JAR 格式允许您压缩文件以提高存储效率。\n传输平台扩展。Java 扩展框架 (Java Extensions Framework) 提供了向 Java 核心平台添加功能的方法，这些扩展是用 JAR 文件打包的 (Java 3D 和 JavaMail 就是由 Sun 开发的扩展例子 )。\n包密封：存储在 JAR 文件中的包可以选择进行 密封，以增强版本一致性和安全性。密封一个包意味着包中的所有类都必须在同一 JAR 文件中找到。\n包版本控制：一个 JAR 文件可以包含有关它所包含的文件的数据，如厂商和版本信息。\n可移植性：处理 JAR 文件的机制是 Java 平台核心 API 的标准部分。\n\nJAR 文件格式这里分别给出两个 JAR 的解压之后的示例\n普通的 JAR 解压之后的文件目录以 fastjson 为例：\n123456789101112131415161718192021222324.├── META-INF│   ├── LICENSE.txt│   ├── MANIFEST.MF│   ├── NOTICE.txt│   ├── maven│   │   └── com.alibaba│   │       └── fastjson│   │           ├── pom.properties│   │           └── pom.xml│   └── services│       ├── javax.ws.rs.ext.MessageBodyReader│       ├── javax.ws.rs.ext.MessageBodyWriter│       ├── javax.ws.rs.ext.Providers│       └── org.glassfish.jersey.internal.spi.AutoDiscoverable└── com    └── alibaba        └── fastjson            ├── JSON.class            ├── JSONArray.class            ├── JSONAware.class            ├── JSONException.class            ├── JSONObject.class            ....省略\n\n\n可执行的 jar (以 SpringBoot 的 FAT JAR 为例）这个 jar 是从 start.spring.io 上下载下来的一个最简单的 demo 打包来的\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859├── BOOT-INF│   ├── classes│   │   ├── application.properties│   │   └── com│   │       └── example   # 应用的.class 文件目录│   │           └── demo│   │               └── DemoApplication.class│   └── lib # 这里存放的是应用的 Maven 依赖的jar包文件│       ├── javax.annotation-api-1.3.2.jar│       ├── jul-to-slf4j-1.7.26.jar│       ├── log4j-api-2.11.2.jar│       ├── log4j-to-slf4j-2.11.2.jar│       ├── logback-classic-1.2.3.jar│       ├── logback-core-1.2.3.jar│       ├── slf4j-api-1.7.26.jar│       ├── snakeyaml-1.23.jar│       ├── spring-aop-5.1.8.RELEASE.jar│       ├── spring-beans-5.1.8.RELEASE.jar│       ├── spring-boot-2.1.6.RELEASE.jar│       ├── spring-boot-autoconfigure-2.1.6.RELEASE.jar│       ├── spring-boot-starter-2.1.6.RELEASE.jar│       ├── spring-boot-starter-logging-2.1.6.RELEASE.jar│       ├── spring-context-5.1.8.RELEASE.jar│       ├── spring-core-5.1.8.RELEASE.jar│       ├── spring-expression-5.1.8.RELEASE.jar│       └── spring-jcl-5.1.8.RELEASE.jar├── META-INF│   ├── MANIFEST.MF│   └── maven│       └── com.example│           └── demo│               ├── pom.properties│               └── pom.xml└── org    └── springframework        └── boot            └── loader #存放的是 Spring boot loader 的 class 文件                ├── ExecutableArchiveLauncher.class                ├── JarLauncher.class                ├── LaunchedURLClassLoader$UseFastConnectionExceptionsEnumeration.class                ├── LaunchedURLClassLoader.class                ├── Launcher.class                ├── MainMethodRunner.class                ├── PropertiesLauncher$1.class                ├── PropertiesLauncher$ArchiveEntryFilter.class                ├── PropertiesLauncher$PrefixMatchingArchiveFilter.class                ├── PropertiesLauncher.class                ├── WarLauncher.class                ├── archive                │   ├── Archive$Entry.class                │   ├── ...                ├── data                │   ├── RandomAccessData.class                │   ├── ...                ├── jar                │   ├── AsciiBytes.class                │   ├── ...                └── util                    └── SystemPropertyUtils.class\n\nMETA-INF大多数 JAR 文件包含一个 META-INF 目录，它用于存储包和扩展的配置数据，如安全性和版本信息。Java 2 平台（标准版【J2SE】）识别并解释 META-INF 目录中的下述文件和目录，以便配置应用程序、扩展和类装载器：\n\nMANIFEST.MF：这个 manifest 文件定义了与扩展和包相关的数据。\n通过 MAVEN 插件打包进来的文件比如：\nmaven\nservices ： 存储所有服务提供程序配置文件\n\n\n其他的还有一些不常看到的：\nINDEX.LIST ：这个文件由 jar工具的新选项 -i生成，它包含在应用程序或者扩展中定义的包的位置信息。它是 JarIndex 实现的一部分，并由类装载器用于加速类装载过程。 \n.SF：这是 JAR 文件的签名文件\n.DSA：与签名文件相关联的签名程序块文件，它存储了用于签名 JAR 文件的公共签名。\nLICENSE.txt ：证书信息\nNOTICE.txt ： 公告信息\n\n\n\n可执行的 JAR 可以执行的 JAR 与 普通的 JAR 最直接的区别就是能否通过 java -jar 来执行。\n\n\n\n\n\n\n\n\n\n一个 可执行的 jar文件是一个自包含的 Java 应用程序，它存储在特别配置的 JAR 文件中，可以由 JVM 直接执行它而无需事先提取文件或者设置类路径。要运行存储在非可执行的 JAR 中的应用程序，必须将它加入到您的类路径中，并用名字调用应用程序的主类。但是使用可执行的 JAR 文件，我们可以不用提取它或者知道主要入口点就可以运行一个应用程序。可执行 JAR 有助于方便发布和执行 Java 应用程序\n 一个可执行的 JAR 必须通过 menifest 文件的头引用它所需要的所有其他从属 JAR。如果使用了 -jar选项，那么环境变量 CLASSPATH 和在命令行中指定的所有类路径都被 JVM 所忽略。\nMANIFEST.MF 文件当我们用 JAR 命令打完包后，会在根目录下面创建 META-INF 目录，该目录下面会有一些对该 JAR 包信息的描述，其中肯定会有一个 MANIFEST.MF 文件，该文件包含了该 JAR 包的版本、创建人和类搜索路径等信息。\n\nFASTJSON jar 中的 MANIFEST.MF 文件\n  12345Manifest-Version: 1.0              # 用来定义manifest文件的版本Archiver-Version: Plexus Archiver  # 详见 http://codehaus-plexus.github.io/plexus-archiver/Built-By: wenshao                  # 构建者Created-By: Apache Maven 3.5.0  #  # 声明该文件的生成者，一般该属性是由 jar 命令行工具生成的Build-Jdk: 1.8.0_162               # 基于构建的 JDK 版本\n\nSpringBoot demo 的 MANIFEST.MF 文件\n  12345678910Manifest-Version: 1.0Implementation-Title: demo                     # 定义了扩展实现的标题Implementation-Version: 0.0.1-SNAPSHOT         # 定义扩展实现的版本Start-Class: com.example.demo.DemoApplication  # 启动类Spring-Boot-Classes: BOOT-INF/classes/         # 编译之后的 class 文件目录Spring-Boot-Lib: BOOT-INF/lib/                 # 当前工程依赖的 jar 包目录Build-Jdk-Spec: 1.8                            # 指定的 JDK 版本Spring-Boot-Version: 2.1.6.RELEASE             # SpringBoot 版本Created-By: Maven Archiver 3.4.0             Main-Class: org.springframework.boot.loader.JarLauncher  # Main 函数\n\n在 Java 平台中， MANIFEST 文件是 JAR 归档中所包含的特殊文件，MANIFEST 文件被用来定义扩展或文件打包相关数据。\nMANIFEST 文件作为一个元数据文件，它包含了不同部分中的 k-v 对数据。\n如果一个 JAR 文件被当作可执行文件，则其中的 MANIFEST 文件需要指出该程序的主类文件，如上面案例中的 SpringBoot demo 的那个 jar 中的MANIFEST 文件所示 \nMANIFEST 作用从 MANIFEST 文件中提供的信息大概可以了解到其基本作用\n\nJAR 包基本信息描述\nMain-Class 指定程序的入口，这样可以直接用java -jar xxx.jar来运行程序\nClass-Path 指定jar包的依赖关系，class loader会依据这个路径来搜索class\n\n获取 MANIFEST.MFJDK 中提供了可以获取 jar 包中 MANIFEST.MF 文件信息的工具，可以通过 java.util.jar 这个类库来获取。\n12345678910111213JarFile jar = new JarFile(new File(&quot;/Users/xxx/Documents/test/demo/target/demo-0.0.1-SNAPSHOT.jar&quot;));Manifest manifest = jar.getManifest();Attributes mainAttributes = manifest.getMainAttributes();for(Map.Entry&lt;Object, Object&gt; attrEntry : mainAttributes.entrySet())&#123;    System.out.println(&quot;main\\t&quot;+attrEntry.getKey()+&quot;:&quot;+attrEntry.getValue());&#125;Map&lt;String, Attributes&gt; entries = manifest.getEntries();for(Map.Entry&lt;String, Attributes&gt; entry : entries.entrySet()) &#123;    Attributes values = entry.getValue();    for (Map.Entry&lt;Object, Object&gt; attrEntry : values.entrySet()) &#123;        System.out.println(attrEntry.getKey() + &quot;:&quot; + attrEntry.getValue());    &#125;&#125;\n\n执行结果为：\n1234567891011main\tImplementation-Title:demomain\tImplementation-Version:0.0.1-SNAPSHOTmain\tStart-Class:com.example.demo.DemoApplicationmain\tSpring-Boot-Classes:BOOT-INF/classes/main\tSpring-Boot-Lib:BOOT-INF/lib/main\tBuild-Jdk-Spec:1.8main\tSpring-Boot-Version:2.1.6.RELEASEmain\tCreated-By:Maven Archiver 3.4.0main\tManifest-Version:1.0main\tMain-Class:org.springframework.boot.loader.JarLauncher\n\nJar 文件和 Manifest 在 java 中的定义下面为 JarFile 的定义，从代码就可以看出，前面我们所介绍的 Jar 是以 ZIP 格式构建一种归档文件，因为它是 ZipFile 的子类。\n1234567891011121314151617181920public class JarFile extends ZipFile &#123;    private SoftReference&lt;Manifest&gt; manRef;    private JarEntry manEntry;    private JarVerifier jv;    private boolean jvInitialized;    private boolean verify;    //指示是否存在Class-Path属性（仅当hasCheckedSpecialAttributes为true时才有效）    private boolean hasClassPathAttribute;    // 如果清单检查特殊属性，则为 true    private volatile boolean hasCheckedSpecialAttributes;    // 在SharedSecrets中设置JavaUtilJarAccess    static &#123;        SharedSecrets.setJavaUtilJarAccess(new JavaUtilJarAccessImpl());    &#125;    /**     * The JAR manifest file name.（JAR清单文件名）     */    public static final String MANIFEST_NAME = &quot;META-INF/MANIFEST.MF&quot;;    // 省略其他&#125;\n下面是 Manifest 类的定义，用来描述 JAR 的 清单文件。从其属性中也很好的观察到，其存储的就是 K-V 键值对数据。\n1234567public class Manifest implements Cloneable &#123;    // manifest main attributes    private Attributes attr = new Attributes();    // manifest entries    private Map&lt;String, Attributes&gt; entries = new HashMap&lt;&gt;();    // 省略其他&#125;\n\n小结JAR 格式远远超出了一种压缩格式，它有许多可以改进效率、安全性和组织 Java 应用程序的功能。因为这些功能已经建立在核心平台 – 包括编译器和类装载器 – 中了，所以开发人员可以利用 JAR 文件格式的能力简化和改进开发和部署过程。\n附：常见的 jar工具用法\n\n\n功能\n命令\n\n\n\n用一个单独的文件创建一个 JAR 文件\njar cf jar-file input-file…\n\n\n用一个目录创建一个 JAR 文件\njar cf jar-file dir-name\n\n\n创建一个未压缩的 JAR 文件\njar cf0 jar-file dir-name\n\n\n更新一个 JAR 文件\njar uf jar-file input-file…\n\n\n查看一个 JAR 文件的内容\njar tf jar-file\n\n\n提取一个 JAR 文件的内容\njar xf jar-file\n\n\n从一个 JAR 文件中提取特定的文件\njar xf jar-file archived-file…\n\n\n运行一个打包为可执行 JAR 文件的应用程序\njava -jar app.jar\n\n\n参考\nJAR 文件揭密\nJAR\nJAR File Specification\n\n","slug":"java/java-base-jar-manifest-intro","date":"2019-06-30T10:45:37.000Z","categories_index":"JAVA","tags_index":"java,JAR,MANIFEST.MF","author_index":"glmapper"},{"id":"d21c52642d3819d7c9e88653990f95af","title":"Linux 下安装 Mysql 数据库","content":"更新，Centos 7 离线安装 Mysql 5.7近期的一个项目，需要使用 MySQL 5.7，但是甲方所提供的机器是不能访问外网环境的，所以只能通过离线安装的方式来搞，这里大概记录一下，备忘。\n\nMySQL 5.7 Linux 安装包下载：https://dev.mysql.com/downloads/mysql/5.7.html\n\n选择 Linux - Generic -&gt; Compressed TAR Archive：(mysql-5.7.18-linux-glibc2.12-x86_64.tar.gz)，版本按需下载即可；下面是具体的安装过程。\n\n\n安装步骤查询并卸载系统自带的数据库 Mariadb123rpm -qa | grep mariadb## 如果有的话，返回的是这种： mariadb-libs-5.5.60-1.el7_5.x86_64rpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps\n\n创建用户和用户组为了数据库管理，对于安装的 MySQL 数据库，生产上我们都会建立一个 mysql用户和mysql用户组。\n123456789# 先检查mysql用户和用户组有没有被使用cat /etc/group | grep mysqlcat /etc/passwd | grep mysql# 添加 mysql 用户组groupadd mysql# 添加mysql用户并加入用户组useradd -g mysql mysql# 修改mysql用户的登陆密码(这里根据需要设置，可以略过)passwd mysql\n文件上传如果甲方提供了 访问 VPN ，那么则通过 VPN 建立连接；或者通过甲方提供的方式将文件上传到指定的机器上\n12345678# 解压安装包,解压后会有一个mysql-5.7.18-linux-glibc2.12-x86_64.tar.gz包tar -xvf mysql-5.7.18-linux-glibc2.5-x86_64.tar# 解压 mysql-5.7.18-linux-glibc2.5-x86_64.tar.gz包tar -zxvf mysql-5.7.18-linux-glibc2.5-x86_64.tar.gz# 此时会生成一个目录 mysql-5.7.18-linux-glibc2.5-x86_64，将其改名为 mysqlmv mysql-5.7.18-linux-glibc2.5-x86_64 mysql# 将 mysql 移到 /usr/local/mysqlmv mysql /usr/local/\n授权按照下面的操作执行\n1234567cd /usr/local/chown -R mysql mysql/chgrp -R mysql mysql/cd mysql/# 创建 data 目录 /usr/local/mysql/datamkdir datachown -R mysql:mysql data\n\n配置文件的创建和配置信息默认这个配置文件是不存在的，需要创建，并且填入配置信息；在 &#x2F;usr&#x2F;local&#x2F;mysql&#x2F; 目录下创建文件并编辑\n12cd /usr/local/mysql/vi my.cnf\n具体配置信息大致如下\n1234567891011121314151617181920[mysql]socket=/var/lib/mysql/mysql.sockdefault-character-set=utf8[mysqld]socket=/var/lib/mysql/mysql.sockport=3306basedir=/usr/local/mysqldatadir=/usr/local/mysql/datamax_connections=200character-set-server=utf8default-storage-engine=INNODBlower_case_table_names=1max_allowed_packet=32Mexplicit_defaults_for_timestamp=truesql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION[mysql.server]user=mysqlbasedir=/usr/local/mysql\n\n安装数据库进入 &#x2F;usr&#x2F;local&#x2F;mysql&#x2F; 目录下，执行安装操作。\n12# 执行安装命令bin/mysql_install_db --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/\n\n安装后，如下信息表示安装成功\n\n\n\n\n\n\n\n\n\n2023-03-23 14:32:16 [WARNING] mysql_install_db is deprecated. Please consider switching to mysqld –initialize2023-03-23 14:32:20 [WARNING] The bootstrap log isn’t empty:2023-03-23 14:32:20 [WARNING] 2023-03-23T06:32:16.437877Z 0 [Warning] –bootstrap is deprecated. Please consider using –initialize instead2023-03-23T06:32:16.438432Z 0 [Warning] Changed limits: max_open_files: 1024 (requested 5000)2023-03-23T06:32:16.438439Z 0 [Warning] Changed limits: table_open_cache: 431 (requested 2000)\n安装成功后设置文件及目录权限：\n1234# 在 /usr/local/mysql 目录下执行cp ./support-files/mysql.server /etc/init.d/mysqldchown 777 my.cnfchmod +x /etc/init.d/mysqld\n启动 mysql\n\n\n\n\n\n\n\n\n&#x2F;etc&#x2F;init.d&#x2F;mysqld restart\n我的机器上是出现了如下的报错\n1234 ERROR! MySQL server PID file could not be found!Starting MySQL.Logging to &#x27;/usr/local/mysql/data/localhost.localdomain.err&#x27;.2023-03-23T06:33:05.379438Z mysqld_safe Directory &#x27;/var/lib/mysql&#x27; for UNIX socket file don&#x27;t exists. ERROR! The server quit without updating PID file (/usr/local/mysql/data/localhost.localdomain.pid).\n\n如果 &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;localhost.localdomain.err 这个文件存在，就进去看一下具体原因，如果没有就按照以下步骤执行。\n12345# 创建 /var/lib/mysql/cd /var/lib/mkdir mysql# 提供读写的权限chmod 777 /var/lib/mysql\n\n配置环境变量，在配置文件中 export PATH=$PATH:/usr/local/mysql/bin\n1234# 修改配置文件 /etc/profilevi /etc/profile# 立即生效source /etc/profile\n然后重新启动即可。\n获取 mysql 安装后的初始密码1234[root@localhost mysql]# cat /root/.mysql_secret# Password set for user &#x27;root@localhost&#x27; at 2023-03-23 14:32:16# 这个就是对应的初始密码，随机生成的cHx#-%,zRho!  \n\n登录 mysql 遇到的问题123mysql -uroot -p# 此时输入密码后可能出现下面的问题Can&#x27;t connect to local MySQL server through socket &#x27;/tmp/mysql.sock&#x27;\n解决方案:1、首先保证在 my.cnf 文件中 socket 的配置如下：\n1234...[mysqld]socket = /var/lib/mysql/mysql.sock...\n2、对 &#x2F;tmp&#x2F;mysql.sock 和 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock 建立软连接\n1ln -s /var/lib/mysql/mysql.sock /tmp/mysql.sock\n修改密码123# 执行语句如下ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;your password&#x27;;flush privileges;\n\n添加远程访问权限12345678910111213141516# 切换到 mysql 数据库use mysql;# 更新权限update user set host=&#x27;%&#x27; where user = &#x27;root&#x27;;#查询一下是否修改成功select host,user from user;# 结果如下表示成功，root用户的host已经修改为&#x27;%&#x27;--+-----------+---------------+--| host      | user          |--+-----------+---------------+--| %         | root          |--| localhost | mysql.session |--| localhost | mysql.sys     |--+-----------+---------------+# 上面的修改结束后，退出数据库，重启数据库服务生效/etc/init.d/mysqld restart\n\n设置开机自启动服务123456# 将mysqld服务加入到系统服务chkconfig --level 35 mysqld on# 检查mysqld服务是否已经生效chkconfig --list mysqld# 增加mysqld服务控制脚本执行权限chmod +x /etc/init.d/mysqld\n\n此时如果通过 远程访问还是访问不通，则可能是因为防火墙的问题；这里有两种解决办法\n\n直接关闭防火墙1systemctl stop firewalld\n开通防火墙，放开对 3306 的拦截1firewalld-cmd --zone=public --add-port=3306/tcp --permanent\n\nCentos 7 在线安装 Mysql 5.7最近在搞 Apollo ，熟悉的同学应该知道，Apollo 需要依赖 Mysql。本以为很容易搞定，但是却踩了一路坑，眼高手低，也参考了网上很多博客，果然是残缺就是美！本篇就简单记录一下这个过程，以便后面参考。\n环境｜ 软件 ｜ 版本｜| ———— | ———— |｜linux ｜ centOS 7｜｜ jdk | 8 || mysql| 5.7.24 |\n\n\n准备安装前，我们可以通过 rpm -qa | grep mysql 检测系统是否自带安装 MySQL，如果当前系统有安装且期望卸载的话，可以通过下面两种删除模式进行删除：\n\n普通删除模式：rpm -e mysql\n强力删除模式：rpm -e --nodeps mysql\n\n安装下载和安装1、下载mysql安装包 \n1234567891011121314151617wget https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm-2018-06-06 16:41:46--  https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm正在解析主机 dev.mysql.com (dev.mysql.com)... xxxx正在连接 dev.mysql.com (dev.mysql.com)|xxxxx|:443... 已连接。已发出 HTTP 请求，正在等待回应... 302 Found位置：https://repo.mysql.com//mysql57-community-release-el7-9.noarch.rpm [跟随至新的 URL]--2018-06-06 16:41:48--  https://repo.mysql.com//mysql57-community-release-el7-9.noarch.rpm正在解析主机 repo.mysql.com (repo.mysql.com)... xxxxx正在连接 repo.mysql.com (repo.mysql.com)|xxxx|:443... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：9224 (9.0K) [application/x-redhat-package-manager]正在保存至: “mysql57-community-release-el7-9.noarch.rpm”100%[==========================================================&gt;] 9,224       --.-K/s 用时 0s      2018-06-06 16:41:48 (169 MB/s) - 已保存 “mysql57-community-release-el7-9.noarch.rpm” [9224/9224])\n\n2、安装\n12345rpm -ivh mysql57-community-release-el7-9.noarch.rpm准备中...                          ################################# [100%]正在升级/安装...   1:mysql57-community-release-el7-9  ################################# [100%]\n\n3、下载安装依赖包\n123456789101112131415yum install mysql-server已加载插件：fastestmirror, langpacksmysql-connectors-community                                                   | 2.5 kB  00:00:00     mysql-tools-community                                                        | 2.5 kB  00:00:00     mysql57-community                                                            | 2.5 kB  00:00:00     (1/3): mysql-connectors-community/x86_64/primary_db                          |  20 kB  00:00:00     (2/3): mysql-tools-community/x86_64/primary_db                               |  41 kB  00:00:00     (3/3): mysql57-community/x86_64/primary_db                                   | 144 kB  00:00:00     Loading mirror speeds from cached hostfile * base: mirrors.cn99.com * extras: mirrors.cn99.com * updates: mirrors.cn99.com正在解决依赖关系 ....\n第一次下载这里会比较慢，no cache\n基本操作1、验证是否安装成功\n\nmysqladmin –version\n\n\n\n\n\n\n\n\n\nmysqladmin  Ver 8.42 Distrib 5.7.22, for Linux on x86_64\n\nmysql -V\n\n\n\n\n\n\n\n\n\nmysql  Ver 14.14 Distrib 5.7.24, for Linux (x86_64) using  EditLine wrapper\n\n\n2、启动 MySQL\n\n\n\n\n\n\n\n\n\nsudo systemctl start mysqld\n3、查看 MySQL 运行状态 \n\n\n\n\n\n\n\n\n\nsudo systemctl status mysqld\n4、停止 MySQL\n\n\n\n\n\n\n\n\n\nsudo systemctl stop mysqld\n5、重启 MySQL\n\n\n\n\n\n\n\n\n\nsudo systemctl restart mysqld\n关于密码Mysql 5.7 默认安装之后 root 是有密码的，获取 MySQL 的临时密码 为了加强安全性，MySQL 5.7 为 root 用户随机生成了一个密码，在 error log 中，关于 error log 的位置，如果安装的是 RPM 包，则默认是 &#x2F;var&#x2F;log&#x2F;mysqld.log 。 只有启动过一次 mysql 才可以查看临时密码。\n在利用 YUM 安装 mysql 数据库过程中，系统会自动生成一个临时密码，获取方式为：\n\n\n\n\n\n\n\n\n\ngrep ‘temporary password’ &#x2F;var&#x2F;log&#x2F;mysqld.log\n没有密码: 如果以前安装过 mysql，这时的 mysqld.log 中就不会有 temporary password这时就需要删除 mysql 残留的数据：\n\n\n\n\n\n\n\n\n\nrm -rf &#x2F;var&#x2F;lib&#x2F;mysql\n执行完毕后需要重新启动 MySQL 服务: \n\n\n\n\n\n\n\n\n\nsudo systemctl restart mysqld\n这时就可以通过上面的命令去查找数据库生成的临时密码了\nmysql 1130 错误可能是你的帐号不允许从远程登陆，只能在 localhost。这个时候只要在 localhost 的那台电脑，登入 mysql 后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，从”localhost”改成”%”\n123mysql -u root -pvmwaremysql&gt;use mysql;mysql&gt; update user set host = &#x27;%&#x27; where user = &#x27;root&#x27;;mysql&gt; select host, user from user;\n\n使得我们当前的账户和密码能够应用的所有的远程主机连接：\n12&gt; GRANT ALL PRIVILEGES ON . TO &#x27;myuser&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;mypassword&#x27; WITH GRANT OPTION;&gt; FLUSH   PRIVILEGES;\n\n","slug":"linux/linux-ops-soft-mysql","date":"2019-06-05T09:09:15.000Z","categories_index":"Linux","tags_index":"mysql,linux,运维","author_index":"glmapper"},{"id":"c6dcfcda5dea0263fc2424962ca2973e","title":"Linux 下安装 Zookeeper","content":"安装 Zookeeper目前 Curator 有 2.x.x 和 3.x.x 两个系列的版本，支持不同版本的 Zookeeper。其中 Curator 2.x.x 兼容 Zookeeper的 3.4.x 和 3.5.x。而 Curator 3.x.x 只兼容 Zookeeper 3.5.x。\n\n\n\n\n\n\n\n\n\nCurator 2.x.x - compatible with both ZooKeeper 3.4.x and ZooKeeper 3.5.xCurator 3.x.x - compatible only with ZooKeeper 3.5.x and includes support for new\n\n\n选择使用 3.4.x 版本 Zookeeper。\n\n下载 Zookeeper ，选择相应的版本，这里以 3.4.13 版本为例：\n1&gt; wget http://apache.fayea.com/zookeeper/zookeeper-3.4.13/zookeeper-3.4.13.tar.gz\n执行上述命令进行下载，下载完成之后对文件进行解压。\n\n解压文件\n1&gt; tar -zxvf zookeeper-3.4.13.tar.gz\n\n创建数据和日志目录\n123&gt; cd zookeeper-3.4.13&gt; mkdir data&gt; mkdir logs\n\n配置文件修改首先将默认的 zoo_sample.cfg 命名为 zoo.cfg\n12&gt; cd conf&gt; cp zoo_sample.cfg zoo.cfg\n编辑 zoo.cfg，将数据目录和日志目录路径修改为上述步骤中创建的两个文件夹：\n123# 配置dataDir 和 dataLogDirdataDir=/home/admin/server/zookeeper-3.4.13/datadataLogDir=/home/admin/server/zookeeper-3.4.13/logs\n\n启动 zookeeper到你安装的zookeeper的bin目录下，如：&#x2F;home&#x2F;admin&#x2F;server&#x2F;zookeeper-3.4.13&#x2F;bin\n1cd /home/admin/server/zookeeper-3.4.13/bin\n执行 start 启动: zkServer.sh start\n\n\n上述是简单的在 linux 环境下安装配置 Zookeeper 的过程，对于在实际的生成环境，请根据自己项目需求进行更加细化的配置。\n安装 Zookeeper 可视化工具为了可以直观的看到 zookeeper 的节点信息，可以考虑部署一个 zookeeper 的管控界面，常见的有 zkui 和 zkweb。\n\nzkui\nzkwebzkui 界面更加简单一点，zkweb 在一些细节展示上更加有优势，这里推荐使用 zkweb。具体部署方式见官方文档。\n\n","slug":"linux/linux-ops-soft-zookeeper","date":"2019-05-04T12:29:18.000Z","categories_index":"Linux","tags_index":"zookeeper,linux,运维","author_index":"glmapper"},{"id":"abea11fd3a48225fb287e26d15ad0ab2","title":"并发编程-关于 CAS 的几个问题","content":"CAS 相关基础知识CAS的全称是Compare And Swap ,即比较交换。CAS 中一般会设计到3个参数:\n\n内存值 V\n旧的预期值A\n要修改的新值B\n\n当且仅当预期值 A 和内存值 V 相同时，将内存值V修改为 B，否则什么都不做。\n\n\n\n\n\n\n\n\n\n这里关于 CPU 指令对于 CAS 的支持不深入研究,有兴趣的可以自行了解。\n\n\nCAS 几个问题很多书籍和文章中都有提出它存在的几个问题：\n\n1、循环时间长开销很大\n2、只能保证一个共享变量的原子操作\n3、ABA 问题\n\n下面就这三个问题展开来聊一下。\n1、关于“循环时间长开销很大”的疑惑与验证自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的开销。但是真的是这样吗？到底多大的并发量才造成 CAS 的自旋次数会增加呢？另外，对于当前的机器及JDK，在无锁，无CAS 的情况下，是否对于结果的影响是真的那么明显呢？对于这个问题，下面做了一个简单的测试，但是测试结果也只是针对在我本地环境下，各位看官可以拉一下代码，在自己电脑上 run 一下，把机器信息、JDK版本以及测试结果留言到评论区。\n\n\n\n\n\n\n\n\n\n本文案例可以这里获取：glmapper-blog-sample-cas\n这里我是用了一个很简单的案例，就是整数自增。使用了两种方式去测试的，一种是无锁，也不用 CAS 操作，另外一种是基于 CAS 的方式。（关于加锁的方式没有验证，有时间再补充吧~）\n计数器类计数器里面有两个方法，一种是CAS 自旋方式，一种是直接自增。代码如下：\n123456789101112131415161718public class Counter &#123;    public AtomicInteger safeCount = new AtomicInteger(0);    public int unsafe = 0;    // 使用自旋的方式    public void safeCount()&#123;        for (;;)&#123;            int i = safeCount.get();            boolean success = safeCount.compareAndSet(i,++i);            if (success)&#123;                break;            &#125;        &#125;    &#125;    // 普通方式自增    public void unsafeCount()&#123;        unsafe++;    &#125;&#125;\n\n模拟并发这里我们模拟使用 1000 个线程，执行 30 次来看下结果，包括总耗时和结果的正确性。\n\nCAS 方式12345678910111213141516171819public static int testSafe() throws InterruptedException &#123;    // 记录开始时间    long start = System.currentTimeMillis();    // 实例化一个 Counter 计数器对象    Counter counter = new Counter();    CountDownLatch countDownLatch = new CountDownLatch(testCounts);    for (int i =0 ;i &lt; testCounts;i++)&#123;        new Thread(()-&gt;&#123;                // 调用 safeCount 方法                counter. safeCount();                countDownLatch.countDown();        &#125;).start();    &#125;    countDownLatch.await();    // 结束时间    long end = System.currentTimeMillis();    safeTotalCostTime += (end-start);    return counter.safeCount.get();&#125;\n普通方式\n\n12345678910111213141516171819public static int testUnSafe() throws InterruptedException &#123;    // 记录开始时间    long start = System.currentTimeMillis();    // 实例化一个 Counter 计数器对象    Counter counter = new Counter();    CountDownLatch countDownLatch = new CountDownLatch(testCounts);    for (int i =0 ;i&lt; testCounts;i++)&#123;        new Thread(()-&gt;&#123;            // 调用 unsafeCount 方法            counter.unsafeCount();            countDownLatch.countDown();        &#125;).start();    &#125;    countDownLatch.await();    // 结束时间    long end = System.currentTimeMillis();    unsafeTotalCostTime += (end-start);    return counter.unsafe;&#125;\n\nmain 方法\n\n12345678910111213141516171819202122public static void main(String[] args) throws InterruptedException &#123;    // 执行 300 次    for (int i =0 ;i&lt; 300;i++)&#123;        // 普通方式        int unSafeResult = testUnSafe();        // cas 方式        int safeResult = testSafe();        // 结果验证，若果正确就将成功次数增加        if (unSafeResult == testCounts)&#123;            totalUnSafeCount++;        &#125;        // 同上        if (safeResult == testCounts)&#123;            totalSafeCount++;        &#125;    &#125;    System.out.println(&quot;test count = &quot; + testCounts);    System.out.println(&quot;非安全计数器正确个数 = &quot; + totalUnSafeCount);    System.out.println(&quot;非安全计数器耗时 = &quot; + unsafeTotalCostTime);    System.out.println(&quot;安全计数器正确个数 = &quot; + totalSafeCount);    System.out.println(&quot;安全计数器耗时 = &quot; + safeTotalCostTime);&#125;\n\n我的机器信息如下：\n\nMacBook Pro (Retina, 15-inch, Mid 2015)\n处理器：2.2 GHz Intel Core i7\n内存：16 GB 1600 MHz DDR3\n\n下面是一些测试数据。\n1000(线程数) * 300(次数)测试结果如下：\n12345test count = 1000非安全计数器正确个数 = 300非安全计数器耗时 = 27193安全计数器正确个数 = 300安全计数器耗时 = 26337\n居然发现不使用 CAS 的方式居然比使用自旋 CAS 的耗时要高出将近 1s。另外一个意外的点，我尝试了好几次，不使用 CAS 的情况得到的结果正确率基本也是 4 个 9  以上的比率，极少数会出现计算结果错误的情况。\n3000(线程数) * 30(次数)测试结果如下：\n12345test count = 3000非安全计数器正确个数 = 30非安全计数器耗时 = 7816安全计数器正确个数 = 30安全计数器耗时 = 8073\n这里看到在耗时上已经很接近了。这里需要考虑另外一个可能影响的点是，因为 testUnSafe 是 testSafe 之前执行的，“JVM 和 机器本身热身” 影响耗时虽然很小，但是也存在一定的影响。\n5000(线程数) * 30(次数)测试结果如下：\n12345test count = 5000非安全计数器正确个数 = 30非安全计数器耗时 = 23213安全计数器正确个数 = 30安全计数器耗时 = 14161\n随着并发量的增加，这里奇怪的是，普通自增方式所消耗的时间要高于CAS方式消耗的时间将近 8-9s 。\n当尝试 10000 次时，是的你没猜错，抛出了 OOM 。但是从执行的结果来看，并没有说随着并发量的增大，普通方式错误的概率会增加，也没有出现预想的 CAS 方式的耗时要比 普通模式耗时多。\n\n\n\n\n\n\n\n\n\n由于测试样本数据比较单一，对于测试结果没法做结论，欢迎大家将各自机器的结果提供出来，以供参考。另外就是，最近看到很多面试的同学，如果有被问道这个问题，还是需要谨慎考虑下。关于是否“打脸”还是“被打脸”还需要更多的测试结果。\nCAS 到底是怎么操作的\nCPU 指令\nUnsafe 类\n\n2、ABA 问题的简单复现网上关于 CAS 讨论另外一个点就是 CAS 中的 ABA 问题，相信大多数同学在面试时如果被问到 CAS ，那么 ABA 问题也会被问到，然后接着就是怎么避免这个问题，是的套路就是这么一环扣一环的。\n我相信 90% 以上的开发人员在实际的工程中是没有遇到过这个问题的，即使遇到过，在特定的情况下也是不会影响到计算结果。但是既然这个问题会被反复提到，那就一定有它导致 bug 的场景，找了一个案例供大家参考：CAS下ABA问题及优化方案 。\n这里先不去考虑怎么去规避这个问题，我们想怎么去通过简单的模拟先来复现这个 ABA 问题。其实这个也很简单，如果你对线程交叉、顺序执行了解的话。\n如何实现多线程的交叉执行这个点实际上也是一个在面试过程中很常见的一个基础问题，我在提供的代码中给了三种实现方式，有兴趣的同学可以拉代码看下。\n下面以 lock 的方式来模拟下这个场景，代码如下：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ConditionAlternateTest&#123;    private static int count = 0;    // 计数器    public AtomicInteger safeCount = new AtomicInteger(0);    // lock    private Lock lock = new ReentrantLock();    // condition 1/2/3 用于三个线程触发执行的条件    Condition c1 = lock.newCondition();    Condition c2 = lock.newCondition();    Condition c3 = lock.newCondition();    // 模拟并发执行    CountDownLatch countDownLatch = new CountDownLatch(1);    // 线程1 ，A     Thread t1 = new Thread(()-&gt; &#123;        try &#123;            lock.lock();            while (count % 3 != 0)&#123;                c1.await();            &#125;            safeCount.compareAndSet(0, 1);            System.out.println(&quot;thread1:&quot;+safeCount.get());            count++;            // 唤醒条件2            c2.signal();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;);     // 线程2 ，B     Thread t2 = new Thread(()-&gt; &#123;        try &#123;            lock.lock();            while (count % 3 != 1)&#123;                c2.await();            &#125;            safeCount.compareAndSet(1, 0);            System.out.println(&quot;thread2:&quot;+safeCount.get());            count++;            // 唤醒条件3            c3.signal();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;);    // 线程2 ，A    Thread t3 = new Thread(()-&gt; &#123;        try &#123;            lock.lock();            while (count % 3 != 2)&#123;                c3.await();            &#125;            safeCount.compareAndSet(0, 1);            System.out.println(&quot;thread3:&quot;+safeCount.get());            count++;            // 唤醒条件1            c1.signal();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; finally &#123;            lock.unlock();        &#125;    &#125;);    // 启动启动线程    public void threadStart() &#123;        t3.start();        t1.start();        t2.start();        countDownLatch.countDown();    &#125;    public static void main(String[] args) throws InterruptedException &#123;        ConditionAlternateTest test = new ConditionAlternateTest();        test.threadStart();        test.countDownLatch.await();    &#125;&#125;\n执行结果：\n123thread1:1thread2:0thread3:1\n\n上面线程交叉的案例实际上并不是严格意义上的 ABA 问题的复现，这里仅是模拟下产生的一个最简单的过程。如果大家有好的案例，也可以分享一下。\nABA 问题解决常见实践：“版本号”的比对，一个数据一个版本，版本变化，即使值相同，也不应该修改成功。\njava 中提供了 AtomicStampedReference 这个类来解决这个 ABA 问题。AtomicStampedReference 原子类是一个带有时间戳的对象引用，在每次修改后，AtomicStampedReference 不仅会设置新值而且还会记录更改的时间。当 AtomicStampedReference 设置对象值时，对象值以及时间戳都必须满足期望值才能写入成功，这也就解决了反复读写时，无法预知值是否已被修改的窘境。\n实现代码这里就不贴了，基于前面的代码改造，下面贴一下运行结果：\n123thread1,第一次修改;值为=1thread2,已经改回为原始值;值为=0thread3,第二次修改;值为=1\n\n3、只能保证一个共享变量的原子操作当对一个共享变量执行操作时，我们可以使用 CAS 的方式来保证原子操作，但是对于对多个变量操作时，循环 CAS 就无法保证操作的原子性了，那么这种场景下，我们就需要使用加锁的方式来解决。\n","slug":"java/java-advance-juc-cas-qa","date":"2019-04-29T11:06:16.000Z","categories_index":"JAVA","tags_index":"并发编程,JUC,CAS","author_index":"glmapper"},{"id":"e6e9029e4c940952840addd5ca00ccc2","title":"linux shell 编程小记","content":"if 条件 OPTION\n\n\nOPTION\n解释\n\n\n\n[-a file]\n如果file存在则为真 ，也可以表示为 and: 条件与if [ -z “condition1” -a -z “condition2” ]\n\n\n[-b file]\n如果file存在且是一个块特殊文件则为真\n\n\n[-c file]\n如果file存在且是一个字特殊文件则为真\n\n\n[-d file]\n如果 file 文件存在且是一个目录则为真，d前的!是逻辑非 #表示目录不存在，则执行后面的 then 操作 if [ ! -d lcd_path&#x2F;par_date ]\n\n\n[-e file]\n如果 file文件存在则为真\n\n\n[-f file]\n如果 file 存在且是一个普通文件则为真\n\n\n[-g file]\n如果 file 存在且已经设置了SGID则为真（SUID 是 Set User ID, SGID 是 Set Group ID的意思）\n\n\n[-h file]\n如果 file 存在且是一个符号连接则为真\n\n\n[-k file]\n如果 file 存在且已经设置粘制位则为真\n\n\n[-p file]\n如果file存在且是一个名字管道（F如果O）则为真。管道是linux里面进程间通信的一种方式，其他的还有像信号（signal）、信号量、消息队列、共享内存、套接字（socket）等\n\n\n[-r file]\n如果file存在且是可读的则为真\n\n\n[-s file]\n如果file存在且大小不为0则为真\n\n\n[-t FD]\n如果文件描述符FD打开且指向一个终端则为真\n\n\n[-u file]\n如果file存在且设置了SUID（set userID）则为真\n\n\n[-w file\n如果file存在且是可写的则为真\n\n\n[-x file]\n如果file存在且是可执行的则为真\n\n\n[-O file]\n如果file存在且属有效用户ID则为真\n\n\n[-G file]\n如果file存在且属有效用户组则为真\n\n\n[-L file]\n如果file存在且是一个符号连接则为真\n\n\n[-N file]\n如果file存在and has been mod如果ied since it was last read则为真\n\n\n[-S file]\n如果file存在且是一个套接字则为真\n\n\n[-o optionname]\n如果shell选项“optionname”开启则为真\n\n\n[-z string]\n“string”的长度为零则为真\n\n\n[-n string] or [string]\n“string”的长度为非零non-zero则为真\n\n\n\n\nif 基本判断\n[file1 –nt file2] 如果file1 has been changed more recently than file2或者file1 exists and file2 does not则为真 \n[file1 –ot file2] 如果file1比file2要老，或者file2存在且file1不存在则为真 \n[file1 –ef file2] 如果file1和file2指向相同的设备和节点号则为真 \n[sting1&#x3D;&#x3D;string2] 如果2个字符串相同。“&#x3D;”may be used instead of “&#x3D;&#x3D;”for strict posix compliance则为真 \n[string1!&#x3D;string2] 如果字符串不相等则为真 \n[string1&lt;string2] 如果“string1”sorts before“string2”lexicographically in the current locale则为真 \n[arg1 OP arg2]  “OP”is one of –eq,-ne,-lt,-le,-gt or –ge\n\n截取字符串\n# 号截取，删除左边字符，保留右边字符。 （非贪婪匹配）\n\n1234var=http://www.glmapper.com# # 号是运算符，*/ 表示从左边开始删除第一个 / 号及左边的所有字符,即删除 http://echo $&#123;var#*//&#125;#结果 www.glmapper.com\n\n\n## 号截取，删除左边字符，保留右边字符。（贪婪匹配）****\n\n12345var=http://www.glmapper.com# ##*/ 表示从左边开始删除最后（最右边）一个 / 号及左边的所有字符echo $&#123;var##*//&#125;# 结果 www.glmapper.com\n\n\n%号截取，删除右边字符，保留左边字符 （非贪婪匹配）\n\n1234var=http://www.glmapper.com# %/* 表示从右边开始，删除第一个 / 号及右边的字符echo $&#123;var%/*&#125;# 结果是：http:/\n\n\n%% 号截取，删除右边字符，保留左边字符  （贪婪匹配）\n\n1234var=http://www.glmapper.com# %%/* 表示从右边开始，删除最后（最左边）一个 / 号及右边的字符echo $&#123;var%%/*&#125;# 结果 ：http: \n\n\n从左边第几个字符开始，及字符的个数\n\n1234var=http://www.glmapper.com# 其中的 0 表示左边第一个字符开始，5 表示字符的总个数echo $&#123;var:0:5&#125;# 结果 http:\n\n\n从左边第几个字符开始，一直到结束\n\n1234var=http://www.glmapper.com# 其中的 7 表示左边第8个字符开始，一直到结束。echo $&#123;var:7&#125;# 结果 www.glmapper.com\n\n\n从右边第几个字符开始，及字符的个数\n\n1234var=http://www.glmapper.com# 其中的 0-3 表示右边算起第3个字符开始，3 表示字符的个数echo $&#123;var:0-3:3&#125;# 结果 com\n\n\n从右边第几个字符开始，一直到结束\n\n1234var=http://www.glmapper.com# 表示从右边第 3 个字符开始，一直到结束echo $&#123;var:0-3&#125;# 结果 com\n\n\n\n\n\n\n\n\n\n\n左边的第一个字符是用 0 表示，右边的第一个字符用 0-1 表示\nbasenamebasename 命令简介去除文件名的目录部分和后缀部分。basename 命令读取 String 参数，删除以 &#x2F;(斜杠) 结尾的前缀以及任何指定的 Suffix 参数，并将剩余的基本文件名称写至标准输出。basename 和 dirname 命令通常用于 shell 脚本中的命令替换来指定和指定的输入文件名称有所差异的输出文件名称。**基本语法如下：\n12basename NAME [SUFFIX]basename OPTION\n\n基本示例12345basename /usr/bin/sort# 返回 sortbasename /usr/bin/sort/glmapper.txt# 返回 glmapper.txt\n\n\n创建基本文件名称的规则\n如果 String 参数是 &#x2F;&#x2F;(双斜杠) 或如果 String 参数包含的都是斜杠字符，则将字符串更改为单个 &#x2F;(斜杠)\n\n12345basename //usr//bin//sort//glmapper.txt# 返回 glmapper.txtbasename ////# 返回 /\n\n\n\n从指定字符串除去任何拖尾的 &#x2F; 字符。\n\n12basename /usr/bin/sort/# 返回 sort\n\n\n如果在 String 参数中剩余任何 &#x2F; 字符，则除去字符串的前缀直到（包含）最后一个 &#x2F; 字符。\n如果指定 Suffix 参数，且它和字符串中的剩余的字符相同，则不修改此字符串\n\n12345basename /usr/bin/sort/glmapper.txt glmapper.txt # 返回glmapper.txt basename /usr/bin/sort/glmapper.txt .txt # 返回 glmapper\n\nshell 查看当前目录下文件的个数测试准备，test 目录下有 test1、test2 两个文件夹和一个 1.txt 文件。\n12345-test├── 1.txt├── test1│   └── test1_1.txt└── test2\n\n\n查看当前目录下文件的个数\n\n12➜  test ls -l | grep &quot;^-&quot; | wc -l   1 # 1.txt\n\n\n查看当前目录下文件的个数，包括子目录里的\n\n12➜  test ls -lR| grep &quot;^-&quot; | wc -l   2 # 1.txt  test1_1.txt\n\n\n查看某目录下文件夹（目录）的个数，包括子目录里的\n\n12➜  test ls -lR| grep &quot;^d&quot; | wc -l\t 2 # test1 test2\n\n\n说明：\n\n12341、ls -l ：长列表输出该目录下文件信息(注意这里的文件,不同于一般的文件,可能是目录、链接、设备文件等)2、grep &quot;^-&quot; ：这里将长列表输出信息过滤一部分,只保留一般文件,如果只保留目录就是 ^d3、wc -l ： 统计输出信息的行数,已经过滤得只剩一般文件了,统计结果就是一般文件信息的行数,\t\t\t\t\t又一行信息对应一个文件,也就是文件的个数\n\n利用简单的命令组合实现配置文件的获取测试准备，在 1.txt 中 增加两个属性：\n12name=glmapperage=26\n\n12345cat /Users/guolei/logs/test/1.txt | sed &#x27;s|[[:blank:]]||g&#x27; | grep &quot;^name=&quot; | cut -d= -f2# 返回 glmapper cat /Users/guolei/logs/test/1.txt | sed &#x27;s|[[:blank:]]||g&#x27; | grep &quot;^age=&quot; | cut -d= -f2# 返回 26\n\n函数封装与返回以上面的解析配置文件为例，将其封装成一个函数\n12345678function load_param()&#123;    # 接受的第一个参数是文件地址    local properties_file=$1    # 接受的第二个参数是属性名    local param=$2    RESULT=`cat $properties_file | sed &#x27;s|[[:blank:]]||g&#x27; | grep &quot;^$param=&quot; | cut -d= -f2`&#125;\n\n调用函数并且获取返回值\n1234load_param 1.txt namePROP_VAL=$RESULTecho $PROP_VAL# 返回 glmapper\n\nshell 实现日志文件的归档处理日志归档简单来说就是，每次希望启动，会将前一次程序运行产生的日志和本地运行产生的日志隔离开来，归档结果就是产生类似于如下的日志文件：\n\nstdout.log.20170909\nstdout.log.20170709\nstdout\n\n所以日志文件的归档在生产脚本中是必须要考虑的，否则就到导致每次产生的文件都会被写入同一份日志文件中。下面是实践过程中归纳的一个日志归档函数：\n123456789101112131415161718192021# archive logfunction archive_log() &#123;    local FILE_STDOUT_LOG=$LOG_ROOT/stdout.log    local FILE_STDERR_LOG=$LOG_ROOT/stderr.log    if [ ! -e $LOG_ROOT ] ; then        mkdir -p $LOG_ROOT    fi    NOW=`date +%Y%m%d.%H%M%S`    # scroll SOFABoot STDOUT log    if [ -e $FILE_STDOUT_LOG ] ; then        mv $FILE_STDOUT_LOG $FILE_STDOUT_LOG.$NOW    fi    # scroll SOFABoot STDERR log    if [ -e $FILE_STDERR_LOG ] ; then        mv $FILE_STDERR_LOG $FILE_STDERR_LOG.$NOW    fi    FILE_STDOUT_LOG_GLOBAL=$FILE_STDOUT_LOG;    FILE_STDERR_LOG_GLOBAL=$FILE_STDERR_LOG;&#125;\n\n\n一个简单的 SOFABoot 启动脚本deploy.sh  简单的启动脚本：\n123456789101112LOG_ROOT= $1;APP_PATH= $2;# 检查 JAVA_HOMEif [ -z &quot;$JAVA_HOME&quot; ]; then  echo &quot;JAVA_HOME not set, exit&quot;  exit 1fi# 使用前面的那个日志归档函数archive_log# 启动 java 程序java -jar $APP_PATH &gt;&gt; $FILE_STDOUT_LOG_GLOBAL 2&gt;&gt; $FILE_STDOUT_LOG_GLOBAL &amp;\n\n运行：\n1sh deploy.sh ./logs app.jar \n\n小结本文记录日常中常遇到的 shell 命令，基础知识部分零碎的参考了网上一些同学的博客，在此做了归纳。也欢迎大家指正。如果你有比较骚气的操作，也欢迎评论席留言，我会验证后更新到文章中来。\n","slug":"linux/linux-program-shell-record","date":"2019-04-20T10:18:42.000Z","categories_index":"Linux","tags_index":"linux,shell","author_index":"glmapper"},{"id":"e185413cf7dca9c0efdf1f0b1164cf4f","title":"ZooKeeper 客户端之 Curator","content":"ZooKeeper 是一个分布式的、开放源码的分布式应用程序协调服务，是 Google 的 Chubby 一个开源的实现。它是集群的管理者，监视着集群中各个节点的状态，根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。\nCurator 是 Netflix 公司开源的一套  Zookeeper 客户端框架，解决了很多 Zookeeper 客户端非常底层的细节开发工作，包括连接重连、反复注册 Watcher 和 NodeExistsException 异常等等。\n\n\nCurator 包含了几个包：\n\ncurator-framework：对 Zookeeper 的底层 api 的一些封装\ncurator-client：提供一些客户端的操作，例如重试策略等\ncurator-recipes：封装了一些高级特性，如：Cache 事件监听、选举、分布式锁、分布式计数器、分布式Barrier 等\n\nCurator 和 zookeeper 的版本问题目前 Curator 有 2.x.x 和 3.x.x 两个系列的版本，支持不同版本的 Zookeeper。其中Curator 2.x.x 兼容 Zookeeper的 3.4.x 和 3.5.x。而 Curator 3.x.x 只兼容 Zookeeper 3.5.x，并且提供了一些诸如动态重新配置、watch删除等新特性。\n12Curator 2.x.x - compatible with both ZooKeeper 3.4.x and ZooKeeper 3.5.xCurator 3.x.x - compatible only with ZooKeeper 3.5.x and includes support for new\n\n如果跨版本会有兼容性问题，很有可能导致节点操作失败，当时在使用的时候就踩了这个坑，抛了如下的异常：\n1KeeperErrorCode = Unimplemented for /***\n\nCurator   API这里就不对比与原生 API 的区别了，Curator 的 API 直接通过 org.apache.curator.framework.CuratorFramework 接口来看，并结合相应的案例进行使用，以备后用。\n\n\n\n\n\n\n\n\n\n为了可以直观的看到 Zookeeper 的节点信息，可以考虑弄一个 zk 的管控界面，常见的有 zkui 和 zkweb。\n\nzkui：https://github.com/DeemOpen/zkui\nzkweb：https://github.com/zhitom/zkweb\n\n我用的 zkweb ，虽然界面上看起来没有 zkui 精简，但是在层次展示和一些细节上感觉比 zkui 好一点\n环境准备之前写的一个在 Linux 上安装部署 Zookeeper 的笔记，其他操作系统请自行谷歌教程吧。\n本文案例工程已经同步到了 github，传送门。\n\n\n\n\n\n\n\n\n\nPS : 目前还没有看过Curator的具体源码，所以不会涉及到任何源码解析、实现原理的东西；本篇主要是实际使用时的一些记录，以备后用。如果文中错误之处，希望各位指出。\nCurator 客户端的初始化和初始化时机在实际的工程中，Zookeeper 客户端的初始化会在程序启动期间完成。\n初始化时机在 Spring 或者 SpringBoot 工程中最常见的就是绑定到容器启动的生命周期或者应用启动的生命周期中：\n\n监听 ContextRefreshedEvent 事件，在容器刷新完成之后初始化 Zookeeper\n监听 ApplicationReadyEvent&#x2F;ApplicationStartedEvent 事件，初始化 Zookeeper 客户端\n\n除了上面的方式之外，还有一种常见的是绑定到 bean 的生命周期中\n\n实现 InitializingBean 接口 ，在 afterPropertiesSet 中完成 Zookeeper 客户端初始化\n\n\n\n\n\n\n\n\n\n\n关于 SpringBoot中的事件机制可以参考之前写过的一篇文章：SpringBoot-SpringBoot中的事件机制。\nCurator 初始化这里使用 InitializingBean 的这种方式，代码如下：\n12345678910111213141516171819202122232425262728public class ZookeeperCuratorClient implements InitializingBean &#123;    private CuratorFramework curatorClient;    @Value(&quot;$&#123;glmapper.zookeeper.address:localhost:2181&#125;&quot;)    private String           connectString;    @Value(&quot;$&#123;glmapper.zookeeper.baseSleepTimeMs:1000&#125;&quot;)    private int              baseSleepTimeMs;    @Value(&quot;$&#123;glmapper.zookeeper.maxRetries:3&#125;&quot;)    private int              maxRetries;    @Value(&quot;$&#123;glmapper.zookeeper.sessionTimeoutMs:6000&#125;&quot;)    private int              sessionTimeoutMs;    @Value(&quot;$&#123;glmapper.zookeeper.connectionTimeoutMs:6000&#125;&quot;)    private int              connectionTimeoutMs;      @Override    public void afterPropertiesSet() throws Exception &#123;        // custom policy        RetryPolicy retryPolicy = new ExponentialBackoffRetry(baseSleepTimeMs, maxRetries);        // to build curatorClient        curatorClient = CuratorFrameworkFactory.builder().connectString(connectString)                .sessionTimeoutMs(sessionTimeoutMs).connectionTimeoutMs(connectionTimeoutMs)                .retryPolicy(retryPolicy).build();        curatorClient.start();    &#125;    public CuratorFramework getCuratorClient() &#123;        return curatorClient;    &#125;&#125;\n\n\n\nglmapper.zookeeper.xxx 是本例中需要在配置文件中配置的 zookeeper 的一些参数，参数解释如下：\n\nbaseSleepTimeMs：重试之间等待的初始时间\nmaxRetries：最大重试次数\nconnectString：要连接的服务器列表\nsessionTimeoutMs：session 超时时间\nconnectionTimeoutMs：连接超时时间\n\n另外，Curator 客户端初始化时还需要指定重试策略，RetryPolicy 接口是 Curator 中重试连接(当zookeeper失去连接时使用)策略的顶级接口，其类继承体系如下图所示：\n\n\nRetryOneTime：只重连一次\nRetryNTime：指定重连的次数N\nRetryUtilElapsed：指定最大重连超时时间和重连时间间隔，间歇性重连直到超时或者链接成功\nExponentialBackoffRetry：基于 “backoff”方式重连，和 RetryUtilElapsed 的区别是重连的时间间隔是动态的。\nBoundedExponentialBackoffRetry： 同 ExponentialBackoffRetry的区别是增加了最大重试次数的控制\n\n除上述之外，在一些场景中，需要对不同的业务进行隔离，这种情况下，可以通过设置 namespace 来解决，namespace 实际上就是指定zookeeper的根路径，设置之后，后面的所有操作都会基于该根目录。\nCurator 基础 API 使用检查节点是否存在checkExists 方法返回的是一个 ExistsBuilder 构造器，这个构建器将返回一个 Stat 对象，就像调用了 org.apache.zookeeper.ZooKeeper.exists()一样。null 表示它不存在，而实际的 Stat 对象表示存在。\n123456public void checkNodeExist(String path) throws Exception &#123;    Stat stat = curatorClient.checkExists().forPath(path);    if (stat != null)&#123;        throw new RuntimeException(&quot;path = &quot;+path +&quot; has bean exist.&quot;);    &#125;&#125;\n\n建议在实际的应用中，操作节点时对所需操作的节点进行 checkExists。\n新增节点\n非递归方式创建节点\n12curatorClient.create().forPath(&quot;/glmapper&quot;);curatorClient.create().forPath(&quot;/glmapper/test&quot;);\n\n先创建&#x2F;glmapper，然后再在&#x2F;glmapper 下面创建 &#x2F;test ，如果直接使用 &#x2F;glmapper&#x2F;test 没有先创建 &#x2F;glmapper 时，会抛出异常：\n1org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /glmapper/test\n\n如果需要在创建节点时指定节点中数据，则可以这样：\n1curatorClient.create().forPath(&quot;/glmapper&quot;,&quot;data&quot;.getBytes());\n\n指定节点类型(EPHEMERAL 临时节点)\n1curatorClient.create().withMode(CreateMode.EPHEMERAL).forPath(&quot;/glmapper&quot;,&quot;data&quot;.getBytes());\n\n递归方式创建节点\n递归方式创建节点有两个方法，creatingParentsIfNeeded 和 creatingParentContainersIfNeeded。在新版本的 zookeeper 这两个递归创建方法会有区别； creatingParentContainersIfNeeded() 以容器模式递归创建节点，如果旧版本 zookeeper，此方法等于creatingParentsIfNeeded()。\n在非递归方式情况下，如果直接创建 &#x2F;glmapper&#x2F;test 会报错，那么在递归的方式下则是可以的\n1curatorClient.create().creatingParentContainersIfNeeded().forPath(&quot;/glmapper/test&quot;);\n\n在递归调用中，如果不指定 CreateMode，则默认PERSISTENT，如果指定为临时节点，则最终节点会是临时节点，父节点仍旧是PERSISTENT\n\n\n删除节点\n非递归删除节点\n1curatorClient.delete().forPath(&quot;/glmapper/test&quot;);\n\n指定具体版本\n1curatorClient.delete().withVersion(-1).forPath(&quot;/glmapper/test&quot;);\n\n使用 guaranteed 方式删除，guaranteed 会保证在session有效的情况下，后台持续进行该节点的删除操作，直到删除掉\n1curatorClient.delete().guaranteed().withVersion(-1).forPath(&quot;/glmapper/test&quot;);\n\n递归删除当前节点及其子节点\n1curatorClient.delete().deletingChildrenIfNeeded().forPath(&quot;/glmapper/test&quot;);\n\n获取节点数据获取节点数据\n1byte[] data = curatorClient.getData().forPath(&quot;/glmapper/test&quot;);\n\n根据配置的压缩提供程序对数据进行解压缩处理\n1byte[] data = curatorClient.getData().decompressed().forPath(&quot;/glmapper/test&quot;);\n\n读取数据并获得Stat信息\n12Stat stat = new Stat();byte[] data = curatorClient.getData().storingStatIn(stat).forPath(&quot;/glmapper/test&quot;);\n\n更新节点数据设置指定值\n1curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;newData&quot;.getBytes());\n\n设置数据并使用配置的压缩提供程序压缩数据\n1curatorClient.setData().compressed().forPath(&quot;/glmapper/test&quot;,&quot;newData&quot;.getBytes());\n\n设置数据，并指定版本\n1curatorClient.setData().withVersion(-1).forPath(&quot;/glmapper/test&quot;,&quot;newData&quot;.getBytes());\n\n获取子列表1List&lt;String&gt; childrenList = curatorClient.getChildren().forPath(&quot;/glmapper&quot;);\n\n事件Curator 也对 Zookeeper 典型场景之事件监听进行封装，这部分能力实在 curator-recipes 包下的。\n事件类型在使用不同的方法时会有不同的事件发生\n12345678910111213141516171819202122232425public enum CuratorEventType&#123;    //Corresponds to &#123;@link CuratorFramework#create()&#125;    CREATE,    //Corresponds to &#123;@link CuratorFramework#delete()&#125;    DELETE,\t\t//Corresponds to &#123;@link CuratorFramework#checkExists()&#125;    EXISTS,\t\t//Corresponds to &#123;@link CuratorFramework#getData()&#125;    GET_DATA,\t\t//Corresponds to &#123;@link CuratorFramework#setData()&#125;    SET_DATA,\t\t//Corresponds to &#123;@link CuratorFramework#getChildren()&#125;    CHILDREN,\t\t//Corresponds to &#123;@link CuratorFramework#sync(String, Object)&#125;    SYNC,\t\t//Corresponds to &#123;@link CuratorFramework#getACL()&#125;    GET_ACL,\t\t//Corresponds to &#123;@link CuratorFramework#setACL()&#125;    SET_ACL,\t\t//Corresponds to &#123;@link Watchable#usingWatcher(Watcher)&#125; or &#123;@link Watchable#watched()&#125;    WATCHED,\t\t//Event sent when client is being closed    CLOSING&#125;\n\n事件监听一次性监听方式：Watcher利用 Watcher 来对节点进行监听操作，可以典型业务场景需要使用可考虑，但一般情况不推荐使用。\n1234567891011 byte[] data = curatorClient.getData().usingWatcher(new Watcher() &#123;     @Override     public void process(WatchedEvent watchedEvent) &#123;       System.out.println(&quot;监听器 watchedEvent：&quot; + watchedEvent);     &#125; &#125;).forPath(&quot;/glmapper/test&quot;);System.out.println(&quot;监听节点内容：&quot; + new String(data));// 第一次变更节点数据curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;newData&quot;.getBytes());// 第二次变更节点数据curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;newChangedData&quot;.getBytes());\n\n上面这段代码对 &#x2F;glmapper&#x2F;test 节点注册了一个 Watcher 监听事件，并且返回当前节点的内容。后面进行两次数据变更，实际上第二次变更时，监听已经失效，无法再次获得节点变动事件了。测试中控制台输出的信息如下：\n12监听节点内容：datawatchedEvent：WatchedEvent state:SyncConnected type:NodeDataChanged path:/glmapper/test\n\nCuratorListener 方式CuratorListener 监听，此监听主要针对 background 通知和错误通知。使用此监听器之后，调用inBackground 方法会异步获得监听，对于节点的创建或修改则不会触发监听事件。\n123456789101112CuratorListener listener = new CuratorListener()&#123;    @Override    public void eventReceived(CuratorFramework client, CuratorEvent event) throws Exception &#123;      System.out.println(&quot;event : &quot; + event);    &#125; &#125;;// 绑定监听器curatorClient.getCuratorListenable().addListener(listener);// 异步获取节点数据curatorClient.getData().inBackground().forPath(&quot;/glmapper/test&quot;);// 更新节点数据curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;newData&quot;.getBytes());\n\n测试中控制台输出的信息如下：\n12event : CuratorEventImpl&#123;type=GET_DATA, resultCode=0, path=&#x27;/glmapper/test&#x27;, name=&#x27;null&#x27;, children=null, context=null, stat=5867,5867,1555140974671,1555140974671,0,0,0,0,4,0,5867, data=[100, 97, 116, 97], watchedEvent=null, aclList=null&#125;\n\n这里只触发了一次监听回调，就是 getData 。\nCurator 引入的 Cache 事件监听机制Curator 引入了 Cache 来实现对 Zookeeper 服务端事件监听，Cache 事件监听可以理解为一个本地缓存视图与远程 Zookeeper 视图的对比过程。Cache 提供了反复注册的功能。Cache 分为两类注册类型：节点监听和子节点监听。\n\nNodeCache\n监听数据节点本身的变化。对节点的监听需要配合回调函数来进行处理接收到监听事件之后的业务处理。NodeCache 通过 NodeCacheListener 来完成后续处理。\n12345678910111213141516String path = &quot;/glmapper/test&quot;;final NodeCache nodeCache = new NodeCache(curatorClient,path);//如果设置为true则在首次启动时就会缓存节点内容到Cache中。 nodeCache.start(true);nodeCache.start();nodeCache.getListenable().addListener(new NodeCacheListener() &#123;@Overridepublic void nodeChanged() throws Exception &#123;System.out.println(&quot;触发监听回调，当前节点数据为：&quot; + new String(nodeCache.getCurrentData().getData()));&#125;&#125;);curatorClient.setData().forPath(path,&quot;1&quot;.getBytes());curatorClient.setData().forPath(path,&quot;2&quot;.getBytes());curatorClient.setData().forPath(path,&quot;3&quot;.getBytes());curatorClient.setData().forPath(path,&quot;4&quot;.getBytes());curatorClient.setData().forPath(path,&quot;5&quot;.getBytes());curatorClient.setData().forPath(path,&quot;6&quot;.getBytes());\n\n注意：在测试过程中，nodeCache.start()，NodeCache 在先后多次修改监听节点的内容时，出现了丢失事件现象，在用例执行的5次中，仅一次监听到了全部事件；如果 nodeCache.start(true)，NodeCache 在先后多次修改监听节点的内容时，不会出现丢失现象。\n\n\n\n\n\n\n\n\n\nNodeCache不仅可以监听节点内容变化，还可以监听指定节点是否存在。如果原本节点不存在，那么Cache就会在节点被创建时触发监听事件，如果该节点被删除，就无法再触发监听事件。\n\nPathChildrenCache\nPathChildrenCache 不会对二级子节点进行监听，只会对子节点进行监听。\n123456789101112131415161718192021222324252627String path = &quot;/glmapper&quot;;PathChildrenCache pathChildrenCache = new PathChildrenCache(curatorClient,path,true);// 如果设置为true则在首次启动时就会缓存节点内容到Cache中。 nodeCache.start(true);pathChildrenCache.start(PathChildrenCache.StartMode.POST_INITIALIZED_EVENT);pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() &#123;  @Override  public void childEvent(CuratorFramework curatorFramework, PathChildrenCacheEvent event) throws Exception &#123;    System.out.println(&quot;-----------------------------&quot;);    System.out.println(&quot;event:&quot;  + event.getType());    if (event.getData()!=null)&#123;      System.out.println(&quot;path:&quot; + event.getData().getPath());    &#125;    System.out.println(&quot;-----------------------------&quot;);  &#125;&#125;);zookeeperCuratorClient.createNode(&quot;/glmapper/test&quot;,&quot;data&quot;.getBytes(),CreateMode.PERSISTENT);Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;1&quot;.getBytes());Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;2&quot;.getBytes());Thread.sleep(1000);zookeeperCuratorClient.createNode(&quot;/glmapper/test/second&quot;,&quot;data&quot;.getBytes(),CreateMode.PERSISTENT);Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test/second&quot;,&quot;1&quot;.getBytes());Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test/second&quot;,&quot;2&quot;.getBytes());Thread.sleep(1000);\n\n注意：在测试过程中发现，如果连续两个操作之间不进行一定时间的间隔，会导致无法监听到下一次事件。因此只会监听子节点，所以对二级子节点 &#x2F;second 下面的操作是监听不到的。测试中控制台输出的信息如下：\n123456789101112131415-----------------------------event:CHILD_ADDEDpath:/glmapper/test----------------------------------------------------------event:INITIALIZED----------------------------------------------------------event:CHILD_UPDATEDpath:/glmapper/test----------------------------------------------------------event:CHILD_UPDATEDpath:/glmapper/test-----------------------------\n\nTreeCache\nTreeCache 使用一个内部类TreeNode来维护这个一个树结构。并将这个树结构与ZK节点进行了映射。所以TreeCache 可以监听当前节点下所有节点的事件。\n1234567891011121314151617181920212223String path = &quot;/glmapper&quot;;TreeCache treeCache = new TreeCache(curatorClient,path);treeCache.getListenable().addListener((client,event)-&gt; &#123;    System.out.println(&quot;-----------------------------&quot;);    System.out.println(&quot;event:&quot;  + event.getType());    if (event.getData()!=null)&#123;      System.out.println(&quot;path:&quot; + event.getData().getPath());    &#125;    System.out.println(&quot;-----------------------------&quot;);&#125;);treeCache.start();zookeeperCuratorClient.createNode(&quot;/glmapper/test&quot;,&quot;data&quot;.getBytes(),CreateMode.PERSISTENT);Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;1&quot;.getBytes());Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test&quot;,&quot;2&quot;.getBytes());Thread.sleep(1000);zookeeperCuratorClient.createNode(&quot;/glmapper/test/second&quot;,&quot;data&quot;.getBytes(),CreateMode.PERSISTENT);Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test/second&quot;,&quot;1&quot;.getBytes());Thread.sleep(1000);curatorClient.setData().forPath(&quot;/glmapper/test/second&quot;,&quot;2&quot;.getBytes());Thread.sleep(1000);\n\n测试中控制台输出的信息如下：\n12345678910111213141516171819202122232425262728-----------------------------event:NODE_ADDEDpath:/glmapper----------------------------------------------------------event:NODE_ADDEDpath:/glmapper/test----------------------------------------------------------event:NODE_UPDATEDpath:/glmapper/test----------------------------------------------------------event:NODE_UPDATEDpath:/glmapper/test----------------------------------------------------------event:NODE_ADDEDpath:/glmapper/test/second----------------------------------------------------------event:NODE_UPDATEDpath:/glmapper/test/second----------------------------------------------------------event:NODE_UPDATEDpath:/glmapper/test/second-----------------------------\n\n事务操作 CuratorFramework 的实例包含 inTransaction( ) 接口方法，调用此方法开启一个 ZooKeeper 事务。 可以复合create、 setData、 check、and&#x2F;or delete 等操作然后调用 commit() 作为一个原子操作提交。\n123456789101112131415161718192021// 开启事务  CuratorTransaction curatorTransaction = curatorClient.inTransaction();Collection&lt;CuratorTransactionResult&gt; commit =   // 操作1 curatorTransaction.create().withMode(CreateMode.EPHEMERAL).forPath(&quot;/glmapper/transaction&quot;)  .and()  // 操作2   .delete().forPath(&quot;/glmapper/test&quot;)  .and()  // 操作3  .setData().forPath(&quot;/glmapper/transaction&quot;, &quot;data&quot;.getBytes())  .and()  // 提交事务  .commit();Iterator&lt;CuratorTransactionResult&gt; iterator = commit.iterator();while (iterator.hasNext())&#123;  CuratorTransactionResult next = iterator.next();  System.out.println(next.getForPath());  System.out.println(next.getResultPath());  System.out.println(next.getType());&#125;\n\n这里debug看了下Collection信息，面板如下：\n\n异步操作前面提到的增删改查都是同步的，但是 Curator 也提供了异步接口，引入了 BackgroundCallback 接口用于处理异步接口调用之后服务端返回的结果信息。BackgroundCallback 接口中一个重要的回调值为 CuratorEvent，里面包含事件类型、响应吗和节点的详细信息。\n在使用上也是非常简单的，只需要带上 inBackground() 就行，如下：\n1curatorClient.getData().inBackground().forPath(&quot;/glmapper/test&quot;);\n\n通过查看 inBackground 方法定义可以看到，inBackground 支持自定义线程池来处理返回结果之后的业务逻辑。\n1public T inBackground(BackgroundCallback callback, Executor executor);\n\n这里就不贴代码了。\n小结本文主要围绕 Curator 的基本 API 进行了学习记录，对于原理及源码部分没有涉及。这部分如果有时间在慢慢研究吧。另外像分布式锁、分布式自增序列等实现停留在理论阶段，没有实践，不敢妄论，用到再码吧。\n参考\nhttp://www.cnblogs.com/felixzh/p/5869212.html\nhttps://my.oschina.net/roccn/blog/918209\n\n","slug":"middleware/middleware-zookeeper-client-curator","date":"2019-04-13T14:09:30.000Z","categories_index":"Middleware","tags_index":"curator,zookeeper","author_index":"glmapper"},{"id":"7b12c81b8791d99dc46d122cdc93aac5","title":"SpringBoot 源码系列-事件机制详解","content":"在这篇文章中聊一聊 Spring 中的扩展机制（一）中对Spring中的事件机制进行了分析。那么对于 SpringBoot 来说，它在 Spring 的基础上又做了哪些拓展呢？本篇将来聊一聊 SpringBoot 中的事件。\n\n\n在 SpringBoot 的启动过程中，会通过 SPI 机制去加载 spring.factories 下面的一些类，这里面就包括了事件相关的类。\n\nSpringApplicationRunListener123# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\\org.springframework.boot.context.event.EventPublishingRunListener\nApplicationListener1234567891011# Application Listenersorg.springframework.context.ApplicationListener=\\org.springframework.boot.ClearCachesApplicationListener,\\org.springframework.boot.builder.ParentContextCloserApplicationListener,\\org.springframework.boot.context.FileEncodingApplicationListener,\\org.springframework.boot.context.config.AnsiOutputApplicationListener,\\org.springframework.boot.context.config.ConfigFileApplicationListener,\\org.springframework.boot.context.config.DelegatingApplicationListener,\\org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\\org.springframework.boot.context.logging.LoggingApplicationListener,\\org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener\n\n SpringApplicationRunListener 类是 SpringBoot 中新增的类。SpringApplication 类 中使用它们来间接调用 ApplicationListener。另外还有一个新增的类是SpringApplicationRunListeners，SpringApplicationRunListeners 中包含了多个 SpringApplicationRunListener。\nSpringApplicationRunListener SpringApplicationRunListener 接口规定了 SpringBoot 的生命周期，在各个生命周期广播相应的事件，调用实际的 ApplicationListener 类。通过对 SpringApplicationRunListener 的分析，也可以对 SpringBoot 的整个启动过程的理解会有很大帮助。\n 先来看下SpringApplicationRunListener 接口的代码：\n123456789101112131415161718public interface SpringApplicationRunListener &#123;\t//当run方法首次启动时立即调用。可用于非常早期的初始化。\tvoid starting();\t//在准备好环境后，但在创建ApplicationContext之前调用。\tvoid environmentPrepared(ConfigurableEnvironment environment);\t//在创建和准备好ApplicationContext之后，但在加载源之前调用。\tvoid contextPrepared(ConfigurableApplicationContext context);\t//在加载应用程序上下文后但刷新之前调用\tvoid contextLoaded(ConfigurableApplicationContext context);\t//上下文已刷新，应用程序已启动，但尚未调用commandlinerunner和applicationrunner。\tvoid started(ConfigurableApplicationContext context);\t//在运行方法完成之前立即调用，此时应用程序上下文已刷新，\t//并且所有commandlinerunner和applicationrunner都已调用。\t//2.0 才有\tvoid running(ConfigurableApplicationContext context);\t//在运行应用程序时发生故障时调用。2.0 才有\tvoid failed(ConfigurableApplicationContext context, Throwable exception);&#125;\nSpringApplicationRunListeners上面提到，SpringApplicationRunListeners 是SpringApplicationRunListener的集合，里面包括了很多SpringApplicationRunListener实例；SpringApplication 类实际上使用的是 SpringApplicationRunListeners 类，与 SpringApplicationRunListener 生命周期相同，调用各个周期的 SpringApplicationRunListener 。然后广播相应的事件到 ApplicationListener。\n\n\n\n\n\n\n\n\n\n代码详见：SpringApplicationRunListeners.\nEventPublishingRunListenerEventPublishingRunListener 类是 SpringApplicationRunListener接口的实现类 ，它具有广播事件的功能。其内部使用 ApplicationEventMulticaster在实际刷新上下文之前发布事件。下面来看下 EventPublishingRunListener 类生命周期对应的事件。\nApplicationStartingEventApplicationStartingEvent 是 SpringBoot 启动开始的时候执行的事件，在该事件中可以获取到 SpringApplication 对象，可做一些执行前的设置，对应的调用方法是 starting()。\nApplicationEnvironmentPreparedEventApplicationEnvironmentPreparedEvent 是SpringBoot 对应 Enviroment 已经准备完毕时执行的事件，此时上下文 context 还没有创建。在该监听中获取到 ConfigurableEnvironment 后可以对配置信息做操作，例如：修改默认的配置信息，增加额外的配置信息等。对应的生命周期方法是 environmentPrepared(environment)；SpringCloud 中，引导上下文就是在这时初始化的。\nApplicationContextInitializedEvent当 SpringApplication 启动并且准备好 ApplicationContext，并且在加载任何 bean 定义之前调用了 ApplicationContextInitializers 时发布的事件。对应的生命周期方法是contextPrepared()\nApplicationPreparedEventApplicationPreparedEvent 是SpringBoot上下文 context 创建完成是发布的事件；但此时 spring 中的 bean 还没有完全加载完成。这里可以将上下文传递出去做一些额外的操作。但是在该监听器中是无法获取自定义 bean 并进行操作的。对应的生命周期方法是 contextLoaded()。\nApplicationStartedEvent这个事件是在 2.0 版本才引入的；具体发布是在应用程序上下文刷新之后，调用任何 ApplicationRunner 和 CommandLineRunner 运行程序之前。\nApplicationReadyEvent这个和 ApplicationStartedEvent 很类似，也是在应用程序上下文刷新之后之后调用，区别在于此时ApplicationRunner 和 CommandLineRunner已经完成调用了，也意味着 SpringBoot 加载已经完成。\nApplicationFailedEventSpringBoot 启动异常时执行的事件，在异常发生时，最好是添加虚拟机对应的钩子进行资源的回收与释放，能友善的处理异常信息。\ndemo 及各个事件的执行顺序下面的各个事件对应的demo及打印出来的执行顺序。\n\nGlmapperApplicationStartingEventListener123456public class GlmapperApplicationStartingEventListener implements ApplicationListener&lt;ApplicationStartingEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationStartingEvent applicationStartingEvent) &#123;        System.out.println(&quot;execute ApplicationStartingEvent ...&quot;);    &#125;&#125;\nGlmapperApplicationEnvironmentPreparedEvent\n\n123456public class GlmapperApplicationEnvironmentPreparedEvent implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationEnvironmentPreparedEvent applicationEnvironmentPreparedEvent) &#123;        System.out.println(&quot;execute ApplicationEnvironmentPreparedEvent ...&quot;);    &#125;&#125;\n\nGlmapperApplicationContextInitializedEvent\n\n123456public class GlmapperApplicationContextInitializedEvent implements ApplicationListener&lt;ApplicationContextInitializedEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationContextInitializedEvent applicationContextInitializedEvent) &#123;        System.out.println(&quot;execute applicationContextInitializedEvent ...&quot;);    &#125;&#125;\n\n\nGlmapperApplicationPreparedEvent\n\n123456public class GlmapperApplicationPreparedEvent implements ApplicationListener&lt;ApplicationPreparedEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationPreparedEvent applicationPreparedEvent) &#123;        System.out.println(&quot;execute ApplicationPreparedEvent ...&quot;);    &#125;&#125;\n\n\nGlmapperApplicationStartedEvent\n\n123456public class GlmapperApplicationStartedEvent implements ApplicationListener&lt;ApplicationStartedEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationStartedEvent applicationStartedEvent) &#123;        System.out.println(&quot;execute ApplicationStartedEvent ...&quot;);    &#125;&#125;\n\nGlmapperApplicationReadyEvent\n\n123456public class GlmapperApplicationReadyEvent implements ApplicationListener&lt;ApplicationReadyEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationReadyEvent applicationReadyEvent) &#123;        System.out.println(&quot;execute ApplicationReadyEvent ...&quot;);    &#125;&#125;\n\n\n执行结果\n\n\nSpringBoot 中的事件体系这里围绕 SpringApplicationRunListener 这个类来说。在实现类 EventPublishingRunListener 中，事件发布有两种模式：\n\n通过 SimpleApplicationEventMulticaster 进行事件广播\n所有监听器交给相应的 Context\n\n所以EventPublishingRunListener 不仅负责发布事件，而且在合适的时机将 SpringApplication 所获取的监听器和应用上下文作关联。\nSimpleApplicationEventMulticasterSimpleApplicationEventMulticaster是 Spring 默认的事件广播器。来看下它是怎么工作的：\n12345678910111213@Overridepublic void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) &#123;    ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event));    for (final ApplicationListener&lt;?&gt; listener : getApplicationListeners(event, type)) &#123;        Executor executor = getTaskExecutor();        if (executor != null) &#123;            executor.execute(() -&gt; invokeListener(listener, event));        &#125;        else &#123;            invokeListener(listener, event);        &#125;    &#125;&#125;\n从上面的代码段可以看出，它是通过遍历注册的每个监听器，并启动来调用每个监听器的 onApplicationEvent 方法。\n下面再来看下 SimpleApplicationEventMulticaster 的类集成结构：这里的 AbstractApplicationContext 下面来聊，这个类实际上就负责了事件体系的初始化工作。\n事件体系的初始化事件体系的初始化对应在 SpringBoot启动过程的 refreshContext这个方法；refreshContext具体调用 AbstractApplicationContext.refresh()方法，最后调用 initApplicationEventMulticaster() 来完成事件体系的初始化,代码如下：\n\n用户可以为容器定义一个自定义的事件广播器，只要实现 ApplicationEventMulticaster 就可以了，Spring 会通过 反射的机制将其注册成容器的事件广播器，如果没有找到配置的外部事件广播器，Spring 就是默认使用 SimpleApplicationEventMulticaster 作为事件广播器。\n事件注册事件注册是在事件体系初始化完成之后做的事情，也是在 AbstractApplicationContext.refresh() 方法中进行调用的。\n这里干了三件事：\n\n首先注册静态指定的 listeners；这里包括我们自定义的那些监听器。\n调用 DefaultListableBeanFactory 中 getBeanNamesForType 得到自定义的 ApplicationListener bean 进行事件注册。\n广播早期的事件。\n\n事件广播事件发布伴随着 SpringBoot 启动的整个生命周期。不同阶段对应发布不同的事件，上面我们已经对各个事件进行了分析，下面就具体看下发布事件的实现：\n\n\n\n\n\n\n\n\n\norg.springframework.context.support.AbstractApplicationContext#publishEvent\n\n\n\n\n\n\n\n\n\nearlyApplicationEvents 中的事件是广播器未建立的时候保存通知信息，一旦容器建立完成，以后都是直接通知。\n广播事件最终还是通过调用 ApplicationEventMulticaster 的 multicastEvent 来实现。而 multicastEvent 也就就是事件执行的方法。\n事件执行上面 SimpleApplicationEventMulticaster 小节已经初步介绍了 multicastEvent 这个方法。补充一点， 如果有可用的 taskExecutor 会使用并发的模式执行事件，但是实际上 SimpleApplicationEventMulticaster 并没有提供线程池实现，默认请况下是使用同步的方式执行事件（org.springframework.core.task.SyncTaskExecutor），所以如果需要异步配置的话，需要自己去实现线程池。\nSpringBoot 启动过程中的事件阶段这里回到 SpringApplication的run方法，看下 SpringBoot 在启动过程中，各个事件阶段做了哪些事情。\nstarting -&gt; ApplicationStartingEvent这里 debug 到 starting 方法，追踪到 multicastEvent，这里 type为 ApplicationStartingEvent；对应的事件如下：\n\nLoggerApplicationListener：配置日志系统。使用logging.config环境变量指定的配置或者缺省配置\nBackgroundPreinitializer：尽早触发一些耗时的初始化任务，使用一个后台线程\nDelegatingApplicationListener：监听到事件后转发给环境变量context.listener.classes指定的那些事件监听器\nLiquibaseServiceLocatorApplicationListener：使用一个可以和 SpringBoot 可执行jar包配合工作的版本替换 liquibase ServiceLocator\n\nlisteners.environmentPrepared-&gt;ApplicationEnvironmentPreparedEvent\n\nAnsiOutputApplicationListener：根据spring.output.ansi.enabled参数配置AnsiOutput\n\nConfigFileApplicationListener：EnvironmentPostProcessor，从常见的那些约定的位置读取配置文件，比如从以下目录读取application.properties,application.yml等配置文件：\n\nclasspath:\nfile:.\nclasspath:config\nfile:.&#x2F;config&#x2F;\n\n  也可以配置成从其他指定的位置读取配置文件。\n\nClasspathLoggingApplicationListener：对环境就绪事件ApplicationEnvironmentPreparedEvent&#x2F;应用失败事件ApplicationFailedEvent做出响应，往日志DEBUG级别输出TCCL(thread context class loader)的 classpath。\n\nFileEncodingApplicationListener：如果系统文件编码和环境变量中指定的不同则终止应用启动。具体的方法是比较系统属性file.encoding和环境变量spring.mandatory-file-encoding是否相等(大小写不敏感)。\n\n\nlisteners.contextPrepared-&gt;ApplicationContextInitializedEvent相关监听器参考上面的描述。\nlisteners.contextLoaded-&gt;ApplicationPreparedEvent相关监听器参考上面的描述。\nrefresh-&gt;ContextRefreshedEvent\n\nConditionEvaluationReportLoggingListener：实际上实现的是 ApplicationContextInitializer接口，其目的是将 ConditionEvaluationReport 写入到日志，使用DEBUG级别输出。程序崩溃报告会触发一个消息输出，建议用户使用调试模式显示报告。它是在应用初始化时绑定一个ConditionEvaluationReportListener事件监听器，然后相应的事件发生时输出ConditionEvaluationReport报告。\nClearCachesApplicationListener：应用上下文加载完成后对缓存做清除工作，响应事件ContextRefreshedEvent。\nSharedMetadataReaderFactoryContextInitializer：　向context注册了一个BeanFactoryPostProcessor：CachingMetadataReaderFactoryPostProcessor实例。\nResourceUrlProvider：handling mappings处理\n\nstarted-&gt;ApplicationStartedEvent相关监听器参考上面的描述。\nrunning-&gt;ApplicationReadyEvent相关监听器参考上面的描述。\nBackgroundPreinitializer&amp;DelegatingApplicationListener这两个贯穿了整个过程，这里拎出来单独解释下：\n\nBackgroundPreinitializer：对于一些耗时的任务使用一个后台线程尽早触发它们开始执行初始化，这是SpringBoot的缺省行为。这些初始化动作也可以叫做预初始化。可以通过设置系统属性spring.backgroundpreinitializer.ignore为true可以禁用该机制。该机制被禁用时，相应的初始化任务会发生在前台线程。\nDelegatingApplicationListener：监听应用事件，并将这些应用事件广播给环境属性context.listener.classes指定的那些监听器。\n\n小结到此，SpringBoot 中的事件相关的东西就结束了。本文从SpringApplicationRunListener这个类说起，接着介绍 SpringBoot 启动过程的事件以及事件的生命周期。最后介绍了 SpringBoot中的内置的这些 监听器在启动过程中对应的各个阶段。\n新年伊始，祝大家新年快乐！\n参考\nhttps://blog.csdn.net/andy_zhang2007/article/details/84105284\n\n","slug":"springboot/springboot-series-event","date":"2019-04-13T09:53:12.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,event,事件机制","author_index":"glmapper"},{"id":"f94d5062192ef9da77e7f3024a117b4b","title":"SpringBoot 实践系列-Kafka简介&集成SpringBoot","content":"\n\n\n\n\n\n\n\n\n 近期在做 SOFA 与 SpringCloud 的集成，希望通过一系列的 DEMO 工程去帮助大家更好的使用 SOFA 和 SpringCloud；同时也希望大家一起来参与共建和 star。\nGitHub传送门：spring-cloud-sofastack-samples\nKafka 简介\n\n\n\n\n\n\n\n\n官方网站：https://kafka.apache.org/\n\n\n\n功能提供Apache Kafka™ 是 一个分布式数据流平台，从官方文档的解释来看，其职能大体如下：\n\nPublish and subscribe to streams of records, similar to a message queue or enterprise messaging system。发布和订阅数据流，与消息队列或企业级消息系统很像。\nStore streams of records in a fault-tolerant durable way。具有很强容灾性的存储数据流\nProcess streams of records as they occur。及时的处理数据流。\n\n作为一个后端司机，大多数情况下都是把 Kafka 作为一个分布式消息队列来使用的，分布式消息队列可以提供应用解耦、流量消峰、消息分发等功能，已经是大型互联网服务架构不可缺少的基础设置了。\n基本概念topic 和 partitionKafka 对数据提供的核心抽象，topic 是发布的数据流的类别或名称。topic 在 Kafka 中，支持多订阅者； 也就是说，topic 可以有零个、一个或多个消费者订阅写到相应 topic 的数据。对应每一个 topic，Kafka 集群会维护像一个如下这样的分区的日志：每个 Partition 都是一个有序的、不可变的并且不断被附加的记录序列，也就是一个结构化提交日志（commit log）。为了保证唯一标性识 Partition 中的每个数据记录，Partition 中的记录每个都会被分配一个叫做偏移（offset）顺序的ID号。通过一个可配置的保留期，Kafka 集群会保留所有被发布的数据，不管它们是不是已经被消费者处理。例如，如果保留期设置为两天，则在发布记录后的两天内，数据都可以被消费，之后它将被丢弃以释放空间。 Kafka 的性能是不为因为数据量大小而受影响的，因此长时间存储数据并不成问题。\n事实上，在每个消费者上保留的唯一元数据是消费者在日志中的偏移位置，这个偏移由消费者控制：通常消费者会在读取记录时线性地提高其偏移值（offset++），但实际上，由于偏移位置由消费者控制，它可以以任何顺序来处理数据记录。 例如，消费者可以重置为较旧的偏移量以重新处理来自过去的数据，或者跳过之前的记录，并从“现在”开始消费。 这种特征的组合意味着 Kafka 消费者非常轻量级，随意的开启和关闭并不会对其他的消费者有大的影响。\n日志中的 Partition 有几个目的：\n\n保证日志的扩展性，topic 的大小不受单个服务器大小的限制。每个单独的 Partition 大小必须小于托管它的服务器磁盘大小，但 topic 可能有很多 Partition，因此它可以处理任意数量的海量数据。\n作为并行处理的单位 (知乎-Partition：Kafka可以将主题划分为多个分区（Partition），会根据分区规则选择把消息存储到哪个分区中，只要如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡和水平扩展。另外，多个订阅者可以从一个或者多个分区中同时消费数据，以支撑海量数据处理能力)\n\nkafka中的topic为什么要进行分区\n\n\n\n\n\n\n\n\n原贴：kafka中的topic为什么要进行分区 ，由于不能转载，此处不摘抄原文~\n生产者生产者将数据发布到他们选择的 topic ， 生产者负责选择要吧数据分配给 topic 中哪个 Partition。这可以通过循环方式（round-robin）简单地平衡负载，或者可以根据某些语义进行分区（例如基于数据中的某些关键字）来完成。\n消费者消费者们使用消费群组(consumer group )名称来标注自己，几个消费者共享一个 group，每一个发布到 topic 的数据会被传递到每个消费群组(consumer group )中的一个消费者实例。 消费者实例可以在不同的进程中或不同的机器上。\n如果所有的消费者实例具有相同的 consumer group，则记录将在所有的消费者实例上有效地负载平衡\n如果所有的消费者实例都有不同的 consumer group，那么每个记录将被广播给所有的消费者进程，每个数据都发到了所有的消费者。\n\n\n\n\n\n\n\n\n\n上图解释源自《Kafka 官方文档》 介绍：\n如上图，一个两个服务器节点的Kafka集群， 托管着4个分区(P0-P3)，分为两个消费者群. 消费者群A有2个消费者实例，消费者群B有4个. 然而，更常见的是，我们发现主题具有少量的消费者群，每个消费者群代表一个“逻辑订户”。每个组由许多消费者实例组成，保证可扩展性和容错能力。这可以说是“发布-订阅”语义，但用户是一组消费者而不是单个进程。 在Kafka中实现消费的方式，是通过将日志中的分区均分到消费者实例上，以便每个实例在任何时间都是“相应大小的一块”分区的唯一消费者。维护消费者组成员资格的过程，由卡夫卡协议动态处理。 如果新的实例加入组，他们将从组中的其他成员接管一些分区; 如果一个实例消失，其分区将被分发到剩余的实例。 Kafka仅提供单个分区内的记录的顺序，而不是主题中的不同分区之间的总顺序。 每个分区排序结合按键分区，足以满足大多数应用程序的需求。 但是，如果您需要使用总顺序，则可以通过仅具有一个分区的主题来实现，尽管这仅意味着每个消费者组只有一个消费者进程。\nKafka 作为消息系统消息系统传统上有两种模式: 队列和发布-订阅。 \n\n队列模式中，消费者池可以从服务器读取，每条记录只会被某一个消费者消费\n允许在多个消费者实例上分配数据处理，但是一旦数据被消费之后，数据就没有了\n\n\n发布订阅模式中，记录将广播给所有消费者\n允许将数据广播到多个进程，但无法缩放和扩容，因为每个消息都发送给每个订阅用户\n\n\n\n\n\n\n\n\n\n\n\n\n本篇只介绍 Kafka 作为消息队列的一些基本概念，更多介绍请参考官方文档。\nKafka 安装这里来看下如何安装 kafka，下载地址：https://kafka.apache.org/downloads。本篇使用的版本是 kafka_2.12-1.1.1。\n\n获取包文件\n1&gt; wget http://mirrors.shu.edu.cn/apache/kafka/1.1.1/kafka_2.12-1.1.1.tgz\n\n解压压缩包\n1&gt; tar -zxvf kafka_2.12-1.1.1.tgz\n\n修改配置文件\n12&gt; cd kafka_2.12-1.1.1/config&gt; vim server.properties\n\n我这里主要修改项包括以下几个：\n12345678# The id of the broker. This must be set to a unique integer for each broker.broker.id=0listeners=PLAINTEXT://192.168.0.1:9092advertised.listeners=PLAINTEXT://192.168.0.1:9092# zookeeper 地址，可以多个zookeeper.connect=192.168.0.6:2181\n\n  Kafka 服务启动需要依赖 Zookeeper ，所以在配置文件中需要指定 Zookeeper 集群地址。Kafka 自己的安装包中解压之后是包括 Zookeeper 的，可以通过以下的方式来启动一个单节点 Zookeeper 实例：\n  1&gt; sh zookeeper-server-start.sh -daemon config/zookeeper.properties\n\n\n\n\n\n\n\n\n\n\n这里我是指定了之前部署的一台ZK机器，所以可以直接将ZK地址指到已部署好的地址。Zookeeper 安装可以参考： Linux 下安装 Zookeeper \n  通过上述操作，下面就可以直接来启动Kafka 服务了：\n  1&gt; sh kafka-server-start.sh config/server.properties\n\nSpringBoot 集成 Kafka构建一个简单的 Kafka Producer 工具依赖\n依赖引入\n\n12345&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;\t&lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;\t&lt;version&gt;1.3.5.RELEASE&lt;/version&gt;&lt;!--$NO-MVN-MAN-VER$--&gt;&lt;/dependency&gt;\n\n\nproducer\n\n为了可以把 Kafka 封装已提供给其他模块使用，大家可以将 Kafka 的生产端工具类使用 SpringBoot 的自动配置机制进行包装，如下：\n123456789@Configurationpublic class KafkaProducerAutoConfiguration &#123;    @Autowired    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;    @Bean    public KafkaSender kafkaSender()&#123;        return new KafkaSender(kafkaTemplate);    &#125;&#125;\n\nKafkaSender\n\n123456789101112public class KafkaSender &#123;    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;    public KafkaSender(KafkaTemplate&lt;String, String&gt; kafkaTemplate) &#123;        this.kafkaTemplate = kafkaTemplate;    &#125;    /**     * send message     */    public void sendMessage(String topic, String message) &#123;        kafkaTemplate.send(topic, message);    &#125;&#125;\n\n自动配置\n\n12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\io.sofastack.cloud.core.kafka.configuration.KafkaProducerAutoConfiguration\n\n工程模块如下：image-20190306151759441.png\n案例测试在测试工程中引入依赖，这个依赖就是上面工程打包来的：\n1234&lt;dependency&gt;\t&lt;groupId&gt;io.sofastack.cloud&lt;/groupId&gt;\t&lt;artifactId&gt;sofastack-cloud-core-kafka&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n在 resources 目录下新建 application.properties 配置文件123456789101112131415161718192021222324#============== kafka ===================# 指定kafka 代理地址，可以多个,这里的192.168.0.1是上面Kafka 启动配置文件中对应的# 注：网上一些帖子中说 Kafka 这里的配置只能是主机名，不支持 ip，没有验证过，# 如果您在验证时出现问题，可以尝试本机绑定下 hostspring.kafka.bootstrap-servers= 192.168.0.1:9092#=============== provider  =======================spring.kafka.producer.retries=0# 每次批量发送消息的数量spring.kafka.producer.batch-size=16384spring.kafka.producer.buffer-memory=33554432# 指定消息key和消息体的编解码方式spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer#=============== consumer  =======================# 指定默认消费者group idspring.kafka.consumer.group-id=test-consumer-groupspring.kafka.consumer.auto-offset-reset=earliestspring.kafka.consumer.enable-auto-commit=truespring.kafka.consumer.auto-commit-interval=100ms# 指定消息key和消息体的编解码方式spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.application.name=kafka-testlogging.path=./logs\n启动类中模拟发送消息\n\n123456789101112131415161718@SpringBootApplication@PropertySource(&quot;classpath:application-kafka.properties&quot;)public class ProviderApplication &#123;    public static void main(String[] args) &#123;        ConfigurableApplicationContext run = SpringApplication.run(ProviderApplication.class, args);        // 这里通过容器获取，正常使用情况下，可以直接使用 Autowired 注入        KafkaSender bean = run.getBean(KafkaSender.class);        for (int i = 0; i &lt; 3; i++) &#123;            //调用消息发送类中的消息发送方法            bean.sendMessage(KafkaContants.TRADE_TOPIC, &quot;send a test message&quot;);            try &#123;                Thread.sleep(3000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n\n编写消费者，在 SpringBoot 工程中，消费者实现非常简单\n\n123456789101112@Componentpublic class KafkaReceiver &#123;    // 配置监听的主体，groupId 和配置文件中的保持一致    @KafkaListener(topics = &#123; KafkaContants.TRADE_TOPIC &#125;, groupId = &quot;test-consumer-group&quot;)    public void listen(ConsumerRecord&lt;?, ?&gt; record) &#123;        Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value());        if (kafkaMessage.isPresent()) &#123;            Object message = kafkaMessage.get();            System.out.println(message);        &#125;    &#125;&#125;\n启动工程后，可以在控制台看下消费者打印的信息：这里保持应用正常运行，再通过服务端来手动发送消息，看下是当前消费者能够正确监听到对应的 topic 并消费。\t\n1&gt; sh kafka-console-producer.sh --broker-list 192.168.0.1:9092 --topic trading\n执行上述命令之后，命令行将会等待输入，这里输入先后输入 glmapper 和 sofa :然后再看下应用程序控制台输入结果如下：image-20190306153452565.png\n参考\nIntroduction\n《Kafka 官方文档》介绍\n\n","slug":"springboot/springboot-series-kafka-introduction","date":"2019-03-07T09:58:54.000Z","categories_index":"SpringBoot","tags_index":"SpringBoot,Kafka,消息","author_index":"glmapper"},{"id":"f93d64595e35ae0269b6922a4bbacf9d","title":"SpringCloud-版本及组件概述","content":"\n\n\n\n\n\n\n\n\n本系列基于Spring Cloud **Finchley SR2 &amp; SOFABoot 3.0.0\nSpring Cloud 为开发人员提供了快速构建分布式系统中一些常见模式的工具（例如配置管理、服务发现、断路器、智能路由、微代理、控制总线、一次性令牌、全局锁、leader选举、分布式session、集群状态）。分布式系统的协调导致了样板模式, 使用 Spring Cloud 开发人员可以快速地支持实现这些模式的服务和应用程序。它们可以在任何分布式环境中很好地工作，包括开发人员自己的笔记本电脑，裸机数据中心，以及Cloud Foundry等托管平台。\n\n\nFeatures\nSpring Cloud专注于为典型用例提供良好的开箱即用体验，并为其他用户提供可扩展性机制。\n\nDistributed&#x2F;versioned configuration       分布式&#x2F;版本化配置\nService registration and discovery         服务注册和发现\nRouting                                                  智能路由\nService-to-service calls                         service-to-service调用\nLoad balancing                                       负载均衡\nCircuit Breakers                                      断路器\nGlobal locks                                            全局锁\nLeadership election and cluster state     leader选举和集群状态管理\nDistributed messaging                            分布式消息\n\n主要项目\n\n\n\n项目名称\n项目职能\n\n\n\nSpring Cloud Config\nSpring Cloud 提供的分布式配置中心，为外部配置提供了客户端和服务端的支持。\n\n\nSpring Cloud Netflix\n与各种Netflix OSS组件集成（Eureka，Hystrix，Zuul，Archaius等）。\n\n\nSpring Cloud Bus\n用于将服务和服务实例与分布式消息传递连接在一起的事件总线。用于跨群集传播状态更改（例如，配置更改事件）。\n\n\nSpring Cloud Cloudfoundry\n提供应用程序与 Pivotal Cloud Foundry 集成。提供服务发现实现，还可以轻松实现受SSO和OAuth2保护的资源。\n\n\nSpring Cloud Open Service Broker\n为构建实现 Open service broker API 的服务代理提供了一个起点。    \n\n\nSpring Cloud Cluster\n提供Leadership选举，如：Zookeeper, Redis, Hazelcast, Consul等常见状态模式的抽象和实现。\n\n\nSpring Cloud Consul\n封装了Consul操作，consul 是一个服务发现与配置工具，与Docker容器可以无缝集成。\n\n\nSpring Cloud Security\n基于spring security的安全工具包，为你的应用程序添加安全控制。在Zuul代理中为负载平衡的OAuth2 rest客户端和身份验证头中继提供支持。\n\n\nSpring Cloud Sleuth\nSpring Cloud 提供的分布式链路跟踪组件，兼容zipkin、HTracer和基于日志的跟踪（ELK）\n\n\nSpring Cloud Data Flow\n大数据操作工具，作为Spring XD的替代产品，它是一个混合计算模型，结合了流数据与批量数据的处理方式。\n\n\nSpring Cloud Stream\n数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。\n\n\nSpring Cloud CLI\n基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。\n\n\nSpring Cloud OpenFeign\n一个http client客户端，致力于减少http client客户端构建的复杂性。\n\n\nSpring Cloud Gateway\nSpring Cloud 提供的网关服务组件\n\n\nSpring Cloud Stream App Starters\nSpring Cloud Stream App Starters是基于Spring Boot的Spring 集成应用程序，可提供与外部系统的集成。\n\n\nSpring Cloud Task\n提供云端计划任务管理、任务调度。\n\n\nSpring Cloud Task App Starters\nSpring Cloud任务应用程序启动器是SpringBoot应用程序，它可以是任何进程，包括不会永远运行的Spring批处理作业，并且在有限的数据处理周期后结束&#x2F;停止。\n\n\nSpring Cloud Zookeeper\n操作Zookeeper的工具包，用于使用zookeeper方式的服务发现和配置管理。\n\n\nSpring Cloud AWS\n提供与托管的AWS集成\n\n\nSpring Cloud Connectors\n便于云端应用程序在各种PaaS平台连接到后端，如：数据库和消息代理服务。\n\n\nSpring Cloud Starters\nSpring Boot式的启动项目，为Spring Cloud提供开箱即用的依赖管理。\n\n\nSpring Cloud Contract\nSpring Cloud Contract是一个总体项目，其中包含帮助用户成功实施消费者驱动合同方法的解决方案。\n\n\nSpring Cloud Pipelines\nSpring Cloud Pipelines提供了一个固定意见的部署管道，其中包含确保您的应用程序可以零停机方式部署并轻松回滚出错的步骤。\n\n\nSpring Cloud Function\nSpring Cloud Function通过函数促进业务逻辑的实现。 它支持Serverless 提供商之间的统一编程模型，以及独立运行（本地或PaaS）的能力。\n\n\nSpringCloud 与 SpringBoot 版本兼容关系\n\n\nRelease Train\nBoot Version\n\n\n\nGreenwich\n2.1.x\n\n\nFinchley\n2.0.x\n\n\nEdgware\n1.5.x\n\n\nDalston\n1.5.x\n\n\nSpringCloud 与子工程版本关系\n\n\nComponent\nEdgware.SR5\nFinchley.SR2\nFinchley.BUILD-SNAPSHOT\n\n\n\nspring-cloud-aws\n1.2.3.RELEASE\n2.0.1.RELEASE\n2.0.1.BUILD-SNAPSHOT\n\n\nspring-cloud-bus\n1.3.3.RELEASE\n2.0.0.RELEASE\n2.0.1.BUILD-SNAPSHOT\n\n\nspring-cloud-cli\n1.4.1.RELEASE\n2.0.0.RELEASE\n2.0.1.BUILD-SNAPSHOT\n\n\nspring-cloud-commons\n1.3.5.RELEASE\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-contract\n1.2.6.RELEASE\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-config\n1.4.5.RELEASE\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-netflix\n1.4.6.RELEASE\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-security\n1.2.3.RELEASE\n2.0.1.RELEASE\n2.0.1.BUILD-SNAPSHOT\n\n\nspring-cloud-cloudfoundry\n1.1.2.RELEASE\n2.0.1.RELEASE\n2.0.1.BUILD-SNAPSHOT\n\n\nspring-cloud-consul\n1.3.5.RELEASE\n2.0.1.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-sleuth\n1.3.5.RELEASE\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-stream\nDitmars.SR4\nElmhurst.SR1\nElmhurst.BUILD-SNAPSHOT\n\n\nspring-cloud-zookeeper\n1.2.2.RELEASE\n2.0.0.RELEASE\n2.0.1.BUILD-SNAPSHOT\n\n\nspring-boot\n1.5.16.RELEASE\n2.0.6.RELEASE\n2.0.7.BUILD-SNAPSHOT\n\n\nspring-cloud-task\n1.2.3.RELEASE\n2.0.0.RELEASE\n2.0.1.BUILD-SNAPSHOT\n\n\nspring-cloud-vault\n1.1.2.RELEASE\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-gateway\n1.0.2.RELEASE\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-openfeign\n\n2.0.2.RELEASE\n2.0.2.BUILD-SNAPSHOT\n\n\nspring-cloud-function\n1.0.1.RELEASE\n1.0.0.RELEASE\n1.0.1.BUILD-SNAPSHOT\n\n\n\nFinchley 构建并使用Spring Boot 2.0.x，与 Spring Boot 1.5.x 不兼容。\nDalston 和 Edgware 基于 Spring Boot 1.5.x 构建，不兼容 SpringBoot 2.0.x \nCamden 版本迭代正式结束，Dalston 将于2018年12月结束使用，Edgware 将遵循 Spring Boot 1.5.x 的生命周期结束。\nCamden 基于SpringBoot 1.4.x 构建，但是也会支持 1.5.x 版本\nBrixton 和 Angel 迭代结束时间是2017年7月，Brixton 基于SpringBoot 1.3.x ，同时也支持 1.4.x 版本\nAngel 基于 SpringBoot 1.2.x ,在某些方式不兼容 SpringBoot 1.3.x 。\nBrixton 构建在SpringBoot 1.3.x ，不兼容 SpringBoot 1.2.x 。一些基于Angel的库和大多数应用程序可以在Brixton上正常运行，但如果OAuth2具备spring-cloud-security 1.0的特性，则需要在任何地方进行更改。x被使用(它们大多在1.3.0中被移到Spring Boot中)。\n\n","slug":"springcloud/spring-cloud-summary","date":"2018-12-31T15:38:38.000Z","categories_index":"SpringCloud","tags_index":"config,gateway,netflix","author_index":"glmapper"},{"id":"aee0f82745fbac70b90b61b5afb7f8ef","title":"SpringCloud-网关 gateway","content":"网关服务核心是将进入的请求正确合理的路由到下层具体的服务进行业务处理，从它的功能来看，网关服务的核心就是路由信息的构建。\nSpring Cloud Gateway 作为 Spring Cloud 生态系统中的网关，目标是替代 Netflix Zuul，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全、监控、埋点和限流等。\n\n\n下面是官方提供的一个工作原理图：\n\n客户端发送请求到 Spring Cloud Gateway，Gateway Handler Mapping 确定请求与路由匹配，则会将请求交给Gateway Web Handler 处理。在代理前后可以执行多个过滤器。最后代理到具体的服务。\n几个概念\nRoute：Gateway 中的基本元素，它有自己的 ID、URI 、 Predicate 集合和 Filter 集合\nPredicate：判断请求的 Url 是否匹配当前的 Route\nFilter ：匹配通过之后对请求和响应的处理及修饰\n\nSpring-Cloud-Gateway 构建路由的数据流向：\n\nRouteDefinition 模型是对 Route 模型中 route 的定义以及描述，Spring-Cloud-Gateway 最终会通过RouteDefinition 来构建起 Route 实例信息。其中 RouteDefinition 代码包含两个数组分别是PredicateDefinition，FilterDefinition。\n内置的 PredicateSpring Cloud Gateway 是通过 Spring WebFlux 的 HandlerMapping 做为底层支持来匹配到转发路由，Spring Cloud Gateway 内置了很多 Predicates 工厂，这些 Predicates 工厂通过不同的 HTTP 请求参数来匹配，多个 Predicates 工厂可以组合使用。下面是内置的Predicates：\n\n\n\n组件\n备注\n\n\n\nAfter Route Predicate Factory\n此谓词匹配当前日期时间之后发生的请求。\n\n\nBefore Route Predicate Factory\n此谓词匹配在当前日期时间之前发生的请求。\n\n\nBetween Route Predicate Factory\n此谓词匹配datetime1之后和datetime2之前发生的请求。 datetime2参数必须在datetime1之后。\n\n\nCookie Route Predicate Factory\nCookie Route Predicate Factory有两个参数，cookie名称和正则表达式。此谓词匹配具有给定名称且值与正则表达式匹配的cookie。\n\n\nHeader Route Predicate Factory\nHeader Route Predicate Factory有两个参数，标题名称和正则表达式。与具有给定名称且值与正则表达式匹配的标头匹配。\n\n\nHost Route Predicate Factory\nHost Route Predicate Factory采用一个参数：主机名模式。该模式是一种Ant样式模式“.”作为分隔符。此谓词匹配与模式匹配的Host标头。\n\n\nMethod Route Predicate Factory\nMethod Route Predicate Factory采用一个参数：要匹配的HTTP方法。\n\n\nPath Route Predicate Factory\n匹配请求的path\n\n\nQuery Route Predicate Factory\nQuery Route Predicate Factory有两个参数：一个必需的参数和一个可选的正则表达式。\n\n\nRemoteAddr Route Predicate Factory\nRemoteAddr Route Predicate Factory采用CIDR符号（IPv4或IPv6）字符串的列表（最小值为1），例如， 192.168.0.1&#x2F;16（其中192.168.0.1是IP地址，16是子网掩码）。\n\n\n工程代码本篇将通过一个简单的 gateway 工程来演示如何使用上面的 Predicate 来实现路由。\n新建工程这里新建一个 glmapper-cloud-gateway 工程，具体细节如下\n依赖引入首先在当前工程的pom文件中引入spring cloud gateway 的依赖：spring-cloud-starter-gateway\n1234567891011&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n配置文件配置文件部分，除了常规的端口，应用名之外；关于spring cloud 的路由规则也可以通过配置文件进行配置，下面先以最简单的 path的方式来演示，最终达到的目标是，当输入：http://localhost:8866/gateway 时，请求信息将会被路由到 http://localhost:8086/hello(这个是一个eureka client，对外提供rest服务，工程详见glmapper-eureka-provider)。\n1234567891011121314151617eureka:  client:    serviceUrl:      defaultZone: http://localhost:8761/eureka/   #eureka server 的地址server:  port: 8866spring:  application:    name: glmapper-cloud-gateway  #应用名  cloud:    gateway:      routes:      - id: glmapper        uri: http://localhost:8086/hello   #目标地址        predicates:        - Path=/gateway   #路由规则\n\n启动应用&amp;验证这里直接启动这个工程，SpringCloud Gateway 不需要额外的注解来开启网关服务，所以这里省略启动类的代码。先后启动 glmapper-eureka-server 、glmapper-eureka-provider、glmapper-cloud-gateway。\n在浏览器中输入：http://localhost:8866/gateway ，输出的结果如下：\n1Hello Glmapper! Now Port is 8086 And hostname is HelloGlmapperService\n\n这里输出的实际上是  http://localhost:8086/hello 提供的资源，说明我们的路由规则已经生效。\n内置 Predicate 规则配置上面已经罗列了所有的 spring cloud gateway 一些内置的 Predicate  ，下面将来使用这些规则来演示下。\n时间匹配Predicate 支持设置一个时间，在请求进行转发的时候，可以通过判断在这个时间之前或者之后进行转发。在上面的列表中可以看出，基于时间的匹配支持某时间节点之前、之后，还支持介于两个时间之间的某个时间段内的匹配。基于某个时间段内的匹配规则常见的场景是限时抢购。\n\nAfter Route Predicate\n\n12345678910server:  port: 8080spring:  cloud:    gateway:      routes:      - id: glmapper    \t\t\t #自定义的路由ID        uri: http://www.glmapper.com #目标服务地址        predicates:        - After=2019-01-10T00:00:00+08:00[Asia/Shanghai] #通过时间匹配 2019年1月10日\n\nAfter Route Predicate 是指在这个时间之后的请求都转发到目标地址。请求时间在 2019年1月10日日00点00分00秒之后的所有请求都转发到地址 http://www.glmapper.com。+08:00是指时间和UTC时间相差八个小时，时间地区为 Asia&#x2F;Shanghai。\n\nBefore Route Predicate\n\n12345678910server:  port: 8080spring:  cloud:    gateway:      routes:      - id: glmapper    \t\t\t #自定义的路由ID        uri: http://www.glmapper.com #目标服务地址        predicates:        - Before=2019-01-10T00:00:00+08:00[Asia/Shanghai] #通过时间匹配 2019年1月10日\n\nBefore Route Predicate 与 After Route Predicate 刚好相反，在某个时间之前的请求的请求都进行转发。\n\nBetween Route Predicate\n\n12345678910server:  port: 8080spring:  cloud:    gateway:      routes:       - id: glmapper\t\t\t\t\t#自定义的路由ID       \turi: http://www.glmapper.com\t#目标服务地址        predicates:         - Between=2019-01-10T00:00:00+08:00[Asia/Shanghai], 2019-01-10T06:00:00+08:00[Asia/Shanghai]\n\n在2019年1月10 零点至6点之间的请求将会被路由到 http://www.glmapper.com ，其他的请求将不会被路由。\nCookie 或者 Header\nCookie Route Predicate\n\n12345678spring:  cloud:    gateway:      routes:      - id: glmapper        uri: http://localhost:8086/hello        predicates:        - Cookie=name,glmapper\n\n这里，如果我的请求信息中存在 cookie name 为 glmapper，值匹配到 glmapper 的串，那么请求将会被路由。\n\n\nPS：这里在配置的时候要注意下 routes 后面格式缩进，否则会抛出一些异常，如：\ntxtProperty: spring.cloud.gateway.routes[0].uri\nValue: null\nReason: 不能为null\nProperty: spring.cloud.gateway.routes[0].predicates\nValue: []\nReason: 不能为空\n当cookie的值不满足时，访问时404\n\n\nHeader Route Predicate\n\n12345678910spring:  application:    name: glmapper-cloud-gateway  cloud:    gateway:      routes:      - id: glmapper        uri: http://localhost:8086/hello        predicates:        - Header=X-Request-Id, \\d+\n\n上面这段配置用于配置 Header 中 X-Request-Id值数字的请求：\n\n同样，如果是非数字的话将会返回 404。\n域名匹配12345678910spring:  application:    name: glmapper-cloud-gateway  cloud:    gateway:      routes:      - id: glmapper        uri: http://localhost:8086/hello        predicates:        - Host=**.glmapper.com\n\n上面这段配置用于匹配 host 为 xxx.glmapper.com 域名的请求：\n\n关于其他的内置 Predicate 均可在官方文档中有实例参考，这里就不一一罗列了。\n组合匹配最后我们来将上面的一些进行组合，假设我需要在 2019.1.10 0点至2019.1.10 6点之间，cookie中带有name=glmapper，header 的 X-Request-Id 为数字，域名是 xx.glmapper.com ，path为 /gateway ，请求方式为GET，参数名为queryParam 的请求路由到 http://localhost:8086/hello。那么具体配置如下\n12345678910111213141516spring:  application:    name: glmapper-cloud-gateway  cloud:    gateway:      routes:      - id: glmapper        uri: http://localhost:8086/hello        predicates:        - Host=**.glmapper.com        - Path=/gateway        - Method=GET        - Header=X-Request-Id,\\d+        - Query=queryParam        - Cookie=name,glmapper        - Between=2019-01-10T00:00:00+08:00[Asia/Shanghai], 2019-01-10T06:00:00+08:00[Asia/Shanghai]\n\n还是通过curl 命令来执行以下：\n\n参考\nSpring Cloud Gateway\n\n","slug":"springcloud/spring-cloud-gateway-project","date":"2018-12-31T15:13:25.000Z","categories_index":"SpringCloud","tags_index":"gateway","author_index":"glmapper"},{"id":"3b1ec91bc07936ed68fe667fb087db85","title":"SpringCloud-熔断器 Hystrix","content":"Hystrix 是 Netflix 的一个开源项目，它能够在服务失效的情况下，通过隔离系统依赖服务的方式，防止服务级联失败，造成服务雪崩。同时Hystrix 还提供了失败回滚机制，使得系统能够更快的从异常中恢复。Hystrix 为服务间调用提供了保护和控制。\n\nHystrix 具有的功能如下：\n\n当通过客户端调用服务出现高延迟或者调用失败时，能够为系统提供保护机制\n在复杂的分布式场景下，可以防止服务雪崩效应\n提供快速失败（Fail Fast） 同时能够快速恢复\n提供失败回滚和优雅的服务降级机制\n提供近实时的监控、报警和运维控制手段\n\nHystrix 在实际应用过程中的使用方式很丰富，可以通过注解，也可以通过集成 HystrixCommand 和HystrixObservableCommand 。本篇将通过案例简单说明下说用方式。\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\n工程背景本节将会创建一个 sofa-hystrix-client 工程，通过 Spring Cloud 提供的负载均衡器 hystrix 实现服务的熔断降级。\n新建 sofa-hystrix-client本工程继续使用《SpringCloud-Eureka 服务注册》中的父工程来构建。\n右击 sofa-eureka-parent 父工程 -&gt; New -&gt; Module，这里选择 Maven 工程；\n\nartifactId：sofa-hystrix-client\n\n修改pom文件pom文件中加入 hysterix 的依赖\n123456789101112131415161718192021&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;    &lt;/dependency&gt; &lt;/dependencies&gt;\n\n配置文件123456789eureka:  client:    service-url:      defaultZone: http://localhost:8761/eureka/spring:  application:    name: hystrix-clientserver:  port: 8787\n\n没有什么特殊的配置，还是作为一个 eureka-client 存在。\n启动类启动类上增加开启断路器的注解@EnableCircuitBreaker\n12345678910111213@SpringBootApplication@EnableCircuitBreakerpublic class SofaHystrixApplication &#123;    @Bean    @LoadBalanced    public RestTemplate restTemplate()&#123;        return new RestTemplate();    &#125;    public static void main(String[] args) &#123;        SpringApplication.run(SofaHystrixApplication.class, args);    &#125;&#125;\n\n资源类\nNormalService\n\n中通过@HystrixCommand标准一个受保护的资源方法 getByServiceId()。getByServiceId 中通过restTemplate 来调用远程服务。@HystrixCommand注解的 fallbackMethod 属性指定当服务不可用时需要执行的 fallback 方法。\n1234567891011121314@Servicepublic class NormalService &#123;    @Autowired    private RestTemplate restTemplate;    @HystrixCommand(fallbackMethod = &quot;fallBack&quot;)    public String getByServiceId()&#123;        return restTemplate.getForObject(&quot;http://HELLOSOFABOOTSERVICE/hello&quot;,String.class);    &#125;    private String fallBack()&#123;        return &quot;Filed to get data&quot;;    &#125;&#125;\n\n\nHystrixRibbonController：通过instanceService调用上面的NormalService资源类\n\n123456789@RestControllerpublic class HystrixRibbonController &#123;    @Autowired    public NormalService instanceService;    @RequestMapping(&quot;/hystrix&quot;)    public String test()&#123;        return instanceService.getByServiceId();    &#125;&#125;\n\n启动&amp;验证先后启动sofa-eureka-server-center 、sofa-eureka-provider、sofa-hystrix-client 三个工程。浏览器中输入：\nhttp://localhost:8787/hystrix ，结果如下：\n1Hello SOFA! Now Port is 8086 And hostname is HelloSOFABootService\n\n关闭 sofa-eureka-provider ，刷新浏览器：\n1Filed to get data\n\n执行了 NormalService 中的 fallback 方法了。\n资源隔离hystrix 中提供了两中隔离策略，一种是基于线程池的隔离、另外一种是基于信号量的隔离。本篇只演示案例，具体原理请参看 hystrix 原理分析 相关文章。\n基于线程池的隔离实现新建一个 SofaThreadPoolHystrixCommand 类，继承 HystrixCommand。代码如下：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class SofaThreadPoolHystrixCommand extends HystrixCommand &#123;    private RestTemplate restTemplate;    public SofaThreadPoolHystrixCommand(RestTemplate restTemplate) &#123;        super(initailize());        this.restTemplate = restTemplate;    &#125;    public static HystrixCommand.Setter initailize()&#123;        // 线程池配置        HystrixThreadPoolProperties.Setter hystrixThreadPoolProperties =             HystrixThreadPoolProperties.Setter()                .withCoreSize(5)                .withKeepAliveTimeMinutes(5)                // 线程等待队列最大长度,默认值:-1 表示不等待直接拒绝,测试表明线程池使用直接决绝策略+ 合适大小的非回缩线程池效率最高.所以不建议修改此值。                .withMaxQueueSize(10)                .withQueueSizeRejectionThreshold(100);        // 命令属性配置,这里指定隔离策略是 THREAD        HystrixCommandProperties.Setter hystrixCommand =             HystrixCommandProperties.Setter() .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.THREAD)                //意味着线程最多允许执行fallback的并发数为10,超过10 报fallback execution rejected                .withFallbackIsolationSemaphoreMaxConcurrentRequests(10);        HystrixCommand.Setter setter = HystrixCommand.Setter            .withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;SofaThreadPoolHystrixCommand&quot;))                .andCommandKey(HystrixCommandKey.Factory.asKey(&quot;sofaBootService&quot;))                .andCommandPropertiesDefaults(hystrixCommand)                .andThreadPoolPropertiesDefaults(hystrixThreadPoolProperties)                .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;sofa-hystrix-thread&quot;));        return setter;    &#125;    /**     * 受保护的资源     * @return     * @throws Exception     */    @Override    protected Object run() throws Exception &#123;        return restTemplate.getForObject(&quot;http://HELLOSOFABOOTSERVICE/hello&quot;,String.class);    &#125;    /**     * 失败执行的保护方法     * @return     */    @Override    protected Object getFallback() &#123;        return &quot;this is fail back policy&quot;;    &#125;&#125;\n\n相关参数说明：\n\nHystrixCommandGroupKey：配置全局唯一标识服务分组的名称，比如账户系统就是一个服务分组，监控时，相同分组的服务会聚合在一起，必填选项。\nHystrixCommandKey：配置全局唯一标识服务的名称，比如账户系统有一个获取账号名的服务，那么就可以为这个服务起一个名字来唯一识别该服务，如果不配置，则默认是简单类名。\nHystrixThreadPoolKey：配置全局唯一标识线程池的名称，相同线程池名称的线程池是同一个，如果不配置，则默认是分组名，此名字也是线程池中线程名字的前缀。\nHystrixThreadPoolProperties：配置线程池参数\nHystrixCommandProperties：配置该命令的一些参数，如 executionIsolationStrategy 配置执行隔离策略，默认是使用线程隔离。配置为 THREAD，线程池隔离；配置为 SEMAPHORE ，信号量隔离\n\n这里为了模拟并发，使用 CountDownLatch 类来控制，在 HystrixRibbonController 中添加 testThread 资源方法：\n123456789@RequestMapping(&quot;/testThread&quot;)public String testThread()&#123;    CountDownLatch countDownLatch = new CountDownLatch(1);    for (int i = 0; i &lt; THREAD_NUM; i ++) &#123;        new Thread(new ConsumerThread(countDownLatch)).start();    &#125;    countDownLatch.countDown();    return &quot;data&quot;;&#125;\n\n内部定义一个内部类，模拟调用：\n12345678910111213141516171819class ConsumerThread implements Runnable &#123;        private final CountDownLatch startLatch;        public ConsumerThread(CountDownLatch startLatch) &#123;            this.startLatch = startLatch;        &#125;        @Override        public void run() &#123;            try &#123;                // 线程等待                startLatch.await();                // 执行操作                SofaThreadPoolHystrixCommand sofaThreadPoolHystrixCommand = new SofaThreadPoolHystrixCommand(restTemplate);                System.out.println(sofaThreadPoolHystrixCommand.execute().toString());            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;\n\n重启当前工程，浏览器执行 http://localhost:8787/testThread\n12345678this is fail back policythis is fail back policythis is fail back policythis is fail back policythis is fail back policy// ... 省略Hello SOFA! Now Port is 8086 And hostname is HelloSOFABootService// ... 省略\n\n基于信号量隔离新建一个 SofaSemaphoreHystrixCommand 类，继承 HystrixCommand。代码如下：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SofaSemaphoreHystrixCommand extends HystrixCommand &#123;    private RestTemplate restTemplate;    public SofaSemaphoreHystrixCommand(RestTemplate restTemplate) &#123;        super(initailize());        this.restTemplate = restTemplate;    &#125;    public static HystrixCommand.Setter initailize()&#123;        // 命令属性配置,这里指定隔离策略是 THREAD        HystrixCommandProperties.Setter hystrixCommand = HystrixCommandProperties.Setter()                .withExecutionIsolationStrategy(HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE)                 //至少有10个请求，熔断器才进行错误率的计算                .withCircuitBreakerRequestVolumeThreshold(0)                //熔断器中断请求5秒后会进入半打开状态,放部分流量过去重试                .withCircuitBreakerSleepWindowInMilliseconds(5000)                //错误率达到50开启熔断保护                .withCircuitBreakerErrorThresholdPercentage(50)                //最大并发请求量                .withExecutionIsolationSemaphoreMaxConcurrentRequests(10)                //意味着信号量最多允许执行fallback的并发数为10,超过10 报fallback execution rejected                .withFallbackIsolationSemaphoreMaxConcurrentRequests(10);        HystrixCommand.Setter setter = HystrixCommand.Setter.                withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;SofaSemaphoreHystrixCommand&quot;))                .andCommandKey(HystrixCommandKey.Factory.asKey(&quot;sofaBootService&quot;))                .andCommandPropertiesDefaults(hystrixCommand)                .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;sofa-hystrix-thread&quot;));        return setter;    &#125;    /**     * 受保护的资源     * @return     * @throws Exception     */    @Override    protected Object run() throws Exception &#123;        return restTemplate.getForObject(&quot;http://HELLOSOFABOOTSERVICE/hello&quot;,String.class);    &#125;    /**     * 失败执行的保护方法     * @return     */    @Override    protected Object getFallback() &#123;        return &quot;this is fail back policy&quot;;    &#125;&#125;\n\n同样使用 CountDownLatch  来模拟并发。在 HystrixRibbonController 中添加 testSemaphore 资源方法：\n123456789@RequestMapping(&quot;/testSemaphore&quot;)    public String testSemaphore()&#123;        CountDownLatch countDownLatch = new CountDownLatch(1);        for (int i = 0; i &lt; THREAD_NUM; i ++) &#123;            new Thread(new ConsumerSemaphore(countDownLatch)).start();        &#125;        countDownLatch.countDown();        return &quot;data&quot;;    &#125;\n\n内部定义一个内部类 ConsumerSemaphore ，模拟调用：\n12345678910111213141516171819class ConsumerSemaphore implements Runnable &#123;        private final CountDownLatch startLatch;        public ConsumerSemaphore(CountDownLatch startLatch) &#123;            this.startLatch = startLatch;        &#125;        @Override        public void run() &#123;            try &#123;                // 线程等待                startLatch.await();                // 执行操作                SofaSemaphoreHystrixCommand sofaThreadPoolHystrixCommand = new SofaSemaphoreHystrixCommand(restTemplate);                System.out.println(sofaThreadPoolHystrixCommand.execute().toString());            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;\n\n结果和线程隔离的差不多。不贴结果了。\n","slug":"springcloud/spring-cloud-hysitrx-project","date":"2018-12-31T15:12:58.000Z","categories_index":"SpringCloud","tags_index":"hystrix","author_index":"glmapper"},{"id":"9c3e8189292b11295e2641e78c47786a","title":"SpringCloud-Spring Cloud Context","content":"\n\n\n\n\n\n\n\n\nA Spring Cloud application operates by creating a “bootstrap” context, which is a parent context for the main application. It is responsible for loading configuration properties from the external sources and for decrypting properties in the local external configuration files. The two contexts share an Environment, which is the source of external properties for any Spring application.\nBy default, bootstrap properties (not bootstrap.properties but properties that are loaded during the bootstrap phase) are added with high precedence, so they cannot be overridden by local configuration.\nThe bootstrap context uses a different convention for locating external configuration than the main application context. Instead of application.yml (or .properties), you can use bootstrap.yml, keeping the external configuration for bootstrap and main context nicely separate.\n\n\n\n\n\n\n\n\n\n\n\n释文：Spring Cloud 应用程序通过创建“引导程序”上下文来运行，该上下文是主应用程序的父上下文共享一个 Environment**，它是任何Spring应用程序的外部属性的来源。\n默认情况下，引导属性（不是bootstrap.properties，而是在引导阶段加载的属性）以高优先级添加，因此本地配置无法覆盖它们。\n引导上下文使用与主应用程序上下文不同的外部配置约定。 因此使用 bootstrap.yml application.yml（或.properties）代替引导和主上下文的外部配置，保持引导程序和主上下文的外部配置很好地分开。\n上面是 SpringCloud 关于引导上下文的一个解释，详见 这里。\nspring cloud 有自己的一套配置初始化机制，所以它实际上是自己启动了一个Spring 上下文，也就是我们说的引导上文。在上面的描述中有提到，引导上下文会以应用上下文的父类存在；在Spring中，如果上下文存在父子关系，也就意味着子上下文会集成父上下文的属性源和配置文件。在SpringBoot的启动过程中，prepareContext 这个操作会进行父子上下文的关系设置，调用栈如下:\n\nsetParent 方法代码片段如下：\n123456789 public void setParent(@Nullable ApplicationContext parent) &#123;    this.parent = parent;    if (parent != null) &#123;        Environment parentEnvironment = parent.getEnvironment();        if (parentEnvironment instanceof ConfigurableEnvironment) &#123;            this.getEnvironment().merge((ConfigurableEnvironment)parentEnvironment);        &#125;    &#125;&#125;\n\n这个可以看到，子上下文会合并掉父上下文的 Environment 。关于父子上下文是怎么关联起来的，下面来看。\n12345678public void initialize(ConfigurableApplicationContext context) &#123;  while(context.getParent() != null &amp;&amp; context.getParent() != context) &#123;  context = (ConfigurableApplicationContext)context.getParent();  &#125;  this.reorderSources(context.getEnvironment());  (new ParentContextApplicationContextInitializer(this.parent)).initialize(context);&#125;\n\nBootstrapApplicationListener上面的代码片段定位在 org.springframework.cloud.bootstrap.BootstrapApplicationListener 这个类；这个监听器监听的事件是  ApplicationEnvironmentPreparedEvent ，对应在SpringBoot启动过程，就是在执行 prepareEnvironment 时触发事件调用。\nBootstrapApplicationListener 的 onApplicationEvent 回调方法中实际上就是用够构建和启动 Spring Cloud  context 的。spring cloud context 算是一个特殊的 spring boot context， 在分析代码的过程中（bootstrapServiceContext方法中）发现，它只扫描 BootstrapConfiguration 这个注解标注的组件。\n这里就着重分析下 SpringCloud Context 的启动过程。\nSpringCloud Context 启动过程通过 spring.cloud.bootstrap.enabled 配置来禁用引导上下文123if (!environment.getProperty(&quot;spring.cloud.bootstrap.enabled&quot;, Boolean.class,true)) &#123; \t return;&#125;\n\n回调函数的开始就会对 spring.cloud.bootstrap.enabled 这个配置值进行校验，来决定是否需要禁止引导。这个在官方文档里面也有明确提到。\n获取 configName12String configName = environment\t\t\t\t.resolvePlaceholders(&quot;$&#123;spring.cloud.bootstrap.name:bootstrap&#125;&quot;);\n可以使用 spring.cloud.bootstrap.name（默认“bootstrap”）或spring.cloud.bootstrap.location（默认为空）指定bootstrap.yml（或.properties）位置，例如在系统属性中。\nbootstrapServiceContext 创建&amp;启动bootstrapServiceContext 是完成此过程的核心方法。\n\n加载 BootstrapConfiguration 自动配置类\n\n123456# Bootstrap componentsorg.springframework.cloud.bootstrap.BootstrapConfiguration=\\org.springframework.cloud.bootstrap.config.PropertySourceBootstrapConfiguration,\\org.springframework.cloud.bootstrap.encrypt.EncryptionBootstrapConfiguration,\\org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration,\\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration\n\nPropertySourceBootstrapConfiguration 将会把 PropertySourceLocator 自定义属性值添加到引导上下文的环境当中，包括如何从远端仓库拉取配置等过程。\n\n构建 SpringApplicationBuilder 类\n123456SpringApplicationBuilder builder = new SpringApplicationBuilder()    .profiles(environment.getActiveProfiles()).bannerMode(Mode.OFF)    .environment(bootstrapEnvironment)    // Don&#x27;t use the default properties in this builder    .registerShutdownHook(false).logStartupInfo(false)    .web(WebApplicationType.NONE);\n\n构建 引导上下文并 run\n1final ConfigurableApplicationContext context = builder.run();\n\n这个 build.run 实际执行的就是 SpringApplication.run 方法。\n\n为关联父子上下文准备1addAncestorInitializer(application, context);\n\n这里会把 ParentContextApplicationContextInitializer 加到应用的 spring context 里，来把自己设置为应用的context 的 parent，具体是在SpringBoot启动过程的 prepareContext 中完成 。\n重载远程属性通过Bootstrap 上下文添加到应用程序的属性源通常是远程的，比如说来自配置中心的，一般情况下本地的配置文件不能覆盖这些远程属性源。\n那么如果想覆盖远程属性源怎么办呢？可以通过启动命令行参数方式设定（启动命令行参数的优先级高于远程配置的优先级）。\n如果想使用应用程序的系统属性或者配置文件覆盖远程属性，那么远程属性源必须设置为 spring.cloud.config.allowOverride &#x3D; true，这个配置在本地设置时不会生效的。在远程属性源中设定上述配置后，就可以通过更为细粒度的设置来控制远程属性是否能被重载，具体配置如下：\n12345spring:\tcloud:  \tconfig:    \toverrideNone: true      overrideSystemProperties: false\n\n\noverrideNone true，本地属性覆盖所有的远程属性\noverrideSystemProperties ，仅覆盖远程属性源中的系统属性和环境变量\n\n自定义 Bootstrap 属性源默认情况下，Bootstrap 的外部配置属性源是 spring cloud config server ，也就是使用配置中心加载外部属性，但是Spring中也允许用户通过将 ProoertySourceLocator 类型的Bean实例添加到 Bootstrap 上下文，也就是在 spring.factories 中添加相应的配置类，来添加额外的属性源来源。这里可以通过SpringCloud里面提供的测试用例来看下：\n123456789101112131415protected static class PropertySourceConfiguration implements PropertySourceLocator &#123;\t// 省略其他代码\t  @Override    public PropertySource&lt;?&gt; locate(Environment environment) &#123;    if (this.name != null) &#123;      assertEquals(this.name,                   environment.getProperty(&quot;spring.application.name&quot;));    &#125;    if (this.fail) &#123;      throw new RuntimeException(&quot;Planned&quot;);    &#125;    return new MapPropertySource(&quot;testBootstrap&quot;, MAP);  &#125;  // 省略其他代码\t&#125;\n\n上面代码段中传入的Envirement 参数用于创建应用上下文，它具有 SpringBoot 提供的属性源，可以使用它们来加载指定的属性源。\n最后将这个自定义的 PropertySourceLocator 配置到 spring.factories 中，这样应用程序就可以使用这个 PropertySourceConfiguration 作为其属性源了。\n12org.springframework.cloud.bootstrap.BootstrapConfiguration=\\xx.xx.x.x.PropertySourceConfiguration \n\n关于Enviroment 的变化配置中心客户端（Spring Cloud Config Client） 应用会监听  EnviromentChangeEvent 事件，当监听到这个事件时，它将持有一个被改变的键值对列表，然后客户端应用会使用这些值来做一些事情：\n\n重新绑定所有的@ConfigurationProperties的Bean@ConfigurationProperties 实例，更新本地的配置属性。\n设置日志等级（logging.level.* 相关配置）\n\nSpring Cloud 中，配置中心服务端使用 Spring Cloud Bus 将EnviromentChangeEvent 事件广播到所有的客户端中，通过这种方式来通过它们 Enviroment 发生变化。\nRefreshScope注解RefreshScope 注解的作用是，当被这个注解标记的 Bean 实例在配置发生变化时可以重新进行初始化。这个注解很好的解决了状态Bean实例只能在初始化的时候才能进行属性注入的问题。\n类org.springframework.cloud.context.scope.refresh.RefreshScope 是上下文中的一个Bean实例，在它的 refreshAll 这个方法中，可以通过清除目标缓存来刷新作用域中的所有Bean实例。RefreshScope中也提供了一个 refresh方法，可以按照名字来刷新单个Bean。\n","slug":"springcloud/spring-cloud-context-analysis","date":"2018-12-31T15:12:24.000Z","categories_index":"SpringCloud","tags_index":"bootstrap","author_index":"glmapper"},{"id":"f57e9d19e374649b9c60d012c1470985","title":"SpringCloud-配置中心 Config Zookeeper","content":"SpringCloud 除了config自己的client&#x2F;server 这套配置中心之外，还可以集成使用 zookeeper 。本篇将演示如何使用 spring-cloud-confg-zookeeper。\n\n\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\nzk &amp; zkui这里我是把 zk 和 zkui 部署在一台 linux 服务器上的。\nzk从 ZooKeeper官网 下载 zookeeper-3.4.13.tar.gz。\n\n解压\n1sudo tar -zxvf zookeeper-3.4.13.tar.gz\n\n目录重命名(可选)\n\n\n1sudo mv zookeeper-3.4.13 zookeeper\n\n\n在 zookeeper 下加一个data目录\n\n12&gt; cd zookeeper&gt; mkdir data\n\n\n修改 zoo.cfg\n\n1vim zoo.cfg\n\n修改 dataDir 地址：\n\n1dataDir=/$&#123;your path&#125;/zookeeper/data\n\n\n其他随意，启动 zk\n\n1zkServer.sh start\n\nzkui下载zkui代码，然后本地安装：\n123$ git clone https://gitee.com/ilanni/zkui.git$ cd zkui/ $ mvn clean install # 进行maven打包，执行成功后会生成target文件夹，其中有jar文件。\n\n执行结束后在zkui文件夹下生成一个target文件夹。\n\n将config.cfg文件复制到target文件夹下\n\n1cp config.cfg target/\n\ntarget文件夹中有两个jar包，我们只需要启动zkui-2.0-SNAPSHOT-jar-with-dependencies.jar就可以了。\n\n修改 config.cfg文件\n\n12&gt; cd target&gt; vim config.cfg\n\n按需修改serverPort、zkServer、userSet 等。\n\n启动\n\n12java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar# nohup java -jar zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &amp;   #退出窗口不退出进程\n\n配置文件既然是以 zk 作为配置中，那么就需要将测试用的配置数据先在zk上进行初始化。有两种方式（均基于zkui）：\n\nzkui 界面通过 import 进行导入，这里新建一个 config.txt ，内容如下：\n\n1/config/sofa/sofa-config-zk,dev=server.port=8085\n\n设置当前应用启动的端口，这里的 root 为 &#x2F;config&#x2F;sofa，应用名是 sofa-config-zk，dev是环境 ，server.port&#x3D;8085 是具体的配置kv。\n\n手动 add node\n\n这里为了方便，采用import的方式，结果如下：\n新建 sofa-config-zookeeper新建一个 SOFABoot 工程，项目为 sofa-config-zookeeper。\n依赖引入123456789101112131415&lt;!-- spring-cloud-config zk 的依赖，必选--&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\t&lt;artifactId&gt;spring-cloud-starter-zookeeper-config&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- spring-cloud-config zk 的依赖，为了自动刷新监听等--&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;\n\n配置文件1234567891011121314spring:  application:    name: sofa-config-zk  profiles:    active: dev  cloud:    zookeeper:      enabled: true  # true:开启zookeeper外部化配置, false:读取本地配置;      connect-string: sofa.cloud.alipay.net:2181      config:        root: /config/sofa   #指定zookeeper中属性的根目录        enabled: true        watcher:          enabled: true    #默认值是true, 监控配置变更后是否自动更新，需配合Spring Boot Actuators 使用\n\n启动类123456@SpringBootApplicationpublic class SofaConfigZookeeperApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaConfigZookeeperApplication.class,args);    &#125;&#125;\n\n没有任何特殊，不需要加额外的注解。\n资源类其实这里可以完全不用通过rest来打印这个属性值，但是为了方便看，还是写一下：\n1234567891011@RestControllerpublic class ZookeeperConfigController &#123;    @Value(&quot;$&#123;server.port&#125;&quot;)    private String serverPort;    @RequestMapping(&quot;/config&quot;)    public String getConfig()&#123;        return serverPort;    &#125;&#125;\n\n启动&amp;验证启动应用，如果成功的话，会有如下的日志：State change: CONNECTED\n动态刷新这里还是需要依赖 actuator 的 &#x2F;refresh 。上面依赖中已经加入了 actuator的相关依赖，所以只需要在资源类上加一个 @RefreshScope 注解即可。\n\n在 ZookeeperConfigController 类上加 @RefreshScope  注解，然后重启应用\n通过 zkui 修改 server.port 为 8086\n访问 http://localhost:8085/config ，返回8086\n\n\n\n\n\n\n\n\n\n\n需要注意，这里因为我们启动时应用时拿到的配置是8085，所以当前服务对外提供服务暴露的端口就是8085 ，当我们修改了zk上的值之后，他会改变 当前运行环境中 Enviroment 的值，但是不会使得服务的端口发生变化，除非重启。\n","slug":"springcloud/spring-cloud-config-zookeeper","date":"2018-12-31T15:11:48.000Z","categories_index":"SpringCloud","tags_index":"zookeeper,config","author_index":"glmapper"},{"id":"c052787b71e80e9cd4e175cda11073d3","title":"SpringCloud-Config 配置中心原理","content":"本篇可以配合《SpringCloud-配置中心 Config》来看，《SpringCloud-配置中心 Config》中是基于SOFABoot 来集成 Spring Cloud Config 的一个 demo 案例。\n在demo中，涉及到三个角色：\n\n配置中心服务端：为配置客户端提供对应的配置信息，配置信息的来源是配置仓库。应用启动时，会从配置仓库拉取配置信息缓存到本地仓库中。\n配置中心客户端：应用启动时从配置服务端拉取配置信息。\n配置仓库：为配置中心服务端提供配置信息存储，Spring Cloud Config 默认是使用git作为仓库的。\n\n\n整体过程：\n\n环境部署之前，将所需的配置信息推送到配置仓库\n启动配置中心服务端，将配置仓库的配置信息拉取到服务端，配置服务端对外提供REST接口\n启动配置客户端，客户端根据 spring.cloud.config 配置的信息去服务器拉取相应的配置\n\n服务端实现配置中心服务端主要做了几件事情：连接配置仓库、拉取远程配置&amp;本地缓存、对外提供API接口服务。\n@EnableConfigServer 及配置类注解 EnableConfigServer 可以开启应用服务对配置中心的支持。当开启之后，配置服务器就会在启动时进行自动配置。具体对应的配置类是 ConfigServerAutoConfiguration，然后又在 ConfigServerAutoConfiguration 这个配置类中引入了其他很多配置类。如下：\n12345678@Configuration@ConditionalOnBean(&#123;Marker.class&#125;)@EnableConfigurationProperties(&#123;ConfigServerProperties.class&#125;)@Import(&#123;EnvironmentRepositoryConfiguration.class, CompositeConfiguration.class, ResourceRepositoryConfiguration.class, ConfigServerEncryptionConfiguration.class, ConfigServerMvcConfiguration.class&#125;)public class ConfigServerAutoConfiguration &#123;    public ConfigServerAutoConfiguration() &#123;    &#125;&#125;\n\n\nEnvironmentRepositoryConfiguration： 环境变量存储相关的配置类\nCompositeConfiguration：组合方式的环境仓库配置类\nResourceRepositoryConfiguration：资源仓库相关的配置类\nConfigServerEncryptionConfiguration：加密断点相关的配置类\nConfigServerMvcConfiguration：对外暴露的MVC端点控制器的配置类\n\n无论是 Spring Cloud 自身提供的默认实现 git ，还是 zk，或者 apollo ；基本思路都是在程序启动时将远端配置拉取到本地作为环境变量来使用，但这些是针对客户端角度来说的。Spring Cloud Config Server 因为其本身是以服务端存在，所以 Config Server 本身的实现思路也值得后面开发借鉴。\n对于服务端来说，其基本职责就是能够将具体存储中的配置信息先拿到，然后提供出 API 供客户端来调用。下面从ConfigServerAutoConfiguration 中 import的这些配置类来具体看下实现。\nEnvironmentRepositoryConfigurationEnvironmentRepositoryConfiguration 是环境变量存储相关的配置类，它本身也提供了很多实现：\n\n上图中可以看到，环境配置仓库支持的有JDBC、SVN、本地文件系统、Git等等。这些对不同环境仓库的支持，在实现上基本都差不多，下面以默认提供的方式git来分析。\n1234@Configuration@Profile(&quot;git&quot;)class GitRepositoryConfiguration extends DefaultRepositoryConfiguration &#123;&#125;\n\nGitRepositoryConfiguration 集成了 DefaultRepositoryConfiguration，这也说明了 Spring Cloud Config 默认使用的是Git。不同的配置类实现都会被标注一个@Profile，可以通过这个来激活相应的配置类；具体做法是在配置服务端的 application.properties(application.yml) 中来指定：\n1spring.profile.active=git\n\n没有设置就是默认使用 GIt。\n12345678910111213141516171819@Configuration@ConditionalOnMissingBean(value = EnvironmentRepository.class, search = SearchStrategy.CURRENT)class DefaultRepositoryConfiguration &#123;\t@Autowired\tprivate ConfigurableEnvironment environment;\t@Autowired\tprivate ConfigServerProperties server;\t@Autowired(required = false)\tprivate TransportConfigCallback customTransportConfigCallback;\t@Bean\tpublic MultipleJGitEnvironmentRepository defaultEnvironmentRepository(\t        MultipleJGitEnvironmentRepositoryFactory gitEnvironmentRepositoryFactory,\t\t\tMultipleJGitEnvironmentProperties environmentProperties) throws Exception &#123;\t\treturn gitEnvironmentRepositoryFactory.build(environmentProperties);\t&#125;&#125;\n\nDefaultRepositoryConfiguration 的 ConditionalOnMissingBean 可以知道，如果上下文中没有 EnvironmentRepository，那么就使用 DefaultRepositoryConfiguration。\nMultipleJGitEnvironmentRepositoryMultipleJGitEnvironmentRepository 是 Git 存储的具体实现类，下面是类图结构：\nMultipleJGitEnvironmentRepository 的顶层接口是 EnvironmentRepository ，当然其他的实现也都是实现了这个接口的。另外一个需要关注的是 SearchPathLocator。\n\nEnvironmentRepository：定义了获取指定应用服务环境信息的方法，返回一个Enviroment\n\n123public interface EnvironmentRepository &#123;\tEnvironment findOne(String application, String profile, String label);&#125;\n\n三个参数，application、profile、label；《SpringCloud-配置中心 Config》 中客户端部分有对这三个的参数的说明及使用方式，通过这三个参数可以具体定位到配置信息。\n\nSearchPathLocator ： 根据传入客户端应用信息，获取对应的配置环境文件的位置。代码见：SearchPathLocator。\n\nSearchPathLocator 中有一个内部类 Locations ，Locdations中定义了应用服务配置存储信息。\n除了这两个之外，还有一个 AbstractScmAccessor，这个抽象类里面定义了一些列与git存储相关的属性和方法。包括远程仓库的地址、账户、密码、ssh 私钥、本地仓库的地址等等。\n\n\n\n\n\n\n\n\n\nSCM : 软件配置管理\nAbstractScmEnvironmentRepositoryAbstractScmEnvironmentRepository 实现了 AbstractScmAccessor 和 EnvironmentRepository ，主要就是EnvironmentRepository 中 findOne 的实现：\n123456789101112131415@Override\tpublic synchronized Environment findOne(String application, String profile, String label) &#123;\t//新建了一个本地仓库作为代理仓库来使用  NativeEnvironmentRepository delegate = new NativeEnvironmentRepository(getEnvironment(),\t\t\t\tnew NativeEnvironmentProperties());    //获取本地仓库中指定应用的位置\t\tLocations locations = getLocations(application, profile, label);\t\tdelegate.setSearchLocations(locations.getLocations());  \t//根据这个路径搜索应用服务的配置信息\t\tEnvironment result = delegate.findOne(application, profile, &quot;&quot;);\t\tresult.setVersion(locations.getVersion());\t\tresult.setLabel(label);\t\treturn this.cleaner.clean(result, getWorkingDirectory().toURI().toString(),\t\t\t\tgetUri());\t&#125;\n\ngetLocations 是一个模板方法，Config Server中提供了三种实现：\n\n分别是单 Git 仓库，多 Git 仓库和 Svn 仓库实现。\n123456789101112@Overridepublic synchronized Locations getLocations(String application, String profile,        String label) &#123;    if (label == null) &#123;        label = this.defaultLabel;    &#125;// 获取最新的版本号    String version = refresh(label);// 根据最新的版本号返回 Locations 定位到资源的搜索路径    return new Locations(application, profile, label, version,            getSearchLocations(getWorkingDirectory(), application, profile, label));&#125;\n\nrefresh 方法做的作用就是刷新本地仓库的配置状态，这样就能保证每次都能拉取到最新的配置信息。下面来分析这个方法。\nJGitEnvironmentRepository#refresh12345678910111213141516171819202122232425262728293031public String refresh(String label) &#123;    Git git = null;    try &#123;    // 创建一个git客户端        git = createGitClient();    // 是否需要执行 git pull        if (shouldPull(git)) &#123;            FetchResult fetchStatus = fetch(git, label);            if (deleteUntrackedBranches &amp;&amp; fetchStatus != null) &#123;                deleteUntrackedLocalBranches(fetchStatus.getTrackingRefUpdates(), git);            &#125;            // 获取后checkout，这样我们就可以获得任何新的分支、tag等。            checkout(git, label);            tryMerge(git, label);        &#125;        else &#123;            // 没有什么要更新，所以只是checkout和merge。            // 合并是因为远程分支以前可能已经更新过            checkout(git, label);            tryMerge(git, label);        &#125;        // 返回当前的版本        return git.getRepository().findRef(&quot;HEAD&quot;).getObjectId().getName();    &#125;    catch (Exception e) &#123;        // 异常处理    &#125;    finally &#123;        // 关闭git    &#125;&#125;\n\n这个里面基本就是通过git客户端的一些操作。先是检查远程仓库的状态，然后判断本地仓库是否要执行刷新操作。如果有状态更新，比如新的提交时，Git客户端就会执行fetch，然后再进行merge，更新到本地仓库。\n\n\n\n\n\n\n\n\n\nMultipleJGitEnvironmentRepository 多仓库的支持，实际上就是遍历了所有的仓库。其他仓库和单仓库是一样的。\n客户端实现Spring Cloud Config Client 没有像其他组件一样提供@EnableConfigClient注解，这里没有必要去标注是一个配置客户端，只要引入了spring-cloud-config-client 依赖即可。\n思路也很清楚，就是在启动时从服务端把配置信息拉取到本地，然后设置到 Enviroment 中。Spring Cloud Config中有两种形式，一种是指定 url，另外一种是通过服务发现，默认是通过指定URI的方式。这里还是先从客户端的自动配置来分析。\n12345678910111213141516171819202122232425262728293031323334353637383940414243@Configuration@EnableConfigurationPropertiespublic class ConfigServiceBootstrapConfiguration &#123;\t@Autowired\tprivate ConfigurableEnvironment environment;  // 客户端配置属性\t@Bean\tpublic ConfigClientProperties configClientProperties() &#123;\t\tConfigClientProperties client = new ConfigClientProperties(this.environment);\t\treturn client;\t&#125;  // 从远程服务器上请求对应的配置信息\t@Bean\t@ConditionalOnMissingBean(ConfigServicePropertySourceLocator.class)\t@ConditionalOnProperty(value = &quot;spring.cloud.config.enabled&quot;, matchIfMissing = true)\tpublic ConfigServicePropertySourceLocator configServicePropertySource(ConfigClientProperties properties) &#123;\t\tConfigServicePropertySourceLocator locator = new ConfigServicePropertySourceLocator(\t\t\t\tproperties);\t\treturn locator;\t&#125;  // 重试机制\t@ConditionalOnProperty(value = &quot;spring.cloud.config.fail-fast&quot;)\t@ConditionalOnClass(&#123; Retryable.class, Aspect.class, AopAutoConfiguration.class &#125;)\t@Configuration\t@EnableRetry(proxyTargetClass = true)\t@Import(AopAutoConfiguration.class)\t@EnableConfigurationProperties(RetryProperties.class)\tprotected static class RetryConfiguration &#123;\t\t@Bean\t\t@ConditionalOnMissingBean(name = &quot;configServerRetryInterceptor&quot;)\t\tpublic RetryOperationsInterceptor configServerRetryInterceptor(\t\t\t\tRetryProperties properties) &#123;\t\t\treturn RetryInterceptorBuilder\t\t\t\t\t.stateless()\t\t\t\t\t.backOffOptions(properties.getInitialInterval(),\t\t\t\t\t\t\tproperties.getMultiplier(), properties.getMaxInterval())\t\t\t\t\t.maxAttempts(properties.getMaxAttempts()).build();\t\t&#125;\t&#125;&#125;\n\n这个配置类中初始化了两个bean:\n\nConfigClientProperties : 对客户端的属性进行配置。\nConfigServicePropertySourceLocator：从远程服务器上请求对应的配置信息，然后注册到容器的Enviroment 对象中去。\n\nConfigClientProperties 中就是客户端的一些属性，如：profile、应用名、标签、远端服务地址等。没有什么特殊的逻辑。主要来看下 ConfigServicePropertySourceLocator 。\nConfigServicePropertySourceLocatorConfigServicePropertySourceLocator 实现了 PropertySourceLocator 接口，PropertySourceLocator 接口的作用就是用来定位 PropertySource 的。直接看locate方法的实现(删除了无关代码)：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Override@Retryable(interceptor = &quot;configServerRetryInterceptor&quot;)public PropertySource&lt;?&gt; locate(Environment environment) &#123;    ConfigClientProperties properties = this.defaultProperties.override(environment);    CompositePropertySource composite = new CompositePropertySource(&quot;configService&quot;);// 实例化一个 restTemplate，用来调用服务端的 API    RestTemplate restTemplate = this.restTemplate == null            ? getSecureRestTemplate(properties)            : this.restTemplate;// ...    try &#123;    // labels ，对对应于profile 如，dev,pre,test这些        String[] labels = new String[] &#123; &quot;&quot; &#125;;        if (StringUtils.hasText(properties.getLabel())) &#123;            labels = StringUtils.commaDelimitedListToStringArray(properties.getLabel());        &#125;        String state = ConfigClientStateHolder.getState();        // 遍历所有的标签，循环调用获取远程配置信息        for (String label : labels) &#123;    // h获取远端环境配置信息            Environment result = getRemoteEnvironment(restTemplate, properties,                    label.trim(), state);            if (result != null) &#123;                log(result);        // result.getPropertySources() can be null if using xml        //使用 xml，可能会为 null                if (result.getPropertySources() != null) &#123;                     for (PropertySource source : result.getPropertySources()) &#123;                        @SuppressWarnings(&quot;unchecked&quot;)                        Map&lt;String, Object&gt; map = (Map&lt;String, Object&gt;) source                                .getSource();                        composite.addPropertySource(                                new MapPropertySource(source.getName(), map));                    &#125;                &#125;        // 设置客户端状态和版本号信息                if (StringUtils.hasText(result.getState())                        || StringUtils.hasText(result.getVersion())) &#123;                    HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;();                    putValue(map, &quot;config.client.state&quot;, result.getState());                    putValue(map, &quot;config.client.version&quot;, result.getVersion());                    composite.addFirstPropertySource(                            new MapPropertySource(&quot;configClient&quot;, map));                &#125;                return composite;            &#125;        &#125;    &#125;    catch (Exception e) &#123;        // ...    &#125;// 如果设置了fial fast ，失败时抛出异常    if (properties.isFailFast()) &#123;        // ...    &#125;// ...    return null;&#125;\n上面代码片段中实际从远端获取配置信息是在 getRemoteEnvironment 这个方法中，以Http 请求的方式获取。获取到配置信息之后是放在 CompositePropertySource 对象中，代码较长，逻辑也比较简单，建议直接阅读源码。\n注入到 Enviroment 中这部分操作是在 Spring Cloud Context 中的入口来完成的。具体参考bootstrapServiceContext 创建&amp;启动 。\n这里会通过 Spring Cloud Context 中的 PropertySourceBootstrapConfiguration 配置类将PropertySourceLocator 自定义属性值添加到引导上下文的环境当中。\n基于服务发现的方式获取配置前面两个小节均是基于指定 http url 的方式获取配置文件的。Spring Cloud Config 中还有一种方式就是基于服务发现的方式。其实这种方式说到底还是基于指定 http url的方式调用，只是通过服务发现找到服务端地址；当然既然有服务的发现与注册，也就会涉及到客户端与服务端之间的会话保证，及时更新可用服务列表这些功能。\n\n获取服务地址\n\n123456789101112@Retryable(interceptor = &quot;configServerRetryInterceptor&quot;)public List&lt;ServiceInstance&gt; getConfigServerInstances(String serviceId) &#123;    logger.debug(&quot;Locating configserver (&quot; + serviceId + &quot;) via discovery&quot;);    List&lt;ServiceInstance&gt; instances = this.client.getInstances(serviceId);    if (instances.isEmpty()) &#123;        throw new IllegalStateException(                &quot;No instances found of configserver (&quot; + serviceId + &quot;)&quot;);    &#125;    logger.debug(&quot;Located configserver (&quot; + serviceId            + &quot;) via discovery. No of instances found: &quot; + instances.size());    return instances;&#125;\n\n通过 DiscoveryClient 客户端，以指定serviceId的方式拿到服务地址。\nDiscoveryClientConfigServiceBootstrapConfiguration 这个自动配置类实现了 ApplicationListener，用于监听上下文刷新事件；DiscoveryClient 在具体的实现中会将上下文刷新事件进行广播，然后执行刷新操作。心跳里面也是执行的刷新操作。对应的方法是DiscoveryClientConfigServiceBootstrapConfiguration#refresh。也就是 refresh方法会根据上下文环境和心跳事件，刷新服务实例。\n以 ZK 作为配置中心《SpringCloud-配置中心 spring-cloud-zk》demo 中介绍了如何使用 zk 作为配置中心。以zk作为配置中心也就是配置信息将从zk中来获取；具体实现也就是实现 PropertySourceLocator 接口，在locate方法中通过zk客户端从zk服务端拉取配置信息。具体实现在ZookeeperPropertySourceLocator#locate中\n12345678910@Overridepublic PropertySource&lt;?&gt; locate(Environment environment) &#123;    if (environment instanceof ConfigurableEnvironment) &#123;    //省略 ...        // 获取外部配置源        PropertySource propertySource = create(propertySourceContext);    //省略 ...    &#125;    // ..&#125;\n\n其他代码片段都省略了，获取 PropertySource 是在 create 方法中，create 方法返回一个 ZookeeperPropertySource 实例对象。在构造函数中，有通过zk客户端去拉取配置信息，具体逻辑在findProperties 方法中：\n12345678910111213141516171819202122private void findProperties(String path, List&lt;String&gt; children) &#123;    try &#123;        // 省略 ...         for (String child : children) &#123;            String childPath = path + &quot;/&quot; + child;            List&lt;String&gt; childPathChildren = getChildren(childPath);    // 获取节点信息            byte[] bytes = getPropertyBytes(childPath);            if (bytes == null || bytes.length == 0) &#123;                if (childPathChildren == null || childPathChildren.isEmpty()) &#123;                    registerKeyValue(childPath, &quot;&quot;);                &#125;            &#125; else &#123;                registerKeyValue(childPath, new String(bytes, Charset.forName(&quot;UTF-8&quot;)));            &#125;            // 检查子节点，即使我们已经找到当前znode的值            findProperties(childPath, childPathChildren);        &#125;    &#125; catch (Exception exception) &#123;        // 省略 ...     &#125;&#125;\n\n自动刷新机制当修改配置信息之后，通过zk自身的监听机制，通知客户端。这个机制是在ZookeeperConfigAutoConfiguration自动配置类中提供。\n12345678910@Configuration@ConditionalOnClass(RefreshEndpoint.class)protected static class ZkRefreshConfiguration &#123;    @Bean    @ConditionalOnProperty(name = &quot;spring.cloud.zookeeper.config.watcher.enabled&quot;, matchIfMissing = true)    public ConfigWatcher configWatcher(ZookeeperPropertySourceLocator locator,            CuratorFramework curator) &#123;        return new ConfigWatcher(locator.getContexts(), curator);    &#125;&#125;\n\nConfigWatcher 实现了 Closeable、TreeCacheListener 和 ApplicationEventPublisherAware 三个接口。Tree Cache 用于观察所有节点的所有数据状态，ApplicationEventPublisherAware用户提供一个publiser，用来发布RefreshEvent 事件。Closeable 用于实现优雅关闭。\n所有当我们改变zk数据节点时，就是触发例如 NODE_ADDED 、NODE_REMOVED、NODE_UPDATED 等事件类型，然后publiser就会发布一个 RefreshEvent 事件，通知客户端进行配置更新操作。从而实现配置的自动刷新。\n","slug":"springcloud/spring-cloud-config-analysis","date":"2018-12-31T15:11:33.000Z","categories_index":"SpringCloud","tags_index":"config","author_index":"glmapper"},{"id":"99a0b1d930b4b5c7bd120823c947d06c","title":"SpringCloud-配置中心 Config Apollo","content":"Apollo（阿波罗）是携程框架部门研发的开源配置管理中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性。\n本篇将搭建一套 Apollo 配置中心环境，并通过一个 demo 案例来演示如何在 SpringCloud 体系中使用 Apollo。\n\n\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\nMysql\n5.7.24\n\n\nCentOS\n7\n\n\n Apollo 自身需要依赖 Mysql，在部署 Apollo 时需要提前安装 Mysql 数据库。关于 Mysql 的安装可以参考：Linux 下安装Mysql数据库。\n根据官方文档，Apollo 服务端需运行在 jdk 1.8 以上，客户端需运行在1.7 以上，Mysql 版本需在 5.6.5 版本以上。具体信息可参考：分布式部署指南。\n部署 Apollo部署步骤共三步：\n\n创建数据库\n\nApollo 服务端依赖于 MySQL 数据库，所以需要事先创建并完成初始化\n\n\n获取安装包\n\nApollo 服务端安装包共有3个：apollo-configservice, apollo-adminservice, apollo-portal\n可以直接下载事先打好的安装包，也可以自己通过源码构建\n\n\n部署 Apollo 服务端\n\n获取安装包后就可以部署到公司的测试和生产环境了\n\n\n\n创建数据库Apollo 服务端共需要两个数据库：ApolloPortalDB和ApolloConfigDB，我们把数据库、表的创建和样例数据都分别准备了 sql 文件，只需要导入数据库即可。\n\n\n\n\n\n\n\n\n\n需要注意的是 ApolloPortalDB 只需要在生产环境部署一个即可，而 ApolloConfigDB 需要在每个环境部署一套，如 fat、uat 和 pro 分别部署 3 套 ApolloConfigDB。\n\n\n\n\n\n\n\n\n\n注意：如果本地已经创建过 Apollo 数据库，请注意备份数据；sql 文件会清空 Apollo 相关的表。\n两份 SQL 文件：\n\napolloportaldb.sql\napolloconfigdb.sql\n\n下载下来之后可通过 Mysql 图形界面工具(如 Navicat )等进行导入。导入完成之后，可以进行如下验证。\nportalDB 验证执行 SQL：\n1select `Id`, `Key`, `Value`, `Comment` from `ApolloPortalDB`.`ServerConfig` limit 1;\n\n查询结果：\n\n\n\nId\nKey\nValue\nComment\n\n\n\n1\napollo.portal.envs\ndev\n可支持的环境列表\n\n\nconfigDB 验证执行 SQL:\n1select `Id`, `Key`, `Value`, `Comment` from `ApolloConfigDB`.`ServerConfig` limit 1;\n\n执行结果：\n\n\n\nId\nKey\nValue\nComment\n\n\n\n1\neureka.service.url\nhttp://127.0.0.1:8080/eureka/\nEureka服务Url\n\n\n\n\n\n\n\n\n\n\n\n本过程只针对新建工程，如果涉及到数据迁移，请参考 Apollo 官方文档\n数据库部分完成之后，接下来就是部署 Apollo 的三个工程。\n工程配置修改Apollo 配置中心 使用需要启动三个工程：apollo-configservice、apollo-adminservice、apollo-portal。\n在自己的服务器上新建一个目录 &#x2F;thirdserver&#x2F;apollo&#x2F; 将官方提供的安装包直接下载到这个目录下，然后解压得到如下列表：\n\napollo-configservice 部署Apollo 服务端需要知道如何连接到你前面创建的数据库，数据库连接串信息位于上一步下载的压缩包中的apollo-configservice-1.2.0-github/config/application-github.properties 中，这里把里面默认的数据库连接地址和账密信息替换成我们自己的就可以。这里使用的是 ApolloConfigDB 库。\n1234# DataSourcespring.datasource.url = jdbc:mysql://$&#123;serverhost&#125;:3306/ApolloConfigDB?characterEncoding=utf8spring.datasource.username = $&#123;yourusername&#125;spring.datasource.password = $&#123;yourpassword&#125;\n\napollo-adminservice 配置文件修改这里同样是修改  config&#x2F;application-github.properties 下面的数据库连接信息。这里也使用的是 ApolloConfigDB 库。配置信息和上面一样。\napollo-portal 配置文件修改\nportal 使用的是 ApolloPortalDB，修改数据库配置信息：\n1234# DataSourcespring.datasource.url = jdbc:mysql://$&#123;serverhost&#125;:3306/ApolloPortalDB?characterEncoding=utf8spring.datasource.username = $&#123;yourusername&#125;spring.datasource.password = $&#123;yourpassword&#125;\n\n修改 meta service 信息，Apollo Portal 需要在不同的环境访问不同的 meta service(apollo-configservice) 地址，所以我们需要在配置中提供这些信息。默认情况下，meta service 和 config service 是部署在同一个 JVM进程，所以 meta service 的地址就是 config service 的地址。配置文件  &#x2F;config&#x2F;apollo-env.properties \n1234567# $&#123;serverhost&#125; 是你当前机器的主机地址local.meta=http://localhost:8080dev.meta=http://$&#123;serverhost&#125;:8080fat.meta=http://$&#123;serverhost&#125;:8080uat.meta=http://$&#123;serverhost&#125;:8080lpt.meta=http://$&#123;serverhost&#125;:8080pro.meta=http://$&#123;serverhost&#125;:8080\n\n这里是把所有环境配置成一样的了，如果没有不需要这些环境，可以删除掉。\n\n\n工程部署在每一个工程的解压包中，都有一个 scripts 文件夹，这里面是 Apollo 工程的启动脚本。三个工程分别先后启动：apollo-configservice、apollo-adminservice、apollo-portal，就是分别执行这三个工程下面的 &#x2F;scripts&#x2F;startup.sh 脚本即可，关闭执行的是 &#x2F;scripts&#x2F;shutdown.sh 脚本。\n访问：http:&#x2F;&#x2F;${serverhost}:8070&#x2F;\n\n可以看到配置中心管控端的界面。\n新建工程\n点击 创建项目，填写一些基本信息，然后提交\n\n\n\n新增一个配置项，填写基本信息，然后提交\n\n当前工程界面\n\n\n\n\n发布配置\n\n\nSpringCloud 工程案例新建 sofa-config-apollo 工程。\n依赖引入 apollo 客户端依赖及其他相关依赖：\n12345678910111213141516171819&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;        &lt;artifactId&gt;spring-cloud-context&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt;        &lt;artifactId&gt;apollo-client&lt;/artifactId&gt;        &lt;version&gt;1.0.0&lt;/version&gt;    &lt;/dependency&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n配置文件123456# 需要与前面 Apollo 中创建项目的appId保持一致app.id=sofa-config-apollo# 设置 apollo meta service 的地址，因为前面meta和config是部署在一起的，所以就是configService的地址apollo.meta=http://$&#123;serverhost&#125;:8080# 配置项sofa.alipay.glmapper.name=glmapper\n\n资源类&amp;启动类启动类启动类上需要开启对 apollo 的支持，使用 @EnableApolloConfig 注解标注\n1234567@SpringBootApplication@EnableApolloConfigpublic class SofaConfigApolloApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaConfigApolloApplication.class, args);    &#125;&#125;\n\n资源类12345678910111213@RestControllerpublic class ApolloConfigController &#123;    @ApolloConfig    private Config config;    @Value(&quot;$&#123;sofa.alipay.glmapper.name&#125;&quot;)    private String name;    @RequestMapping(&quot;/apollo&quot;)    public String getConfig()&#123;        return name;    &#125;&#125;\n\n注意，我在配置文件中指定的是 sofa.alipay.glmapper.name 值是 glmapper，而在配置中心配置的值是glmapper@leishu。同时这里也把 apollo 自己的这个 Config 配置类也注入进来，稍后看下这的对象的信息。\n运行程序&amp;验证启动当前工程之前需要确保 Apollo 的相关服务已经起来了，然后运行当前应用。在浏览器中输入：\nhttp://localhost:8080/config ，结果如下：\n1glmapper@leishu\n\n可以看到这里拿到的是配置中心的配置值，覆盖了我们本地配置文件中的配置。断点看到 config 的信息：\n\nConfig 对象就是当前集群环境下，指定 appId 的所有配置信息的集合。\n更改配置&amp;及时刷新\n更改配置\n\n\n\n发布配置\n\n\n\n刷新 http://localhost:8080/apollo 地址\n\n1glmapper@leishu-update\n\n这里没有重启服务，配置动态更新了\n@ApolloConfigChangeListener 来监听配置变更资源类 ApolloConfigController 中增加一个监听方法\n1234@ApolloConfigChangeListenerprivate void onChange(ConfigChangeEvent changeEvent) &#123;\tSystem.out.println(&quot;发生变更了...&quot;);&#125;\n\n然后重新在配置中心的界面上修改配置值：glmapper@leishu-update -&gt; glmapper@leishu-update-event，然后发布。然后可以在控制台看到日志：\n12发生变更了...2019-01-07 14:36:08.939  INFO 39072 --- [Apollo-Config-1] c.f.a.s.p.AutoUpdateConfigChangeListener : Auto update apollo changed value successfully, new value: glmapper@leishu-update-event, key: sofa.alipay.glmapper.name, beanName: apolloConfigController, field: com.alipay.sofa.cloud.controller.ApolloConfigController.name","slug":"springcloud/spring-cloud-config-apollo","date":"2018-12-31T15:11:23.000Z","categories_index":"SpringCloud","tags_index":"config,apollo","author_index":"glmapper"},{"id":"8dde0e1ef80128bea4c1d65d0e4f86c2","title":"SpringCloud-配置中心 Config Github","content":"在分布式系统中，每一个功能模块都能拆分成一个独立的服务，一次请求的完成，可能会调用很多个服务协调来完成，为了方便服务配置文件统一管理，更易于部署、维护，所以就需要一个地方来管理这些配置信息。\n在 spring cloud Config 就提供了这样的能力，通过集中化管理的方式，支持配置文件放在在配置服务的内存中远程 Git 仓库以及Subversion。\n本篇将通过一个简单的 demo ，使用 spring cloud Config 原生提供的基于 Git 的方式来实现微服务体系下的配置管理功能。\n\n\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\n工程背景本节将通过 SOFABoot 来集成 Spring Cloud Config ，以 git 作为存储，来实现分布式环境下的配置管理。本工程的父工程仍然是《SpringCloud-Eureka 服务注册》中构建的父工程。 \n由于我们是以 git 来存储配置文件的，因此我们需要在 github 上新建一个存储配置文件的空间，为了更方面的模拟，这里创建了两个配置文件：\n\nglmapper-dev.properties\n\n123name=leishu@glmapper_devblog=http://www.glmapper.comversion=dev\n\nglmapper-pre.properties\n\n123name=leishu@glmapper_preblog=http://www.glmapper.comversion=pre\n\n\n\n\n\n\n\n\n\n\ngithub 地址：https://github.com/glmapper/glmapper-config-repository\n新建 sofa-config-server右击 sofa-eureka-parent 父工程 -&gt; New -&gt; Module，这里选择 Maven 工程；\n\nartifactId：sofa-config-server\n\n修改 pom 文件这里直接引入 config 的依赖即可\n12345678910111213&lt;parent&gt;  &lt;artifactId&gt;sofa-eureka-parent&lt;/artifactId&gt;  &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;sofa-config-server&lt;/artifactId&gt;&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;\t&lt;/dependency&gt;&lt;/dependencies&gt;\n\n配置文件1234567891011121314151617181920212223#服务端口server:  port: 8091  #服务名称spring:  application:    name: sofa-config-server  #服务的git仓库地址  cloud:    config:      server:        git:          uri: https://github.com/glmapper/glmapper-config-repository          search-paths: /**          username: glmapper_2018@163.com          password: ******      #指定分支      label: master#服务注册中心eureka:  client:    service-url:      defaultZone: http://localhost:8761/eureka/\n\n\n\n\n\n\n\n\n\n\n如果你的 github 仓库是公开的话，就不需要输入账户和密码就可以访问。\n启动类在启动类上加 @EnableConfigServer 注解，激活对配置中心的支持\n1234567@SpringBootApplication@EnableConfigServerpublic class SofaConfigServerApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaConfigServerApplication.class,args);    &#125;&#125;\n启动 &amp; 验证因为配置中心作为一个独立的服务，所以不需要依赖其他服务的先启动，直接运行当前程序即可。这里我们首先需要验证下 server 端是否已经成功拉取到了 github 上面的配置信息：\n访问：http://localhost:8091/glmapper/pre/master\n12345678910111213141516171819&#123;    &quot;name&quot;: &quot;glmapper&quot;,    &quot;profiles&quot;: [        &quot;pre&quot;    ],    &quot;label&quot;: &quot;master&quot;,    &quot;version&quot;: &quot;f9e8c1f2825d23031cb13d40e396a23c0f975d2d&quot;,    &quot;state&quot;: null,    &quot;propertySources&quot;: [        &#123;            &quot;name&quot;: &quot;https://github.com/glmapper/glmapper-config-repository/glmapper-pre.properties&quot;,            &quot;source&quot;: &#123;                &quot;name&quot;: &quot;leishu@glmapper-pre&quot;,                &quot;blog&quot;: &quot;http://www.glmapper.com&quot;,                &quot;version&quot;: &quot;pre&quot;            &#125;        &#125;    ]&#125;\n\nOK ，说明服务端已经成功拉取到了github上的配置文件了。\n\n\n\n\n\n\n\n\n\n关于地址的说明：http://localhost:8091/glmapper/pre/master 。前半部分是ip和端口，没什么好说的。glmapper&#x2F;pre&#x2F;master，因为我在github上新建的配置文件名是 glmapper-dev.properties 和 glmapper-pre .properties ;所以这里地址的规则就是 &#x2F;glmapper&#x2F;pre ，后面的 master 可带可不带，区别在于返回的 JSON 数据 label 是 null 还是 master，label 指向分支。\n客户端本节构建一个简单的客户端工程 sofa-config-client ，用于从 sofa-config-server 上获取配置文件并展示。sofa-config-client 同样基于《SpringCloud-Eureka 服务注册》中构建的父工程。 \n修改 pom 文件12345678910111213141516171819&lt;parent&gt;  &lt;artifactId&gt;sofa-eureka-parent&lt;/artifactId&gt;  &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;sofa-config-client&lt;/artifactId&gt;&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;\n\n引入 spring-cloud-starter-config 和  spring-boot-starter-web 依赖。\n配置文件配置文件包括两个，一个是 application.yml ，另一个是 bootstrap.yml\n\napplication.yml\n\n12345spring:  application:    name: sofa-config-clientserver:  port: 8099\n\n\nbootstrap.yml\n\n1234567spring:  cloud:    config:      name: glmapper\t\t\t\t\t\t\t\t      profile: pre      uri: http://localhost:8091/   #指向配置中心的地址      label: master\n\n启动类启动类不需要做什么修改，也不需要额外加什么注解\n123456@SpringBootApplicationpublic class SofaConfigClientApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaConfigClientApplication.class, args);    &#125;&#125;\n\n资源类新建一个资源类，用于输出展示拉取到的配置信息\n123456789101112131415161718@RestControllerpublic class ConfigClientController &#123;    @Value(&quot;$&#123;name&#125;&quot;)    private  String name;    @Value(&quot;$&#123;blog&#125;&quot;)    private  String blog;    @Value(&quot;$&#123;version&#125;&quot;)    private  String version;    @RequestMapping(&quot;/config&quot;)    public String config()&#123;        return &quot;name:&quot;+name+&quot; ,blog:&quot;+blog+&quot; ,version:&quot;+version;    &#125;&#125;\n\n启动和运行先后启动配置中心服务端和客户端程序。在浏览器中输入：http://localhost:8099/config ，返回如下：\n1name:leishu@glmapper-pre ,blog:http://www.glmapper.com ,version:pre\n我们尝试下将 github 中 glmapper-pre.properties 这个配置文件进行修改，看下是否在这能获取到最新的依赖，修改之后，如下：\n123name=leishu@glmapper_pre_updateblog=http://www.glmapper.comversion=pre\n重新刷新浏览器地址，返回如下：\n1name:leishu@glmapper-pre ,blog:http://www.glmapper.com ,version:pre\n这里并没有发生任何变换，因为 SpringBoot 项目只会在项目启动时才会获取一次配置文件信息，当我们修改了 github 上的配置文件之后，当前的配置中心客户端并没有主动去获取配置值，所以不会有新的值，我们获取到的还是旧的值。那么下面通过修改和增加一些组件和配置来实现不停服动态更新配置。\n配置动态更新要实现配置的动态更新，需要借助于 springboot 的 actuator 监控模块。所有需要在客户端pom文件中引入 actuator 的依赖信息。\n1234&lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;\n配置文件 application.yml 中增加配置，将&#x2F;actuator&#x2F;refresh 断点暴露出来，注意不要配置在 boostrap.yml 中。\n12345678910spring:  application:    name: sofa-config-clientserver:  port: 8099management:  endpoints:    web:      exposure:        include: refresh\n资源类中开启更新机制，在 ConfigClientController 类中增加 @RefreshScope 注解，然后重启客户端。\n首先执行：http://localhost:8099/config ，得到结果如下：\n1name:leishu@glmapper-pre ,blog:http://www.glmapper.com ,version:pre&lt;br /&gt;\n\n更新 github 上配置文件的值，将 name 改为 name:leishu@glmapper-pre，通过 curl 或者 postman 执行下 刷新：\n12&gt; curl -X POST http://localhost:8099/actuator/refresh&gt; [&quot;config.client.version&quot;,&quot;name&quot;]%\n再次刷新执行 http://localhost:8099/config ，结果如下：\n1name:leishu@glmapper-pre-update ,blog:http://www.glmapper.com ,version:pre\n\n\n\n","slug":"springcloud/spring-cloud-config-github","date":"2018-12-31T15:11:08.000Z","categories_index":"SpringCloud","tags_index":"config,github","author_index":"glmapper"},{"id":"17d5e51f35b1836a64abac3ed89ad69f","title":"Spring Cloud-Eureka Client 原理解析","content":"\n\n\n\n\n\n\n\n\n原文： https://blog.csdn.net/sinat_25518349/article/details/85423398\n前面一些 demo 中已经介绍了如何使用 SOFABoot 来集成 Spring Cloud Netflix Eureka 组件。本篇将来先解析下 Eureka Client 的工作原理。\n\n\nNetflix 和 SpringCloudspring-cloud-commons 模块是 spring 在分布式领域上(服务发现，服务注册，断路器，负载均衡)的规范定义。spring-cloud-netflix 是基于此规范的具体实现，Netflix OSS 里的各种组件也都实现了这个 commons 规范。关系如下：\n\nSpring Cloud Netflix Eureka 服务发现实现原理基于上图，这里以 Eureka 中的服务发现为例，来具体讲下是如何实现的。Spring Cloud common 中提供了用于服务发现的两个关键类：DiscoveryClient 接口 和 EnableDiscoveryClient 注解。\nDiscoveryClient 接口下面这张图描述的是在服务发现这个功能上，SpringCloud 是如何与 Netflix 整合的。在 spring-cloud-netflix-eureka-client 中对 Spring Cloud Common 中的 DiscoveryClient 接口进行了实现，实现类是 EurekaDiscoveryClient 。\n\nDiscoveryClient 的接口定义与方法：\n123456789101112131415161718192021222324/** * DiscoveryClient表示服务发现常用的读取操作，例如Netflix Eureka或consul.io * @author Spencer Gibb */public interface DiscoveryClient &#123;\t/**\t * 实现描述\t * @return the description\t */\tString description();\t/**\t * 获取与特定serviceId关联的所有ServiceInstances\t * @param serviceId the serviceId to query\t * @return a List of ServiceInstance\t */\tList&lt;ServiceInstance&gt; getInstances(String serviceId);\t/**\t * 返回所有已知的服务ID\t */\tList&lt;String&gt; getServices();&#125;\n\nEurekaDiscoveryClient 中实现了这几个方法，但是 EurekaDiscoveryClient 自身没有实现如何与服务端交互的逻辑，而是通过 com.netflix.DiscoveryClient 类来完成。所以 spring-cloud-netflix-eureka-client 干的事情就是实现了 Spring Cloud Common 规范，然后在实现上包装了 netflix 。\n@EnableDiscoveryClient 注解123456789@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(EnableDiscoveryClientImportSelector.class)public @interface EnableDiscoveryClient &#123;  //是否自动注册，默认是true。\tboolean autoRegister() default true;&#125;\n\nEnableDiscoveryClientImportSelector 将会从 META-INF/spring.factories 里找出 key 为 org.springframework.cloud.client.discovery.EnableDiscoveryClient 的类。\n对于 autoRegister ：\n\n如果自动注册属性为true，会在找出的这些类里再加上一个类：AutoServiceRegistrationConfiguration， AutoServiceRegistrationConfiguration 内部会使用@EnableConfigurationProperties(AutoServiceRegistrationProperties.class) 触发构造AutoServiceRegistrationProperties 这个 bean。像eureka，nacos，它们的自动化配置类里都使用了@ConditionalOnBean(AutoServiceRegistrationProperties.class) 来确保存在AutoServiceRegistrationProperties 这个 bean 存在的时候才会构造 AutoServiceRegistration 进行注册。\n如果自动注册属性为 false，在Environment 里加一个 PropertySource，内部的配置项是spring.cloud.service-registry.auto-registration.enabled，值是false(代表不构造AutoServiceRegistrationProperties.class)。这样 eureka 就不会注册。\n\n对应上面这段逻辑的代码如下：\n\nspring-cloud-netflix-eureka-client 自己也提供了一个注解 EnableEurekaClient，其作用于这个注解一样\nEureka 架构图\n\nconsumer  : 服务消费方，eureka client 角色，可以从 eureka server 上拉取到其他已注册服务的信息，从而根据这些信息找到自己所需的服务，然后发起远程调用。\nprovider : 服务提供方，eureka client 角色，可以向 eureka server 上注册和更新自己的信息，当然作为 eureka client ，它也可以从server 上获取到其他服务的信息。\nEureka server : 服务注册中心，提供服务注册和服务发现功能；\n同步复制 ： eureka server 之间进行注册服务信息的同步，这样可以保证集群中每个server 都能提供完整的服务信息。\n\n\n\n\n\n\n\n\n\n\n关于 AWS 上 Regin 和 Availability Zone 的概念，请自行查阅相关资料\n源码解析配置信息读取Eureka Client的自动配置类是 org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration ，这里面主要就负责了一些配置信息的服务诸如 DiscoveryClient 、EurekaServiceRegistry等主要bean的初始化工作。\n另外还有一个 EurekaDiscoveryClientConfiguration 类，负责配置自动注册和应用的健康检查器初始化。\n读取 eureka.client.*12345678910@Bean@ConditionalOnMissingBean(value = EurekaClientConfig.class, search = SearchStrategy.CURRENT)public EurekaClientConfigBean eurekaClientConfigBean(ConfigurableEnvironment env) &#123;\tEurekaClientConfigBean client = new EurekaClientConfigBean();  if (&quot;bootstrap&quot;.equals(this.env.getProperty(&quot;spring.config.name&quot;))) &#123;    // 默认情况下，我们不会在引导过程中注册，但是以后会有另一个机会。    client.setRegisterWithEureka(false);  &#125;  return client;&#125;\n\nEurekaClientConfigBean 封装的是 eureka client 和 eureka server 交互所需要的配置信息，比如前面demo工程中的 eureka.client.service-url.defaultZone 的配置。\n读取 eureka.instance.*123456@Bean@ConditionalOnMissingBean(value = EurekaInstanceConfig.class, search = SearchStrategy.CURRENT)public EurekaInstanceConfigBean eurekaInstanceConfigBean(InetUtils inetUtils,\tManagementMetadataProvider managementMetadataProvider) &#123;  // 代码较长，此处省略&#125;\n\nEurekaInstanceConfigBean 封装的是 eureka client 自身实例的配置信息，提供服务注册的基本元数据信息。\n核心组件 bean 初始化这里也实例化了一些核心的组件bean。\nApplicationInfoManager\nEurekaClientConfiguration#eurekaApplicationInfoManager\n\n1234567@Bean@ConditionalOnMissingBean(value = ApplicationInfoManager.class, search = SearchStrategy.CURRENT)public ApplicationInfoManager eurekaApplicationInfoManager(EurekaInstanceConfig config) &#123;  InstanceInfo instanceInfo = new InstanceInfoFactory().create(config);  return new ApplicationInfoManager(config, instanceInfo);&#125;\n\n\nRefreshableEurekaClientConfiguration#eurekaApplicationInfoManager12345678@Bean@ConditionalOnMissingBean(value = ApplicationInfoManager.class, search = SearchStrategy.CURRENT)@org.springframework.cloud.context.config.annotation.RefreshScope@Lazypublic ApplicationInfoManager eurekaApplicationInfoManager(EurekaInstanceConfig config) &#123;  InstanceInfo instanceInfo = new InstanceInfoFactory().create(config);  return new ApplicationInfoManager(config, instanceInfo);&#125;\n\n\n\n\n\n\n\n\n\n\nRefreshScope ，被此注解标注的情况下，将会被动态刷新。包括属性信息等，注意，对于动态刷新，被RefreshScope标记的类不能是final的。\nApplicationInfoManager 是应用信息管理器，用于管理服务实例的信息类 InstanceInfo 和服务实例的配置信息类 EurekaInstanceConfig 。\nDiscoveryClient1234@Beanpublic DiscoveryClient discoveryClient(EurekaInstanceConfig config, EurekaClient client) &#123;\treturn new EurekaDiscoveryClient(config, client);&#125;\n\nDiscoveryClient ，前面说到，这个类是Spring Cloud 中用于服务发现使用的客户端接口。注意这里是SpringCloud提供的接口，不是netflix中的类。\nEurekaServiceRegistry1234@Beanpublic EurekaServiceRegistry eurekaServiceRegistry() &#123;\treturn new EurekaServiceRegistry();&#125;\n\nEurekaServiceRegistry 是 ServiceRegistry 的实现类。ServiceRegistry 是 SpringCloud 提供了注册和注销等方法，这些方法允许用户提供自定义注册服务。\nEurekaRegistration12345678910@Bean@ConditionalOnBean(AutoServiceRegistrationProperties.class)@ConditionalOnProperty(value = &quot;spring.cloud.service-registry.auto-registration.enabled&quot;, matchIfMissing = true)public EurekaRegistration eurekaRegistration(EurekaClient eurekaClient, CloudEurekaInstanceConfig instanceConfig, ApplicationInfoManager applicationInfoManager, ObjectProvider&lt;HealthCheckHandler&gt; healthCheckHandler) &#123;    return EurekaRegistration.builder(instanceConfig)            .with(applicationInfoManager)            .with(eurekaClient)            .with(healthCheckHandler)            .build();&#125;\n\n每个 ServiceRegistry 实现都有自己的 Registry 实现。\n\nZookeeperRegistration -&gt; ZookeeperServiceRegistry\nZookeeperRegistration -&gt; EurekaServiceRegistry\nConsulRegistration       -&gt; ConsulServiceRegistry\n\n如果你需要自定义实现 ServiceRegistry ，则也不要提供一个 Registration  的实现。\n服务发现服务发现的基本情况在上面已经提到了，但是由于 SpingCloud 中并没有提供具体的交互操作而是由 com.netflix.discovery.DiscoveryClient 来完成具体工作。所以关于服务服务发现这里就直接围绕这个类来展开。\n\nLookopService123456789101112131415public interface LookupService&lt;T&gt; &#123;    // 根据服务实例注册的appName 来获取 Application    Application getApplication(String appName);    // 返回当前注册表中所有的服务实例信息    Applications getApplications();    // 根据服务实例Id获取服务实例信息    List&lt;InstanceInfo&gt; getInstancesById(String id);    /**     * 获取下一个可能的服务器，以处理来自从eureka接收到的注册表信息的请求。     * @virtualHostname 与服务器关联的虚拟主机名。     * @secure 指示是HTTP还是HTTPS请求     *     */    InstanceInfo getNextServerFromEureka(String virtualHostname, boolean secure);&#125;\n\nLookupService 接口的作用就是用于查找活动服务实例；总共提供了四个方法，很好理解。每个方法的作用见注释。\nEurekaClientEurekaClient 也是一个接口，集成并且扩展了 LookupService。\n\n\n\n\n\n\n\n\n\nThis interface does NOT try to clean up the current client interface for eureka 1.x. Rather it triesto provide an easier transition path from eureka 1.x to eureka 2.x.从这来看，EurekaClient 的存在是为了给 Eureka1.x 向 Eureka 2.x 升级提供容错能力。\nEurekaClient 在 LookupService 基础上扩展了很多方法，如下：\n1234567891011121314151617public interface EurekaClient extends LookupService &#123;  \t// 省去@Deprecated方法和获取服务实例信息的接口方法\t\t// 注册健康检查处理器    public void registerHealthCheck(HealthCheckHandler healthCheckHandler);\t\t// 监听client服务信息的更新    public void registerEventListener(EurekaEventListener eventListener);   \t// 取消监听    public boolean unregisterEventListener(EurekaEventListener eventListener); \t\t// 获取当前健康检查处理器    public HealthCheckHandler getHealthCheckHandler();\t\t// 关闭 eureka 客户端。还向eureka服务器发送撤销注册请求。    public void shutdown();  \t// EurekaClientConfig    public EurekaClientConfig getEurekaClientConfig(); \t\t// ApplicationInfoManager    public ApplicationInfoManager getApplicationInfoManager();&#125;\n\nHealthCheckHandler 这个是用于检查当前客户端状态的，这个在后面心跳机制里面会说道。\nDiscoveryClientcom.netflix.discovery.DiscoveryClient，这个类会在构造函数中完成一系列重要的操作，如：拉取注册表信息，服务注册，初始化心跳机制，缓存刷新，按需注册定时任务等等。\n123456DiscoveryClient(ApplicationInfoManager applicationInfoManager, \t\t\t\t\t\t\t\t EurekaClientConfig config,                 AbstractDiscoveryClientOptionalArgs args,                Provider&lt;BackupRegistry&gt; backupRegistryProvider) &#123;// ... &#125;\n\n几个参数的释义如下：\n\napplicationInfoManager ：应用信息管理器\nconfig ：client 与 server 交互的配置信息\nargs ：客户端提供的过滤器类型(支持jersey1和jersey2)，后面用来构建 EurekaTransport\nbackupRegistryProvider ： 备份注册中心\n\n服务发现下面代码片段也是在 DiscoveryClient 的构造函数里面的，这里就是拉取注册服务信息的逻辑：\n123if (clientConfig.shouldFetchRegistry() &amp;&amp; !fetchRegistry(false)) &#123;\tfetchRegistryFromBackup();&#125;\n\nclientConfig.shouldFetchRegistry() 这个方法拿到的就是配置文件中 eureka.client.fetch-registry 的值，默认为true，表示从 eureka server 拉取注册表信息。\nfetchRegistry(boolean)是从 eureka server 拉取注册信息的方法，参数用于表示是否是强制拉取全量的注册信息；此方法除非在协调eureka服务器和客户端注册表信息方面存在问题，否则此方法只尝试在第一次进行全量获取，后面均是增量获取。\nfetchRegistryFromBackup() 如果 eureka server 服务不可用，则采用的备用方案。\n底层通信实现 EurekaTransportEurekaTransport 是 DiscoveryClient 的内部类，EurekaTransport 封装了具体的基于 jersey 的底层通信实现。\nFetchRegistry\n上图为拉取注册信息的整个过程。对于黄色贴条上的条件，如果满足其中一个，则都会进行全量拉取；否则进行增量拉取。计算 hash 值是为了后面可以与 server 端应用信息的进行对比，用于感知是否需要重新进行拉取操作。\n服务注册服务注册逻辑也是在 DiscoveryClient 的构造函数中完成，代码片段如下：\n12345678910if (clientConfig.shouldRegisterWithEureka() &amp;&amp; clientConfig.shouldEnforceRegistrationAtInit()) &#123;  try &#123;    if (!register() ) &#123;    throw new IllegalStateException(&quot;Registration error at startup. Invalid server response.&quot;);  \t&#125;  &#125; catch (Throwable th) &#123;    logger.error(&quot;Registration error at startup: &#123;&#125;&quot;, th.getMessage());    throw new IllegalStateException(th);  &#125;&#125;\n\n向server端注册需要满足的两个条件是：1、允许向server端注册  2、是否在客户端初始化期间强制注册\n1234567891011121314boolean register() throws Throwable &#123;  logger.info(PREFIX + &quot;&#123;&#125;: registering service...&quot;, appPathIdentifier);  EurekaHttpResponse&lt;Void&gt; httpResponse;  try &#123;  \thttpResponse = eurekaTransport.registrationClient.register(instanceInfo);  &#125; catch (Exception e) &#123;    logger.warn(PREFIX + &quot;&#123;&#125; - registration failed &#123;&#125;&quot;, appPathIdentifier, e.getMessage(), e);    throw e;  &#125;  if (logger.isInfoEnabled()) &#123;  \tlogger.info(PREFIX + &quot;&#123;&#125; - registration status: &#123;&#125;&quot;, appPathIdentifier, httpResponse.getStatusCode());  &#125;  return httpResponse.getStatusCode() == 204;&#125;\n\n通过 eurekaTransport 对象，基于 REST 调用向 eureka server 进行服务注册。\n心跳机制心跳机制的初始化工作也是在 DiscoveryClient 构造函数中完成。在DiscoveryClient构造函数的最后，有一个初始化调度任务的方法，在这个方法里就包括心跳的初始化。\nheartbeatExecutor 心跳线程池：\n1234567heartbeatExecutor = new ThreadPoolExecutor(    1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS,    new SynchronousQueue&lt;Runnable&gt;(),    new ThreadFactoryBuilder()            .setNameFormat(&quot;DiscoveryClient-HeartbeatExecutor-%d&quot;)            .setDaemon(true)            .build()\n\nscheduler 提交周期执行：\n1234567891011// Heartbeat timerscheduler.schedule(    new TimedSupervisorTask(    &quot;heartbeat&quot;,    scheduler,    heartbeatExecutor,    renewalIntervalInSecs,    TimeUnit.SECONDS,    expBackOffBound,    new HeartbeatThread()    ),renewalIntervalInSecs, TimeUnit.SECONDS);\n\nTimedSupervisorTask 是 eureka 中自动调节间隔的周期性任务类。HeartbeatThread 是具体执行任何的线程，run方法中执行的就是 renew() 续期。\n1234567891011121314151617181920212223242526boolean renew() &#123;  EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse;  try &#123;    // 通过 eurekaTransport 来与 server 通信续期    httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null);    logger.debug(PREFIX + &quot;&#123;&#125; - Heartbeat status: &#123;&#125;&quot;, appPathIdentifier, httpResponse.getStatusCode());    // 404 标识当前服务实例不存在    if (httpResponse.getStatusCode() == 404) &#123;      // 记录心跳次数      REREGISTER_COUNTER.increment();      logger.info(PREFIX + &quot;&#123;&#125; - Re-registering apps/&#123;&#125;&quot;, appPathIdentifier, instanceInfo.getAppName());      long timestamp = instanceInfo.setIsDirtyWithTime();      // 重新注册      boolean success = register();      if (success) &#123;      \tinstanceInfo.unsetIsDirty(timestamp);      &#125;    \treturn success;    &#125;    // 200 状态正常    return httpResponse.getStatusCode() == 200;  &#125; catch (Throwable e) &#123;    logger.error(PREFIX + &quot;&#123;&#125; - was unable to send heartbeat!&quot;, appPathIdentifier, e);    return false;  &#125;&#125;\n\n服务下线关闭 eureka client，还向 eureka server 发送撤销注册请求。该方法在DiscoveryClient#shutdown 方法中。\n123456789101112131415161718192021222324252627282930@PreDestroy@Overridepublic synchronized void shutdown() &#123;    // 保证原子操作    if (isShutdown.compareAndSet(false, true)) &#123;        logger.info(&quot;Shutting down DiscoveryClient ...&quot;);        if (statusChangeListener != null &amp;&amp; applicationInfoManager != null) &#123;            // 应用管理器取消状态监听            applicationInfoManager.unregisterStatusChangeListener(statusChangeListener.getId());        &#125;        // 清理任务调度执行        cancelScheduledTasks();        // If APPINFO was registered        if (applicationInfoManager != null                &amp;&amp; clientConfig.shouldRegisterWithEureka()                &amp;&amp; clientConfig.shouldUnregisterOnShutdown()) &#123;            //设置服务实例状态为 DOWN            applicationInfoManager.setInstanceStatus(InstanceStatus.DOWN);            //注销注册            unregister();        &#125;                    // 关闭 jersey 客户端        if (eurekaTransport != null) &#123;            eurekaTransport.shutdown();        &#125;        heartbeatStalenessMonitor.shutdown();        registryStalenessMonitor.shutdown();        logger.info(&quot;Completed shut down of DiscoveryClient&quot;);    &#125;&#125;\n\n参考\n《SpringCloud 微服务架构进阶》\n\n","slug":"springcloud/spring-cloud-eureka-client-analysis","date":"2018-12-31T14:48:45.000Z","categories_index":"SpringCloud","tags_index":"eureka","author_index":"glmapper"},{"id":"f85e030cf230f0e9651658c347d1ad1b","title":"SpringCloud-Eureka 服务发现","content":"本篇将继续接着上一篇 SpringCloud-服务注册 ，通过使用 DiscoveryClient 来实现服务发现，并且消费。\nDiscoveryClient 源自于 spring-cloud-client-discovery ，是 spring cloud 中被定义用来服务发现的公共接口，在 spring cloud 的各类服务发现组件中，都有对应的实现，如 eureka、consul、zookeeper 。它提供从服务注册中心获取服务实例信息的能力。如果我们想自己实现一个服务发现组件，集成到spring cloud 中，就完全可以通过实现此接口来完成。\n\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\n工程背景本案例使用 SOFABoot 3.0.x 版本集成 SringCloud F版。工程如下：\n\nsofa-eureka-consumer-discovery     服务消费方\n\n本工程的父工程继续使用《SpringCloud-Eureka 服务注册》文中新建的父工程。\n新建 sofa-eureka-consumer-discovery这里我们通过 sofa-eureka-consumer-discovery 这个工程来手动发现服务。\n右击 sofa-eureka-parent 父工程 -&gt; New -&gt; Module，这里选择 Maven 工程；\n\nartifactId：sofa-eureka-consumer-discovery。\n\n修改 pom 文件引入 spring-cloud-starter-netflix-eureka-client 依赖。\n1234567891011121314151617181920 &lt;parent&gt;   &lt;artifactId&gt;sofa-eureka-parent&lt;/artifactId&gt;   &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;   &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;sofa-eureka-consumer-discovery&lt;/artifactId&gt;&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;\n\n配置文件123server.port=8088spring.application.name=sofa-eureka-discoveryeureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/\n\n启动类1234567@SpringBootApplication@EnableEurekaClientpublic class SofaEurekaConsumerDiscoveryApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaEurekaConsumerDiscoveryApplication.class, args);    &#125;&#125;\n\n服务获取这里通过 DiscoveryClient 对像手动获取到 HELLOSOFASERVICE 服务对应的所有实例。\n123456789101112131415161718192021@RestControllerpublic class DiscoveryController &#123;    @Autowired    private DiscoveryClient discoveryClient;    @RequestMapping(&quot;/instance&quot;)    public String getInstance()&#123;        List&lt;ServiceInstance&gt; list = discoveryClient.getInstances(&quot;HELLOSOFASERVICE&quot;);        System.out.println(&quot;current service size = &quot; + discoveryClient.getServices().size());        StringBuilder stringBuilder = new StringBuilder();        for( String s :  discoveryClient.getServices())&#123;            stringBuilder.append(&quot;services=&quot; + s).append(&quot;\\n&quot;);            List&lt;ServiceInstance&gt; serviceInstances =  discoveryClient.getInstances(s);            for(ServiceInstance si : serviceInstances)&#123;                stringBuilder.append(&quot;url=&quot;).append(si.getUri()).append(&quot;\\n&quot;);            &#125;        &#125;        stringBuilder.append(&quot;instance num&quot;).append(&quot;=&quot;).append(list.size());        return stringBuilder.toString();    &#125;&#125;\n\n启动 &amp; 验证启动当前工程，在此之前确保 注册中心和服务提供工程均已正常启动。然后在浏览器中输入：http:localhost:8088&#x2F;instance\n可以看到获取到的实例信息与注册中心上的实例信息是匹配的。\n","slug":"springcloud/spring-cloud-eureka-discovery-project","date":"2018-12-31T14:48:17.000Z","categories_index":"SpringCloud","tags_index":"eureka","author_index":"glmapper"},{"id":"552d04375420669150f7f05539f0ea4b","title":"SpringCloud-Eureka 服务注册","content":"\n\n\n\n\n\n\n\n\n原文： https://blog.csdn.net/sinat_25518349/article/details/85423332\nSpring Cloud Netflix Eureka 是 Spring Cloud 提供的用于服务注册和发现的基础组件，在 Spring Cloud 微服务体系中承担着相当重要的角色。Eureka 作为一个开箱即用的基础组件，其屏蔽了底层 Client 和 Server 交互的细节，使得开发者能够快速入手，将更多的精力投入到业务逻辑上去。\n\n\nEureka 是基于 Rest 实现的，及底层客户端和服务端之间的交互是通过 Rest 服务进行交互的。Eureka 包括两个部分，即服务端可客户端。\n\n服务端：Eureka Server ,提供服务注册和发现的功能\n客户端：Eureka Client ,将自己的信息注册到 Eureka Server ，并从 Eureka Server 中发现其他服务。\n\nEureka 本篇将先来搭建一个服务端，以作为后续篇幅的注册中心来使用。\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\n工程背景本案例使用 SOFABoot 3.0.x 版本集成 SringCloud F版。工程如下：\n\nsofa-eureka-server         服务注册中心\nsofa-eureka-provider      服务提供方\nsofa-eureka-comsumer   服务消费方\n\n本工程都是在同一个父工程下面的，因此工程构建开始会新建一个 SOFABoot 工程作为父工程。\n新建父工程这里父工程直接新建一个SpringBoot 工程。可以使用 IDEA 的生成，也可以通过 SOFABoot 快速开始 新建一个 SpringBoot 工程，删除 src 目录，然后修改 pom.xml 文件。\n\ngourpId : com.alipay.sofa\nartifactId : sofa-eureka-parent\n\nparent 依赖修改123456&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;    &lt;relativePath/&gt; &lt;/parent&gt;\n\n替换为：\n12345&lt;parent&gt;    &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;    &lt;artifactId&gt;sofaboot-dependencies&lt;/artifactId&gt;    &lt;version&gt;3.0.0&lt;/version&gt;&lt;/parent&gt;\n\n管控 SpringCloud 依赖在主 pom 里面加入 SpringCloud 的依赖管控。版本为 Finchley.RC1\n123456789101112131415&lt;properties&gt;\t&lt;spring-cloud.version&gt;Finchley.RC1&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;      &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;      &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt;      &lt;type&gt;pom&lt;/type&gt;      &lt;scope&gt;import&lt;/scope&gt;    &lt;/dependency&gt;  &lt;/dependencies&gt;&lt;/dependencyManagement&gt;\n\n配置 SpringCloud 仓库在主pom.xml 中添加如下配置\n1234567&lt;repositories&gt;  &lt;repository&gt;    &lt;id&gt;spring-milestones&lt;/id&gt;    &lt;name&gt;Spring Milestones&lt;/name&gt;    &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;  &lt;/repository&gt;&lt;/repositories&gt;\n\nOK，到这里，父工程创建完毕。\n新建 sofa-eureka-server-centersofa-eureka-server-center 作为注册中心的服务端。\n右击 sofa-eureka-parent 父工程 -&gt; New -&gt; Module，这里选择 Maven 工程；\n\nartifactId：sofa-eureka-server-center。\n\npom 文件修改引入 spring-cloud-starter-netflix-eureka-server 依赖，如下：\n123456789101112131415 &lt;parent&gt;   &lt;artifactId&gt;sofa-eureka-parent&lt;/artifactId&gt;   &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;   &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;sofa-eureka-server-center&lt;/artifactId&gt;&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;\n\n新建资源文件 application.yml在 &#x2F;src&#x2F;main&#x2F;resources 目录下新建 application.yml 或者 application.properties。这里以.yml文件为例：\n12345678910111213server:  port: 8761    #指定服务端口eureka:  instance:    hostname: localhost  client:    register-with-eureka: false    fetch-registry: false    service-url:      defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/spring:  application:    name: sofa-eureka-server\n\n\n\n\n\n\n\n\n\n\n配置文件后面统一说明\n启动类在 &#x2F;src&#x2F;main&#x2F;resources 目录下新建 com.alipay.sofa.cloud 包目录，并且在当前包路劲下新建 SofaEurekaServerApplication 类，并且类上加上 @EnableEurekaServer 注解。\n1234567@SpringBootApplication@EnableEurekaServerpublic class SofaEurekaServerApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaEurekaServerApplication.class, args);    &#125;&#125;\n\n启动程序 &amp; 验证启动当前应用。并且浏览器中输入：http://localhost:8761/\n\n服务正常运行，界面如上图所示；此时还没有服务注册进来，因此红色框内显示 ：No instances available\n新建 sofa-eureka-providersofa-eureka-provider 作为服务提供方，将会向注册中心 sofa-eureka-server-center 上注册服务。\n右击 sofa-eureka-parent 父工程 -&gt; New -&gt; Module，这里选择 Maven 工程；\n\nartifactId：sofa-eureka-provider。\n\npom 文件修改引入 spring-cloud-starter-netflix-eureka-client 和 spring-boot-starter-web 依赖，如下：\n1234567891011121314151617181920&lt;parent&gt;  &lt;artifactId&gt;sofa-eureka-parent&lt;/artifactId&gt;  &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;artifactId&gt;sofa-eureka-provider&lt;/artifactId&gt;  &lt;dependencies&gt;  &lt;dependency&gt;  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;  &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;  &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;\n\n新建资源文件在 &#x2F;src&#x2F;main&#x2F;resources 目录下新建 application.yml 或者 application.properties。这里以.yml文件为例：\n123456789server:  port: 8082eureka:  client:    service-url:      defaultZone: http://localhost:8761/eureka/  #指定注册中心地址spring:  application:    name: HelloSOFAService   #服务名称\n\n启动类在 &#x2F;src&#x2F;main&#x2F;resources 目录下新建 com.alipay.sofa.cloud 包目录，并且在当前包路劲下新建 SofaEurekaProviderApplication 类，并且类上加上 @EnableEurekaClient 注解。\n1234567@SpringBootApplication@EnableEurekaClientpublic class SofaEurekaProviderApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaEurekaProviderApplication.class, args);    &#125;&#125;\n\n服务提供类这里在  com.alipay.sofa.cloud.controller 包下新建 SofaController 类。\n123456789101112@RestControllerpublic class SofaController &#123;    @Value(&quot;$&#123;server.port&#125;&quot;)    private String port;    @Value(&quot;$&#123;spring.application.name&#125;&quot;)    private String hostname;      @RequestMapping(&quot;/hello&quot;)    public String hello() &#123;        return &quot;Hello SOFA! Now Port is &quot;+port +&quot; And hostname is &quot; +hostname;    &#125;&#125;\n这里在接口中返回 hostname 和 port ，方便后面验证负载均衡测试使用。\n启动程序 &amp; 验证在启动 sofa-eureka-provider 之前，需要先启动 sofa-wureka-server-center 。两个都启动成功之后，浏览器输入：http://localhost:8761/ \n\n此时我将 sofa-eureka-provider 中的配置文件的端口修改为 8081，再注册一个。\n\n可以看到 服务为 HELLOSOFASERVICE 的有两个服务提供方。\n","slug":"springcloud/spring-cloud-eureka-register-project","date":"2018-12-31T14:48:05.000Z","categories_index":"SpringCloud","tags_index":"eureka","author_index":"glmapper"},{"id":"76e31334599a8ccc9ba49abb2e09bda4","title":"SpringCloud-负载均衡器 Ribbon","content":"上一篇 SpringCloud-声明式服务调用 Feign 中介绍了如何使用 Feign 来完成服务调用。因为 Feign 本身已经集成了 Ribbon ，所以也具有负载均衡的能力。那么本篇将使用 RestTemplate + Ribbon 来实现服务调用和负载均衡策略。\n\n\nRibbon 简介Ribbon 是管理HTTP和TCP服务客户端的负载均衡器。Ribbon 具有一些列带有名称的客户端，也就是带有名称的Ribbon 客户端。每个客户端由可配置的组件构成，负责一类服务的调用请求。Spring Cloud 通过RibbonClientConfiguration 为每个Ribbon 客户端创建一个ApplicationContext 上下文来进行组件装配。Ribbon 作为 Spring Cloud的负载均衡机制的实现，可以与OpenFeign 和 RestTemplate 进行无缝集成，让二者也具有负载均衡的能力。\n负载均衡策略\n\n\n策略类\n命名\n备注\n\n\n\nRoundRobinRule\n轮训策略\n按顺序循环选择 Server\n\n\nRandomRule\n随机策略\n随机选择 Server\n\n\nRetryRule\n重试策略\n在一个配置时问段内当选择 Server 不成功，则一直尝试选择一个可用的 Server\n\n\nBestAvailableRule\n最低并发策略\n逐个考察 Server，如果 Server 断路器打开，则忽略，再选择其中并发连接最低的 Server    \n\n\nAvailabilityFilteringRule\n可用过滤策略\n过滤掉一直连接失败并被标记为 circuit tripped 的 Server，过滤掉那些高并发连接的 Server（active connections 超过配置的网值）\n\n\nResponseTimeWeightedRule\n响应时间加权策略\n根据 Server 的响应时间分配权重。响应时间越长，权重越低，被选择到的概率就越低；响应时间越短，权重越高，被选择到的概率就越高。这个策略很贴切，综合了各种因素，如：网络、磁盘、IO等，这些因素直接影响着响应时间\n\n\nZoneAvoidanceRule\n区域权衡策略\n综合判断 Server 所在区域的性能和 Server 的可用性轮询选择 Server，并且判定一个 AWS Zone 的运行性能是否可用，剔除不可用的 Zone 中的所有 Server\n\n\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\n工程背景本节将会创建一个 sofa-eureka-consumer-Ribbon 工程，通过 Spring Cloud 提供的负载均衡器 Ribbon 实现服务的负载均衡，并对 Ribbon 中的负载均衡策略进行验证。\n新建 sofa-eureka-consumer-ribbon本工程继续使用《SpringCloud-Eureka 服务注册》中的父工程来构建。\n右击 sofa-eureka-parent 父工程 -&gt; New -&gt; Module，这里选择 Maven 工程；\n\nartifactId：sofa-eureka-consumer-ribbon\n\n前面我们已经对feign进行的实际操作，因此本节使用 Ribbon + RestTemplate 组合实现具体的负载均衡实验。\n修改 pom 文件1234567891011121314151617181920212223242526&lt;parent&gt;  &lt;artifactId&gt;sofa-eureka-parent&lt;/artifactId&gt;  &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;sofa-eureka-consumer-ribbon&lt;/artifactId&gt;&lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;/dependencies&gt;\n配置文件123456789server:  port: 8889eureka:  client:    service-url:      defaultZone: http://localhost:8761/eureka/spring:  application:    name: eureka-consumer-ribbon\n\n启动类这里需要引入 @EnableEurekaClient 注解，表示当前是一个客户端。\n1234567891011121314@SpringBootApplication@EnableEurekaClientpublic class SofaEurekaConsumerRibbonApplication &#123;    @Bean    @LoadBalanced    public RestTemplate restTemplate()&#123;        return new RestTemplate();    &#125;    public static void main(String[] args) &#123;        SpringApplication.run(SofaEurekaConsumerRibbonApplication.class, args);    &#125;&#125;\n@LoadBalanced ： Spring Cloud 为客户端负载均衡创建了特定的注解，被该注解修饰的 RestTemplate Bean实例，Spring Cloud 就会让 RestTemplate 使用相关的负载均衡策略，默认情况下使用的就是 Ribbon。\n资源类这里我们通过 restTemplate 去访问 Provider 提供的服务，需要注意，这里为了演示作用，直接将资源 Url 固定写成：http://HELLOSOFASERVICE/hello ，HELLOSOFASERVICE 为 Provider 提供的服务的实例名称，也就是 Eureka 服务端界面上对应的 Application。\n1234567891011@RestControllerpublic class RibbonController &#123;    @Autowired    private RestTemplate restTemplate;    @RequestMapping(&quot;/hello&quot;)    public String hello()&#123;        return restTemplate.getForObject(&quot;http://HELLOSOFASERVICE/hello&quot;,String.class);    &#125;&#125;\n\n启动服务这里正常先后启动 服务注册中心 sofa-eureka-server-center ；服务提供方 sofa-eureka-provider ，服务提供方为了方便演示，这里启动4个实例，对应的端口分别为：8081，8082，8083，8084，如下：\n\n然后启动当前 sofa-eurek-consumer-ribbon 工程。默认情况下，不指定任何负载均衡策略，使用的是轮询策略。\n浏览器输入 http://localhost:8889/hello ，调用10次：\n123456789101112Hello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8083 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8084 And hostname is HelloSOFAService  Hello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8083 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8084 And hostname is HelloSOFAService  Hello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAService\n从结果来看，默认策略应该是轮询（不用情况下，调用顺序不一定是1-2-3-4，但是以每4组为一组来看，存在周期性）。\n负载均衡策略设置全局设置全局设置就是自己定义一个配置类，然后在配置类中指定具体的负载均衡策略。在com.alipay.sofa.cloud.configuration 包下面新建一个配置类，这里使用的策略是随机策略：\n12345678@Configurationpublic class RibbonGlobalLoadBalancingConfiguration &#123;    @Bean    public IRule ribbonRule() &#123;        return new RandomRule();    &#125;&#125;\n\n浏览器输入 http://localhost:8889/hello ，调用10次：\n123456789101112Hello SOFA! Now Port is 8083 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8084 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8084 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8083 And hostname is HelloSOFAService  Hello SOFA! Now Port is 8082 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8083 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8084 And hostname is HelloSOFAService  Hello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8081 And hostname is HelloSOFAService\n\n从结果来看，具有随机属性。\n针对单个服务的 Ribbon 负载均衡策略新建一个 RibbonRandomLBConfiguration 配置类，这里有个前提是需要删除 全局配置类  。\n123456@Configurationpublic class RibbonRandomLBConfiguration &#123;    @Bean    public IRule ribbonRule() &#123;        return new RandomRule();    &#125;\n修改启动类，增加 @RibbonClient 注解，并且通过 configuration 指定负载均衡策略。\n123456789101112131415@SpringBootApplication@EnableEurekaClient@RibbonClient(name=&quot;HELLOSOFASERVICE&quot;,configuration = RibbonRandomLBConfiguration.class)public class SofaEurekaConsumerRibbonApplication &#123;    @Bean    @LoadBalanced    public RestTemplate restTemplate()&#123;        return new RestTemplate();    &#125;    public static void main(String[] args) &#123;        SpringApplication.run(SofaEurekaConsumerRibbonApplication.class, args);    &#125;&#125;\n浏览器输入 http://localhost:8889/hello ，调用10次：\n123456789101112Hello SOFA! Now Port is 8083 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8083 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8083 And hostname is HelloSOFAService  Hello SOFA! Now Port is 8084 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8081 And hostname is HelloSOFAService  Hello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8083 And hostname is HelloSOFAService\n从结果来看，具有随机属性。\n@RibbonClient 注解属性中，name 并非是一个数组，也就是说只能指定一个服务实例。那么基于上述情况，如果还存在另外一个服务，比如 SOFABOOTHELLOSERVICE ，那么对于此服务的调用会是什么情况呢？\n先向注册中心注册两个服务：HELLOSOFABOOTSERVICE 和 HELLOSOFASERVICE\n\n修改 RibbonController ，增加一个 &#x2F;helloBoot 资源地址：\n12345678910111213141516@RestControllerpublic class RibbonController &#123;    @Autowired    private RestTemplate restTemplate;    @RequestMapping(&quot;/hello&quot;)    public String hello()&#123;        return restTemplate.getForObject(&quot;http://HELLOSOFASERVICE/hello&quot;,String.class);    &#125;    @RequestMapping(&quot;/helloBoot&quot;)    public String helloBoot()&#123;        return restTemplate.getForObject(&quot;http://HELLOSOFABOOTSERVICE/hello&quot;,String.class);    &#125;&#125;\n\n重启启动当前服务。\n浏览器中输入：http://localhost:8889/hello ，验证结果满足随机调用。\n浏览器中输入：http://localhost:8889/helloBoot ，验证结果满足轮询调用。\n基于配置文件的负载均衡策略设置个人感觉基于配置文件配置方式更加直观，而且对于多个服务对应不同的负载策略设置也更加清晰，下面对HELLOSOFASERVICE 和  HELLOSOFABOOTSERVICE 均使用随机策略。\n1234567HELLOSOFASERVICE:  ribbon:    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRuleHELLOSOFABOOTSERVICE:  ribbon:    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule\n启动类中删除以下注解配置：\n1@RibbonClient(name = &quot;HELLOSOFASERVICE&quot;, configuration = RibbonRandomLBConfiguration.class)\n重启启动当前服务。\n浏览器中输入：http://localhost:8889/hello ，验证结果满足随机调用。浏览器中输入：http://localhost:8889/helloBoot ，验证结果满足随机调用。\n","slug":"springcloud/spring-cloud-ribbon-project","date":"2018-12-31T14:47:01.000Z","categories_index":"SpringCloud","tags_index":"负载均衡,eureka,feign","author_index":"glmapper"},{"id":"21548e9ec276e6ad92466723ebcdde83","title":"SpringCloud-声明式服务调用 Feign","content":"Fegin 是一个声明式的 web 服务客户端，它使得编写 web 服务客户端变得更加容易。使用 Fegin 创建一个接口并对它进行注解。它具有可插拔的注解支持包括 Feign 注解与 JAX-RS 注解，Feign 还支持可插拔的编码器与解码器，Spring Cloud 增加了对 Spring MVC 的注解，Spring Web 默认使用了 HttpMessageConverters。Fegin 还可以集成 Ribbon 和 Hystrix 来提供负载均衡和网络断路器的功能。\n本篇将使用 Fegin + eureka client 来完成服务发现和调用。\n\n\n环境准备\n\n\n类别\n值\n\n\n\nJDK\n1.8.0_162\n\n\nSOFABoot&#x2F;SpringBoot\n3.0.0&#x2F;2.0.x.RELEASE\n\n\nSpringCloud\nFinchley.RC1\n\n\nIDE\nIDEA\n\n\n工程背景本节将会创建一个 sofa-eureka-consumer-feign 工程，使用 Feign 提供的 web 客户端来访问 sofa-eureka-provider 发布的服务。同时也基于此工程验证基于 Feign 实现的负载均衡。\n新建 sofa-eureka-consumer-feign本工程继续使用《SpringCloud-Eureka 服务注册》中的父工程来构建。\n右击 sofa-eureka-parent 父工程 -&gt; New -&gt; Module，这里选择 Maven 工程；\n\nartifactId：sofa-eureka-consumer-feign\n\n修改pom文件123456789101112131415161718192021222324&lt;parent&gt;   &lt;artifactId&gt;sofa-eureka-parent&lt;/artifactId&gt;   &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;   &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;sofa-eureka-server-center&lt;/artifactId&gt;&lt;dependencys&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;      &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;      &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;  &lt;/dependency&gt;&lt;/dependencys&gt;\n\n修改配置文件123server.port=8888eureka.client.service-url.defaultZone=http://localhost:8761/eureka/spring.application.name=eureka-consumer-feign\n\n启动类这里需要添加 @EnableEurekaClient 和 @EnableFeignClients 两个注解。\n12345678@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class SofaEurekaConsumerFeignApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SofaEurekaConsumerFeignApplication.class, args);    &#125;&#125;\n\n资源类\ncom.alipay.sofa.cloud.service 包下新建  HelloSOFAService\n\n12345@FeignClient(&quot;helloSOFAService&quot;)public interface HelloSOFAService &#123;    @RequestMapping(value = &quot;/hello&quot;, method = RequestMethod.GET)    String hello();&#125;\n\n\ncom.alipay.sofa.cloud.controller 包下新建  FeignController\n\n1234567891011@RestControllerpublic class FeignController &#123;    @Autowired    private HelloSOFAService helloSOFAService;    @RequestMapping(&quot;/hello&quot;)    public String hello()&#123;        return helloSOFAService.hello();    &#125;&#125;\n\n\n启动 &amp; 验证启动当前工程，在此之前请以此启动 注册中心 sofa-eureka-server-center 和 sofa-eureka-provider 两个工程。\n\n\n\n\n\n\n\n\n\n注：这里我启动了两个 provider 工程\n浏览器输入：http:localhost:8888&#x2F;hello，观察到浏览器中依次展示：\n1234Hello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8081 And hostname is HelloSOFAServiceHello SOFA! Now Port is 8082 And hostname is HelloSOFAService\n这里可以看待 通过 feign 提供的客户端能力已经访问到了远程服务，由于 feign 集成了 ribbon 因此也就默认实现了负载均衡的能力。从结果来看，默认的负载均衡策略是轮询。\n","slug":"springcloud/spring-cloud-feign-project","date":"2018-12-31T14:46:42.000Z","categories_index":"SpringCloud","tags_index":"http,eureka,feign","author_index":"glmapper"},{"id":"d6e90c53f3989086d699165ea9667bd3","title":"SpringSession系列-集成SpringBoot","content":"springSession是 spring 旗下的一个项目，把 servlet 容器实现的 httpSession替换为springSession，专注于解决session管理问题。可简单快速且无缝的集成到我们的应用中。本文通过一个案例，使用SpringBoot来集成 SpringSession，并且使用Redis作为存储来实践下SpringSession 的使用。\n\n\n环境准备因为需要使用Redis作为底层Session的存储介质，实现分布式session，因此需要安装Redis。\nRedis 安装1、从官网下载最新版的Redis\n\n2、解压\n1tar zxvf redis-5.0.0.tar.gz\n3、编译测试\n1sudo make test\n4、编译安装\n1sudo make install\n\n5、安装问题\n如果您之前安装过，重复安装且没有卸载干净的话，会报下面的错\n12make[1]: *** [test] Error 1 make: *** [test] Error 2\n解决这个错误，执行下面的语句即可： \n123make distclean make make test\n正确安装姿势如下：\n\n6、启动Redis在您的Redis安装目录下，有 redis-server ，执行该脚本命令：\n\nOK，到这里，Redis的安装工作完毕。\nSpringBoot 工程准备这里我们直接通过Idea来构建我们的SpringBoot工程。\n1File-&gt;New-&gt;Project : Spring Initializr\n\n\nOK，SpringBoot 工程准备完毕，这里选择创建的是一个Web工程。\n集成集成主要是依赖引入，这里需要redis和session的依赖\n依赖引入123456789101112&lt;dependencies&gt;    &lt;!--redis 依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;    &lt;/dependency&gt;    &lt;!--sessions 依赖--&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;        &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;\n\n配置application.properties123456789#服务端口server.port=8080#redi主机地址spring.redis.host=localhost#redis服务端口spring.redis.port=6379# spring session使用存储类型，spirngboot默认就是使用redis方式，如果不想用可以填none。spring.session.store-type=redis\n\n在启动类中加入@EnableRedisHttpSession  注解1234567@SpringBootApplication@EnableRedisHttpSessionpublic class SpringBootSessionApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SpringBootSessionApplication.class, args);    &#125;&#125;\n测试先来编写一个Controller\n12345678910111213141516171819202122232425262728/** * SessionController *  * @author: glmapper@leishu * @since: 18/11/3 下午3:16 * @version 1.0 **/@Controller@RequestMapping(value = &quot;/&quot;)public class SessionController &#123;        @ResponseBody    @RequestMapping(value = &quot;/session&quot;)    public Map&lt;String, Object&gt; getSession(HttpServletRequest request) &#123;        request.getSession().setAttribute(&quot;userName&quot;, &quot;glmapper&quot;);        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();        map.put(&quot;sessionId&quot;, request.getSession().getId());        return map;    &#125;        @ResponseBody    @RequestMapping(value = &quot;/get&quot;)    public String get(HttpServletRequest request) &#123;        String userName = (String) request.getSession().getAttribute(&quot;userName&quot;);        return userName;    &#125;&#125;\n测试结果启动SpringBoot 工程；然后浏览器中输入地址 http://localhost:8080/session；\n这里对应执行的是我们上面Controller中的第一个方法getSession，这个方法向session中设置了一个值。\n下面我们执行：http://localhost:8080/get  这里是从session中取值:\n\n到此，SpringBoot 整合 SpringSession 的过程就完成了。这里我们只是引入了依赖，然后做了简单的配置，那么我们的请求是如何被 SpringSession 处理的呢？从我们一贯的认知来看，对于基于Servlet规范的容器（SpringBoot 使用的是嵌入式Tomcat）的应用，请求最先被处理的是Filter。我们在基于Spring+SpringMvc这套技术栈开发时,如果我们需要做权限管理，通过会基于Filter或者拦截器。但是这里貌似我们什么也没做，但是请求确实被SpringSession处理了。OK，我们来扒一扒。\nSpringSession 是如何处理请求的？上面这张截图想必大家都不陌生，是SpringBoot的启动日志；上图红色框内的是当前应用注册是Filter信息，从这里可以看到有个和 session 有关的Filter：sessionRepositoryFilter；这个bean对应的类是：\n12org.springframework.boot.autoconfigure.session.SessionRepositoryFilterConfiguration.ConditionalOnBean=org.springframework.session.web.http.SessionRepositoryFilter\n在这里找到了\n这里涉及到SpringBoot的自动配置，从spring-boot-autoconfig包下加载spring-autoconfigure-metadata.properties 配置文件，然后获取所有支持自动配置的信息；SpringSession 也在其中。关于如何加载并且注册不在本文的范畴之内，我们继续来分析SpringSession的处理过程。\nSpringSession 的处理过程从上面SpringBoot的启动过程我们找到了处理session的Filter，然后知道了它是通过自动配置的方式被注册到当前的容器并且来处理请求。\n123@Order(SessionRepositoryFilter.DEFAULT_ORDER)public class SessionRepositoryFilter&lt;S extends Session&gt; extends OncePerRequestFilter &#123;\n从SessionRepositoryFilter的定义来看：\n\n1、使用了Order，并且配置了一个很小的值（Integer.MIN_VALUE + 50），以此来确保session的Filter在Filter链中被优先执行。\n2、集成了OncePerRequestFilter，确保在一次请求只通过一次filter，而不需要重复执行\n\n为什么 session 的 Filter 要被优先执行呢？因为我们的请求被包装了，如果SessionRepositoryFilter不优先处理请求，可能会导致后续的请求行为不一致，这里涉及到 springSession无缝替换应用服务器的request的原理：\n\n1.自定义个Filter，实现doFilter方法 \n2.继承 HttpServletRequestWrapper 、HttpServletResponseWrapper 类，重写getSession等相关方法(在这些方法里调用相关的 session存储容器操作类)。 \n3.自定义request和response类；并把它们分别传递到过滤器链 \n4.把该filter配置到过滤器链的第一个位置上\n\nOK，了解了这些背景，我们来跟踪下整个处理流程。\n1、断点到 doFilterInternal\n从这里可以看到request和response类被包装了。\n2、断点到 getSession这里是从Redis中拿我们session数据的地方\n\n\n先从我们当前servlet容器中去拿，如果拿到则直接返回\n\n去Redis中取\n    这里会有一个缓存处理，并非是每次都到Reids中去查一次，避免一次与Reids的交互。\n\n如果缓存当前应用容器缓存中有，则直接返回当前被缓存的session\n如果没有，则从请求中获取sessionId，并且根据当前sessionId去Reids中查找session数据\n更新缓存session，sessionId,requestedSessionCached 等数据状态\n\n\n如果Redis中有，则更新session相关信息并返回\n\n如果Reids中没有找到，则根据 create 来判断是否创建新的session。\n\n\n断点到 readCookieValuesSpringSession提供了两种保存和传递SessionId的方式，一种是基于Cookie的，一种是基于Header的。SpringSession中默认使用的是基于Cookie的方式。readCookieValues 就是实现如何从Cookie中获取sessionId的。\n\n这个过程其实很简单，先是从request中获取当前请求携带的所以的Cookie信息，然后将匹配到的 cookieName 为 “SESSION” 的Cookie进行解析。\n断点到 RedisOperationsSessionRepository -&gt; getSession这里是从Redis中取session数据的地方\n\n根据sessionId 从 Redis中取到 entries 数据\n构建 RedisSession 并返回\n\n断点到 commitSessioncommitSession作用是通过 HttpSessionIdResolver 将sessionId写到response，并且进行持久化。\n\n这里的 session 其实是已经更新过状态的，比如重新设置了 session 的过期时间等。session 提交实际上就意味着当前请求已经处理完毕了。\n小结本文先介绍了如何使用 SpringBoot 集成 SpringSession，并且以 Redis 作为存储。然后简单分析了 SpringSession 的处理过程，本文对 SpringSession 的原理部分没有进行深入分析，下一篇分析下SpringSession的原理。\n","slug":"spring/spring-session-intergration-boot","date":"2018-12-10T01:16:19.000Z","categories_index":"spring","tags_index":"session,分布式,redis","author_index":"glmapper"},{"id":"a51f93717fc52b7309abb94021410992","title":"SpringSession系列-请求与响应重写","content":"我们知道，HttpServletRequset和HttpServletResponse是Servlet标准所指定的Java语言与Web容器进行交互的接口。接口本身只规定java语言对web容器进行访问的行为方式，而具体的实现是由不同的web容器在其内部实现的。\n那么在运行期，当我们需要对HttpServletRequset和HttpServletResponse的默认实例进行扩展时，我们就可以继承HttpServletRequestWrapper和HttpServletResponseWrapper来实现。\n\n\n在 SpringSession中因为我们要实现不依赖容器本身的getSession 实现，因此需要扩展 HttpServletRequset，通过重写getSession来实现分布式session的能力。下面就来看下SpringSession中对于HttpServletRequset的扩展。\n1、请求重写SpringSession 中对于请求重写，在能力上主要体现在存储方面，也就是getSession方法上。在 SessionRepositoryFilter 这个类中，是通过内部类的方式实现了对HttpServletRequset和HttpServletResponse的扩展。\n1.1 HttpServletRequset 扩展实现12345678910111213141516171819private final class SessionRepositoryRequestWrapper\t\t\textends HttpServletRequestWrapper &#123;\t// HttpServletResponse 实例\tprivate final HttpServletResponse response;\t// ServletContext 实例\tprivate final ServletContext servletContext;        // requestedSession session对象        private S requestedSession;         // 是否缓存 session        private boolean requestedSessionCached;\t// sessionId\tprivate String requestedSessionId;\t// sessionId 是否有效\tprivate Boolean requestedSessionIdValid;\t// sessionId 是否失效\tprivate boolean requestedSessionInvalidated;\t\t// 省略方法&#125;\n\n1.2 构造方法123456private SessionRepositoryRequestWrapper(HttpServletRequest request,\t\tHttpServletResponse response, ServletContext servletContext) &#123;\tsuper(request);\tthis.response = response;\tthis.servletContext = servletContext;&#125;\n构造方法里面将 HttpServletRequest、HttpServletResponse 以及 ServletContext 实例传递进来，以便于后续扩展使用。\n1.3 getSession 方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Overridepublic HttpSessionWrapper getSession(boolean create) &#123;    // 从当前请求线程中获取 session\tHttpSessionWrapper currentSession = getCurrentSession();\t// 如果有直接返回\tif (currentSession != null) &#123;\t\treturn currentSession;\t&#125;\t// 从请求中获取 session，这里面会涉及到从缓存中拿session的过程\tS requestedSession = getRequestedSession();\tif (requestedSession != null) &#123;\t    // 无效的会话id(不支持的会话存储库)请求属性名称。\t    // 这里看下当前的sessionId是否有效\t\tif (getAttribute(INVALID_SESSION_ID_ATTR) == null) &#123;\t\t    // 设置当前session的最后访问时间，用于延迟session的有效期\t\t\trequestedSession.setLastAccessedTime(Instant.now());\t\t\t// 将requestedSessionIdValid置为true\t\t\tthis.requestedSessionIdValid = true;\t\t\t// 包装session\t\t\tcurrentSession = new HttpSessionWrapper(requestedSession, getServletContext());\t\t\t// 不是新的session，如果是新的session则需要改变sessionId\t\t\tcurrentSession.setNew(false);\t\t\t// 将session设置到当前请求上下文\t\t\tsetCurrentSession(currentSession);\t\t\t// 返回session\t\t\treturn currentSession;\t\t&#125;\t&#125;\telse &#123;\t\t// 这里处理的是无效的sessionId的情况，但是当前请求线程 session有效\t\tif (SESSION_LOGGER.isDebugEnabled()) &#123;\t\t\tSESSION_LOGGER.debug(\t\t\t\t\t&quot;No session found by id: Caching result for getSession(false) for this HttpServletRequest.&quot;);\t\t&#125;\t\t// 将invalidSessionId置为true\t\tsetAttribute(INVALID_SESSION_ID_ATTR, &quot;true&quot;);\t&#125;\t// 是否需要创建新的session\tif (!create) &#123;\t\treturn null;\t&#125;\tif (SESSION_LOGGER.isDebugEnabled()) &#123;\t\tSESSION_LOGGER.debug(\t\t\t\t&quot;A new session was created. To help you troubleshoot where the session was created we provided a StackTrace (this is not an error). You can prevent this from appearing by disabling DEBUG logging for &quot;\t\t\t\t\t\t+ SESSION_LOGGER_NAME,\t\t\t\tnew RuntimeException(\t\t\t\t\t\t&quot;For debugging purposes only (not an error)&quot;));\t&#125;\t// 创建新的session\tS session = SessionRepositoryFilter.this.sessionRepository.createSession();\t// 设置最后访问时间，也就是指定了当前session的有效期限\tsession.setLastAccessedTime(Instant.now());\t// 包装下当前session\tcurrentSession = new HttpSessionWrapper(session, getServletContext());\t//设置到当前请求线程\tsetCurrentSession(currentSession);\treturn currentSession;&#125;\n\n上面这段代码有几个点，这里单独来解释下。\n\ngetCurrentSession\n这是为了在同一个请求过程中不需要重复的去从存储中获取session，在一个新的进来时，将当前的 session 设置到当前请求中，在后续处理过程如果需要getSession就不需要再去存储介质中再拿一次。\n\n\ngetRequestedSession\n这个是根据请求信息去取session，这里面就包括了sessionId解析，从存储获取session对象等过程。\n\n\n是否创建新的session对象   \n在当前请求中和存储中都没有获取到session信息的情况下，这里会根据create参数来判断是否创建新的session。这里一般用户首次登录时或者session失效时会走到。\n\n\n\n1.4 getRequestedSession根据请求信息来获取session对象\n1234567891011121314151617181920212223private S getRequestedSession() &#123;    // 缓存的请求session是否存在\tif (!this.requestedSessionCached) &#123;            // 获取 sessionId            List&lt;String&gt; sessionIds = SessionRepositoryFilter.this.httpSessionIdResolver            \t\t.resolveSessionIds(this);            // 通过sessionId来从存储中获取session            for (String sessionId : sessionIds) &#123;            \tif (this.requestedSessionId == null) &#123;            \t\tthis.requestedSessionId = sessionId;            \t&#125;            \tS session = SessionRepositoryFilter.this.sessionRepository            \t\t\t.findById(sessionId);            \tif (session != null) &#123;            \t\tthis.requestedSession = session;            \t\tthis.requestedSessionId = sessionId;            \t\tbreak;            \t&#125;            &#125;            this.requestedSessionCached = true;\t&#125;\treturn this.requestedSession;&#125;\n这段代码还是很有意思的，这里获取sessionId返回的是个列表。当然这里是SpringSession的实现策略，因为支持session，所以这里以列表的形式返回的。OK，继续来看如何解析sessionId的：\n[外链图片转存中…(img-RttDZ5t0-1650764287870)]\n这里可以看到SpringSession对于sessionId获取的两种策略，一种是基于cookie，一种是基于header；分别来看下具体实现。\n1.4.1 CookieHttpSessionIdResolver 获取 sessionIdCookieHttpSessionIdResolver 中获取sessionId的核心代码如下：[外链图片转存中…(img-jN2CqgSr-1650764287871)]其实这里没啥好说的，就是读cookie。从request将cookie信息拿出来，然后遍历找当前sessionId对应的cookie,这里的判断也很简单， 如果是以SESSION开头，则表示是 SessionId，毕竟cookie是共享的，不只有sessionId，还有可能存储其他内容。\n另外这里面有个 jvmRoute，这个东西实际上很少能够用到，因为大多数情况下这个值都是null。这个我们在分析CookieSerializer时再来解释。\n1.4.2 HeaderHttpSessionIdResolver 获取 sessionId[外链图片转存中…(img-GinHnGhX-1650764287872)]这个获取更直接粗暴，就是根据 headerName 从 header 中取值。\n回到getRequestedSession，剩下的代码中核心的都是和sessionRepository这个有关系，这部分就会涉及到存储部分。不在本篇的分析范围之内，会在存储实现部分来分析。\n1.5 HttpSessionWrapper[外链图片转存中…(img-NLT9vKvP-1650764287872)]\n上面的代码中当我们拿到session实例是通常会包装下，那么用到的就是这个HttpSessionWrapper。\nHttpSessionWrapper 继承了 HttpSessionAdapter，这个HttpSessionAdapter就是将SpringSession 转换成一个标准HttpSession的适配类。HttpSessionAdapter 实现了标准servlet规范的HttpSession接口。\n1.5.1 HttpSessionWrapperHttpSessionWrapper 重写了 invalidate 方法。从代码来看，调用该方法产生的影响是：\n\nrequestedSessionInvalidated 置为true，标识当前 session 失效。\n将当前请求中的session设置为null，那么在请求的后续调用中通过getCurrentSession将拿不到session信息。\n当前缓存的 session 清楚，包括sessionId，session实例等。\n删除存储介质中的session对象。\n\n1.5.2 HttpSessionAdapterSpringSession和标准HttpSession的配置器类。这个怎么理解呢，来看下一段代码：\n12345@Overridepublic Object getAttribute(String name) &#123;\tcheckState();\treturn this.session.getAttribute(name);&#125;\n对于基于容器本身实现的HttpSession来说，getAttribute的实现也是有容器本身决定。但是这里做了转换之后，getAttribute将会通过SpringSession中实现的方案来获取。其他的API适配也是基于此实现。\nSessionCommittingRequestDispatcher实现了 RequestDispatcher 接口。关于RequestDispatcher可以参考这篇文章【Servlet】关于RequestDispatcher的原理。SessionCommittingRequestDispatcher对forward的行为并没有改变。对于include则是在include之前提交session。为什么这么做呢？\n 因为include方法使原先的Servlet和转发到的Servlet都可以输出响应信息，即原先的Servlet还可以继续输出响应信息；即请求转发后，原先的Servlet还可以继续输出响应信息，转发到的Servlet对请求做出的响应将并入原先Servlet的响应对象中。 \n 所以这个在include调用之前调用commit，这样可以确保被包含的Servlet程序不能改变响应消息的状态码和响应头。\n2 响应重写响应重写的目的是确保在请求提交时能够把session保存起来。来看下SessionRepositoryResponseWrapper类的实现：\n[外链图片转存中…(img-GQr4aCqq-1650764287873)]这里面实现还就是重写onResponseCommitted，也就是上面说的，在请求提交时能够通过这个回调函数将session保存到存储容器中。\n2.1 session 提交最后来看下 commitSession\n[外链图片转存中…(img-LfCJyYua-1650764287874)]\n这个过程不会再去存储容器中拿session信息，而是直接从当前请求中拿。如果拿不到，则在回写cookie时会将当前session对应的cookie值设置为空，这样下次请求过来时携带的sessionCookie就是空，这样就会重新触发登陆。\n如果拿到，则清空当前请求中的session信息，然后将session保存到存储容器中，并且将sessionId回写到cookie中。\n小结本篇主要对SpringSession中重写Request和Response进行了分析。通过重写Request请求来将session的存储与存储容器关联起来，通过重写Response来处理session提交，将session保存到存储容器中。\n后面我们会继续来分析SpringSession的源码。最近也在学习链路跟踪相关的技术，也准备写一写，有兴趣的同学可以一起讨论。\n","slug":"spring/spring-session-rewrite-req-resp","date":"2018-12-10T01:15:21.000Z","categories_index":"spring","tags_index":"session,分布式,redis","author_index":"glmapper"},{"id":"46a9cf97b63fb53bbaac01eae86dbdc2","title":"SpringSession系列-分布式Session实现方案","content":"\n\n\n\n\n\n\n\n\nhttps://juejin.cn/post/6844903721206300685\n上一篇文章 SpringSession：集成SpringBoot 中介绍了如何在SpringBoot中来集成 SpringSession，整个过程非常简单，同时也简单分析了下SpringSession的作用原理。继上一篇实践之后，本文主要来分析 SpringSession 的原理。\n\n\n1、从 session 的一致性方案说起关于 session 和 cookie 的一些知识，大家可以参考下我之前写的一篇文章：聊一聊 session 和 cookie 。\nSession作为服务器端使用的一种记录客户端状态的机制，其对客户端是透明的；但是Session 的正常运作仍然需要客户端浏览器的支持。我们都知道，HTTP协议是无状态的，Session不能依据HTTP连接来判断是否为同一客户，因此服务器需要向客户端浏览器发送一个识别标志（sessionId）,这个识别标志通过是通过Cookie机制来完成。\n1.1、session 一致性问题的由来当用户首次访问我们的Servlet时，应用服务器端会给用户创建一个独立的Session，并且存储在内存中。这种情况在单应用服务器场景下是可以满足的（这里不讨论其一个弊端，就是内存占用给服务器带来的压力的问题）。在集群场景下，这种机制就会到来问题：\n1.1.1、单机场景\n因为是一台应用服务器，用户的每次请求都是由这台机器来处理，所以不会有session共享问题。\n1.1.2、集群场景\n假设现在集群中有三台机器，（从上到下：A-&gt;B-&gt;C）。当前用户首次发起访问时，请求被分配到 A 机器处理，Session 数据被写入 A 机器的内存中；当再次发起访问 时，请求被分配的 B 处理，但此时 B 内存中并没有当前用户的任何数据，这样就出现了session不一致的情况了。\n1.2、Session 一致性问题的方案对于当前服务化、单元化应用盛行的时代，简单的内存型的 Session 已经不能够满足我们的要求了。那么我们就需要寻求一种方案来替换目前单机内存存储实现的方案。\n1.2.1 基于 IP-HASH 的实现机制在 1.1.2 中因为我们无法知道请求会被分配到哪台机器来处理，所以会导致session不一致的问题出现。如果我们可以解决让每个用户的请求能够固定的打到某一台机器上，那么上面提到的问题其实也就不存在了。IP-HASH 就是这样一种方案。通过对请求的客户端 IP 进行 HASH 计算，并将计算结果映射到具体一台机器，这样就可以将请求固定分配到某一台机器上，从而有效的避免session一致性问题的出现。\n这种方案的好处在于:\n\n不需要修改任何应用代码，0 侵入。\n安全性高，不依赖其他三方缓存框架带来的风险\n成本低\n\n但是问题也很明显，这种方式实际上是规避了session一致性问题的出现，并非是针对session一致性问题给出的解决方案。主要问题：\n\n基于应用内存，会给应用服务器带来一定的压力\n服务重启会导致session数据丢失\n不利于水平扩展，水平扩展也可能丢失session\n存在单点负载高的情况，就是多数请求经过HASH计算之后打到同一台机器，而其他机器处于空闲状态。\n\n1.2.2 session 复制这种方式的实现原理是应用服务器创建session之后通过组播的方式将session发送到组播地址内的其他应用服务器上。这种方式相较于IP-HASH 的方式要靠谱一点：\n\n同样不需要更改任何业务代码\n能够适应多种负载策略\n机器重启或者宕机之后不怕丢失，因为有冗余备份\n\n但是这种方式也有比较大的问题：\n\n首先就是服务器之间同步session会占用一定的网络资源，同时session在不同的机器之间进行同步存在延迟。\n还是基于内存存储，局限于机器内存容量影响，水平扩展能力差\n服务器内存因为需要存储其他机器上的session数据，对内存的消耗会随着集群的规模变大而变大，可能会导致机器频繁触发GC。\n\n1.2.3 借助三方缓存框架实现 session 集中管理上面两种方式都是有服务器自己来管理session的，主要问题还是在于对于性能和内存的影响。而这种方式的原理是将session托管给三方软件（如redis）来统一管理。这种方式可以有效的解决性能、内存占用以及水平扩展等问题。但是因为引入了三方软件，在实现复杂度、运维成本等方面会有所增加。\n目前所接触到的分布式session的实现方案，大多都是基于这种方式来实现的；SpringSession 也不例外。\n2、SpringSession 功能结构分析前面对分布式场景下的 Session一致性问题进行了说明，并对解决Session一致性的问题的几种策略进行的分析（有点糙，网上这些知识有很多）。在了解这些背景之后，我们来看下 SpringSession 的实现原理。\n2.1 简介Spring Session 提供了用于管理用户会话信息的API和实现，在不依赖特定于应用程序容器的解决方案的情况下，使得支持群集会话变得更加简单。它还提供了透明的集成：\n\n允许以应用程序容器（Tomcat等）中立的方式替换 HttpSesseion，支持在 headers 中提供 session IDs 来使用 RESTful API。\n提供在接收 WebSocket 消息时保持 HTTP 会话存活的能力\n允许以应用程序容器中立的方式替换 Spring WebFlux 的 WebSession。\n\n\n\n\n\n\n\n\n\n\n以上来自官网文档翻译 Spring Session \n2.2 模块Spring Session 主要包括 4 个模块：\n\nspring-session-core ：提供了 Spring Session 核心功能和API\nspring-session-data-redis：以 redis 作为存储机制的 SessionRepository 实现\nspring-session-hazelcast：以 Hazelcast 作为存储机制的 SessionRepository 实现\nspring-session-jdbc：以关系型数据库作为存储机制的 SessionRepository 实现\n\n总体来说就是 核心API+存储实现；工程模块截图如下：\n\n2.3 功能结构SpringSession整体上可以分为三块：\n\n对于Web层的处理，这里包括对于请求的重写，自定义的filter加入到filter chain，cookie处理，http header处理等\n公共基础封装，比如存储类的顶层抽象接口定义，自定配置，事件处理等。\n存储部分，这部分实际上是对公共基础封装接口的实现，提供了丰富的存储实现，包括redis，内存存储，jdbc等。\n\n2.4 多 session 支持对于常用的分布式session，在实现上一般会依赖于 cookie。但是在 springsession 中提供了基于header来传递jessionID的策略实现。同时在 2.0.4 版本之前，对于同一个浏览器同一个网站，springsession 支持多个session问题，但是在此版本之后抛弃了对于对 session 的支持。关于更多关于多session支持可以查看 SpringSession 的官方文档。\n小结本文对分布式 session 的几种实现策略进行了简单的介绍。对于分布式 session 而言，如何解决一致性问题是关键，目前我见过的绝大多数方案均是以 【借助三方缓存框架实现 session 集中管理】 这种来实现的，包括本系列文章中所要介绍的 SpringSession。\n除分布式session一致性方式解决方案的介绍之外，作为SpringSession 的第二篇文章，在这里简单分析了下Springsession的功能模块，以便后续展开对源码的分析。\n","slug":"spring/spring-session-distribution-solution","date":"2018-12-10T01:14:52.000Z","categories_index":"spring","tags_index":"session,分布式,redis","author_index":"glmapper"},{"id":"13e3061ae0f9c367c54ed2cb6b629b40","title":"SpringSession系列-存储机制之Redis&Map","content":"在之前的文章中已经对SpringSession的功能结构，请求&#x2F;响应重写等做了介绍。本文将继续来介绍下SpringSession中存储部分的设计。存储是分布式session中算是最核心的部分，通过引入三方的存储容器来实现session的存储，从而有效的解决session共享的问题。\n\n\n1、SpringSession存储的顶级抽象接口SpringSession存储的顶级抽象接口是org.springframework.session包下的SessionRepository这个接口。SessionRepository的类图结构如下：\n这里先来看下SessionRepository这个顶层接口中定义了哪些方法：\n12345678910public interface SessionRepository&lt;S extends Session&gt; &#123;    //创建一个session\tS createSession();\t//保存session\tvoid save(S session);\t//通过ID查找session\tS findById(String id);\t//通过ID删除一个session\tvoid deleteById(String id);&#125;\n从代码来看还是很简单的，就是增删查。下面看具体实现。在2.0版本开始SpringSession中也提供了一个和SessionRepository具体相同能力的ReactiveSessionRepository，用于支持响应式编程模式。\n2、MapSessionRepository基于HashMap实现的基于内存存储的存储器实现，这里就主要看下对于接口中几个方法的实现。\n12345public class MapSessionRepository implements SessionRepository&lt;MapSession&gt; &#123;\tprivate Integer defaultMaxInactiveInterval;\tprivate final Map&lt;String, Session&gt; sessions;\t//...&#125;\n可以看到就是一个Map，那后面关于增删查其实就是操作这个Map了。\ncreateSession123456789@Overridepublic MapSession createSession() &#123;\tMapSession result = new MapSession();\tif (this.defaultMaxInactiveInterval != null) &#123;\t\tresult.setMaxInactiveInterval(\t\t\tDuration.ofSeconds(this.defaultMaxInactiveInterval));\t&#125;\treturn result;&#125;\n这里很直接，就是new了一个MapSession，然后设置了session的有效期。\nsave1234567@Overridepublic void save(MapSession session) &#123;\tif (!session.getId().equals(session.getOriginalId())) &#123;\t\tthis.sessions.remove(session.getOriginalId());\t&#125;\tthis.sessions.put(session.getId(), new MapSession(session));&#125;\n这里面先判断了session中的两个ID，一个originalId，一个当前id。originalId是第一次生成session对象时创建的，后面都不会在变化。通过源码来看，对于originalId，只提供了get方法。对于id呢，其实是可以通过changeSessionId来改变的。\n这里的这个操作实际上是一种优化行为，及时的清除掉老的session数据来释放内存空间。\nfindById123456789101112@Overridepublic MapSession findById(String id) &#123;\tSession saved = this.sessions.get(id);\tif (saved == null) &#123;\t\treturn null;\t&#125;\tif (saved.isExpired()) &#123;\t\tdeleteById(saved.getId());\t\treturn null;\t&#125;\treturn new MapSession(saved);&#125;\n这个逻辑也很简单，先从Map中根据id取出session数据，如果没有就返回null，如果有则再判断下是否过期了，如果过期了就删除掉，然后返回null。如果查到了，并且没有过期的话，则构建一个MapSession返回。\nOK，基于内存存储的实现系列就是这些了，下面继续来看其他存储的实现。\n3、FindByIndexNameSessionRepositoryFindByIndexNameSessionRepository继承了SessionRepository接口，用于扩展对第三方存储的实现。\n123456789101112public interface FindByIndexNameSessionRepository&lt;S extends Session&gt;\t\textends SessionRepository&lt;S&gt; &#123;\t\t\tString PRINCIPAL_NAME_INDEX_NAME = FindByIndexNameSessionRepository.class.getName()\t\t\t.concat(&quot;.PRINCIPAL_NAME_INDEX_NAME&quot;);\tMap&lt;String, S&gt; findByIndexNameAndIndexValue(String indexName, String indexValue);\tdefault Map&lt;String, S&gt; findByPrincipalName(String principalName) &#123;\t\treturn findByIndexNameAndIndexValue(PRINCIPAL_NAME_INDEX_NAME, principalName);\t&#125;&#125;\nFindByIndexNameSessionRepository添加一个单独的方法为指定用户查询所有会话。这是通过设置名为FindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME的Session的属性值为指定用户的username来完成的。开发人员有责任确保属性被赋值，因为SpringSession不会在意被使用的认证机制。官方文档中给出的例子如下：\n123String username = &quot;username&quot;;this.session.setAttribute(\tFindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME, username);\nFindByIndexNameSessionRepository的一些实现会提供一些钩子自动的索引其他的session属性。比如，很多实现都会自动的确保当前的Spring Security用户名称可通过索引名称FindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME进行索引。一旦会话被索引，就可以通过下面的代码检索：\n1234String username = &quot;username&quot;;Map&lt;String, Session&gt; sessionIdToSession = \tthis.sessionRepository.findByIndexNameAndIndexValue(\tFindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME,username);\n下图是FindByIndexNameSessionRepository接口的三个实现类：\n下面来分别分析下这三个存储的实现细节。\n3.1 RedisOperationsSessionRepositoryRedisOperationsSessionRepository的类图结构如下，MessageListener是redis消息订阅的监听接口。\n代码有点长，就不在这里面贴了，一些注释可以在这个 SpringSession中文分支 来看。这里还是主要来看下对于那几个方法的实现。\n3.1.1 createSession这里和MapSessionRepository的实现基本一样的，那区别就在于Session的封装模型不一样，这里是RedisSession，实际上RedisSession的实现是对MapSession又包了一层。下面会分析RedisSession这个类。\n12345678910@Overridepublic RedisSession createSession() &#123;     // RedisSession,这里和MapSession区别开\tRedisSession redisSession = new RedisSession();\tif (this.defaultMaxInactiveInterval != null) &#123;\t\tredisSession.setMaxInactiveInterval(\t\t\t\tDuration.ofSeconds(this.defaultMaxInactiveInterval));\t&#125;\treturn redisSession;&#125;\n在看其他两个方法之前，先来看下RedisSession这个类。\n3.1.2 RedisSession这个在模型上是对MapSession的扩展，增加了delta这个东西。\n123456789101112final class RedisSession implements Session &#123;       // MapSession 实例对象，主要存数据的地方\t\tprivate final MapSession cached;\t\t// 原始最后访问时间\t\tprivate Instant originalLastAccessTime;\t\tprivate Map&lt;String, Object&gt; delta = new HashMap&lt;&gt;();\t\t// 是否是新的session对象\t\tprivate boolean isNew;\t\t// 原始主名称\t\tprivate String originalPrincipalName;\t\t// 原始sessionId\t\tprivate String originalSessionId;\ndelta是一个Map结构，那么这里面到底是放什么的呢？具体细节见 saveDelta 这个方法。saveDelta 这个方法会在两个地方被调用，一个是下面要说道的save方法，另外一个是 flushImmediateIfNecessary 这个方法：\n12345private void flushImmediateIfNecessary() &#123;\tif (RedisOperationsSessionRepository.this.redisFlushMode == RedisFlushMode.IMMEDIATE) &#123;\t\tsaveDelta();\t&#125;&#125;\n RedisFlushMode提供了两种推送模式：\n\nON_SAVE：只有在调用save方法时执行，在web环境中这样做通常是尽快提交HTTP响应\nIMMEDIATE：只要有变更就会直接写到redis中，不会像ON_SAVE一样，在最后commit时一次性写入\n\n追踪flushImmediateIfNecessary 方法调用链如下：那么到这里基本就清楚了，首先save这个方法，当主动调用save时就是将数据推到redis中去的，也就是ON_SAVE这种情况。那么对于IMMEDIATE这种情况，只有调用了上面的四个方法，SpringSession 才会将数据推送到redis。\n所以delta里面存的是当前一些变更的 key-val 键值对象，而这些变更是由setAttribute、removeAttribute、setMaxInactiveIntervalInSeconds、setLastAccessedTime这四个方法触发的；比如setAttribute(k,v)，那么这个k-&gt;v就会被保存到delta里面。\n3.1.3 save在理解了saveDelta方法之后再来看save方法就简单多了。save 对应的就是RedisFlushMode.ON_SAVE。\n123456789101112@Overridepublic void save(RedisSession session) &#123;   // 直接调用 saveDelta推数据到redis\tsession.saveDelta();\tif (session.isNew()) &#123;\t   // sessionCreatedKey-&gt;channl\t\tString sessionCreatedKey = getSessionCreatedChannel(session.getId());\t\t// 发布一个消息事件，新增 session，以供 MessageListener 回调处理。\t\tthis.sessionRedisOperations.convertAndSend(sessionCreatedKey, session.delta);\t\tsession.setNew(false);\t&#125;&#125;\n3.1.4 findById查询这部分和基于Map的差别比较大，因为这里并不是直接操作Map，而是与Redis 进行一次交互。\n1234@Overridepublic RedisSession findById(String id) &#123;\treturn getSession(id, false);&#125;\n\n调用getSession方法：\n12345678910111213141516private RedisSession getSession(String id, boolean allowExpired) &#123;\t// 根据ID从redis中取出数据\tMap&lt;Object, Object&gt; entries = getSessionBoundHashOperations(id).entries();\tif (entries.isEmpty()) &#123;\t\treturn null;\t&#125;\t//转换成MapSession\tMapSession loaded = loadSession(id, entries);\tif (!allowExpired &amp;&amp; loaded.isExpired()) &#123;\t\treturn null;\t&#125;\t//转换成RedisSession\tRedisSession result = new RedisSession(loaded);\tresult.originalLastAccessTime = loaded.getLastAccessedTime();\treturn result;&#125;\nloadSession中构建MapSession：\n1234567891011121314151617181920212223242526private MapSession loadSession(String id, Map&lt;Object, Object&gt; entries) &#123;   // 生成MapSession实例\tMapSession loaded = new MapSession(id);\t//遍历数据\tfor (Map.Entry&lt;Object, Object&gt; entry : entries.entrySet()) &#123;\t\tString key = (String) entry.getKey();\t\tif (CREATION_TIME_ATTR.equals(key)) &#123;\t\t    // 设置创建时间\t\t\tloaded.setCreationTime(Instant.ofEpochMilli((long) entry.getValue()));\t\t&#125;\t\telse if (MAX_INACTIVE_ATTR.equals(key)) &#123;\t\t\t // 设置最大有效时间\t\t\tloaded.setMaxInactiveInterval(Duration.ofSeconds((int) entry.getValue()));\t\t&#125;\t\telse if (LAST_ACCESSED_ATTR.equals(key)) &#123;\t\t\t// 设置最后访问时间\t\t\tloaded.setLastAccessedTime(Instant.ofEpochMilli((long) entry.getValue()));\t\t&#125;\t\telse if (key.startsWith(SESSION_ATTR_PREFIX)) &#123;\t\t// 设置属性\t\t\tloaded.setAttribute(key.substring(SESSION_ATTR_PREFIX.length()),\t\t\t\t\tentry.getValue());\t\t&#125;\t&#125;\treturn loaded;&#125;\n3.1.5 deleteById根据sessionId删除session数据。具体过程看代码注释。\n123456789101112131415161718@Overridepublic void deleteById(String sessionId) &#123;   // 获取 RedisSession\tRedisSession session = getSession(sessionId, true);\tif (session == null) &#123;\t\treturn;\t&#125;   // 清楚当前session数据的索引\tcleanupPrincipalIndex(session);\t//执行删除操作\tthis.expirationPolicy.onDelete(session);\tString expireKey = getExpiredKey(session.getId());\t//删除expireKey\tthis.sessionRedisOperations.delete(expireKey);\t//session有效期设置为0\tsession.setMaxInactiveInterval(Duration.ZERO);\tsave(session);&#125;\n3.1.6 onMessage最后来看下这个订阅回调处理。这里看下核心的一段逻辑：\n123456789101112131415boolean isDeleted = channel.equals(this.sessionDeletedChannel);// Deleted 还是 Expired ？if (isDeleted || channel.equals(this.sessionExpiredChannel)) &#123;\t// 此处省略无关代码\t// Deleted\tif (isDeleted) &#123;\t   // 发布一个 SessionDeletedEvent 事件\t\thandleDeleted(session);\t&#125;\t// Expired\telse &#123;\t\t// 发布一个 SessionExpiredEvent 事件\t\thandleExpired(session);\t&#125;&#125;\n3.2 Redis 存储的一些思考首先按照我们自己常规的思路来设计的话，我们会怎么来考虑这个事情。这里首先要声明下，我对 Redis 这个东西不是很熟，没有做过深入的研究；那如果是我来做，可能也就仅仅限于存储。\n\nfindByIndexNameAndIndexValue的设计，这个的作用是通过indexName和indexValue来返回当前用户的所有会话。但是这里需要考虑的一个事情是，通常情况下，一个用户只会关联到一个会话上面去，那这种设计很显然，我的理解是为了支持单用户多会话的场景。\nindexName：FindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME\nindexValue：username\n\n\n实现 MessageListener 接口，增加事件通知能力。通过监听这些事件，可以做一些session操作管控。但是实际上 SpringSession 中并没有做任何事情，从代码来看，publishEvent方法是空实现。等待回复中 #issue 128712345678private ApplicationEventPublisher eventPublisher = new ApplicationEventPublisher() &#123;\t@Override\tpublic void publishEvent(ApplicationEvent event) &#123;\t&#125;\t@Override\tpublic void publishEvent(Object event) &#123;\t&#125;&#125;;\nRedisFlushMode ，SpringSession中提供了两种模式的推送，一种是ON_SAVE，另外一种是IMMEDIATE。默认是ON_SAVE，也就是常规的在请求处理结束时进行一次sessionCommit操作。RedisFlushMode 的设计感觉是为session数据持久化的时机提供了另外一种思路。\n\n小结存储机制设计部分就一基于内存和基于Redis两种来分析；另外基于jdbc和hazelcast有兴趣的同学可以自己查看源码。\n参考\nhttps://blog.csdn.net/zyhlwzy/article/details/78062646\nhttps://docs.spring.io/spring-session/docs/2.0.0.M4/reference/html5/#api\n\n","slug":"spring/spring-session-store-redis","date":"2018-12-10T01:14:11.000Z","categories_index":"spring","tags_index":"session,分布式,redis","author_index":"glmapper"},{"id":"a69e5cb15ae185e57bcc31169f7e2e99","title":"SpringSession系列-sessionId解析和Cookie读写策略","content":"\n\n\n\n\n\n\n\n\n原文：https://blog.csdn.net/sinat_25518349/article/details/85042029\n\n\n\n\n\n\n\n\n\n首先需求在这里说明下，SpringSession的版本迭代的过程中肯定会伴随着一些类的移除和一些类的加入，目前本系列使用的版本是github上对象的master的代码流版本。如果有同学对其他版本中的一些类或者处理有疑惑，欢迎交流。\n本篇将来介绍下SpringSession中两种sessionId解析的策略，这个在之前的文章中其实是有提到过的，这里再拿出来和SpringSession中Cookie相关策略一起学习下。\n\n\nsessionId 解析策略SpringSession中对于sessionId的解析相关的策略是通过HttpSessionIdResolver这个接口来体现的。HttpSessionIdResolver有两个实现类：\n这两个类就分别对应SpringSession解析sessionId的两种不同的实现策略。再深入了解不同策略的实现细节之前，先来看下HttpSessionIdResolver接口定义的一些行为有哪些。\nHttpSessionIdResolverHttpSessionIdResolver定义了sessionId解析策略的契约（Contract）。允许通过请求解析sessionId，并通过响应发送sessionId或终止会话。接口定义如下：\n12345public interface HttpSessionIdResolver &#123;\tList&lt;String&gt; resolveSessionIds(HttpServletRequest request);\tvoid setSessionId(HttpServletRequest request, HttpServletResponse response,String sessionId);\tvoid expireSession(HttpServletRequest request, HttpServletResponse response);&#125;\nHttpSessionIdResolver中有三个方法：\n\nresolveSessionIds：解析与当前请求相关联的sessionId。sessionId可能来自Cookie或请求头。\nsetSessionId：将给定的sessionId发送给客户端。这个方法是在创建一个新session时被调用，并告知客户端新sessionId是什么。\nexpireSession：指示客户端结束当前session。当session无效时调用此方法，并应通知客户端sessionId不再有效。比如，它可能删除一个包含sessionId的Cookie，或者设置一个HTTP响应头，其值为空就表示客户端不再提交sessionId。\n\n下面就针对上面提到的两种策略来进行详细的分析。\n基于Cookie解析sessionId这种策略对应的实现类是CookieHttpSessionIdResolver，通过从Cookie中获取session；具体来说，这个实现将允许使用CookieHttpSessionIdResolver#setCookieSerializer(CookieSerializer)指定Cookie序列化策略。默认的Cookie名称是“SESSION”。创建一个session时，HTTP响应中将会携带一个指定 Cookie name且value是sessionId的Cookie。Cookie 将被标记为一个 session cookie，Cookie 的 domain path 使用 context path，且被标记为HttpOnly，如果HttpServletRequest#isSecure()返回true，那么Cookie将标记为安全的。如下：\n\n\n\n\n\n\n\n\n\n关于Cookie，可以参考：聊一聊session和cookie。\n12HTTP/1.1 200 OKSet-Cookie: SESSION=f81d4fae-7dec-11d0-a765-00a0c91e6bf6; Path=/context-root; Secure; HttpOnly\n这个时候，客户端应该通过在每个请求中指定相同的Cookie来包含session信息。例如：\n123GET /messages/ HTTP/1.1Host: example.comCookie: SESSION=f81d4fae-7dec-11d0-a765-00a0c91e6bf6\n当会话无效时，服务器将发送过期的HTTP响应Cookie，例如:\n12HTTP/1.1 200 OKSet-Cookie: SESSION=f81d4fae-7dec-11d0-a765-00a0c91e6bf6; Expires=Thur, 1 Jan 1970 00:00:00 GMT; Secure; HttpOnly\nCookieHttpSessionIdResolver 类的实现如下：\n1234567891011121314151617181920212223242526272829303132333435363738public final class CookieHttpSessionIdResolver implements HttpSessionIdResolver &#123;\tprivate static final String WRITTEN_SESSION_ID_ATTR = CookieHttpSessionIdResolver.class\t\t\t.getName().concat(&quot;.WRITTEN_SESSION_ID_ATTR&quot;);\t// Cookie序列化策略，默认是 DefaultCookieSerializer\tprivate CookieSerializer cookieSerializer = new DefaultCookieSerializer();\t@Override\tpublic List&lt;String&gt; resolveSessionIds(HttpServletRequest request) &#123;\t\t// 根据提供的cookieSerializer从请求中获取sessionId\t\treturn this.cookieSerializer.readCookieValues(request);\t&#125;\t@Override\tpublic void setSessionId(HttpServletRequest request, HttpServletResponse response,\t\t\tString sessionId) &#123;\t\tif (sessionId.equals(request.getAttribute(WRITTEN_SESSION_ID_ATTR))) &#123;\t\t\treturn;\t\t&#125;\t\trequest.setAttribute(WRITTEN_SESSION_ID_ATTR, sessionId);\t\t// 根据提供的cookieSerializer将sessionId回写到cookie中\t\tthis.cookieSerializer\t\t\t\t.writeCookieValue(new CookieValue(request, response, sessionId));\t&#125;\t@Override\tpublic void expireSession(HttpServletRequest request, HttpServletResponse response) &#123;\t\t// 这里因为是过期，所以回写的sessionId的值是“”，当请求下次进来时，就会取不到sessionId，也就意味着当前会话失效了\t\tthis.cookieSerializer.writeCookieValue(new CookieValue(request, response, &quot;&quot;));\t&#125;     // 指定Cookie序列化的方式\tpublic void setCookieSerializer(CookieSerializer cookieSerializer) &#123;\t\tif (cookieSerializer == null) &#123;\t\t\tthrow new IllegalArgumentException(&quot;cookieSerializer cannot be null&quot;);\t\t&#125;\t\tthis.cookieSerializer = cookieSerializer;\t&#125;&#125;\n这里可以看到CookieHttpSessionIdResolver 中的读取操作都是围绕CookieSerializer来完成的。CookieSerializer 是SpringSession中对于Cookie操作提供的一种机制。下面细说。\n基于请求头解析sessionId这种策略对应的实现类是HeaderHttpSessionIdResolver，通过从请求头header中解析出sessionId。具体地说，这个实现将允许使用HeaderHttpSessionIdResolver(String)来指定头名称。还可以使用便利的工厂方法来创建使用公共头名称(例如“X-Auth-Token”和“authenticing-info”)的实例。创建会话时，HTTP响应将具有指定名称和sessionId值的响应头。\n12345678// 使用X-Auth-Token作为headerNamepublic static HeaderHttpSessionIdResolver xAuthToken() &#123;\treturn new HeaderHttpSessionIdResolver(HEADER_X_AUTH_TOKEN);&#125;// 使用Authentication-Info作为headerNamepublic static HeaderHttpSessionIdResolver authenticationInfo() &#123;\treturn new HeaderHttpSessionIdResolver(HEADER_AUTHENTICATION_INFO);&#125;\nHeaderHttpSessionIdResolver在处理sessionId上相比较于CookieHttpSessionIdResolver来说简单很多。就是围绕request.getHeader(String)和request.setHeader(String,String)两个方法来玩的。\nHeaderHttpSessionIdResolver这种策略通常会在无线端来使用，以弥补对于无Cookie场景的支持。\nCookie 序列化策略基于Cookie解析sessionId的实现类CookieHttpSessionIdResolver 中实际对于Cookie的读写操作都是通过CookieSerializer来完成的。SpringSession 提供了CookieSerializer接口的默认实现DefaultCookieSerializer，当然在实际应用中，我们也可以自己实现这个接口，然后通过CookieHttpSessionIdResolver#setCookieSerializer(CookieSerializer)方法来指定我们自己的实现方式。\n\n\n\n\n\n\n\n\n\nPS：不得不说，强大的用户扩展能力真的是Spring家族的优良家风。\n篇幅有限，这里就只看下两个点：\n\nCookieValue 存在的意义是什么\nDefaultCookieSerializer回写Cookie的的具体实现，读Cookie在 SpringSession系列-请求与响应重写 这篇文章中有介绍过，这里不再赘述。\njvm_router的处理\n\nCookieValueCookieValue是CookieSerializer中的内部类，封装了向HttpServletResponse写入所需的所有信息。其实CookieValue的存在并没有什么特殊的意义，个人觉得作者一开始只是想通过CookieValue的封装来简化回写cookie链路中的参数传递的问题，但是实际上貌似并没有什么减少多少工作量。\nCookie 回写Cookie 回写我觉得对于分布式session的实现来说是必不可少的；基于标准servlet实现的HttpSession，我们在使用时实际上是不用关心回写cookie这个事情的，因为servlet容器都已经做了。但是对于分布式session来说，由于重写了response，所以需要在返回response时需要将当前session信息通过cookie的方式塞到response中返回给客户端-这就是Cookie回写。下面是DefaultCookieSerializer中回写Cookie的逻辑，细节在代码中通过注释标注出来。\n123456789101112131415161718192021222324252627282930313233343536373839404142@Overridepublic void writeCookieValue(CookieValue cookieValue) &#123;\tHttpServletRequest request = cookieValue.getRequest();\tHttpServletResponse response = cookieValue.getResponse();\tStringBuilder sb = new StringBuilder();\tsb.append(this.cookieName).append(&#x27;=&#x27;);\tString value = getValue(cookieValue);\tif (value != null &amp;&amp; value.length() &gt; 0) &#123;\t\tvalidateValue(value);\t\tsb.append(value);\t&#125;\tint maxAge = getMaxAge(cookieValue);\tif (maxAge &gt; -1) &#123;\t\tsb.append(&quot;; Max-Age=&quot;).append(cookieValue.getCookieMaxAge());\t\tOffsetDateTime expires = (maxAge != 0)\t\t\t\t? OffsetDateTime.now().plusSeconds(maxAge)\t\t\t\t: Instant.EPOCH.atOffset(ZoneOffset.UTC);\t\tsb.append(&quot;; Expires=&quot;)\t\t\t\t.append(expires.format(DateTimeFormatter.RFC_1123_DATE_TIME));\t&#125;\tString domain = getDomainName(request);\tif (domain != null &amp;&amp; domain.length() &gt; 0) &#123;\t\tvalidateDomain(domain);\t\tsb.append(&quot;; Domain=&quot;).append(domain);\t&#125;\tString path = getCookiePath(request);\tif (path != null &amp;&amp; path.length() &gt; 0) &#123;\t\tvalidatePath(path);\t\tsb.append(&quot;; Path=&quot;).append(path);\t&#125;\tif (isSecureCookie(request)) &#123;\t\tsb.append(&quot;; Secure&quot;);\t&#125;\tif (this.useHttpOnlyCookie) &#123;\t\tsb.append(&quot;; HttpOnly&quot;);\t&#125;\tif (this.sameSite != null) &#123;\t\tsb.append(&quot;; SameSite=&quot;).append(this.sameSite);\t&#125;\tresponse.addHeader(&quot;Set-Cookie&quot;, sb.toString());&#125;\n这上面就是拼凑字符串，然后塞到Header里面去，最终再浏览器中显示大体如下：\n1Set-Cookie: SESSION=f81d4fae-7dec-11d0-a765-00a0c91e6bf6; Path=/context-root; Secure; HttpOnly\n\njvm_router的处理在Cookie的读写代码中都涉及到对于jvmRoute这个属性的判断及对应的处理逻辑。\n1、读取Cookie中的代码片段\n123if (this.jvmRoute != null &amp;&amp; sessionId.endsWith(this.jvmRoute)) &#123;\tsessionId = sessionId.substring(0,sessionId.length() - this.jvmRoute.length());&#125;\n2、回写Cookie中的代码片段\n123if (this.jvmRoute != null) &#123;\tactualCookieValue = requestedCookieValue + this.jvmRoute;&#125;\njvm_route是Nginx中的一个模块，其作用是通过session cookie的方式来获取session粘性。如果在cookie和url中并没有session，则这只是个简单的 round-robin 负载均衡。其具体过程分为以下几步：\n\n1.第一个请求过来，没有带session信息，jvm_route就根据round robin策略发到一台tomcat上面。\n2.tomcat添加上 session 信息，并返回给客户。\n3.用户再次请求，jvm_route看到session中有后端服务器的名称，它就把请求转到对应的服务器上。\n\n从本质上来说，jvm_route也是解决session共享的一种解决方式。这种和 SpringSession系列-分布式Session实现方案 中提到的基于IP-HASH的方式有点类似。那么同样，这里存在的问题是无法解决宕机后session数据转移的问题，既宕机就丢失。\nDefaultCookieSerializer 中除了Cookie的读写之后，还有一些细节也值得关注下，比如对Cookie中值的验证、remember-me的实现等。\n参考\nSpringSession官方文档\njvm_router原理\nSpringSession中文注释持续更新代码分支\n\n","slug":"spring/spring-session-id-resolver","date":"2018-12-10T01:13:31.000Z","categories_index":"spring","tags_index":"session,分布式,redis","author_index":"glmapper"},{"id":"0b1e2bd1c4a4b8d7f121fe03a5fb0ef3","title":"SOFATracer 插件埋点机制详解","content":"\n\n\n\n\n\n\n\n\nSOFATracer 是一个用于分布式系统调用跟踪的组件，通过统一的 traceId 将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的。这些日志可用于故障的快速发现，服务治理等。\n从 RoadMap 和 PR 来看，目前 SOFATracer 已经支持了丰富的组件插件埋点。\n\n\n\n目前还未支持的主要是 Dubbo、MQ 以及 Redis 等。本文将从 SOFATracer 已提供的一个插件源码来分析下 SOFATracer 插件的埋点实现。\n1 SOFATracer 插件埋点机制SOFATracer 插件的作用实际上就是对于不同组件进行埋点，以便于收集这些组件的链路数据。SOFATracer 埋点方式一般是通过 Filter、Interceptor 机制实现的。\n另一个是，SOFATracer 的埋点方式并不是基于 OT-api 进行埋点的，而是基于 SOFATracer 自己的 api 进行埋点的，详见 issue#126。\n1.1 Filter or Interceptor目前已实现的插件中，像 MVC 插件是基于 Filter 进行埋点的，httpclient、resttemplate 等是基于Interceptor进行埋点的。在实现插件时，要根据不同插件的特性来选择具体的埋点方式。\n 当然除了这两种方式之外还可以通过静态代理的方式来实现埋点。比如 sofa-tracer-datasource-plugin 插件就是将不同的数据源进行统一代理给 SmartDatasource，从而实现埋点的。\n1.2 AbstractTracer APISOFATracer 中所有的插件均需要实现自己的 Tracer 实例，如 Mvc 的 SpringMvcTracer 、HttpClient的 HttpClientTracer 等，这一点与基于 Opentracing-api 接口埋点的实现有所区别。\n\n1、基于 SOFATracer api 埋点方式插件扩展\n\n\nAbstractTracer 是 SOFATracer 用于插件扩展使用的一个抽象类，根据插件类型不同，又可以分为 clientTracer 和 serverTracer，分别对应于：AbstractClientTracer 和 AbstractServerTracer，再通过 AbstractClientTracer 和 AbstractServerTracer 衍生出具体的组件 Tracer 实现。这种方式的好处在于，所有的插件实现均由 SOFATracer 本身来管控，对于不同的组件可以轻松的实现差异化和定制化。缺点也源于此，每增加一个组件都需要做一些重复工作。\n\n2、基于 OpenTracing-api 埋点方式插件扩展\n\n\n这种埋点方式不基于 SOFATracer  自身提供的 API，而是基于 OpenTracing-api 接口。因为均遵循 OpenTracing-api 规范，所以组件和 Tracer 实现可以独立分开来维护。这样就可以对接开源的一些基于 OpenTracing-api 规范实现的组件。例如：OpenTracing API Contributions。\nSOFATracer 在后面将会在 4.0 版本中支持基于 OT-api 的埋点方式，对外部组件接入扩展提供支持。\n1.3 AbstractTracer这里先来看下 AbstractTracer  这个抽象类中具体提供了哪些抽象方法，也就是对于 AbstractClientTracer 和 AbstractServerTracer 需要分别扩展哪些能力。\n123456789101112131415161718192021// 获取client端 摘要日志日志名protected abstract String getClientDigestReporterLogName();// 获取client端 摘要日志滚动策略keyprotected abstract String getClientDigestReporterRollingKey();// 获取client端 摘要日志日志名keyprotected abstract String getClientDigestReporterLogNameKey();// 获取client端 摘要日志编码器protected abstract SpanEncoder&lt;SofaTracerSpan&gt; getClientDigestEncoder();// 创建client端 统计日志Reporter类protected abstract AbstractSofaTracerStatisticReporter generateClientStatReporter();// 获取server端 摘要日志日志名protected abstract String getServerDigestReporterLogName();// 获取server端 摘要日志滚动策略keyprotected abstract String getServerDigestReporterRollingKey();// 获取server端 摘要日志日志名keyprotected abstract String getServerDigestReporterLogNameKey();// 获取server端 摘要日志编码器protected abstract SpanEncoder&lt;SofaTracerSpan&gt; getServerDigestEncoder();// 创建server端 统计日志Reporter类protected abstract AbstractSofaTracerStatisticReporter generateServerStatReporter();\n\n\n\n从  AbstractTracer 类提供的抽象方法来看，不管是 client 还是 server，在具体的 Tracer 组件实现中，都必须提供以下实现：\n\nDigestReporterLogName :当前组件摘要日志的日志名称\nDigestReporterRollingKey : 当前组件摘要日志的滚动策略\nSpanEncoder：对摘要日志进行编码的编码器实现\nAbstractSofaTracerStatisticReporter : 统计日志 reporter 类的实现类。\n\n2 SpringMVC 插件埋点分析这里我们以 SpringMVC 插件为例，来分析下如何实现一个埋点插件的。这里是官方给出的案例工程：基于 Spring MVC 示例落地日志 。\n2.1 实现 Tracer 实例SpringMvcTracer 继承了 AbstractServerTracer 类，是对 serverTracer 的扩展。\n\n\n\n\n\n\n\n\n\nPS：如何确定一个组件是client端还是server端呢？就是看当前组件是请求的发起方还是请求的接受方，如果是请求发起方则一般是client端，如果是请求接收方则是 server 端。那么对于 MVC 来说，是请求接受方，因此这里实现了 AbstractServerTracer 类。\n1public class SpringMvcTracer extends AbstractServerTracer\n\n\n\n2.1.1 构造函数与单例对象在构造函数中，需要传入当前 Tracer 的 traceType，SpringMvcTracer 的 traceType 为 “springmvc”。这里也可以看到，tracer 实例是一个单例对象，对于其他插件也是一样的。\n12345678910111213141516171819private volatile static SpringMvcTracer springMvcTracer = null;/*** * Spring MVC Tracer Singleton * @return singleton */public static SpringMvcTracer getSpringMvcTracerSingleton() &#123;    if (springMvcTracer == null) &#123;        synchronized (SpringMvcTracer.class) &#123;            if (springMvcTracer == null) &#123;                springMvcTracer = new SpringMvcTracer();            &#125;        &#125;    &#125;    return springMvcTracer;&#125;private SpringMvcTracer() &#123;    super(&quot;springmvc&quot;);&#125;\n\n2.1.2 AbstractServerTracer 抽象类在看 SpringMvcTracer 实现之前，先来看下 AbstractServerTracer。\n1234567891011121314151617181920212223public abstract class AbstractServerTracer extends AbstractTracer &#123;    // 构造函数，子类必须提供一个构造函数    public AbstractServerTracer(String tracerType) &#123;        super(tracerType, false, true);    &#125;    // 因为是server端，所以Client先关的提供了默认实现，返回null    protected String getClientDigestReporterLogName() &#123;        return null;    &#125;    protected String getClientDigestReporterRollingKey() &#123;        return null;    &#125;    protected String getClientDigestReporterLogNameKey() &#123;        return null;    &#125;    protected SpanEncoder&lt;SofaTracerSpan&gt; getClientDigestEncoder() &#123;        return null;    &#125;    protected AbstractSofaTracerStatisticReporter generateClientStatReporter() &#123;        return null;    &#125;&#125;\n\n结合上面  AbstractTracer 小节中抽象方法分析，这里在 AbstractServerTracer 中将 client 对应的抽象方法提供了默认实现，也就是说如果要继承 AbstractServerTracer 类，那么就必须实现 server 对应的所有抽象方法。\n2.1.3 SpringMVCTracer 实现下面是 SpringMvcTracer 部分对 server 部分抽象方法的实现。\n1234567891011121314151617181920212223242526272829@Overrideprotected String getServerDigestReporterLogName() &#123;    return SpringMvcLogEnum.SPRING_MVC_DIGEST.getDefaultLogName();&#125;@Overrideprotected String getServerDigestReporterRollingKey() &#123;    return SpringMvcLogEnum.SPRING_MVC_DIGEST.getRollingKey();&#125;@Overrideprotected String getServerDigestReporterLogNameKey() &#123;    return SpringMvcLogEnum.SPRING_MVC_DIGEST.getLogNameKey();&#125;@Overrideprotected SpanEncoder&lt;SofaTracerSpan&gt; getServerDigestEncoder() &#123;    if (Boolean.TRUE.toString().equalsIgnoreCase(        SofaTracerConfiguration.getProperty(SPRING_MVC_JSON_FORMAT_OUTPUT))) &#123;        return new SpringMvcDigestJsonEncoder();    &#125; else &#123;        return new SpringMvcDigestEncoder();    &#125;&#125;@Overrideprotected AbstractSofaTracerStatisticReporter generateServerStatReporter() &#123;    return generateSofaMvcStatReporter();&#125;\n\n目前 SOFATracer 日志名、滚动策略key等都是通过枚举类来定义的，也就是一个组件会对应这样一个枚举类，在枚举类里面定义这些常量。\n2.2 SpringMvcLogEnum 类实现SpringMVC 插件中的枚举类是 SpringMvcLogEnum。\n12345678910111213public enum SpringMvcLogEnum &#123;    // 摘要日志相关    SPRING_MVC_DIGEST(&quot;spring_mvc_digest_log_name&quot;,                       &quot;spring-mvc-digest.log&quot;,                      &quot;spring_mvc_digest_rolling&quot;),     // 统计日志相关    SPRING_MVC_STAT(&quot;spring_mvc_stat_log_name&quot;,                     &quot;spring-mvc-stat.log&quot;,                     &quot;spring_mvc_stat_rolling&quot;);    // 省略部分代码....&#125;\n\n在 XXXLogEnum 枚举类中定义了当前组件对应的摘要日志和统计日志的日志名和滚动策略，因为 SOFATracer 目前还没有服务端的能力，链路数据不是直接上报给 server 的，因此 SOFATracer 提供了落到磁盘的能力。不同插件的链路日志也会通过 XXXLogEnum 指定的名称将链路日志输出到各个组件对应的日志目录下。\n2.3 统计日志 Reportor 实现SOFATracer 中统计日志打印的实现需要各个组件自己来完成，具体就是需要实现一个AbstractSofaTracerStatisticReporter 的子类，然后实现 doReportStat 这个方法。当然对于目前的实现来说，我们也会重写 print 方法。\n2.3.1 doReportStat123456789101112131415161718192021222324252627@Overridepublic void doReportStat(SofaTracerSpan sofaTracerSpan) &#123;    Map&lt;String, String&gt; tagsWithStr = sofaTracerSpan.getTagsWithStr();    // 构建StatMapKey对象    StatMapKey statKey = new StatMapKey();    // 增加 key:当前应用名    statKey.addKey(CommonSpanTags.LOCAL_APP, tagsWithStr.get(CommonSpanTags.LOCAL_APP));    // 增加 key:请求 url    statKey.addKey(CommonSpanTags.REQUEST_URL, tagsWithStr.get(CommonSpanTags.REQUEST_URL));    // 增加 key:请求方法    statKey.addKey(CommonSpanTags.METHOD, tagsWithStr.get(CommonSpanTags.METHOD));    // 压测标志    statKey.setLoadTest(TracerUtils.isLoadTest(sofaTracerSpan));    // 请求响应码    String resultCode = tagsWithStr.get(CommonSpanTags.RESULT_CODE);    // 请求成功标识    boolean success = (resultCode != null &amp;&amp; resultCode.length() &gt; 0 &amp;&amp; this        .isHttpOrMvcSuccess(resultCode));    statKey.setResult(success ? &quot;true&quot; : &quot;false&quot;);    //end    statKey.setEnd(TracerUtils.getLoadTestMark(sofaTracerSpan));    //value the count and duration    long duration = sofaTracerSpan.getEndTime() - sofaTracerSpan.getStartTime();    long values[] = new long[] &#123; 1, duration &#125;;    // reserve    this.addStat(statKey, values);&#125;\n\n 这里就是就是将统计日志添加到日志槽里，等待被消费(输出到日志)。具体可以参考：SofaTracerStatisticReporterManager.StatReporterPrinter。\n2.3.2 printprint 方法是实际将数据写入到磁盘的方法。\n1234567891011121314151617181920212223242526272829303132333435@Overridepublic void print(StatKey statKey, long[] values) &#123;    if (this.isClosePrint.get()) &#123;        //关闭统计日志输出        return;    &#125;    if (!(statKey instanceof StatMapKey)) &#123;        return;    &#125;    StatMapKey statMapKey = (StatMapKey) statKey;    try &#123;        // 构建需要打印的数据串        jsonBuffer.reset();        jsonBuffer.appendBegin();        jsonBuffer.append(&quot;time&quot;, Timestamp.currentTime());        jsonBuffer.append(&quot;stat.key&quot;, this.statKeySplit(statMapKey));        jsonBuffer.append(&quot;count&quot;, values[0]);        jsonBuffer.append(&quot;total.cost.milliseconds&quot;, values[1]);        jsonBuffer.append(&quot;success&quot;, statMapKey.getResult());        //压测        jsonBuffer.appendEnd(&quot;load.test&quot;, statMapKey.getEnd());        if (appender instanceof LoadTestAwareAppender) &#123;            ((LoadTestAwareAppender) appender).append(jsonBuffer.toString(),                statMapKey.isLoadTest());        &#125; else &#123;            appender.append(jsonBuffer.toString());        &#125;        // 这里强制刷一次        appender.flush();    &#125; catch (Throwable t) &#123;        SelfLog.error(&quot;统计日志&lt;&quot; + statTracerName + &quot;&gt;输出异常&quot;, t);    &#125;&#125;\n\nprint 这个方法里面就是将 statMapKey 中，也就是 doReportStat 中塞进来的数据转换成  json 格式，然后刷到磁盘。需要注意的是这里是强制 flush 了一次。如果没有重写 print 这个方法的话，则是在SofaTracerStatisticReporterManager.StatReporterPrinter 里面调用 print 方法刷到磁盘。\n2.4 数据传播格式实现SOFATracer 支持使用 OpenTracing 的内建格式进行上下文传播。\n1234567891011121314151617public class SpringMvcHeadersCarrier implements TextMap &#123;    private HashMap&lt;String, String&gt; headers;    public SpringMvcHeadersCarrier(HashMap&lt;String, String&gt; headers) &#123;        this.headers = headers;    &#125;    @Override    public void put(String key, String value) &#123;        headers.put(key, value);    &#125;    @Override    public Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator() &#123;        return headers.entrySet().iterator();    &#125;&#125;\n\n2.5 自定义编码格式实现这个决定了摘要日志打印的格式，和在统计日志里面的实现要有所区分。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class SpringMvcDigestJsonEncoder extends AbstractDigestSpanEncoder &#123;    // 重写encode,对span进行编码处理    @Override    public String encode(SofaTracerSpan span) throws IOException &#123;        JsonStringBuilder jsonStringBuilder = new JsonStringBuilder();        //日志打印时间        jsonStringBuilder.appendBegin(&quot;time&quot;, Timestamp.format(span.getEndTime()));        appendSlot(jsonStringBuilder, span);        return jsonStringBuilder.toString();    &#125;    // 具体字段处理    private void appendSlot(JsonStringBuilder jsonStringBuilder, SofaTracerSpan sofaTracerSpan) &#123;            SofaTracerSpanContext context = sofaTracerSpan.getSofaTracerSpanContext();        Map&lt;String, String&gt; tagWithStr = sofaTracerSpan.getTagsWithStr();        Map&lt;String, Number&gt; tagWithNumber = sofaTracerSpan.getTagsWithNumber();        //当前应用名        jsonStringBuilder            .append(CommonSpanTags.LOCAL_APP, tagWithStr.get(CommonSpanTags.LOCAL_APP));        //TraceId        jsonStringBuilder.append(&quot;traceId&quot;, context.getTraceId());        //RpcId        jsonStringBuilder.append(&quot;spanId&quot;, context.getSpanId());        //请求 URL        jsonStringBuilder.append(CommonSpanTags.REQUEST_URL,            tagWithStr.get(CommonSpanTags.REQUEST_URL));        //请求方法        jsonStringBuilder.append(CommonSpanTags.METHOD, tagWithStr.get(CommonSpanTags.METHOD));        //Http 状态码        jsonStringBuilder.append(CommonSpanTags.RESULT_CODE,            tagWithStr.get(CommonSpanTags.RESULT_CODE));        Number requestSize = tagWithNumber.get(CommonSpanTags.REQ_SIZE);        //Request Body 大小 单位为byte        jsonStringBuilder.append(CommonSpanTags.REQ_SIZE,            (requestSize == null ? 0L : requestSize.longValue()));        Number responseSize = tagWithNumber.get(CommonSpanTags.RESP_SIZE);        //Response Body 大小，单位为byte        jsonStringBuilder.append(CommonSpanTags.RESP_SIZE, (responseSize == null ? 0L            : responseSize.longValue()));        //请求耗时（MS）        jsonStringBuilder.append(&quot;time.cost.milliseconds&quot;,            (sofaTracerSpan.getEndTime() - sofaTracerSpan.getStartTime()));        jsonStringBuilder.append(CommonSpanTags.CURRENT_THREAD_NAME,            tagWithStr.get(CommonSpanTags.CURRENT_THREAD_NAME));        //穿透数据放在最后        jsonStringBuilder.appendEnd(&quot;baggage&quot;, baggageSerialized(context));    &#125;&#125;\n\n从这里其实也可以看出，统计日志和摘要日志的不同点。统计日志里面核心的数据是 span 里面的 tags 数据，但是其主要作用是统计当前组件的次数。摘要日志里面除了 tags 里面的数据之外还会包括例如 traceId 和 spanId 等信息。\n\n统计日志\n\n1&#123;&quot;time&quot;:&quot;2018-11-28 14:42:25.127&quot;,&quot;stat.key&quot;:&#123;&quot;method&quot;:&quot;GET&quot;,&quot;local.app&quot;:&quot;SOFATracerSpringMVC&quot;,&quot;request.url&quot;:&quot;http://localhost:8080/springmvc&quot;&#125;,&quot;count&quot;:3,&quot;total.cost.milliseconds&quot;:86,&quot;success&quot;:&quot;true&quot;,&quot;load.test&quot;:&quot;F&quot;&#125;\n\n\n摘要日志\n\n1&#123;&quot;time&quot;:&quot;2018-11-28 14:46:08.216&quot;,&quot;local.app&quot;:&quot;SOFATracerSpringMVC&quot;,&quot;traceId&quot;:&quot;0a0fe91b1543387568214100259231&quot;,&quot;spanId&quot;:&quot;0.1&quot;,&quot;request.url&quot;:&quot;http://localhost:8080/springmvc&quot;,&quot;method&quot;:&quot;GET&quot;,&quot;result.code&quot;:&quot;200&quot;,&quot;req.size.bytes&quot;:-1,&quot;resp.size.bytes&quot;:0,&quot;time.cost.milliseconds&quot;:2,&quot;current.thread.name&quot;:&quot;http-nio-8080-exec-2&quot;,&quot;baggage&quot;:&quot;&quot;&#125;\n\n\n\n2.6 请求拦截埋点对于基于标准 servlet 实现的组件，要实现对请求的拦截过滤，通常就是 Filter 了。sofa-tracer-springmvc-plugin 插件埋点的实现就是基于 Filter 机制完成的。\nSpringMvcSofaTracerFilter 实现了 javax.servlet.Filter 接口，因此遵循标准的 servlet 规范的容器也可以通过此插件进行埋点。参考文档：对于标准 servlet 容器的支持（ tomcat&#x2F;jetty 等）。\n1public class SpringMvcSofaTracerFilter implements Filter\n\n2.6.1 基本埋点思路对于一个组件来说，一次处理过程一般是产生一个 span。这个span的生命周期是从接收到请求到返回响应这段过程。\n但是这里需要考虑的问题是如何与上下游链路关联起来呢？在 Opentracing 规范中，可以在 Tracer 中 extract 出一个跨进程传递的 SpanContext 。然后通过这个 SpanContext 所携带的信息将当前节点关联到整个 tracer 链路中去。当然有提取(extract)就会有对应的注入(inject)。\n链路的构建一般是 client-server-client-server 这种模式的，那这里就很清楚了，就是会在 client 端进行注入(inject)，然后再 server 端进行提取(extract)，反复进行，然后一直传递下去。\n 在拿到 SpanContext 之后，此时当前的 span 就可以关联到这条链路中了，那么剩余的事情就是收集当前组件的一些数据。\n整个过程大概分为以下几个阶段：\n\n从请求中提取 spanContext\n构建 span，并将当前 span 存入当前 tracer上下文中（SofaTraceContext.push(span)） 。\n设置一些信息到span中\n返回响应\nspan结束&amp;上报\n\n下面逐一分析下这几个过程。\n2.6.2 从请求中提取 spanContext这里的提取用到了上面我们提到的#数据传播格式实现#SpringMvcHeadersCarrier 这个类。上面分析到，因为mvc 做作为 server 端存在的，所以在 server 端就是从请求中 extract 出 SpanContext。\n1234567891011121314151617public SofaTracerSpanContext getSpanContextFromRequest(HttpServletRequest request) &#123;    HashMap&lt;String, String&gt; headers = new HashMap&lt;String, String&gt;();    // 获取请求头信息     Enumeration headerNames = request.getHeaderNames();    while (headerNames.hasMoreElements()) &#123;        String key = (String) headerNames.nextElement();        String value = request.getHeader(key);        headers.put(key, value);    &#125;    // 拿到 SofaTracer 实例对象    SofaTracer tracer = springMvcTracer.getSofaTracer();    // 解析出 SofaTracerSpanContext（SpanContext的实现类）    SofaTracerSpanContext spanContext = (SofaTracerSpanContext) tracer.extract(        ExtendFormat.Builtin.B3_HTTP_HEADERS, new SpringMvcHeadersCarrier(headers));    spanContext.setSpanId(spanContext.nextChildContextId());    return spanContext;&#125;\n\n2.6.3 获取 span &amp; 数据获取serverReceive 这个方法是在 AbstractTracer 类中提供了实现，子类不需要关注这个。在 SOFATracer 中将请求大致分为以下几个过程：\n\n客户端发送请求  clientSend      cs\n服务端接受请求  serverReceive sr\n服务端返回结果  serverSend     ss\n客户端接受结果  clientReceive  cr\n\n无论是哪个插件，在请求处理周期内都可以从上述几个阶段中找到对应的处理方法。因此，SOFATracer 对这几个阶段处理进行了封装。这四个阶段实际上会产生两个 span，第一个 span 的起点是 cs，到 cr 结束；第二个 span是从 sr 开始，到 ss 结束。也就是说当执行 clientSend 和 serverReceive 时会返回一个 span 对象。来看下MVC中的实现：\n\n红色框内对应的服务端接受请求，也就是 sr 阶段，产生了一个 span 。红色框下面的这段代码是为当前这个 span 设置一些基本的信息，包括当前应用的应用名、当前请求的url、当前请求的请求方法以及请求大小。\n2.6.4 返回响应与结束 span在 filter 链执行结束之后，在 finally 块中又补充了当前请求响应结果的一些信息到 span 中去。然后调用serverSend 结束当前 span。这里关于 serverSend 里面的逻辑就不展开说了，不过能够想到的是这里肯定是调用span.finish 这个方法( opentracing 规范中，span.finish 的执行标志着一个 span 的结束)，当前也会包括对于数据上报的一些逻辑处理等。\n\n3 思路总结与插件编写流程在第2节中以 SpringMVC 插件为例，分析了下  SOFATracer 插件埋点实现的一些细节。那么本节则从整体思路上来总结下如何编写一个 SOFATracer 的插件。\n\n1、确定所要实现的插件，然后确定以哪种方式来埋点\n2、实现当前插件的 Tracer 实例，这里需要明确当前插件是以 client 存在还是以 server 存在。\n3、实现一个枚举类，用来描述当前组件的日志名称和滚动策略 key 值等\n4、实现插件摘要日志的 encoder ，实现当前组件的定制化输出\n5、实现插件的统计日志 Reporter 实现类，通过继承 AbstractSofaTracerStatisticReporter 类并重写doReportStat。\n6、定义当前插件的传播格式\n\n 当然最重要的还是对于要实现插件的理解，要明确我们需要收集哪些数据。\n小结本文先介绍了SOFATracer的埋点方式与标准OT-api 埋点方式的区别，然后对 SOFATracer 中 SpringMVC 插件的埋点实现进行了分析。希望通过本文能够让更多的同学理解埋点实现这样一个过程以及需要关注的一些点。如果有兴趣或者有什么实际的需求，欢迎来讨论。\n","slug":"sofa/sofa-tracer-mvc-plugin","date":"2018-12-07T11:09:56.000Z","categories_index":"SOFA","tags_index":"分布式链路跟踪,Tracer,spring mvc","author_index":"glmapper"},{"id":"1e1a697103974a7aac0ac3d3d33e9f33","title":"SOFABoot 健康检查能力分析","content":"Liveness Check &amp;  Readiness CheckSpring Boot 提供了一个基础的健康检查的能力，中间件和应用都可以扩展来实现自己的健康检查逻辑。但是 Spring Boot 的健康检查只有 Liveness Check 的能力，缺少 Readiness Check 的能力，这样会有比较致命的问题。当一个微服务应用启动的时候，必须要先保证启动后应用是健康的，才可以将上游的流量放进来（来自于 RPC，网关，定时任务等等流量），否则就可能会导致一定时间内大量的错误发生。\n\n\n针对 Spring Boot 缺少 Readiness Check 能力的情况，SOFABoot 增加了 Spring Boot 现有的健康检查的能力，提供了 Readiness Check 的能力。利用 Readiness Check 的能力，SOFA 中间件中的各个组件只有在 Readiness Check 通过之后，才将流量引入到应用的实例中，比如 RPC，只有在 Readiness Check 通过之后，才会向服务注册中心注册，后面来自上游应用的流量才会进入。\n除了中间件可以利用 Readiness Check 的事件来控制流量的进入之外，PAAS 系统也可以通过访问 http://localhost:8080/actuator/readiness 来获取应用的 Readiness Check 的状况，用来控制例如负载均衡设备等等流量的进入。\n使用方式SOFABoot 的健康检查能力需要引入：\n1234&lt;dependency&gt;    &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt;    &lt;artifactId&gt;healthcheck-sofa-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;\n\n区别于SpringBoot的：\n1234&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;\n\n\n\n\n\n\n\n\n\n\n详细工程科参考：sofa-boot\n健康检查启动日志\n代码分析既然是个Starter，那么就先从 spring.factories 文件来看：\n12345org.springframework.context.ApplicationContextInitializer=\\com.alipay.sofa.healthcheck.initializer.SofaBootHealthCheckInitializerorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\com.alipay.sofa.healthcheck.configuration.SofaBootHealthCheckAutoConfiguration\n\nSofaBootHealthCheckInitializerSofaBootHealthCheckInitializer 实现了 ApplicationContextInitializer 接口。\nApplicationContextInitializer 是 Spring 框架原有的概念，这个类的主要目的就是在            ConfigurableApplicationContext 类型（或者子类型）的 ApplicationContext 做 refresh 之前，允许我们                   对 ConfigurableApplicationContext 的实例做进一步的设置或者处理。\n123456789101112131415public class SofaBootHealthCheckInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123;    @Override    public void initialize(ConfigurableApplicationContext applicationContext) &#123;        Environment environment = applicationContext.getEnvironment();        if (SOFABootEnvUtils.isSpringCloudBootstrapEnvironment(environment)) &#123;            return;        &#125;        // init logging.level.com.alipay.sofa.runtime argument        String healthCheckLogLevelKey = Constants.LOG_LEVEL_PREFIX                                        + HealthCheckConstants.SOFABOOT_HEALTH_LOG_SPACE;        SofaBootLogSpaceIsolationInit.initSofaBootLogger(environment, healthCheckLogLevelKey);      SofaBootHealthCheckLoggerFactory.getLogger(SofaBootHealthCheckInitializer.class).info(            &quot;SOFABoot HealthCheck Starting!&quot;);    &#125;&#125;\n\nSofaBootHealthCheckInitializer 在 initialize 方法中主要做了两件事：\n\n验证当前 environment 是否是 SpringCloud 的（3.0.0 开始支持 springCloud，之前版本无此 check）\n初始化 logging.level\n\n这两件事和健康检查没有什么关系，但是既然放在这个模块里面还是来看下。\n1、springCloud 环境验证首先就是为什么会有这个验证。SOFABoot 在支持 SpringcLoud 时遇到一个问题，就是当在 classpath 中添加spring-cloud-context 依赖关系时,org.springframework.context.ApplicationContextInitializer会被调用两次。具体背景可参考 # issue1151  &amp;&amp; # issue 232\n1234567891011121314private final static String SPRING_CLOUD_MARK_NAME = &quot;org.springframework.cloud.bootstrap.BootstrapConfiguration&quot;;public static boolean isSpringCloudBootstrapEnvironment(Environment environment) &#123;    if (environment instanceof ConfigurableEnvironment) &#123;        return !((ConfigurableEnvironment) environment).getPropertySources().contains(            SofaBootInfraConstants.SOFA_BOOTSTRAP)               &amp;&amp; isSpringCloud();    &#125;    return false;&#125;public static boolean isSpringCloud() &#123;    return ClassUtils.isPresent(SPRING_CLOUD_MARK_NAME, null);&#125;\n\n上面这段代码是 SOFABoot 提供的一个用于区分 引导上下文  和 应用上下文 的方法：\n\n检验是否有&quot;org.springframework.cloud.bootstrap.BootstrapConfiguration&quot;这个类来判断当前是否引入了spingCloud的引导配置类\n从environment 中获取 MutablePropertySources 实例，验证 MutablePropertySources 中是否包括 sofaBootstrap （ 如果当前环境是 SOFA bootstrap environment，则包含 sofaBootstrap；这个是在 SofaBootstrapRunListener 回调方法中设置进行的 ）\n\n2、初始化 logging.level这里是处理 SOFABoot 日志空间隔离的。\n1234567891011121314151617181920public static void initSofaBootLogger(Environment environment, String runtimeLogLevelKey) &#123;    // 初始化 logging.path 参数    String loggingPath = environment.getProperty(Constants.LOG_PATH);    if (!StringUtils.isEmpty(loggingPath)) &#123;        System.setProperty(Constants.LOG_PATH, environment.getProperty(Constants.LOG_PATH));        ReportUtil.report(&quot;Actual &quot; + Constants.LOG_PATH + &quot; is [ &quot; + loggingPath + &quot; ]&quot;);    &#125;    //for example : init logging.level.com.alipay.sofa.runtime argument    String runtimeLogLevelValue = environment.getProperty(runtimeLogLevelKey);    if (runtimeLogLevelValue != null) &#123;        System.setProperty(runtimeLogLevelKey, runtimeLogLevelValue);    &#125;    // init file.encoding    String fileEncoding = environment.getProperty(Constants.LOG_ENCODING_PROP_KEY);    if (!StringUtils.isEmpty(fileEncoding)) &#123;        System.setProperty(Constants.LOG_ENCODING_PROP_KEY, fileEncoding);    &#125;&#125;\n\nSofaBootHealthCheckAutoConfiguration这个类是 SOFABoot 健康检查机制的自动化配置实现。\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configurationpublic class SofaBootHealthCheckAutoConfiguration &#123;    /** ReadinessCheckListener: 容器刷新之后回调 */    @Bean    public ReadinessCheckListener readinessCheckListener() &#123;        return new ReadinessCheckListener();    &#125;    /** HealthCheckerProcessor: HealthChecker处理器 */    @Bean    public HealthCheckerProcessor healthCheckerProcessor() &#123;        return new HealthCheckerProcessor();    &#125;    /** HealthCheckerProcessor: HealthIndicator处理器 */    @Bean    public HealthIndicatorProcessor healthIndicatorProcessor() &#123;        return new HealthIndicatorProcessor();    &#125;    /** AfterReadinessCheckCallbackProcessor: ReadinessCheck之后的回调处理器 */    @Bean    public AfterReadinessCheckCallbackProcessor afterReadinessCheckCallbackProcessor() &#123;        return new AfterReadinessCheckCallbackProcessor();    &#125;    /** 返回 SofaBoot健康检查指标类 实例*/    @Bean    public SofaBootHealthIndicator sofaBootHealthIndicator() &#123;        return new SofaBootHealthIndicator();    &#125;    @ConditionalOnClass(Endpoint.class)    public static class ConditionReadinessEndpointConfiguration &#123;        @Bean        @ConditionalOnEnabledEndpoint        public SofaBootReadinessCheckEndpoint sofaBootReadinessCheckEndpoint() &#123;            return new SofaBootReadinessCheckEndpoint();        &#125;    &#125;    @ConditionalOnClass(Endpoint.class)    public static class ReadinessCheckExtensionConfiguration &#123;        @Bean        @ConditionalOnMissingBean        @ConditionalOnEnabledEndpoint        public ReadinessEndpointWebExtension readinessEndpointWebExtension() &#123;            return new ReadinessEndpointWebExtension();        &#125;    &#125;&#125;\n\nReadinessCheckListener12public class ReadinessCheckListener implements PriorityOrdered,                                   ApplicationListener&lt;ContextRefreshedEvent&gt; \n\n从代码来看，ReadinessCheckListener 实现了 ApplicationListener 监听器接口，其所监听的事件对象是ContextRefreshedEvent，即当容器上下文刷新完成之后回调。 SOFABoot 中通过这个监听器来完成 readniess check 的处理。\nonApplicationEvent 回调方法：\n12345678910public void onApplicationEvent(ContextRefreshedEvent event) &#123;    // healthCheckerProcessor init    healthCheckerProcessor.init();    // healthIndicatorProcessor init    healthIndicatorProcessor.init();    // afterReadinessCheckCallbackProcessor init    afterReadinessCheckCallbackProcessor.init();    // readiness health check execute    readinessHealthCheck();&#125;\n\n\n初始化 healthCheckerProcessor，这个里面就是将当前所有的HealthChecker类型的bean找出来，然后放在一个map中，等待后面的 readiness check。\n\n12345678910111213141516171819public void init() &#123;    // 是否已经初始化了    if (isInitiated.compareAndSet(false, true)) &#123;        // applicationContext 应用上下文不能为null        Assert.notNull(applicationContext, () -&gt; &quot;Application must not be null&quot;);        // 获取所有类型是 HealthChecker 的bean        Map&lt;String, HealthChecker&gt; beansOfType = applicationContext                .getBeansOfType(HealthChecker.class);        // 排序        healthCheckers = HealthCheckUtils.sortMapAccordingToValue(beansOfType,                applicationContext.getAutowireCapableBeanFactory());        // 构建日志信息，对应在健康检查日志里面打印出来的是：        // ./logs/health-check/common-default.log:Found 0 HealthChecker implementation        StringBuilder healthCheckInfo = new StringBuilder(512).append(&quot;Found &quot;)                .append(healthCheckers.size()).append(&quot; HealthChecker implementation:&quot;)                .append(String.join(&quot;,&quot;, healthCheckers.keySet()));        logger.info(healthCheckInfo.toString());    &#125;&#125;\n\n\n初始化 healthIndicatorProcessor，将所有的healthIndicator 类型的bean 找出来，然后放在一个map中等待readiness check。如果想要在 SOFABoot 的 Readiness Check 里面增加一个检查项，那么可以直接扩展 Spring Boot 的HealthIndicator这个接口。\n\n12345678910111213141516171819202122232425public void init() &#123;    // 是否已经初始化    if (isInitiated.compareAndSet(false, true)) &#123;        // applicationContext 验证        Assert.notNull(applicationContext, () -&gt; &quot;Application must not be null&quot;);        // 获取所有HealthIndicator类型的bean        Map&lt;String, HealthIndicator&gt; beansOfType = applicationContext                .getBeansOfType(HealthIndicator.class);        // 支持 Reactive 方式        if (ClassUtils.isPresent(REACTOR_CLASS, null)) &#123;            applicationContext.getBeansOfType(ReactiveHealthIndicator.class).forEach(                    (name, indicator) -&gt; beansOfType.put(name, () -&gt; indicator.health().block()));        &#125;        // 排序        healthIndicators = HealthCheckUtils.sortMapAccordingToValue(beansOfType,                applicationContext.getAutowireCapableBeanFactory());        // 构建日志信息        // Found 2 HealthIndicator implementation:        // sofaBootHealthIndicator, diskSpaceHealthIndicator        StringBuilder healthIndicatorInfo = new StringBuilder(512).append(&quot;Found &quot;)                .append(healthIndicators.size()).append(&quot; HealthIndicator implementation:&quot;)                .append(String.join(&quot;,&quot;, healthIndicators.keySet()));        logger.info(healthIndicatorInfo.toString());    &#125;&#125;\n\n\n初始化 afterReadinessCheckCallbackProcessor。如果想要在 Readiness Check 之后做一些事情，那么可以扩展 SOFABoot 的这个接口\n\n12345678910111213141516171819public void init() &#123;    //  是否已经初始化    if (isInitiated.compareAndSet(false, true)) &#123;        // applicationContext 验证        Assert.notNull(applicationContext, () -&gt; &quot;Application must not be null&quot;);        // 找到所有 ReadinessCheckCallback 类型的 bean         Map&lt;String, ReadinessCheckCallback&gt; beansOfType = applicationContext                .getBeansOfType(ReadinessCheckCallback.class);        // 排序        readinessCheckCallbacks = HealthCheckUtils.sortMapAccordingToValue(beansOfType,                applicationContext.getAutowireCapableBeanFactory());        // 构建日志        StringBuilder applicationCallbackInfo = new StringBuilder(512).append(&quot;Found &quot;)                .append(readinessCheckCallbacks.size())                .append(&quot; ReadinessCheckCallback implementation: &quot;)                .append(String.join(&quot;,&quot;, beansOfType.keySet()));        logger.info(applicationCallbackInfo.toString());    &#125;&#125;\n\n\nreadinessHealthCheck，前面的几个init方法中均是为readinessHealthCheck做准备的，到这里SOFABoot已经拿到了当前多有的HealthChecker、HealthIndicator 和 ReadinessCheckCallback 类型的 bean 信息。\n12345678910111213141516171819202122232425262728293031323334// readiness health checkpublic void readinessHealthCheck() &#123;    // 是否跳过所有check,可以通过 com.alipay.sofa.healthcheck.skip.all 配置项配置决定    if (skipAllCheck()) &#123;        logger.warn(&quot;Skip all readiness health check.&quot;);    &#125; else &#123;        // 是否跳过所有 HealthChecker 类型bean的 readinessHealthCheck,        // 可以通过com.alipay.sofa.healthcheck.skip.component配置项配置        if (skipComponent()) &#123;            logger.warn(&quot;Skip HealthChecker health check.&quot;);        &#125; else &#123;            //HealthChecker 的 readiness check            healthCheckerStatus = healthCheckerProcessor                .readinessHealthCheck(healthCheckerDetails);        &#125;        // 是否跳过所有HealthIndicator 类型bean的readinessHealthCheck        // 可以通过 com.alipay.sofa.healthcheck.skip.indicator配置项配置        if (skipIndicator()) &#123;            logger.warn(&quot;Skip HealthIndicator health check.&quot;);        &#125; else &#123;            //HealthIndicator 的 readiness check            healthIndicatorStatus = healthIndicatorProcessor                .readinessHealthCheck(healthIndicatorDetails);        &#125;    &#125;    // ReadinessCheck 之后的回调函数，做一些后置处理    healthCallbackStatus = afterReadinessCheckCallbackProcessor        .afterReadinessCheckCallback(healthCallbackDetails);    if (healthCheckerStatus &amp;&amp; healthIndicatorStatus &amp;&amp; healthCallbackStatus) &#123;        logger.info(&quot;Readiness check result: success&quot;);    &#125; else &#123;        logger.error(&quot;Readiness check result: fail&quot;);    &#125;&#125;\n\nReadiness Check 做了什么前面是 SOFABoot 健康检查组件处理健康检查逻辑的一个大体流程，了解到了 Readiness 包括检查 HealthChecker 类型的bean和HealthIndicator 类型的 bean。其中HealthIndicator是SpringBoot自己的接口 ，而 HealthChecker 是 SOFABoot 提供的接口。下面继续通过 XXXProcess 来看下 Readiness Check 到底做了什么？\nHealthCheckerProcessorHealthChecker 的健康检查处理器，readinessHealthCheck 方法\n12345678910111213public boolean readinessHealthCheck(Map&lt;String, Health&gt; healthMap) &#123;    Assert.notNull(healthCheckers, &quot;HealthCheckers must not be null.&quot;);    logger.info(&quot;Begin SOFABoot HealthChecker readiness check.&quot;);    boolean result = healthCheckers.entrySet().stream()            .map(entry -&gt; doHealthCheck(entry.getKey(), entry.getValue(), true, healthMap, true))            .reduce(true, BinaryOperators.andBoolean());    if (result) &#123;        logger.info(&quot;SOFABoot HealthChecker readiness check result: success.&quot;);    &#125; else &#123;        logger.error(&quot;SOFABoot HealthChecker readiness check result: failed.&quot;);    &#125;    return result;&#125;\n\n这里每个HealthChecker又委托给doHealthCheck来检查\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private boolean doHealthCheck(String beanId, HealthChecker healthChecker, boolean isRetry,                              Map&lt;String, Health&gt; healthMap, boolean isReadiness) &#123;    Assert.notNull(healthMap, &quot;HealthMap must not be null&quot;);    Health health;    boolean result;    int retryCount = 0;    // check 类型  readiness ？ liveness    String checkType = isReadiness ? &quot;readiness&quot; : &quot;liveness&quot;;    do &#123;        // 获取 Health 对象        health = healthChecker.isHealthy();        // 获取 健康检查状态结果        result = health.getStatus().equals(Status.UP);        if (result) &#123;            logger.info(&quot;HealthChecker[&#123;&#125;] &#123;&#125; check success with &#123;&#125; retry.&quot;, beanId, checkType,retryCount);            break;        &#125; else &#123;            logger.info(&quot;HealthChecker[&#123;&#125;] &#123;&#125; check fail with &#123;&#125; retry.&quot;, beanId, checkType,retryCount);        &#125;        // 重试 &amp;&amp; 等待        if (isRetry &amp;&amp; retryCount &lt; healthChecker.getRetryCount()) &#123;            try &#123;                retryCount += 1;                TimeUnit.MILLISECONDS.sleep(healthChecker.getRetryTimeInterval());            &#125; catch (InterruptedException e) &#123;                logger                    .error(                        String                            .format(                                &quot;Exception occurred while sleeping of %d retry HealthChecker[%s] %s check.&quot;,                                retryCount, beanId, checkType), e);            &#125;        &#125;    &#125; while (isRetry &amp;&amp; retryCount &lt; healthChecker.getRetryCount());    // 将当前 实例 bean 的健康检查结果存到结果集healthMap中    healthMap.put(beanId, health);    try &#123;        if (!result) &#123;            logger                .error(                    &quot;HealthChecker[&#123;&#125;] &#123;&#125; check fail with &#123;&#125; retry; fail details:&#123;&#125;; strict mode:&#123;&#125;&quot;,                    beanId, checkType, retryCount,                    objectMapper.writeValueAsString(health.getDetails()),                    healthChecker.isStrictCheck());        &#125;    &#125; catch (JsonProcessingException ex) &#123;        logger.error(            String.format(&quot;Error occurred while doing HealthChecker %s check.&quot;, checkType), ex);    &#125;    // 返回健康检查结果    return !healthChecker.isStrictCheck() || result;&#125;\n\n这里的 doHealthCheck 结果需要依赖具体 HealthChecker 实现类的处理。通过这样一种方式可以SOFABoot可以很友好的实现对所以 HealthChecker 的健康检查。HealthIndicatorProcessor 的 readinessHealthCheck 和HealthChecker的基本差不多；有兴趣的可以自行阅读源码 Alipay-SOFABoot。\nAfterReadinessCheckCallbackProcessor这个接口是 SOFABoot 提供的一个扩展接口， 用于在 Readiness Check 之后做一些事情。其实现思路和前面的XXXXProcessor 是一样的，对之前初始化时得到的所有的ReadinessCheckCallbacks实例bean逐一进行回调处理。\n123456789101112131415public boolean afterReadinessCheckCallback(Map&lt;String, Health&gt; healthMap) &#123;    logger.info(&quot;Begin ReadinessCheckCallback readiness check&quot;);    Assert.notNull(readinessCheckCallbacks, &quot;ReadinessCheckCallbacks must not be null.&quot;);    boolean result = readinessCheckCallbacks.entrySet().stream()            .map(entry -&gt; doHealthCheckCallback(entry.getKey(), entry.getValue(), healthMap))            .reduce(true, BinaryOperators.andBoolean());    if (result) &#123;        logger.info(&quot;ReadinessCheckCallback readiness check result: success.&quot;);    &#125; else &#123;        logger.error(&quot;ReadinessCheckCallback readiness check result: failed.&quot;);    &#125;    return result;&#125;\n\n同样也是委托给了doHealthCheckCallback来处理\n123456789101112131415161718private boolean doHealthCheckCallback(String beanId,                                      ReadinessCheckCallback readinessCheckCallback,                                      Map&lt;String, Health&gt; healthMap) &#123;    Assert.notNull(healthMap, () -&gt; &quot;HealthMap must not be null&quot;);    boolean result = false;    Health health = null;    try &#123;        health = readinessCheckCallback.onHealthy(applicationContext);        result = health.getStatus().equals(Status.UP);        // print log 省略    &#125; catch (Throwable t) &#123;        // 异常处理    &#125; finally &#123;        // 存入 healthMap        healthMap.put(beanId, health);    &#125;    return result;&#125;\n扩展 Readiness Check 能力按照上面的分析，我们可以自己来实现下这几个扩展。\n实现 HealthChecker 接口1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class GlmapperHealthChecker implements HealthChecker &#123;    @Override    public Health isHealthy() &#123;        // 可以检测数据库连接是否成功        // 可以检测zookeeper是否启动成功        // 可以检测redis客户端是否启动成功        // everything you want ...        if(OK)&#123;            return Health.up().build();        &#125;        return Health.down().build();    &#125;    @Override    public String getComponentName() &#123;        // 组件名        return &quot;GlmapperComponent&quot;;    &#125;        @Override    public int getRetryCount() &#123;        // 重试次数        return 1;    &#125;    @Override    public long getRetryTimeInterval() &#123;        // 重试间隔        return 0;    &#125;    @Override    public boolean isStrictCheck() &#123;        return false;    &#125;&#125;\n\n实现 ReadinessCheckCallback 接口123456789101112@Componentpublic class GlmapperReadinessCheckCallback implements ReadinessCheckCallback &#123;    @Override    public Health onHealthy(ApplicationContext applicationContext) &#123;        Object glmapperHealthChecker = applicationContext.getBean(&quot;glmapperHealthChecker&quot;);        if (glmapperHealthChecker instanceof GlmapperHealthChecker)&#123;            return Health.up().build();        &#125;        return Health.down().build();    &#125;&#125;\n\n再来看下健康检查日志：\n\n可以看到我们自己定义的检查类型ready了。\n从日志看到有一个 sofaBootHealthIndicator，实现了HealthIndicator 接口。\n1234567891011121314151617public class SofaBootHealthIndicator implements HealthIndicator &#123;    private static final String    CHECK_RESULT_PREFIX = &quot;Middleware&quot;;    @Autowired    private HealthCheckerProcessor healthCheckerProcessor;    @Override    public Health health() &#123;        Map&lt;String, Health&gt; healths = new HashMap&lt;&gt;();        // 调用了 healthCheckerProcessor 的 livenessHealthCheck        boolean checkSuccessful = healthCheckerProcessor.livenessHealthCheck(healths);        if (checkSuccessful) &#123;            return Health.up().withDetail(CHECK_RESULT_PREFIX, healths).build();        &#125; else &#123;            return Health.down().withDetail(CHECK_RESULT_PREFIX, healths).build();        &#125;    &#125;&#125;\n\nlivenessHealthCheck 和 readinessHealthCheck 两个方法都是交给 doHealthCheck 来处理的，没有看出来有什么区别。\n小结本文基于 SOFABoot 3.0.0 版本，与之前版本有一些区别。详细变更见：SOFABoot upgrade_3_x。本篇文章简单介绍了 SOFABoot 对 SpringBoot 健康检查能力扩展的具体实现细节。\n最后再来补充下 liveness 和 readiness，从字面意思来理解，liveness就是是否是活的，readiness 就是意思是否可访问的。\n\nreadiness：应用即便已经正在运行了，它仍然需要一定时间才能 提供 服务，这段时间可能用来加载数据，可能用来构建缓存，可能用来注册服务，可能用来选举 Leader等等。总之 Readiness 检查通过前是不会有流量发给应用的。目前 SOFARPC 就是在 readiness check 之后才会将所有的服务注册到注册中心去。\nliveness：检测应用程序是否正在运行\n\n","slug":"sofa/sofa-boot-health-analizy","date":"2018-11-16T11:14:43.000Z","categories_index":"SOFA","tags_index":"框架,Readiness Check","author_index":"glmapper"},{"id":"91728ee079160c4f8cfcf9d960a59096","title":"nginx 反向代理和负载均衡策略实战案例","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903594244702215\n引言先来看下nginx在web服务器排名上的趋势：\n存在即合理，那为什么要使用nginx呢？这得看看nginx能帮我们做些什么。\n\n\n首先，nginx能做反向代理【关于反向代理和正向代理此处不做说明了，感兴趣的小伙伴自行谷歌】；比方说，我想在本地使用 www.glmapper1.com 的域名去访问www.taobao.com。那么这个时候我们就可以通过nginx去实现。\n再者，nginx能实现负载均衡，什么是负载均衡呢？就是说应用部署在不同的服务器上，但是通过统一的域名进入，nginx则对请求进行分发，将请求分发到不同的服务器上去处理，这样就可以有效的减轻了单台服务器的压力。\n在上面这两种情况下，nginx服务器的作用都只是作为分发服务器，真正的内容，我们可以放在其他的服务器上，这样来，还能起到一层安全隔壁的作用，nginx作为隔离层。\n解决跨域问题\n\n\n\n\n\n\n\n\n\n同源：URL由协议、域名、端口和路径组成，如果两个URL的协议、域名和端口相同，则表示他们同源。\n\n\n\n\n\n\n\n\n\n浏览器的同源策略：浏览器的同源策略，限制了来自不同源的”document”或脚本，对当前”document”读取或设置某些属性。从一个域上加载的脚本不允许访问另外一个域的文档属性。\n因为nginx和tomcat不能共用同一端口,url一样，端口不同，这样就会有跨域问题。\nPS：点到为止，这里本次测试没有涉及，就不妄自菲薄了！！!\n配置文件解析配置文件主要由四部分组成：\n\nmain(全区设置)\nserver(主机配置)\nhttp(控制着nginx http处理的所有核心特性)\nlocation(URL匹配特定位置设置)。\n\n\nupstream(负载均衡服务器设置)\n\n下面以默认的配置文件来说明下具体的配置文件属性含义：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152#Nginx的worker进程运行用户以及用户组#user  nobody;#Nginx开启的进程数worker_processes  1;#定义全局错误日志定义类型，[debug|info|notice|warn|crit]#error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#指定进程ID存储文件位置#pid        logs/nginx.pid;#事件配置events &#123;            #use [ kqueue | rtsig | epoll | /dev/poll | select | poll ];    #epoll模型是Linux内核中的高性能网络I/O模型，如果在mac上面，就用kqueue模型。    use kqueue;        #每个进程可以处理的最大连接数，理论上每台nginx服务器的最大连接数为worker_processes*worker_connections。理论值：worker_rlimit_nofile/worker_processes    worker_connections  1024;&#125;#http参数http &#123;    #文件扩展名与文件类型映射表    include       mime.types;    #默认文件类型    default_type  application/octet-stream;        #日志相关定义    #log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;    #                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;    #                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;        #连接日志的路径，指定的日志格式放在最后。    #access_log  logs/access.log  main;    #开启高效传输模式    sendfile        on;        #防止网络阻塞    #tcp_nopush     on;    #客户端连接超时时间，单位是秒    #keepalive_timeout  0;    keepalive_timeout  65;    #开启gzip压缩输出    #gzip  on;    #虚拟主机基本设置    server &#123;        #监听的端口号        listen       80;        #访问域名        server_name  localhost;                #编码格式，如果网页格式与当前配置的不同的话将会被自动转码        #charset koi8-r;        #虚拟主机访问日志定义        #access_log  logs/host.access.log  main;                #对URL进行匹配        location / &#123;            #访问路径，可相对也可绝对路径            root   html;            #首页文件，匹配顺序按照配置顺序匹配            index  index.html index.htm;        &#125;                #错误信息返回页面        #error_page  404              /404.html;                # redirect server error pages to the static page /50x.html        #        error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;            root   html;        &#125;                #访问URL以.php结尾则自动转交给127.0.0.1        # proxy the PHP scripts to Apache listening on 127.0.0.1:80        #        #location ~ \\.php$ &#123;        #    proxy_pass   http://127.0.0.1;        #&#125;                #php脚本请求全部转发给FastCGI处理        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000        #        #location ~ \\.php$ &#123;        #    root           html;        #    fastcgi_pass   127.0.0.1:9000;        #    fastcgi_index  index.php;        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;        #    include        fastcgi_params;        #&#125;        #禁止访问.ht页面        # deny access to .htaccess files, if Apache&#x27;s document root        # concurs with nginx&#x27;s one        #        #location ~ /\\.ht &#123;        #    deny  all;        #&#125;    &#125;    #第二个虚拟主机配置    # another virtual host using mix of IP-, name-, and port-based configuration    #    #server &#123;    #    listen       8000;    #    listen       somename:8080;    #    server_name  somename  alias  another.alias;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;    #HTTPS虚拟主机定义    # HTTPS server    #    #server &#123;    #    listen       443 ssl;    #    server_name  localhost;    #    ssl_certificate      cert.pem;    #    ssl_certificate_key  cert.key;    #    ssl_session_cache    shared:SSL:1m;    #    ssl_session_timeout  5m;    #    ssl_ciphers  HIGH:!aNULL:!MD5;    #    ssl_prefer_server_ciphers  on;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;    include servers/*;&#125;\n\n反向代理实例假设我现在需要本地访问www.baidu.com;配置如下：\n1234567891011server &#123;    #监听80端口    listen 80;    server_name localhost;     # individual nginx logs for this web vhost    access_log /tmp/access.log;    error_log  /tmp/error.log ;    location / &#123;        proxy_pass http://www.baidu.com;    &#125;\n\n验证结果：\n\n可以看到，我在浏览器中使用localhost打开了百度的首页…\n负载均衡实例下面主要验证最常用的三种负载策略。虚拟主机配置：\n123456789101112131415161718192021222324server &#123;    #监听80端口    listen 80;    server_name localhost;        # individual nginx logs for this web vhost    access_log /tmp/access.log;    error_log  /tmp/error.log ;    location / &#123;        #负载均衡        #轮询         #proxy_pass http://polling_strategy;        #weight权重        #proxy_pass http://weight_strategy;        #ip_hash        # proxy_pass http://ip_hash_strategy;        #fair        # proxy_pass http://fair_strategy;        #url_hash        # proxy_pass http://url_hash_strategy;        #重定向        #rewrite ^ http://localhost:8080;    &#125;\n\n轮询策略123456# 1、轮询（默认）# 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 upstream polling_strategy &#123;     server glmapper.net:8080; # 应用服务器1    server glmapper.net:8081; # 应用服务器2&#125; \n\n测试结果（通过端口号来区分当前访问）：\n12348081：hello8080：hello8081：hello8080：hello\n\n权重策略123456#2、指定权重#指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 upstream  weight_strategy &#123;     server glmapper.net:8080 weight=1; # 应用服务器1    server glmapper.net:8081 weight=9; # 应用服务器2&#125;\n测试结果：总访问次数15次，根据上面的权重配置，两台机器的访问比重：2：13；满足预期！\nip hash策略123456789#3、IP绑定 ip_hash#每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，#可以解决session的问题;在不考虑引入分布式session的情况下，#原生HttpSession只对当前servlet容器的上下文环境有效upstream ip_hash_strategy &#123;     ip_hash;     server glmapper.net:8080; # 应用服务器1    server glmapper.net:8081; # 应用服务器2&#125; \n\n\n\n\n\n\n\n\n\n\niphash 算法:ip是基本的点分十进制，将ip的前三个端作为参数加入hash函数。这样做的目的是保证ip地址前三位相同的用户经过hash计算将分配到相同的后端server。作者的这个考虑是极为可取的，因此ip地址前三位相同通常意味着来着同一个局域网或者相邻区域，使用相同的后端服务让nginx在一定程度上更具有一致性。\n为什么说要解释下iphash,因为采坑了；和猪弟在进行这个策略测试时使用了5台机器来测试的，5台机器均在同一个局域网内【192.168.3.X】;测试时发现5台机器每次都路由到了同一个服务器上，一开始以为是配置问题，但是排查之后也排除了这个可能性。最后考虑到可能是对于同网段的ip做了特殊处理，验证之后确认了猜测。\n其他负载均衡策略这里因为需要安装三方插件，时间有限就不验证了，知悉即可！\n1234567891011121314151617#4、fair（第三方）#按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream fair_strategy &#123;     server glmapper.net:8080; # 应用服务器1    server glmapper.net:8081; # 应用服务器2    fair; &#125; #5、url_hash（第三方）#按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，#后端服务器为缓存时比较有效。 upstream url_hash_strategy &#123;     server glmapper.net:8080; # 应用服务器1    server glmapper.net:8081; # 应用服务器2     hash $request_uri;     hash_method crc32; &#125; \n\n重定向rewrite1234location / &#123;    #重定向    #rewrite ^ http://localhost:8080;&#125;\n验证思路：本地使用localhost:80端口进行访问，根据nginx的配置，如果重定向没有生效，则最后会停留在当前localhost:80这个路径，浏览器中的地址栏地址不会发生改变；如果生效了则地址栏地址变为localhost:8080；\n通过验证，满足预期！\n总结本文先对nginx的作用和基本的配置做了简单说明；然后通过负载均衡的实例测试了不同负载均衡算法的具体应用反馈结果。帮助自己更加深刻的理解nginx服务器中的一些配置细节。感谢刘秘提供的helloworld程序【基于springboot的脚手架，有需要的可以联系他获取；还有就是刘秘是个男的…😜】\n参考\nhttp://nginx.org/\nhttps://www.nginx.com/\nhttp://www.sohu.com/a/161411719_324809\n\n","slug":"middleware/middleware-nginx-proxy","date":"2018-11-15T13:24:52.000Z","categories_index":"Middleware","tags_index":"nginx,反向代理,负载均衡","author_index":"glmapper"},{"id":"80757c505c28d656f4a66a57e05f0132","title":"关于 rpc 的整理和理解","content":"RPC 的主要目标就是为了让构建分布式计算（应用）变得更加简单，在提供强大的远程调用能力时不损失本地调用的语义简洁性。 为实现该目标，RPC 框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。\n\n\n架构演变\n所有的界面和服务均在同一个进程下\n\n基于mvc的视图与服务分离，但是实际上还是在一个应用系统中，只不过在功能层次上划分的更加细致\n\n粒度更细，对于不同的功能服务进行切分，并进行单独的部署\n\n面向服务的架构，将应用程序的不同功能单元（称为服务）通过这些服务之间定义良好的接口和契约联系起来\n\n微服务\n  此处不支持图片展示，自行脑补！！！\n\n\n随着业务量和用户量的增加，架构也是从单一系统走向分布式系统，我能想到的是，这种架构的演变主要解决的问题在于：\n\n通过业务模块的拆分，使得每个模块的职责更加清晰，但是模块的职责边界的划分往往也是很疼头的事情。\n细致的划分使得项目在管理上面会更加方面，从代码的角度来说，开发和维护的成本也会降低，不会因为一个bug去跑整个项目了。\n提高了系统的容错率，单一系统如果宕机那就真的gg了，另外就是，单个环节出现问题也会导致项目无法正常运行（比如数据库出问题了）。对于分布式系统来说，一般都会使用冗余的方式来提高可用性，个人理解就是可以提供多个一样的服务，它们之间可以进行切换。\n分布式系统带来的问题一个是成本，硬件成本，运维成本都会增加。\n\nrpc简介及常用的rpc框架随着集中式架构向分布式架构的转变，应用系统之间的服务调用与通讯问题成为了首要解决的需求。\n而RPC 的主要目标就是为了让构建分布式计算（应用）变得更加简单，在提供强大的远程调用能力时不损失本地调用的语义简洁性。 为实现该目标，RPC 框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。\n如下代码：\n123456789101112131415   @Autowiredprivate GlRpcAgent glRpcAgent; //rpc代理/** * @param param 此处约定参数以Map键值对的形式传递 */@Overridepublic List&lt;OrderInfo&gt; queryOrdersByUserId(Map&lt;String, Object&gt; param) &#123;\t//创建远程调用代理（远程服务的类的全限定名）\tOrderConsumeAgent orderConsumer=glRpcAgent.getAgent(&quot;com.glmapper.rpc.interface.OrderConsumeInterface&quot;);\t//通过代理获取返回结果  此处getOrders为远程服务器上的com.glmapper.rpc.interface.OrderConsumeInterface接口中的方法，param为参数\tMap&lt;String,Object&gt; resultMap=(Map)orderConsumer.call(&quot;getOrders&quot;,param);\t//解析返回结果（远程方法同样以Map集合的方式放回）\tList&lt;OrderInfo&gt; orders = parseResultMap(resultMap);\treturn orders;&#125;\n为什么要以全限定名来获取呢，这个我们将会在后面来说。\n什么是RPCIn distributed computing a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in another address space(commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction.RPC 的全称是 Remote Procedure Call 是一种进程间通信方式。 它允许程序调用另一个进程上（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。\n从定义中可以得知，RPC主要来解决三件事情：\n\n进程间通讯\n提供和本地方法调用一样的调用机制\n屏蔽程序员对远程调用的细节实现\n\n首先是进程间的通信问题，对于分布式环境，rpc能够帮助我们解决不同服务器之间的通信及数据传输问题，即做好方法调用到数据的转换，然后借助网络进行数据传递；rpc客户端向rpc服务端发起远程服务调用，通过请求的封装，参数的封装，序列化、编码、约定协议传输、解析请求、处理请求、封装返回消息数据、在进行返回数据的序列化、编码、在通过网络返回给客户端。再者是提供和本地方法调用一样的调用机制，为什么这么说，对于业务系统来说，我们更多的关注点在于如何解决实际的业务需求问题，而不想花更多的时间和心思在诸如上述过程中关于网络传输及编解码过程，因此对于rpc来说，需要将这些编解码、协议约定、网络传输等进行一个整体的封装，然后只向业务系统提供最简单的调用方式。最后一个屏蔽程序员对远程调用的细节实现，其实也就是第二点中提到的那些功能的封装，我们不用去关系rpc到底是如何实现的，也不用关心它是如何运作的，对于业务开发人员来说，通过约定的方式进行类似于本地方法调用的形式来调用远程服务接口就可以了。那么如何实现透明化的远程调用呢？什么样的内部封装才能让我们觉得像以本地调用方式调用远程服务呢？对于java来说就是使用代理。java代理有两种方式：1） jdk 动态代理（接口代理）；2）cglib代理（子类代理）。尽管字节码生成方式实现的代理更为强大和高效，但代码不易维护，大部分公司实现RPC框架时还是选择动态代理方式。这部分也将会在后续的章节中展开来说。\nRPC基本原理上面说到，rpc需要对一些远程调用的内部实现进行封装。我们说到有以下几个点：\n\n序列化\n编解码\n协议\n网络\n\n从发起远程调用到接收到数据返回结果，大致过程是：\n1）服务消费方（client）调用以本地调用方式调用服务；2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；3）client stub找到服务地址，并将消息发送到服务端；4）server stub收到消息后进行解码；5）server stub根据解码结果调用本地的服务；6）本地服务执行并将结果返回给server stub；7）server stub将返回结果打包成消息并发送至消费方；8）client stub接收到消息，并进行解码；9）服务消费方得到最终结果。\n那么rpc就相当于将step2-step8的步骤进行了封装。下面借用一张网上的图片来帮助我们理解这个过程。\n\nRPC模型对于上图，我们进行进一步的拆解得到（来自网络）：\nRPC 服务端通过 RpcServer 去暴露服务接口，而客户端通过 RpcClient 去获取服务接口。客户端像调用本地方法一样去调用远程接口方法，RPC 框架提供接口的代理实现，实际的调用将委托给代理 RpcProxy。代理封装调用信息并将调用转交给 RpcInvoker 去实际执行。在客户端的 RpcInvoker 通过连接器 RpcConnector 去维持与服务端的通道 RpcChannel，并使用 RpcProtocol 执行协议编码（encode）并将编码后的请求消息通过通道发送给服务端。RPC 服务端接收器 RpcAcceptor接收客户端的调用请求，同样使用 RpcProtocol 执行协议解码（decode）。解码后的调用信息传递给 RpcProcessor 去控制处理调用过程，最后再委托调用给 RpcInvoker 去实际执行并返回调用结果。\n通过上述分析可知，这里面包括以下核心组件：\n\n用于暴露服务接口的RpcServer \n用于发现服务接口的RpcClient \n远程接口的代理实现RpcProxy \n负责协议编解码的RpcProtocol（实际的rpc框架中一般会提供多种不同的实现）\n网络连接器（之前看过一篇文章说9个组件，对于咱们这个来说，部分模块可以集成在client和server中）\n\n常见的RPC框架目前常见的分布式RPC框架有以下几个：\n\ndubbo阿里巴巴公司开源的一个Java高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和 Spring框架无缝集成\nmotan新浪微博开源的一个Java 框架。它诞生的比较晚，起于2013年，2016年5月开源。Motan 在微博平台中已经广泛应用，每天为数百个服务完成近千亿次的调用。\nrpcxGo语言生态圈的Dubbo， 比Dubbo更轻量，实现了Dubbo的许多特性，借助于Go语言优秀的并发特性和简洁语法，可以使用较少的代码实现分布式的RPC服务。\ngRPCGoogle开发的高性能、通用的开源RPC框架，主要面向移动应用开发并基于HTTP&#x2F;2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。本身它不是分布式的，所以要实现上面的框架的功能需要进一步的开发。\nthriftApache的一个跨语言的高性能的服务框架\n\nRPC与MQMQ(message queue)消息队列，从某种程度上来说，同样可以实现RPC的功能。从功能特点上来说，MQ可以把消息存储，而RPC不行。关于MQ和RPC做了以下简单的对比，如下图所示：\n\n总结本文对RPC的基本原理、特点以及基本组件进行了简单的说明，让我们可以对RPC有一个基本的了解。关于常见的RPC框架也做了基本认识，对于这些优秀的框架，我们在实现我们自己RPC时可以借鉴一下这些架构里的一些模式以及技术。最后说明了下为什么我们会在分布式架构中要使用RPC而不是MQ，对于MQ来说，在处理同步调用无法满足实际的生产需求，而RPC才更加适合分布式应用的实际需要。\n","slug":"middleware/middleware-rpc-about","date":"2018-11-12T13:22:44.000Z","categories_index":"Middleware","tags_index":"rpc","author_index":"glmapper"},{"id":"9c68ad813f6c311ba3519d423fc2af91","title":"JUC·ThreadPoolExecutor 线程池","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903560899985415\nThreadPoolExecutor算是JUC中最常用的类之一了。ThreadPoolExecutor，顾名思义，thread-pool-executor,硬翻译就是“线程-池-执行者”；java中，通过ThreadPoolExecutor可以很容易的创建一个线程池。但是我们为什么要使用线程池？呢？它能够带来什么样的优势呢？它又是怎么实现的呢？OK，带着这几个问题，我们来学习一下JAVA中的线程池技术。\n\n\n为什么要使用线程池？关于这个问题其实有点鸡肋，我觉得再问这个问题之前更应该问为什么要有线程池。那为什么呢?\n\nthis is a 例子：\n快递行业最近两年发展的灰常火热，听说工资也非常的高，搞得我一天天的都没有心思去好好写代码了...\n之前的小快递公司都是没有固定的快递员的，就是说，每次去送一件快递，站点负责人就需要去找一个人来帮忙送，送完之后就没有然后了(当然，钱还是要给的)。\n但是后来随着货越来越多，找人给钱成本太大，而且农忙时还需要花很长时间去找人，所以就雇用了5个人，签了合同，长期为站点配送。\n以前都是随时用随时找，现在不是，现在是成立了一个物流公司，开了一个配送部，配送部门规定正式配送员最多只能有五个人。\n之前配送的缺点是什么：\n\n每次有货，我都会去临时找一个人，然后签订临时合同，送完之后解除合同。很麻烦。这也是不用线程池的缺点，就是任务来了，我们需要频繁的去创建新的线程，用完之后还需要释放线程资源，对于系统的消耗是很大的。\n因为配送的货车只有那么几个，如果临时签订的人多了，车子不够用，其他人只能等着车子送完之后才能用。\n\n成立配送部之后解决的问题\n\n成立配送部之后呢，因为签订的是劳务合同，我们可以重复的让配送员配送不同的货物。达到线程资源的复用。\n因为限定了最多招聘的人数，可以很好的避免招过多无用的人。\n\n\nOK，我们以上述例子来对应理解线程池的基本原理\n先来看下，JAVA对ThreadPoolExecutor的类申明：\n1public class ThreadPoolExecutor extends AbstractExecutorService \n在【初识】-JUC·Executor框架中给出了Executor的继承体系。ThreadPoolExecutor就是具备线程池功能的集成者。\n构造方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//构造方法一public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue) &#123;                              this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,         Executors.defaultThreadFactory(), defaultHandler);          &#125; //构造方法二 public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory) &#123;    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,         threadFactory, defaultHandler);&#125;//构造方法三public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          RejectedExecutionHandler handler) &#123;    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,         Executors.defaultThreadFactory(), handler);&#125;//构造方法四public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory,                          RejectedExecutionHandler handler) &#123;    if (corePoolSize &lt; 0 ||        maximumPoolSize &lt;= 0 ||        maximumPoolSize &lt; corePoolSize ||        keepAliveTime &lt; 0)        throw new IllegalArgumentException();    if (workQueue == null || threadFactory == null || handler == null)        throw new NullPointerException();    this.corePoolSize = corePoolSize;    this.maximumPoolSize = maximumPoolSize;    this.workQueue = workQueue;    this.keepAliveTime = unit.toNanos(keepAliveTime);    this.threadFactory = threadFactory;    this.handler = handler;&#125;\n从上面的代码可以看出，构造方法（一、二、三）都是通过调用（四）来做具体属性初始化的。那么我们直接来看构造方法四；在构造方法四中总共需要7个参数，先来看下每个参数的具体含义：\n\ncorePoolSize\n  核心线程数大小。那么什么是核心线程数呢，我们可以类比于上面例子中的配送部中签订劳动合同的人的个数。\n\nmaximumPoolSize\n  最大线程数。加入说现在是双十一期间，快递异常的多，配送部的5个人完全忙不过来，而且仓库也满了，怎么办呢？这个时候就需要再招聘一些临时配送员，假设maximumPoolSize为10，那么也就是说，临时招聘可以招5个人，配送部签订正式劳动合同的人和签订临时合同的人加一块不能超过配送部规定的最大人数（10人）。所以说，maximumPoolSize就是线程池能够允许的存在的最大线程的数量。\n\nkeepAliveTime\n  存活时间。为什么要有这个呢？想一下，双十一过去了，货物已经配送的差不多了。临时合同写的是如果临时配送员2天没有配送了，那配送部就有权利终止临时合同，现在已经达到2天这个点了，需要开除这些临时配送专员了。对于线程池来说，keepAliveTime就是用来表示，当除核心线程池之外的线程超过keepAliveTime时间之后，就需要被系统回收了。\n\nunit\n  keepAliveTime的时间单位。\n\nworkQueue\n  工作队列。这个就相当于一个仓库，现在配送部5个人都在配送，但是还不断的有新的快递达到，这个时候就需要一个仓库来存放这些快递。对于线程池来说，当核心线程都有自己的任务处理，并且还有任务进来的时候，就会将任务添加到工作队列中去。\n\nthreadFactory\n  线程工厂。就是用来创建线程的。可以类比成招聘组，会给每个线程分配名字或者编号这样。\n\nhandler\n  RejectedExecutionHandler 用来描述拒绝策略的。假设现在我的仓库也满足，并且配送部已经达到10个人了。怎么办呢，那么只能采用一些策略来拒绝任务了。\n\n\n线程池的状态1234567891011// runState is stored in the high-order bits//RUNNING；该状态的线程池接收新任务，并且处理阻塞队列中的任务private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;//SHUTDOWN；该状态的线程池不接收新任务，但会处理阻塞队列中的任务；private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;//STOP；不接收新任务，也不处理阻塞队列中的任务，并且会中断正在运行的任务；private static final int STOP       =  1 &lt;&lt; COUNT_BITS;//所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;//线程池彻底终止，就变成TERMINATED状态。 private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;\n\n下面是在网上发现的一位大牛的图；感觉可以较为直观的描述状态的变更\n\n工作原理\n有几个点需要注意。\n1、如何提交一个任务到线程池？12345678910111213141516171819202122public void execute(Runnable command) &#123;    //任务为null,直接抛出空指针异常    if (command == null)        throw new NullPointerException();    int c = ctl.get();    //如果线程数大于等于基本线程数，将任务加入队列    if (workerCountOf(c) &lt; corePoolSize) &#123;        if (addWorker(command, true))            return;        c = ctl.get();    &#125;    if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123;        int recheck = ctl.get();        if (! isRunning(recheck) &amp;&amp; remove(command))            reject(command);        else if (workerCountOf(recheck) == 0)            addWorker(null, false);    &#125;    else if (!addWorker(command, false))        reject(command);&#125;\n\n\n如果少于corePoolSize线程正在运行，请尝试使用给定命令启动一个新线程作为其第一个任务。 对addWorker的调用会自动检查runState和workerCount，从而防止错误报警，在不应该的时候通过返回false来添加线程。\n如果一个任务能够成功排队，那么我们仍然需要再次检查是否应该添加一个线程（因为现有的线程自上次检查以来已经死掉）或者自从进入这个方法以来，池关闭了。所以我们重新检查状态，如果当前command已经stop了，那么就退出工作队列，如果没有的话就开始一个新的线程。\n如果队列满了，会想尝试去创建一个新的线程去执行，如果创建不了，那就执行拒绝策略。\n\n2、如何创建一个线程去处理任务？通过实现这个接口去创建一个新的线程\n123public interface ThreadFactory &#123;    Thread newThread(Runnable r);&#125;\n\n3、如何将任务添加到队列？通过addWorker方法来添加，其实在excute中只是作为一个提交任务的入口，实际的处理逻辑都是在addWorker这个方法里来完成的。addWorker有两个参数：\n\nfirstTask 当前任务\ncore 用来标注当前需要创建的线程是否是核心线程，如果core为true，则表明创建的是核心线程，也就是说当前还没有达到最大核心线程数。\n\n先来看下这个方法的前半部分：\n1234567891011121314151617181920212223242526272829private boolean addWorker(Runnable firstTask, boolean core) &#123;    retry:    //自旋方式    for (;;) &#123;        //获取当前线程池的状态        int c = ctl.get();        int rs = runStateOf(c);            //如果状态是STOP，TIDYING,TERMINATED状态的话，则会返回false        //如果状态是SHUTDOWN，但是firstTask不为空或者workQueue为空的话，那么直接返回false。        if (rs &gt;= SHUTDOWN &amp;&amp;            ! (rs == SHUTDOWN &amp;&amp;               firstTask == null &amp;&amp;               ! workQueue.isEmpty()))            return false;        //通过自旋的方式，判断要添加的worker是否为corePool范畴之内的        for (;;) &#123;            int wc = workerCountOf(c);            if (wc &gt;= CAPACITY ||                wc &gt;= (core ? corePoolSize : maximumPoolSize))                return false;            if (compareAndIncrementWorkerCount(c))                break retry;            c = ctl.get();  // Re-read ctl            if (runStateOf(c) != rs)                continue retry;            // else CAS failed due to workerCount change; retry inner loop        &#125;    &#125;\n\n&#x2F;&#x2F;如果超过CAPACITY限制了则直接返回false\n1wc &gt;= CAPACITY\n&#x2F;&#x2F;判断当前的workerCount是否大于corePoolsize，否则则判断是否大于maximumPoolSize&#x2F;&#x2F;具体的比较取决于入参core是true还是false。\n1wc &gt;= (core ? corePoolSize : maximumPoolSize)\n如果上面两个有一个满足了，则直接返回false。\n下面是判断WorkerCount通过CAS操作增加1是否成功，成功的话就到此结束\n12if (compareAndIncrementWorkerCount(c))    break retry;\n如果不成功，则再次判断当前线程池的状态，如果现在获取到的状态与进入自旋的状态不一致的话，那么则通过continue retry重新进行状态的判断。\n123c = ctl.get();  // Re-read ctlif (runStateOf(c) != rs)    continue retry;\n\n再来看下这个方法的后面半个部分：\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849boolean workerStarted = false;boolean workerAdded = false;Worker w = null;try &#123;    final ReentrantLock mainLock = this.mainLock;    //创建一个新的Worker对象    w = new Worker(firstTask);    final Thread t = w.thread;    //    if (t != null) &#123;    //加锁        mainLock.lock();        try &#123;            // 在锁定的情况下重新检查。            // 在一下情况退出：ThreadFactory 创建失败或者在获取锁之前shut down了            int c = ctl.get();            int rs = runStateOf(c);           //状态校验            if (rs &lt; SHUTDOWN ||                (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123;                if (t.isAlive()) // 预先检查t是可以启动的                    throw new IllegalThreadStateException();                //添加至workers中                workers.add(w);                int s = workers.size();                //如果超过了历史最大线程数，则将当前池数量设置为历史最大线程记录数                if (s &gt; largestPoolSize)                    largestPoolSize = s;                //标识添加工作线程成功                workerAdded = true;            &#125;        &#125; finally &#123;        //解锁            mainLock.unlock();        &#125;        //如果添加成功则启动当前工作线程        if (workerAdded) &#123;            t.start();            //并将当前线程状态设置为已启动            workerStarted = true;        &#125;    &#125;&#125; finally &#123;//添加失败    if (! workerStarted)        addWorkerFailed(w);&#125;return workerStarted;&#125;\n拒绝策略有哪些？\n\n1、AbortPolicy：直接抛出异常，默认策略；\n2、CallerRunsPolicy：使用调用者自己的当前线程来执行任务；\n3、DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；\n4、DiscardPolicy：直接丢弃任务；\n\n当然我们也可以自定义拒绝策略。\n常用工作队列类型1、ArrayBlockingQueue\n基于数组的阻塞队列，长度有限\n2、LinkedBlockingQuene\n基于链表的阻塞队列，长度无限，使用这个可能会导致我们的拒绝策略失效。因为可以无限的创建新的工作线程。\n3、PriorityBlockingQueue\n具有优先级的无界阻塞队列；\n3、SynchronousQuene\nSynchronousQuene是一个是一个不存储元素的BlockingQueue；每一个put操作必须要等待一个take操作，否则不能继续添加元素。所以这个比较特殊，它不存我们的任务，也就说说它的每个put操作必须等到另一个线程调用take操作，否则put操作一直处于阻塞状态。\nWorker这个是ThreadPoolExecutor的一个内部类，表示一个工作线程。重要的是这个内部类实现了AbstractQueuedSynchronizer（AQS:抽象队列同步器）抽象类。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475private final class Worker    extends AbstractQueuedSynchronizer    implements Runnable&#123;    /**     * This class will never be serialized, but we provide a     * serialVersionUID to suppress a javac warning.     */    private static final long serialVersionUID = 6138294804551838833L;    /** 当前work持有的线程 */    final Thread thread;    /** 运行的初始任务。 可能为空。*/    Runnable firstTask;    /** 每个线程完成任务的计数器 */    volatile long completedTasks;    /**     * 构造函数     */    Worker(Runnable firstTask) &#123;    // 禁止中断，直到runWorker        setState(-1);         //想提交的任务交给当前工作线程        this.firstTask = firstTask;        //通过线程工厂创建一个新的线程        this.thread = getThreadFactory().newThread(this);    &#125;    /** 将run方法的执行委托给外部runWorker */    public void run() &#123;        runWorker(this);    &#125;    // 是否锁定    //    // 0代表解锁状态。    // 1代表锁定状态。    protected boolean isHeldExclusively() &#123;        return getState() != 0;    &#125;    //尝试获取锁（重写AQS的方法）    protected boolean tryAcquire(int unused) &#123;        if (compareAndSetState(0, 1)) &#123;            setExclusiveOwnerThread(Thread.currentThread());            return true;        &#125;        return false;    &#125;    //尝试释放锁（重写AQS的方法）    protected boolean tryRelease(int unused) &#123;        setExclusiveOwnerThread(null);        setState(0);        return true;    &#125;    //加锁    public void lock()        &#123; acquire(1); &#125;    //尝试加锁    public boolean tryLock()  &#123; return tryAcquire(1); &#125;    //解锁    public void unlock()      &#123; release(1); &#125;    //是否锁定    public boolean isLocked() &#123; return isHeldExclusively(); &#125;    //如果启动则中断    void interruptIfStarted() &#123;        Thread t;        if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123;            try &#123;                t.interrupt();            &#125; catch (SecurityException ignore) &#123;            &#125;        &#125;    &#125;&#125;\n\nrunWorker最后来看下runWorker这个方法（ThreadPoolExecutor中的方法）：\n12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123;    Thread wt = Thread.currentThread();    Runnable task = w.firstTask;    w.firstTask = null;    w.unlock(); // allow interrupts    boolean completedAbruptly = true;    try &#123;        while (task != null || (task = getTask()) != null) &#123;            w.lock();            // If pool is stopping, ensure thread is interrupted;            // if not, ensure thread is not interrupted.  This            // requires a recheck in second case to deal with            // shutdownNow race while clearing interrupt            if ((runStateAtLeast(ctl.get(), STOP) ||                 (Thread.interrupted() &amp;&amp;                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;                !wt.isInterrupted())                wt.interrupt();            try &#123;                beforeExecute(wt, task);                Throwable thrown = null;                try &#123;                    task.run();                &#125; catch (RuntimeException x) &#123;                    thrown = x; throw x;                &#125; catch (Error x) &#123;                    thrown = x; throw x;                &#125; catch (Throwable x) &#123;                    thrown = x; throw new Error(x);                &#125; finally &#123;                    afterExecute(task, thrown);                &#125;            &#125; finally &#123;                task = null;                w.completedTasks++;                w.unlock();            &#125;        &#125;        completedAbruptly = false;    &#125; finally &#123;        processWorkerExit(w, completedAbruptly);    &#125;&#125;\n\n\n\n\n\n\n\n\n\n下面是对注释的蹩脚翻译，欢迎吐槽，但注意尺度，O(∩_∩)O哈哈~\n主要工作循环运行。重复地从队列中获取任务并执行它们，同时处理一些问题: \n\n我们可能会从最初的任务开始，在这种情况下，我们不需要得到第一个任务。否则，只要池正在运行，我们就从getTask获得任务。 如果它返回null，则由于更改池状态或配置参数而导致worker退出。其他退出的结果是在外部代码中抛出的异常，在这种情况下completeAbruptly成立，这通常会导致processWorkerExit来取代这个线程。\n在运行任何任务之前，获取锁以防止任务正在执行时发生其他池中断，调用clearInterruptsForTaskRun确保除非池正在停止，则此线程没有设置其中断。\n每个任务运行之前都会调用beforeExecute，这可能会引发一个异常，在这种情况下，我们会导致线程死亡（断开循环completeAbruptly为true），而不处理任务。\n假设beforeExecute正常完成，我们运行任务，收集任何抛出的异常发送到afterExecute。 我们分别处理RuntimeException，Error（这两个规范保证我们陷阱）和任意的Throwables。 因为我们不能在Runnable.run中重新抛出Throwable，所以我们把它们封装在Errors中（到线程的UncaughtExceptionHandler）。 任何抛出的异常也保守地导致线程死亡。\ntask.run完成后，我们调用afterExecute，这也可能会抛出一个异常，这也会导致线程死亡。 根据JLS Sec 14.20，即使task.run抛出，这个异常也是有效的。\n\n异常机制的最终效果是afterExecute和线程的UncaughtExceptionHandler拥有关于用户代码遇到的任何问题的准确信息。\n总结本文是 JUC 的第二篇，意在通过查看源码来了解线程池的具体工作原理。文中如果存在不当的描述，希望小伙伴们能够及时提出。灰常感谢！\n","slug":"java/java-advance-juc-thread-pool-executor","date":"2018-11-11T07:39:42.000Z","categories_index":"JAVA","tags_index":"并发编程,JUC,ThreadPoolExecutor,线程池","author_index":"glmapper"},{"id":"ffd243d8ccdbdfb51e5fe7667716827d","title":"看完这个不会配置 logback ，请你吃瓜！","content":"\n\n\n\n\n\n\n\n\n原文: https://juejin.cn/post/6844903641535479821\n之前在 日志？聊一聊 slf4j 这篇文章中聊了下 slf4j。本文也从实际的例子出发，针对logback 的日志配置进行学习。\n\n\nlogack 简介\n\n\n\n\n\n\n\n\nlogback 官网：https://logback.qos.ch/\n目前还没有看过日志类框架的源码，仅限于如何使用。所以就不说那些“空话”了。最直观的认知是：\n\nlogback和log4j是一个人写的\nspringboot默认使用的日志框架是logback。\n三个模块组成\nlogback-core\nlogback-classic\nlogback-access\n\n\n其他的关于性能，关于内存占用，关于测试，关于文档详见源码及官网说明\n\nlogback-core 是其它模块的基础设施，其它模块基于它构建，显然，logback-core 提供了一些关键的通用机制。logback-classic 的地位和作用等同于 Log4J，它也被认为是 Log4J 的一个改进版，并且它实现了简单日志门面 SLF4J；而 logback-access 主要作为一个与 Servlet 容器交互的模块，比如说tomcat或者 jetty，提供一些与 HTTP 访问相关的功能。\n配置文件详解这部分主要来学习下logback配置文件的一些配置项。\nconfiguration先来看这张图，这个结构就是整个logback.xml配置文件的结构。\n对应来看下配置文件：\n1234567891011121314151617&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;      &lt;property name=&quot;glmapper-name&quot; value=&quot;glmapper-demo&quot; /&gt;     &lt;contextName&gt;$&#123;glmapper-name&#125;&lt;/contextName&gt;             &lt;appender&gt;        //xxxx    &lt;/appender&gt;           &lt;logger&gt;        //xxxx    &lt;/logger&gt;        &lt;root&gt;                    //xxxx    &lt;/root&gt;  &lt;/configuration&gt;  \n\n\n\n\n\n\n\n\n\n\nps：想使用spring扩展profile支持，要以logback-spring.xml命名，其他如property需要改为springProperty\n\nscan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。\nscanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。\ndebug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。\n\ncontextName每个logger都关联到logger上下文，默认上下文名称为“default”。但可以使用contextName标签设置成其他名字，用于区分不同应用程序的记录\nproperty用来定义变量值的标签，property标签有两个属性，name和value；其中name的值是变量的名称，value的值时变量定义的值。通过property定义的值会被插入到logger上下文中。定义变量后，可以使“${name}”来使用变量。如上面的xml所示。\nlogger用来设置某一个包或者具体的某一个类的日志打印级别以及指定appender。\nroot根logger，也是一种logger，且只有一个level属性\nappender负责写日志的组件，下面会细说\nfilterfilter其实是appender里面的子元素。它作为过滤器存在，执行一个过滤器会有返回DENY，NEUTRAL，ACCEPT三个枚举值中的一个。\n\nDENY：日志将立即被抛弃不再经过其他过滤器\nNEUTRAL：有序列表里的下个过滤器过接着处理日志\nACCEPT：日志会被立即处理，不再经过剩余过滤器\n\n案例分析首先来配置一个非常简单的文件。这里申请下，我使用的是 logback-spring.xml。和 logback.xml 在properties上有略微差别。其他都一样。\n\n\n\n\n\n\n\n\n\n工程：springboot+web\n先来看下项目目录\n\nproperties中就是指定了日志的打印级别和日志的输出位置：\n1234#设置应用的日志级别logging.level.com.glmapper.spring.boot=INFO#路径logging.path=./logs\n\n通过控制台输出的loglogback-spring.xml的配置如下：123456789101112&lt;configuration&gt;    &lt;!-- 默认的控制台日志输出，一般生产环境都是后台启动，这个没太大作用 --&gt;    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %-5level %logger&#123;80&#125; - %msg%n&lt;/Pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;        &lt;root level=&quot;info&quot;&gt;        &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;\n\n打印日志的controller123456789101112private static final Logger LOGGER =LoggerFactory.getLogger(HelloController.class);@Autowiredprivate TestLogService testLogService;@GetMapping(&quot;/hello&quot;)public String hello()&#123;    LOGGER.info(&quot;GLMAPPER-SERVICE:info&quot;);    LOGGER.error(&quot;GLMAPPER-SERVICE:error&quot;);    testLogService.printLogToSpecialPackage();    return &quot;hello spring boot&quot;;&#125;\n\n验证结果：123401:50:39.633 INFO  com.glmapper.spring.boot.controller.HelloController- GLMAPPER-SERVICE:info01:50:39.633 ERROR com.glmapper.spring.boot.controller.HelloController- GLMAPPER-SERVICE:error\n\n上面的就是通过控制台打印出来的，这个时候因为我们没有指定日志文件的输出，因为不会在工程目录下生产logs文件夹。\n控制台不打印，直接输出到日志文件先来看下配置文件：\n1234567891011121314151617181920212223242526272829303132333435&lt;configuration&gt;    &lt;!-- 属性文件:在properties文件中找到对应的配置项 --&gt;    &lt;springProperty scope=&quot;context&quot; name=&quot;logging.path&quot;  source=&quot;logging.path&quot;/&gt;    &lt;springProperty scope=&quot;context&quot; name=&quot;logging.level&quot; source=&quot;logging.level.com.glmapper.spring.boot&quot;/&gt;    &lt;!-- 默认的控制台日志输出，一般生产环境都是后台启动，这个没太大作用 --&gt;    &lt;appender name=&quot;STDOUT&quot;        class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %-5level %logger&#123;80&#125; - %msg%n&lt;/Pattern&gt;        &lt;/encoder&gt;    &lt;/appender&gt;        &lt;appender name=&quot;GLMAPPER-LOGGERONE&quot;    class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;        &lt;append&gt;true&lt;/append&gt;        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;            &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;        &lt;/filter&gt;        &lt;file&gt;            $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log        &lt;/file&gt;        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;            &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt;            &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;        &lt;/rollingPolicy&gt;        &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;            &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;            &lt;charset&gt;UTF-8&lt;/charset&gt;        &lt;/encoder&gt;    &lt;/appender&gt;        &lt;root level=&quot;info&quot;&gt;        &lt;appender-ref ref=&quot;GLMAPPER-LOGGERONE&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;\n\n这里我们appender-ref指定的appender是GLMAPPER-LOGGERONE，因为之前没有名字为GLMAPPER-LOGGERONE的appender，所以要增加一个name为GLMAPPER-LOGGERONE的appender。\n注意上面这个配置，我们是直接接将root的appender-ref直接指定到我们的GLMAPPER-LOGGERONE这个appender的。所以控制台中将只会打印出bannar之后就啥也不打印了，所有的启动信息都会被打印在日志文件glmapper-loggerone.log中。\n\n但是实际上我们不希望我的业务日志中会包括这些启动信息。所以这个时候我们就需要通过logger标签来搞事情了。将上面的配置文件进行简单修改：\n12345678&lt;logger name=&quot;com.glmapper.spring.boot.controller&quot; level=&quot;$&#123;logging.level&#125;&quot;        additivity=&quot;false&quot;&gt;    &lt;appender-ref ref=&quot;GLMAPPER-LOGGERONE&quot; /&gt;&lt;/logger&gt;&lt;root level=&quot;$&#123;logging.level&#125;&quot;&gt;    &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;&lt;/root&gt;\n\n让root指向控制台输出；logger负责打印包com.glmapper.spring.boot.controller下的日志。\n验证结果还是通过我们的测试controller来打印日志为例，但是这里不会在控制台出现日志信息了。期望的日志文件在./logs/glmapper-spring-boot/glmapper-loggerone.log 。\n\nlogger和appender的关系上面两种是一个基本的配置方式，通过上面两个案例，我们先来了解下logger/appender/root之间的关系，然后再详细的说下logger和appender的配置细节。\n在最前面介绍中提到，root是根logger,所以他两是一回事；只不过root中不能有name 和additivity属性，是有一个level。\nappender是一个日志打印的组件，这里组件里面定义了打印过滤的条件、打印输出方式、滚动策略、编码方式、打印格式等等。但是它仅仅是一个打印组件，如果我们不使用一个logger或者root的appender-ref指定某个具体的appender时，它就没有什么意义。\n因此appender让我们的应用知道怎么打、打印到哪里、打印成什么样；而logger则是告诉应用哪些可以这么打。例如某个类下的日志可以使用这个appender打印或者某个包下的日志可以这么打印。\nappender 配置详解这里以上面案例中的名为GLMAPPER-LOGGERONE的appender说明：\n123456789101112131415161718&lt;appender name=&quot;GLMAPPER-LOGGERONE&quot;    class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;    &lt;append&gt;true&lt;/append&gt;    &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;        &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;    &lt;/filter&gt;    &lt;file&gt;        $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log    &lt;/file&gt;    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;        &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt;        &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;charset&gt;UTF-8&lt;/charset&gt;    &lt;/encoder&gt;&lt;/appender&gt;\n\nappender 有两个属性 name和class;name指定appender名称，class指定appender的全限定名。上面声明的是名为GLMAPPER-LOGGERONE，class为ch.qos.logback.core.rolling.RollingFileAppender的一个appender。\nappender 的种类\nConsoleAppender：把日志添加到控制台\nFileAppender：把日志添加到文件\nRollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。它是FileAppender的子类\n\nappend 子标签1&lt;append&gt;true&lt;/append&gt;\n如果是 true，日志被追加到文件结尾，如果是false，清空现存文件，默认是true。\nfilter 子标签在简介中提到了filter；作用就是上面说的。可以为appender 添加一个或多个过滤器，可以用任意条件对日志进行过滤。appender 有多个过滤器时，按照配置顺序执行。\nThresholdFilter临界值过滤器，过滤掉低于指定临界值的日志。当日志级别等于或高于临界值时，过滤器返回NEUTRAL；当日志级别低于临界值时，日志会被拒绝。\n123&lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;    &lt;level&gt;INFO&lt;/level&gt;&lt;/filter&gt;\n\nLevelFilter级别过滤器，根据日志级别进行过滤。如果日志级别等于配置级别，过滤器会根据onMath(用于配置符合过滤条件的操作) 和 onMismatch(用于配置不符合过滤条件的操作)接收或拒绝日志。\n12345&lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;     &lt;level&gt;INFO&lt;/level&gt;     &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;     &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;   &lt;/filter&gt; \n关于NEUTRAL、ACCEPT、DENY 见上文简介中关于filter的介绍。\nfile 子标签file 标签用于指定被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。\n123&lt;file&gt;    $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log&lt;/file&gt;\n\n这个表示当前appender将会将日志写入到$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log这个目录下。\nrollingPolicy 子标签这个子标签用来描述滚动策略的。这个只有appender的class是RollingFileAppender时才需要配置。这个也会涉及文件的移动和重命名（a.log-&gt;a.log.2018.07.22）。\nTimeBasedRollingPolicy最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。这个下面又包括了两个属性：\n\nFileNamePattern\nmaxHistory\n\n123456789&lt;rollingPolicy     class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;    &lt;!--日志文件输出的文件名:按天回滚 daily --&gt;    &lt;FileNamePattern&gt;        $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-loggerone.log.%d&#123;yyyy-MM-dd&#125;    &lt;/FileNamePattern&gt;    &lt;!--日志文件保留天数--&gt;    &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;&lt;/rollingPolicy&gt;\n上面的这段配置表明每天生成一个日志文件，保存30天的日志文件\nFixedWindowRollingPolicy根据固定窗口算法重命名文件的滚动策略。\nencoder 子标签对记录事件进行格式化。它干了两件事：\n\n把日志信息转换成字节数组\n把字节数组写入到输出流\n\n12345&lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;    &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125;    - %msg%n&lt;/pattern&gt;    &lt;charset&gt;UTF-8&lt;/charset&gt;&lt;/encoder&gt;\n\n目前encoder只有PatternLayoutEncoder一种类型。\n定义一个只打印error级别日志的appcener1234567891011121314151617181920212223 &lt;!-- 错误日志 appender ： 按照每天生成日志文件 --&gt;&lt;appender name=&quot;ERROR-APPENDER&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;    &lt;append&gt;true&lt;/append&gt;    &lt;!-- 过滤器，只记录 error 级别的日志 --&gt;    &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;        &lt;level&gt;error&lt;/level&gt;    &lt;/filter&gt;    &lt;!-- 日志名称 --&gt;    &lt;file&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-error.log&lt;/file&gt;    &lt;!-- 每天生成一个日志文件，保存30天的日志文件 --&gt;    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;        &lt;!--日志文件输出的文件名:按天回滚 daily --&gt;        &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-error.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt;        &lt;!--日志文件保留天数--&gt;        &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;        &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;!-- 编码 --&gt;        &lt;charset&gt;UTF-8&lt;/charset&gt;    &lt;/encoder&gt;&lt;/appender&gt;\n\n定义一个输出到控制台的appender123456&lt;!-- 默认的控制台日志输出，一般生产环境都是后台启动，这个没太大作用 --&gt;&lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;    &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;        &lt;Pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %-5level %logger&#123;80&#125; - %msg%n&lt;/Pattern&gt;    &lt;/encoder&gt;&lt;/appender&gt;\n\nlogger 配置详解1234&lt;logger name=&quot;com.glmapper.spring.boot.controller&quot;        level=&quot;$&#123;logging.level&#125;&quot; additivity=&quot;false&quot;&gt;    &lt;appender-ref ref=&quot;GLMAPPER-LOGGERONE&quot; /&gt;&lt;/logger&gt;\n上面的这个配置文件描述的是：com.glmapper.spring.boot.controller这个包下的$&#123;logging.level&#125;级别的日志将会使用GLMAPPER-LOGGERONE来打印。logger有三个属性和一个子标签：\n\nname:用来指定受此logger约束的某一个包或者具体的某一个类。\nlevel:用来设置打印级别（TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF），还有一个值INHERITED或者同义词NULL，代表强制执行上级的级别。如果没有设置此属性，那么当前logger将会继承上级的级别。\naddtivity:用来描述是否向上级logger传递打印信息。默认是true。\n\nappender-ref则是用来指定具体appender的。\n不同日志隔离打印案例在前面的例子中我们有三种appender,一个是指定包约束的，一个是控制error级别的，一个是控制台的。然后这小节我们就来实现下不同日志打印到不同的log文件中。\n根据包进行日志文件隔离这个例子里我们将com.glmapper.spring.boot.controller中的日志输出到glmapper-controller.log；将com.glmapper.spring.boot.service中的日志输出到glmapper-service.log。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!--打印日志到glmapper-service.log的appender--&gt;&lt;appender name=&quot;GLMAPPER-SERVICE&quot;          class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;    &lt;append&gt;true&lt;/append&gt;    &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;        &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;    &lt;/filter&gt;    &lt;file&gt;        $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-service.log    &lt;/file&gt;    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;        &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-service.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt;        &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;charset&gt;UTF-8&lt;/charset&gt;    &lt;/encoder&gt;&lt;/appender&gt;&lt;!--打印日志到glmapper-controller.log的appender--&gt;&lt;appender name=&quot;GLMAPPER-CONTROLLER&quot;          class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;    &lt;append&gt;true&lt;/append&gt;    &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;        &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;    &lt;/filter&gt;    &lt;file&gt;        $&#123;logging.path&#125;/glmapper-spring-boot/glmapper-controller.log    &lt;/file&gt;    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;        &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-controller.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt;        &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;charset&gt;UTF-8&lt;/charset&gt;    &lt;/encoder&gt;&lt;/appender&gt;&lt;!--此logger约束将.controller包下的日志输出到GLMAPPER-CONTROLLER，错误日志输出到GERROR-APPENDE；GERROR-APPENDE见上面--&gt;&lt;logger name=&quot;com.glmapper.spring.boot.controller&quot; level=&quot;$&#123;logging.level&#125;&quot; additivity=&quot;false&quot;&gt;    &lt;appender-ref ref=&quot;GLMAPPER-CONTROLLER&quot; /&gt;    &lt;appender-ref ref=&quot;GERROR-APPENDER&quot; /&gt;&lt;/logger&gt;&lt;!--此logger约束将.service包下的日志输出到GLMAPPER-SERVICE，错误日志输出到GERROR-APPENDE；GERROR-APPENDE见上面--&gt;&lt;logger name=&quot;com.glmapper.spring.boot.service&quot; level=&quot;$&#123;logging.level&#125;&quot; additivity=&quot;false&quot;&gt;    &lt;appender-ref ref=&quot;GLMAPPER-SERVICE&quot; /&gt;    &lt;appender-ref ref=&quot;GERROR-APPENDER&quot; /&gt;&lt;/logger&gt;\n\n来看运行结果\n1、glmaper-controller\n\n2、glmapper-service\n\n3、glmapper-error\n\n满足我们的预期，但是这里有个小问题。在info日志里出现了error,当然这是正常的。假如我们不想在info里面出现error怎么办呢？很简单，我们以APPENDER-SERVICE为例，将filter过滤器进行修改：\n将下面的：\n123&lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;    &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;&lt;/filter&gt;\n修改为：\n1234567&lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;    &lt;level&gt;ERROR&lt;/level&gt;    &lt;!-- 如果命中就禁止这条日志 --&gt;    &lt;onMatch&gt;DENY&lt;/onMatch&gt;      &lt;!-- 如果没有命中就使用这条规则 --&gt;    &lt;onMismatch&gt;ACCEPT&lt;/onMismatch&gt;  &lt;/filter&gt;\n\n这里同时要注意的是，在logger中level需要设置为info级别。\n根据类进行日志文件隔离这个其实也是和上面那个差不过，只不过粒度更细一点，一般情况下比如说我们有个定时任务类需要单独来记录其日志信息，这样我们就可以考虑使用基于类维度来约束打印。\n123456789101112131415161718192021222324252627&lt;!--特殊功能单独appender 例如调度类的日志--&gt;&lt;appender name=&quot;SCHEDULERTASKLOCK-APPENDER&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;    &lt;append&gt;true&lt;/append&gt;    &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;        &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;    &lt;/filter&gt;    &lt;file&gt;$&#123;logging.path&#125;/glmapper-spring-boot/scheduler-task-lock.log&lt;/file&gt;    &lt;!-- 每天生成一个日志文件，保存30天的日志文件 --&gt;    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;        &lt;!--日志文件输出的文件名:按天回滚 daily --&gt;        &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/scheduler-task-lock.log.%d&#123;yyyy-MM-dd&#125;&lt;/FileNamePattern&gt;        &lt;!--日志文件保留天数--&gt;        &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;        &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;!-- 编码 --&gt;        &lt;charset&gt;UTF-8&lt;/charset&gt;    &lt;/encoder&gt;&lt;/appender&gt;&lt;!--这里指定到了具体的某一个类--&gt;&lt;logger name=&quot;com.glmapper.spring.boot.task.TestLogTask&quot; level=&quot;$&#123;logging.level&#125;&quot; additivity=&quot;true&quot;&gt;        &lt;appender-ref ref=&quot;SCHEDULERTASKLOCK-APPENDER&quot; /&gt;        &lt;appender-ref ref=&quot;ERROR-APPENDER&quot; /&gt;    &lt;/logger&gt;\n最终TestLogTask中的日志将会被打印到这个自己独立的log文件中。如下所示：\n\n根据自定义 logger 的 name 进行日志文件隔离logger的name除了类、包等约束之外，当然还可以这样来玩。。。\n在进行案例之前，这里先把前面案例中logger声明的代码贴一下，以作对比,以TestLogTask类中的日志为例：\n12private static final Logger LOGGER =LoggerFactory.getLogger(TestLogTask.class);\n在getLogger中我们是将当前对象的class作为参数的，这个是为了打印时获取其全限定名的（见下面3-）。\n12341-2018-07-21 11:15:42.003 [pool-1-thread-1] 2-INFO  3-com.glmapper.spring.boot.task.TestLogTask -4-com.glmapper.spring.boot.task:info\n\n业务类定义我们同样是service包下定义一个类TestLogNameServiceImpl\n1234567891011121314package com.glmapper.spring.boot.service;@Service(&quot;testLogNameService&quot;)public class TestLogNameServiceImpl implements TestLogNameService &#123;    private static final Logger LOGGER =    LoggerFactory.getLogger(&quot;GLMAPPER-TEST-LOG&quot;);    @Override    public void print() &#123;        LOGGER.info(&quot;GLMAPPER-TEST-LOG:this is special logger-----info&quot;);        LOGGER.error(&quot;GLMAPPER-TEST-LOG:this is special logger-------error&quot;);    &#125;&#125;\nappender和logger配置123456789101112131415161718192021222324252627&lt;appender name=&quot;ROOT-APPENDER&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;    &lt;append&gt;true&lt;/append&gt;    &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;        &lt;level&gt;$&#123;logging.level&#125;&lt;/level&gt;    &lt;/filter&gt;    &lt;file&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-test.log&lt;/file&gt;    &lt;!-- 每天生成一个日志文件，保存30天的日志文件 --&gt;    &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt;        &lt;!--日志文件输出的文件名:按天回滚 daily --&gt;        &lt;FileNamePattern&gt;$&#123;logging.path&#125;/glmapper-spring-boot/glmapper-test.log.%d&#123;yyyy-MM-dd&#125;        &lt;/FileNamePattern&gt;        &lt;!--日志文件保留天数--&gt;        &lt;MaxHistory&gt;30&lt;/MaxHistory&gt;    &lt;/rollingPolicy&gt;    &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt;        &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt;        &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt;        &lt;!-- 编码 --&gt;        &lt;charset&gt;UTF-8&lt;/charset&gt;    &lt;/encoder&gt;&lt;/appender&gt;&lt;!--这里的name和业务类中的getLogger中的字符串是一样的--&gt;&lt;logger name=&quot;GLMAPPER-TEST-LOG&quot; level=&quot;$&#123;logging.level&#125;&quot; additivity=&quot;true&quot;&gt;        &lt;appender-ref ref=&quot;ROOT-APPENDER&quot; /&gt;        &lt;appender-ref ref=&quot;ERROR-APPENDER&quot; /&gt;    &lt;/logger&gt;\n\n我们这个预期的是TestLogNameServiceImpl中的日志不打印到glmapper-service.log中，而是打印到glmapper-test.log中。\n1、glmapper-test.log\n\n2、glmapper-service.log\n\n满足我们的预期。\n如何使用logback打印mybatis的sql语句这个还是比较坑的。为什么。看下这个：\n123&lt;settings&gt;    &lt;setting name=&quot;logImpl&quot; value=&quot;slf4j&quot; /&gt;&lt;/settings&gt;\n\n在mybatis-configration.xml中，我们通过这样一个配置项来关联到具体的日志组件。但是logImpl的实现中是没有logback的。那么怎么办呢？这里只能通过slf4j的方式桥接到logback。\n然后在我们的logback-spring.xml中进行如下配置：\n1234 &lt;!-- 将sql语句输出到具体的日志文件中 --&gt;&lt;logger name=&quot;com.alipay.sofa.cloudplatform.common.dao&quot; level=&quot;$&#123;logging.sql.level&#125;&quot; additivity=&quot;false&quot;&gt;    &lt;appender-ref ref=&quot;SQL-APPENDER&quot;/&gt;&lt;/logger&gt;\n这里有几个点需要注意的。首先是$&#123;logging.sql.level&#125;这个必须是debug，这个是由mybatis本身实现决定的。而这里的name设定的com.alipay.sofa.cloudplatform.common.dao值就是我们dao接口的包路径。\n网上看了一个比较典型的案例，这种方式只能输出到控制台，并不能将文件输出到日志文件；它是根据内部的一个实现机制偷了个懒。mybatis用logback日志不显示sql的解决办法。\n总结本篇博客主要是整理最近工作中的一些日志配置积累，将每个细节进行总结一下，以作备忘。如果有时间的话会考虑看一个日志框架的源码。其实我觉得还是很有必要的，日志组件毕竟是需要进行日志文件落盘的，这个会涉及到许多的性能问题、缓冲区问题、队列问题、当然还有一些锁的问题、同步打印或者异步打印等问题。有兴趣的小伙伴可以看看，然后分享给我们。\n后面准备写一写蚂蚁金服SOFABoot和SpringBoot的一些文章，如果有兴趣可以先看一波。\nSOFABoot GitHub 传送门\n","slug":"middleware/middleware-log-logback-config","date":"2018-11-10T13:24:52.000Z","categories_index":"Middleware","tags_index":"log,logback","author_index":"glmapper"},{"id":"ea749b0e098fcfc64d921f856c074bce","title":"JUC·Executor 框架","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903560371503112\n前言多线程和并发这两个东西真的是向往已久，总是有一种神秘的感觉，想去探索一波，又担心水平不够无法驾驭。想以读书笔记的方式来写，但是又觉得缺少自己的一些思考；但是在没有足够并发编程经验的情况下又没法去写出很深刻的东西，毕竟没有踩过坑。所以在阅读spring源码的同时，也想抽点时间来看一看JUC的东西，关于这块只能说是记录自己学习JUC的一个过程，尝试用一些具体的代码demo来加深理解。所以就把本系列写成《【 初识】-JUC·XXXX》，用来让自己打开并发编程的大门。\n\n\nJUCJUC即java.util.concurrent；也就是java提供的并发包。JUC中从包结构上来看主要是：\n\njava.util.concurrent\n  在这个包下面主要是线程池、并发集合以及一些并发工具类。线程池相关是围绕Excetor框架来构建；这也是本文下面部分的重点。\n\njava.util.concurrent.atomic\n  这个包下面是一些原子操作类，算是并发辅助工具类，基本实现依赖于CAS；\n\njava.util.concurrent.locks\n  这个从名字就可以知道它的作用，就是提供锁。\n\n\nJUC各个模块的类\n整体框架\n\n\n\natomic\n\n\n\nlocks\n\n\n\n并发集合\n\n\n\n并发工具\n\n\n\nforkJoin\n  fork-join在JUC中有下面三个类：\n  1public class ForkJoinPool extends AbstractExecutorService\n  1public abstract class ForkJoinTask&lt;V&gt; implements Future&lt;V&gt;, Serializable\n  1public class ForkJoinWorkerThread extends Thread\n\nFutureFuture提供了可以获取异步执行结果的方法，区别于Runnable的run方法，run是不提供返回结果的。\n1234567891011121314public interface Future&lt;V&gt; &#123;    //取消    boolean cancel(boolean mayInterruptIfRunning);    //如果任务完成前被取消，则返回true。    boolean isCancelled();    //如果任务执行结束，无论是正常结束或是中途取消还是发生异常，都返回true。    boolean isDone();    //获取异步执行的结果，如果没有结果可用，此方法会阻塞直到异步计算完成。    V get() throws InterruptedException, ExecutionException;    //获取异步执行结果，如果没有结果可用，此方法会阻塞，但是会有时间限制，    //如果阻塞时间超过设定的timeout时间，该方法将抛出异常。    V get(long timeout, TimeUnit unit) throws InterruptedException,     ExecutionException, TimeoutException;&#125;\n\nCallable声明了一个名称为call()的方法，同时这个方法可以有返回值V，也可以抛出异常\n123public interface Callable&lt;V&gt; &#123;   V   call()   throws Exception; &#125; \n\n关于Callable和Future的使用一般情况下都是结合我们的线程池来使用的。\nExecutorExecutor接口是线程池实现的顶级接口，其和spring中的BeanFactory所承担的角色差不多，就是提供顶级的功能约束，具体实现交于不同子类来完成。\n12345678910111213public interface Executor &#123;    /**     * Executes the given command at some time in the future.  The command     * may execute in a new thread, in a pooled thread, or in the calling     * thread, at the discretion of the &lt;tt&gt;Executor&lt;/tt&gt; implementation.     *     * @param command the runnable task     * @throws RejectedExecutionException if this task cannot be     * accepted for execution.     * @throws NullPointerException if command is null     */    void execute(Runnable command);&#125;\n下面是JUC中Executor框架的整体结构：\n\nExecutorService12345678910111213141516171819202122232425262728293031323334353637383940414243public interface ExecutorService extends Executor &#123;    //关闭线程池    void shutdown();        List&lt;Runnable&gt; shutdownNow();    //是否为Shutdown状态    boolean isShutdown();    //是否为Terminated状态    boolean isTerminated();        //超过超时时间时，会监测ExecutorService是否已经关闭    //若关闭则返回true，否则返回false。    //一般情况下会和shutdown方法组合使用。    boolean awaitTermination(long timeout, TimeUnit unit)        throws InterruptedException;        //返回一个Future对象，参数接收的是一个Callable的实现    //Callable接口中的call()方法有一个返回值，可以返回任务的执行结果    //区别于Runnable接口中的run()方法（void修饰，没有返回值）。    &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);        &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);    //返回一个Future对象，通过返回的Future对象，我们可以检查提交的任务是否执行完成了。     Future&lt;?&gt; submit(Runnable task);        //返回一个Future的List，其中对应着每个Callable任务执行后的Future对象。    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)        throws InterruptedException;    //增加了超时控制        &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,                                  long timeout, TimeUnit unit)        throws InterruptedException;                    //接收参数是一个Callable的集合，    //返回的是所有Callable集合任务中某一个任务的执行结果    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)        throws InterruptedException, ExecutionException;    //增加了超时控制    &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,                    long timeout, TimeUnit unit)        throws InterruptedException, ExecutionException, TimeoutException;&#125;\n\nExecutorService 再Executor接口的基础上扩展了对线程池状态的控制以及提交任务执行的超时控制。线程池的基本功能还不够完善，不能真正的具备处理具体业务的能力（毕竟是个接口，O(∩_∩)O哈哈~）。\n","slug":"java/java-advance-juc-executor","date":"2018-11-10T06:16:22.000Z","categories_index":"JAVA","tags_index":"并发编程,JUC,Executor","author_index":"glmapper"},{"id":"f1ca72d2339ef0d0df0ca0f7ea0b32bd","title":"怎么写一个死锁？","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903520886325255\n看着看着就想着怎么能写一个死锁呢，打开 eclipse，突然感觉无从下手；之前都是一直在解决阻塞、死锁这些问题，现在反过来去写一个死锁感觉有点莫名奇妙。。。\nok, 写一个死锁就要有一种场景，并且满足死锁的条件。\n\n互斥条件：一个资源每次只能被一个进程使用。\n请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放\n不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。\n循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。\n\n\n\n首先要有竞争的资源，并且两个线程要同时都在等待对方释放资源。那我们先弄两个资源：\n12Object lock=new Object();Object lock2=new Object();\n然后有两个线程：\n12345Tr1 tr1=new Tr1(lock, lock2);Tr2 tr2=new Tr2(lock, lock2);\t\tThread t1=new Thread(tr1);Thread t2=new Thread(tr2);\n启动：\n12t1.start();t2.start();\n那么对于lock，lock2怎么再线程内部产生竞争关系呢？来看代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.glmapper.base.synchronize;public class Tr1 implements Runnable &#123;\tObject lock;\tObject lock2;\tpublic Tr1(Object lock,Object lock2)&#123;\t\tthis.lock= lock;\t\tthis.lock2= lock2;\t&#125;\t@Override\tpublic void run() &#123;\t    //获取lock\t\tsynchronized (lock) &#123;\t\t\tSystem.out.println(Thread.currentThread().getName()+&quot;获取了lock锁&quot;);\t\t\ttry &#123;\t\t\t\tThread.sleep(3000);\t\t\t&#125; catch (Exception e) &#123;\t\t\t&#125;\t\t\t//获取lock2\t\t\tsynchronized (lock2) &#123;\t\t\t\tSystem.out.println(Thread.currentThread().getName()+&quot;获取了lock2锁&quot;);\t\t\t&#125;\t\t&#125;\t&#125;&#125;public class Tr2 implements Runnable &#123;\t\tObject lock;\tObject lock2;\tpublic Tr2(Object lock,Object lock2)&#123;\t\tthis.lock= lock;\t\tthis.lock2= lock2;\t&#125;\t@Override\tpublic void run() &#123;\t    //获取lock2\t\tsynchronized (lock2) &#123;\t\t\tSystem.out.println(Thread.currentThread().getName()+&quot;获取了lock2锁&quot;);\t\t\ttry &#123;\t\t\t\tThread.sleep(3000);\t\t\t&#125; catch (Exception e) &#123;\t\t\t&#125;\t\t\t//获取lock\t\t\tsynchronized (lock) &#123;\t\t\t\tSystem.out.println(Thread.currentThread().getName()+&quot;获取了lock锁&quot;);\t\t\t&#125;\t\t&#125;\t\t\t&#125;&#125;\n分析一下：当线程1获取lock时，线程2获取了lock2锁；然后线程1继续执行，到这里，\n123synchronized (lock2) &#123;\tSystem.out.println(Thread.currentThread().getName()+&quot;获取了lock2锁&quot;);&#125;\n此时需要获取到lock2这个锁，但是lock2现在被线程2持有；同时，线程2也开始执行到：\n123synchronized (lock) &#123;\tSystem.out.println(Thread.currentThread().getName()+&quot;获取了lock锁&quot;);&#125;\n此时线程2也在尝试获取lock这把锁，但是lock又被线程1持有了。两个线程都在等待对方释放资源，造成了死锁。OK，完成了。。。当我准备关机时，发现还在等呢？？？那为什么呢？？我们开看下发生了什么….\n\n通过jps来看下我们程序进程\n使用jstack -l 【pid】 来看下信息\n\n两个线程都处于BLOCKED状态了…,继续往下看found 1 deadlock.如我们所愿，死锁发生了！\n","slug":"java/java-advance-juc-thread-deadlock","date":"2018-11-10T05:55:55.000Z","categories_index":"JAVA","tags_index":"thread,lock,并发编程","author_index":"glmapper"},{"id":"9c34f2d9e4aaac9e5f4272c83ef2d6d2","title":"并发编程---进程、线程安全","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903502154563597\n在 java 中，所有的变量（实例字段，静态字段，构成数组的元素，不包括局部变量和方法参数）都存储在主内存中，内个线程都有自己的工作内存，线程的工作内存保存被线程使用到的变量的主内存副本拷贝。线程对变量的所有操作都必须在工作内存中进行，为不能直接读写主内存的变量。不同线程之间也不恩能够直接访问对方工作内存中的变量，线程间比变量值的传递通过主内存来完成。\n本文主要是了解并发编程中的涉及一些基础概念，如：临界区、互斥量、CAS、重排序以及 Java 语言中的一些关键字。\n\n\n临界区保证在某一时刻只有一个线程能访问数据的简便方法，在任意时刻只允许一个线程对资源进行访问。如果有多个线程试图同时访问临界区，那么在有一个线程进入后，其他所有试图访问临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操作共享资源的目的\n互斥量互斥量和临界区很相似，只能拥有互斥对象的线程才能具有访问资源的权限，由于互斥对象只有一个，因此就决定了任何情况下次共享资源都不会同时被多个线程所访问。当前占据资源的线程在任务处理完后应将拥有的互斥对象交出，以便其他线程在获得后可以访问资源。互斥量比临界区复杂，因为使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。\n管程&#x2F;信号量管程和信号量是同一个概念。指一个互斥独占锁定的对象或称为互斥体。在给定的时间，仅有一个线程可以获得管程。当一个线程需要锁定，他必须进入管程。所有其他的试图进入已经锁定的管程的线程必须挂起直到第一个线程退出管程。这些其他的线程被称为等待线程。一个拥有管程的线程如果愿意的话可以再次进入相同的管程（可重入性）\nCAS操作CAS操作（compare  and swap）CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则返回V。这是一种乐观锁的思路，它相信在它修改之前，没有其它线程去修改它；而Synchronized是一种悲观锁，它认为在它修改之前，一定会有其它线程去修改它，悲观锁效率很低。下面来看一下AtomicInteger是如何利用CAS实现原子性操作的。\n重排序编译器和处理器为了提高性能，而在程序执行时会对程序进行重排序。他的出现是为了提高程序的并发度。从而提高性能；但是对于多线程程序，重排序可能会导致程序执行的结果不是我们需要的结果，重排序分为编译器和处理器俩个方面。而处理器重排序包括指令级重排序和内存重排序。\nJAVA中线程安全相关关键字及类主要包括：synchronized，Volitile，ThreadLocal，Lock，Condition\n2.1 Volitile作用：\n\n1）保证了心智能立即存储到主内存才，每次使用前立即从主内存中刷新\n2）禁止指令重排序优化\n\nVolitile关键字不能保证在多线程环境下对共享数据的操作的正确性，可以使用在自己状态改变之后需要立即通知所有线程的情况下，只保证可见性，不保证原子性。即通过刷新变量值确保可见性。\nJava中synchronized和final也能保证可见性\nsynchronized：同步快通过变量锁定前必须清空工作内存中的变量值，重新从主内存中读取变量值，解锁前必须把变量值同步回主内存来确保可见性。\nfinal:被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this引用传递进去，那么在其他线程中就能看见final字段的值，无需同步就可以被其他线程正确访问。\n2.2 synchronized把代码块声明为synchronized，有俩个作用，通常是指改代码具有原子性和可见性。如果没有同步机制提供的这种可见性，线程看到的共享比那里可能是修改前的值或不一致的值，这将引发许多严重问题。\n原理：当对象获取锁是，他首先是自己的高速缓存无效，这样就可以保证直接从主内存中装入变量，同样在对象释放锁之前，他会刷新其高速缓存，强制使已做的任何更改都出现在主内存中，这样会保证在同一个锁上同步的俩个线程看到在synchronized块内修改的变量的相同值。\nsynchronized 释放由JVM自己管理。\n存在的问题：\n\n1）无法中断一个正在等待获得锁的线程\n2）无法通过投票得到锁，如果不想等待下去，也就没法得到锁\n3）同步还需要锁的释放只能在与获得锁所在的堆栈帧相同的堆栈中进行，多数情况下，这没问题（而且与一场处理交互的很好），但是，确实存在一些非块结构的锁定更适合情况。\n\n2.3 LockLock是有JAVA编写而成的，在java这个层面是无关JVM实现的。包括：ReentrantLock，ReadWriteLock。其本质都依赖于AbstractQueueSynchronized类。Lock提供了很多锁的方式，尝试锁，中断锁等。释放锁的过程由JAVA开发人员自己管理。\n就性能而言，对于资源冲突不多的情况下synchronized更加合理，但如果资源访问冲突多的情况下，synchronized的性能会快速下降，而Lock可以保持平衡。\n2.4 conditionCondition将Object监视器方法（wait，notify,notifyall）分解成截然不同的对象，以便通过这些对象与任意Lock实现组合使用，为每个对象提供多个等待set(wait-set),，其中Lock替代了synchronized方法和语句的使用，condition替代了Object监视器方法的使用。Condition实例实质上被你绑定到一个锁上。要为特定Lock实例获得Condition实例，请使用其newCondition（）方法。\n2.5 ThreadLock线程局部变量。\n变量是同一个，但是每个线程都使用同一个初始值，也就是使用同一个变量的一个新的副本，这种情况下TreadLocal就非常有用。\n应用场景：当很多线程需要多次使用同一个对象，并且需要该对象具有相同初始值的时候，最适合使用TreadLocal。\n事实上，从本质上讲，就是每个线程都维持一个MAP，而这个map的key就是TreadLocal,而值就是我们set的那个值，每次线程在get的时候，都从自己的变量中取值，既然从自己的变量中取值，那就肯定不存在线程安全的问题。总体来讲，TreadLocal这个变量的状态根本没有发生变化。它仅仅是充当了一个key的角色，另外提供给每一个线程一个初始值。如果允许的话，我们自己就能实现一个这样的功能，只不过恰好JDK就已经帮助我们做了这个事情。\n使用TreadLocal维护变量时，TreadLocal为每个使用该变量的线程提供独立地变量副本，所以每一个线程都可以独立地改变自己的副本，而不会英语其他线程所对应的副本。从线程的角度看，目标变量对象是线程的本地变量，这也是类名中Local所需要表达的意思。\nTreadLocal的四个方法：\n\nvoid set(Object val),设置当前线程的线程局部变量的值\nObject get（）返回当前线程所对用的线程局部变量。\nvoid remove() 将当前线程局部变量的值删除，目的是为了减少内存的占用，线程结束后，局部变量自动被GC\nObject  initValue() 返回该线程局部变量的初始值，使用protected修饰，显然是为了让子类覆盖而设计的。\n\n线程安全的实现方式3.1 互斥同步在多线程访问的时候，保证同一时间只有一条线程使用。临界区，互斥量，管程都是同步的一种手段。\njava 中最基本的互斥同步手段是synchronized，编译之后会形成monitorenter和monitorexit这俩个字节码指令，这俩个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象，还有一个锁的计数器，来记录加锁的次数，加锁几次就要同样解锁几次才能恢复到无锁状态。\njava 的线程是映射到操作系统的原生线程之上的，不管阻塞还是唤醒都需要操作系统的帮助完成，都需要从用户态转换到核心态，这是很耗费时间的，是 java 语言中的一个重量级的操作，虽然虚拟机本身会做一点优化的操作，比如通知操作系统阻塞之前会加一段自旋等待的过程，避免频繁切换到核心态。\n3.2 非阻塞同步互斥和同步最主要的问题就是阻塞和唤醒所带来的性能的问题，所以这通常叫阻塞同步（悲观的并发策略）.随着硬件指令集的发展，我们有另外的选择：基于冲突检测的乐观并发策略，通俗讲就是先操作，如果没有其他线程争用共享的数据，操作就成功，如果有，则进行其他的补偿（最常见的就是不断的重试）。这种乐观的并发策略许多实现都不需要把线程先挂起，这种同步操作被称为非阻塞同步。\n3.3 无同步部分代码天生就是线程安全的，不需要同步。\n\n1）可重入代码：纯代码，具有不依赖存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等特征，它的返回结果是可以预测的。\n2）线程本地存储：把共享数据的可见性范围限制在同一个线程之内，这样就无需同步也能保证线程之间不出现数据争用问题。可以通过java.lang.TreadLocal类来实现线程本地存储的功能。\n\n","slug":"java/java-advance-juc-thread-process","date":"2018-11-10T05:39:42.000Z","categories_index":"JAVA","tags_index":"thread,并发编程","author_index":"glmapper"},{"id":"e760e8eb6263e803ada2984a9066d5b1","title":"分布式链路跟踪组件 SOFATracer 和 Zipkin 模型转换原理","content":"\n\n\n\n\n\n\n\n\n分布式链路跟踪组件 SOFATracer 和 Zipkin 模型转换\n","slug":"sofa/sofa-tracer-zipkin-model-convert","date":"2018-11-10T04:33:56.000Z","categories_index":"SOFA","tags_index":"分布式链路跟踪,Tracer,Zipkin","author_index":"glmapper"},{"id":"ef8677c434be29d2befc4ae95f7a33d3","title":"SOFATracer 中 Disruptor 实践","content":"OpenTraceing 规范\nOpenTracing语义标准\n语义惯例\n官方文档\n\n\n\nSOFATracer 对 OpenTraceing 的实现\n\n\n\n\n\n\n\n\nSOFATracer  就是根据 OpenTracing 规范 衍生出来的分布式 链路跟 踪的解决方案。\n\nGitHub SOFATrcer\n\n概念OpenTracing 标准中有三个重要的相互关联的类型，分别是Tracer, Span和 SpanContext。\n\n\n\n\n\n\n\n\n\n【下面的概念说明过程中，如不做说明，所使用的案例代码均以SOFATracer中的实现为例。】\nTracer一个 trace 代表一个潜在的，分布式的，存在并行数据或并行执行轨迹（潜在的分布式、并行）的系统。一个trace可以认为是多个span的有向无环图（DAG）。\nTracer接口用来创建Span，以及处理如何处理Inject(serialize) 和 Extract (deserialize)，用于跨进程边界传递。\nSOFATracer 中 SofaTracer 这个类实现了 opentracing 的 Tracer 接口，并在此规范接口上做了一些扩展。看下Tracer 中声明的方法：\n123456789101112public interface Tracer &#123;    //启动一个新的span    SpanBuilder buildSpan(String operationName);    //将SpanContext上下文Inject（注入）到carrier    &lt;C&gt; void inject(SpanContext spanContext, Format&lt;C&gt; format, C carrier);    //将SpanContext上下文从carrier中Extract（提取）    &lt;C&gt; SpanContext extract(Format&lt;C&gt; format, C carrier);           interface SpanBuilder &#123;    // 省略    &#125; &#125;\n\n所以从接口定义来看，要实现一个Tracer，必须要实现其以下的几个能力：\n启动一个新的spanSOFATracer 实现了 Tracer 中 buildSpan 方法：\n1234@Overridepublic SpanBuilder buildSpan(String operationName) &#123;    return new SofaTracerSpanBuilder(operationName);&#125;\n\noperationName :操作名称，字符串类型，表示由Span完成的工作 (例如，RPC方法名称、函数名称或一个较大的计算任务中的阶段的名称)。操作名称应该用泛化的字符串形式标识出一个Span实例。\n何为泛化的字符串形式，比如现在有一个操作：获取用户 ；下面有几种标识方式：\n\n1、&#x2F;get\n2、&#x2F;get&#x2F;user\n3、&#x2F;get&#x2F;user&#x2F;123\n\n方式1过于抽象，方式3过于具体。方式2是正确的操作名。\n将SpanContext上下文Inject（注入）到carrier12345678@Overridepublic &lt;C&gt; void inject(SpanContext spanContext, Format&lt;C&gt; format, C carrier) &#123;    RegistryExtractorInjector&lt;C&gt; registryInjector = TracerFormatRegistry.getRegistry(format);    if (registryInjector == null) &#123;        throw new IllegalArgumentException(&quot;Unsupported injector format: &quot; + format);    &#125;    registryInjector.inject((SofaTracerSpanContext) spanContext, carrier);&#125;\n\n\nSpanContext :实例\nformat（格式化）描述，一般会是一个字符串常量，但不做强制要求。通过此描述，通知Tracer实现，如何对SpanContext进行编码放入到carrier中。carrier，根据format确定。Tracer实现根据format声明的格式，将SpanContext序列化到carrier对象中。\n\n\n\n\n\n\n\n\n\n\nRegistryExtractorInjector 见后面\n将SpanContext上下文从carrier中Extract（提取）12345678@Overridepublic &lt;C&gt; SpanContext extract(Format&lt;C&gt; format, C carrier) &#123;    RegistryExtractorInjector&lt;C&gt; registryExtractor = TracerFormatRegistry.getRegistry(format);    if (registryExtractor == null) &#123;        throw new IllegalArgumentException(&quot;Unsupported extractor format: &quot; + format);    &#125;    return registryExtractor.extract(carrier);&#125;\n\n\n格式描述符(format descriptor)(通常但不一定是字符串常量)，告诉Tracer的实现如何在载体对象中对SpanContext进行编码\n载体(carrier)，其类型由格式描述符指定。Tracer的实现将根据格式描述对此载体对象中的SpanContext进行编码\n\n返回一个SpanContext实例，可以使用这个SpanContext实例，通过Tracer创建新的Span。\nFormat从Tracer的注入和提取来看，format都是必须的。\nInject（注入）和Extract（提取）依赖于可扩展的format参数。format参数规定了另一个参数&quot;carrier&quot;的类型，同时约束了&quot;carrier&quot;中SpanContext是如何编码的。所有的Tracer实现，都必须支持下面的format。\n\nText Map: 基于字符串：字符串的map,对于key和value不约束字符集。\nHTTP Headers: 适合作为HTTP头信息的，基于字符串：字符串的map。（RFC 7230.在工程实践中，如何处理HTTP头具有多样性，强烈建议tracer的使用者谨慎使用HTTP头的键值空间和转义符）\nBinary: 一个简单的二进制大对象，记录SpanContext的信息。\n\n在上面的注入和提取代码中，有如下代码片段：\n123456//注入RegistryExtractorInjector&lt;C&gt; registryInjector  =     TracerFormatRegistry.getRegistry(format);//提取RegistryExtractorInjector&lt;C&gt; registryExtractor =     TracerFormatRegistry.getRegistry(format);\n\n来通过TracerFormatRegistry这个类来来看下 SOFATracer 中的 Format 的具体实现。\nX-B3在看Format之前，先了解下X-B3。\n12Access-Control-Expose-Headers: X-B3-TraceId,X-B3-ParentSpanId,X-B3-SpanId\n\nHTTP请求时其span参数通过http headers来传递追踪信息；header中对应的key分别是:\n\nX-B3-TraceId: 64 encoded bits（id被encode为hex Strings）\nX-B3-SpanId : 64 encoded bits\nX-B3-ParentSpanId: 64 encoded bits\nX-B3-Sampled:(是否采样) Boolean (either “1” or “0”)（下面的调用是否进行采样）\nX-B3-Flags:a Long\n\nSOFATracer 中的 Format具体代码在 tracer-core -&gt; com.alipay.common.tracer.core.registy 包下:\n\nTextMapFormatter\nTextMapB3Formatter\nHttpHeadersFormatter\nHttpHeadersB3Formatter\nBinaryFormater\n\nBinaryFormater：这个的注入和提取实现没有编解码一说；本身就是基于二进制流的操作。\nTextMapB3Formatter&#x2F;TextMapFormatter 和 HttpHeadersB3Formatter&#x2F;HttpHeadersFormatter 区别就在于编解码不同。HttpHeadersB3Formatter使用的是 URLDecoder.decode &amp;&amp; URLDecoder.encode ; TextMapB3Formatter 返回的是值本身（如果为空或者null则返回空字符串）。\nTextMapFormatter和TextMapB3Formatter区别在于注入或者提取是使用的key不用。TextMapB3Formatter中使用的是 x-b3-&#123;&#125; 的字符串作为key。\nSpan一个span代表系统中具有开始时间和执行时长的逻辑运行单元。span之间通过嵌套或者顺序排列建立逻辑因果关系。当Span结束后(span.finish())，除了通过Span获取SpanContext外，下列其他所有方法都不允许被调用。\n同样先来看下opentracing规范 api 定义的 span 的定义及方法：\n123456789101112131415161718public interface Span extends Closeable &#123;    SpanContext context();    void finish();    void finish(long finishMicros);    void close();    Span setTag(String key, String value);    Span setTag(String key, boolean value);    Span setTag(String key, Number value);    Span log(Map&lt;String, ?&gt; fields);    Span log(long timestampMicroseconds, Map&lt;String, ?&gt; fields);    Span log(String event);    Span log(long timestampMicroseconds, String event);    Span setBaggageItem(String key, String value);    String getBaggageItem(String key);    Span setOperationName(String operationName);    Span log(String eventName, /* @Nullable */ Object payload);    Span log(long timestampMicroseconds, String eventName, /* @Nullable */ Object payload);&#125; \n\n通过Span获取SpanContext12345//SOFATracerSpan@Overridepublic SpanContext context() &#123;    return this.sofaTracerSpanContext;&#125;\n\n返回值，Span构建时传入的SpanContext。这个返回值在Span结束后(span.finish())，依然可以使用。\n复写操作名12345@Overridepublic Span setOperationName(String operationName) &#123;    this.operationName = operationName;    return this;&#125;\n\noperationName:新的操作名，覆盖构建Span时，传入的操作名。\n结束Span123456789101112@Overridepublic void finish() &#123;    this.finish(System.currentTimeMillis());&#125;@Overridepublic void finish(long endTime) &#123;    this.setEndTime(endTime);    //关键记录:report span    this.sofaTracer.reportSpan(this);    SpanExtensionFactory.logStoppedSpan(this);&#125;\n\n有一个可选参数，如果指定完成时间则使用当前指定的时间；如果省略此参数，使用当前时间作为完成时间。finish方法中会将当前span进行report操作。\n为Span设置tagTag 是一个key:value格式的数据。key必须是String类型，value可以是字符串、布尔或者数字。\n\n字符串类型的value 设置tag\n\n1234567891011121314151617181920@Overridepublic Span setTag(String key, String value) &#123;    if (StringUtils.isBlank(key) || StringUtils.isBlank(value)) &#123;        return this;    &#125;    this.tagsWithStr.put(key, value);    //注意:server 还是 client 在 OpenTracing 标准中是用 tags 标识的,所以在这里进行判断    if (isServer()) &#123;        Reporter serverReporter = this.sofaTracer.getServerReporter();        if (serverReporter != null) &#123;            this.setLogType(serverReporter.getReporterType());        &#125;    &#125; else if (isClient()) &#123;        Reporter clientReporter = this.sofaTracer.getClientReporter();        if (clientReporter != null) &#123;            this.setLogType(clientReporter.getReporterType());        &#125;    &#125;    return this;&#125;\n\n\n布尔类型的value 设置tag\n\n1234public Span setTag(String key, boolean value) &#123;    this.tagsWithBool.put(key, value);    return this;&#125;\n\n\n数字类型的value 设置tag\n\n1234567public Span setTag(String key, Number number) &#123;    if (number == null) &#123;        return this;    &#125;    this.tagsWithNumber.put(key, number);    return this;&#125;\n\nLog结构化数据1234567891011@Overridepublic Span log(long currentTime, Map&lt;String, ?&gt; map) &#123;    AssertUtils.isTrue(currentTime &gt;= startTime, &quot;current time must greater than start time&quot;);    this.logs.add(new LogData(currentTime, map));    return this;&#125;@Overridepublic Span log(Map&lt;String, ?&gt; map) &#123;    return this.log(System.currentTimeMillis(), map);&#125;\n\n\nMap&lt;String, ?&gt; map : 键必须是字符串类型，值可以是任意类型\ncurrentTime : 时间戳。如果指定时间戳，那么它必须在span的开始和结束时间之内。\n\n设置一个baggage（随行数据）元素Baggage元素是一个键值对集合，将这些值设置给给定的Span，Span的SpanContext，以及所有和此Span有直接或者间接关系的本地Span。 也就是说，baggage元素随trace一起保持在带内传递。（译者注：带内传递，在这里指，随应用程序调用过程一起传递）\nBaggage元素为OpenTracing的实现全栈集成，提供了强大的功能 （例如：任意的应用程序数据，可以在移动端创建它，显然的，它会一直传递了系统最底层的存储系统。由于它如此强大的功能，他也会产生巨大的开销，请小心使用此特性。\n再次强调，请谨慎使用此特性。每一个键值都会被拷贝到每一个本地和远程的下级相关的span中，因此，总体上，他会有明显的网络和CPU开销。\n12345@Overridepublic Span setBaggageItem(String key, String value) &#123;    this.sofaTracerSpanContext.setBizBaggageItem(key, value);    return this;&#125;\n\nSofaTracerSpan 中的属性\nsofaTracer  : 当前 tracer\nspanReferences : 当前span的关系，ChildOf(引用) or FollowsFrom（跟随）\ntagsWithStr : String 类型的tag 集合\ntagsWithBool : 布尔类型的tag集合\ntagsWithNumber : 数值类型的tag集合\nlogs : log结构化数据列表，通过span.log（map）操作的map,均存储在logs中。\noperationName：当前span的操作名\nsofaTracerSpanContext：当前 spanContext\nstartTime : 当前span 开始时间\nendTime  : 当前span 结束时间，在finish方法中传入。\nlogType : report时才有意义:摘要日志类型,日志能够正确打印的关键信息；当前 span 的日志类型,如:客户端为 rpc-client-digest.log,服务端为 rpc-server-digest.log\nparentSofaTracerSpan：父亲 span,当作为客户端结束并弹出线程上下文时,需要将父亲 span 再放入\n\nSpanContextopentracing 中 SpanContext 接口中只有一个baggageItems方法，通过这个方法来遍历所有的baggage元素。\n123public interface SpanContext &#123;    Iterable&lt;Map.Entry&lt;String, String&gt;&gt; baggageItems();&#125;\n\n相对于OpenTracing中其他的功能，SpanContext更多的是一个“概念”。也就是说，OpenTracing实现中，需要重点考虑，并提供一套自己的API。\nOpenTracing的使用者仅仅需要，在创建span、向传输协议Inject（注入）和从传输协议中Extract（提取）时，使用SpanContext和references，\nOpenTracing要求，SpanContext是不可变的，目的是防止由于Span的结束和相互关系，造成的复杂生命周期问题。\nDisruptor 简介\n\n\n\n\n\n\n\n\nA High Performance Inter-Thread Messaging Library 高性能的线程间消息传递库\n关于 Disruptor 的 一些原理分析可以参考：disruptor\n案例先通过 Disruptor 的一个小例子来有个直观的认识；先看下它的构造函数：\n1234567891011public Disruptor(        final EventFactory&lt;T&gt; eventFactory,        final int ringBufferSize,        final ThreadFactory threadFactory,        final ProducerType producerType,        final WaitStrategy waitStrategy)&#123;    this(        RingBuffer.create(producerType, eventFactory, ringBufferSize, waitStrategy),        new BasicExecutor(threadFactory));&#125;\n\n\neventFactory : 在环形缓冲区中创建事件的 factory\nringBufferSize:环形缓冲区的大小，必须是2的幂。\nthreadFactory：用于为处理器创建线程。\nproducerType：生成器类型以支持使用正确的sequencer和publisher创建RingBuffer；枚举类型，SINGLE、MULTI两个项。对应于 SingleProducerSequencer和MultiProducerSequencer两种Sequencer。\nwaitStrategy : 等待策略；\n\n如果我们想构造一个disruptor,那么我们就需要上面的这些组件。从eventFactory来看，还需要一个具体的Event来作为消息事件的载体。【下面按照官方给的案例进行简单的修改作为示例】\n消息事件 LongEvent ，能够被消费的数据载体123456789public class LongEvent &#123;    private long value;    public void set(long value) &#123;        this.value = value;    &#125;    public long getValue() &#123;        return value;    &#125;&#125;\n\n创建消息事件的factory123456public class LongEventFactory implements EventFactory&lt;LongEvent&gt; &#123;    @Override    public LongEvent newInstance() &#123;        return new LongEvent();    &#125;&#125;\n\nConsumerThreadFactory1234567public class ConsumerThreadFactory implements ThreadFactory &#123;    private final AtomicInteger index = new AtomicInteger(1);    @Override    public Thread newThread(Runnable r) &#123;        return new Thread(r, &quot;disruptor-thread-&quot; + index.getAndIncrement());    &#125;&#125;\n\nOK ，上面的这些可以满足创建一个disruptor了：\n123456789101112131415private int ringBufferCapacity = 8;//消息事件生产FactoryLongEventFactory longEventFactory = new LongEventFactory();//执行事件处理器线程FactoryConsumerThreadFactory consumerThreadFactory = new ConsumerThreadFactory();//用于环形缓冲区的等待策略。WaitStrategy waitStrategy = new BlockingWaitStrategy();//构建disruptorDisruptor&lt;LongEvent&gt; disruptor = new Disruptor&lt;&gt;(    longEventFactory,    ringBufferCapacity,    longEventThreadFactory,    ProducerType.SINGLE,    waitStrategy);\n\n现在是已经有了 disruptor 了，然后通过：start 来启动：\n12//启动 disruptor disruptor.start();\n\n到这里，已经构建了一个disruptor；但是目前怎么使用它来发布消息和消费消息呢？\n发布消息下面在 for 循环中 发布 5 条数据：\n12345678910RingBuffer&lt;LongEvent&gt; ringBuffer = disruptor.getRingBuffer();for (long l = 0; l &lt; 5; l++)&#123;    long sequence = ringBuffer.next();    LongEvent event = ringBuffer.get(sequence);    event.set(100+l);    System.out.println(&quot;publish event :&quot; + l);    ringBuffer.publish(sequence);    Thread.sleep(1000);&#125;\n\n消息已经发布，下面需要设定当前disruptor的消费处理器。前面已经有个LongEvent 和 EventFactory ; 在disruptor中是通过 EventHandler 来进行消息消费的。\n编写消费者代码1234567public class LongEventHandler implements EventHandler&lt;LongEvent&gt; &#123;    @Override    public void onEvent(LongEvent event, long sequence, boolean endOfBatch) throws Exception &#123;        System.out.println(&quot;Event: &quot; + event.getValue()+&quot; -&gt; &quot; + Thread.currentThread().getName());        Thread.sleep(2000);    &#125;&#125;\n\n将 eventHandler 设置到 disruptor 的处理链上\n123//将处理事件的事件处理程序 -&gt; 消费事件的处理程序LongEventHandler longEventHandler = new LongEventHandler();disruptor.handleEventsWith(longEventHandler);\n\n运行结果（这里）：123456789101112131415publish event :0Event: 0 -&gt; disruptor-thread-1--------------------------------&gt;publish event :1Event: 1 -&gt; disruptor-thread-1--------------------------------&gt;publish event :2Event: 2 -&gt; disruptor-thread-1--------------------------------&gt;publish event :3Event: 3 -&gt; disruptor-thread-1--------------------------------&gt;publish event :4Event: 4 -&gt; disruptor-thread-1--------------------------------&gt;\n\n基本概念和原理Disruptor整个基于ringBuffer实现的生产者消费者模式的容器。主要属性\n12345private final RingBuffer&lt;T&gt; ringBuffer;private final Executor executor;private final ConsumerRepository&lt;T&gt; consumerRepository = new ConsumerRepository&lt;&gt;();private final AtomicBoolean started = new AtomicBoolean(false);private ExceptionHandler&lt;? super T&gt; exceptionHandler = new ExceptionHandlerWrapper&lt;&gt;();\n\n\nringBuffer：内部持有一个 RingBuffer 对象，Disruptor 内部的事件发布都是依赖这个RingBuffer对象完成的。\nexecutor：消费事件的线程池\nconsumerRepository：提供存储库机制，用于将EventHandler与EventProcessor关联起来\nstarted : 用于标志当前Disruptor是否已经启动\nexceptionHandler : 异常处理器，用于处理BatchEventProcessor事件周期中 uncaught exceptions 。\n\nRingBuffer环形队列[实现上是一个数组]，可以类比为BlockingQueue之类的队列，ringBuffer的使用，使得内存被循环使用，减少了某些场景的内存分配回收扩容等耗时操作。\n12public final class RingBuffer&lt;E&gt; extends RingBufferFields&lt;E&gt; implements Cursored, EventSequencer&lt;E&gt;, EventSink&lt;E&gt; \n\n\nE：在事件的交换或并行协调期间存储用于共享的数据的实现 -&gt; 消息事件\n\nSequencer RingBuffer 中 生产者的顶级父接口，其直接实现有SingleProducerSequencer和MultiProducerSequencer；对应 SINGLE、MULTI 两个枚举值。\n\nEventHandler事件处置器，改接口用于对外扩展来实现具体的消费逻辑。如上面 demo 中的 LongEventHandler ;\n1234//回调接口，用于处理&#123;@link RingBuffer&#125;中可用的事件public interface EventHandler&lt;T&gt; &#123;    void onEvent(T event, long sequence, boolean endOfBatch) throws Exception;&#125;\n\n\nevent : RingBuffer 已经发布的事件\nsequence : 正在处理的事件 的序列号\nendOfBatch : 用来标识否是来自 RingBuffer 的批次中的最后一个事件\n\nSequenceBarrier消费者路障。规定了消费者如何向下走。事实上，该路障算是变向的锁。\n12345678910111213final class ProcessingSequenceBarrier implements SequenceBarrier &#123;    //当等待（探测）的需要不可用时，等待的策略    private final WaitStrategy waitStrategy;    //依赖的其它Consumer的序号，这个用于依赖的消费的情况，    //比如A、B两个消费者，只有A消费完，B才能消费。    private final Sequence     dependentSequence;    private volatile boolean   alerted = false;    //Ringbuffer的写入指针    private final Sequence     cursorSequence;    //RingBuffer对应的Sequencer    private final Sequencer    sequencer;    //exclude method&#125;\n\nwaitStrategy 决定了消费者采用何种等待策略。\nWaitStrategy\n\n\n\n\n\n\n\n\nStrategy employed for making {@link EventProcessor}s wait on a cursor {@link Sequence}.\nEventProcessor 的等待策略；具体实现在 disruptor 中有8种，\n\n这些等待策略不同的核心体现是在如何实现 waitFor 这个方法上。\nEventProcessor事件处理器，实际上可以理解为消费者模型的框架，实现了线程Runnable的run方法，将循环判断等操作封在了里面。该接口有三个实现类:\n1、BatchEventProcessor\n12345678910public final class BatchEventProcessor&lt;T&gt; implements EventProcessor &#123;    private final AtomicBoolean           running          = new AtomicBoolean(false);    private ExceptionHandler&lt;? super T&gt;   exceptionHandler = new FatalExceptionHandler();    private final DataProvider&lt;T&gt;         dataProvider;    private final SequenceBarrier         sequenceBarrier;    private final EventHandler&lt;? super T&gt; eventHandler;    private final Sequence                sequence         = new Sequence(                                      Sequencer.INITIAL_CURSOR_VALUE);    private final TimeoutHandler          timeoutHandler;    //exclude method&#125;\n\n\nExceptionHandler：异常处理器\nDataProvider：数据来源，对应 RingBuffer\nEventHandler：处理 Event 的回调对象\nSequenceBarrier：对应的序号屏障\nTimeoutHandler：超时处理器，默认情况为空，如果要设置，只需要要将关联的EventHandler实现TimeOutHandler即可。\n\n如果我们选择使用 EventHandler 的时候，默认使用的就是 BatchEventProcessor，它与EventHandler是一一对应，并且是单线程执行。\n如果某个RingBuffer有多个BatchEventProcessor，那么就会每个BatchEventProcessor对应一个线程。\n2、WorkProcessor\n1234567891011121314151617public final class WorkProcessor&lt;T&gt; implements EventProcessor &#123;    private final AtomicBoolean running = new AtomicBoolean(false);    private final Sequence sequence = new Sequence(Sequencer.INITIAL_CURSOR_VALUE);    private final RingBuffer&lt;T&gt; ringBuffer;    private final SequenceBarrier  sequenceBarrier;    private final WorkHandler&lt;? super T&gt; workHandler;    private final ExceptionHandler&lt;? super T&gt; exceptionHandler;    private final Sequence workSequence;    private final EventReleaser eventReleaser = new EventReleaser() &#123;            @Override            public void release() &#123;                sequence.set(Long.MAX_VALUE);            &#125;    &#125;;    private final TimeoutHandler timeoutHandler;&#125;\n\n基本和 BatchEventProcessor 类似，不同在于，用于处理Event的回调对象是WorkHandler。\n原理图\n无消费者情况下，生产者保持生产，但是 remainingCapacity 保持不变在写demo的过程中，本来想通过不设定 消费者 来观察 RingBuffer 可用容量变化的。但是验证过程中，一直得不到预期的结果，(注：没有设置消费者，只有生产者)，先看结果：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950publish event :0bufferSie:8remainingCapacity:8cursor:0--------------------------------&gt;publish event :1bufferSie:8remainingCapacity:8cursor:1--------------------------------&gt;publish event :2bufferSie:8remainingCapacity:8cursor:2--------------------------------&gt;publish event :3bufferSie:8remainingCapacity:8cursor:3--------------------------------&gt;publish event :4bufferSie:8remainingCapacity:8cursor:4--------------------------------&gt;publish event :5bufferSie:8remainingCapacity:8cursor:5--------------------------------&gt;publish event :6bufferSie:8remainingCapacity:8cursor:6--------------------------------&gt;publish event :7bufferSie:8remainingCapacity:8cursor:7--------------------------------&gt;publish event :8bufferSie:8remainingCapacity:8cursor:8--------------------------------&gt;publish event :9bufferSie:8remainingCapacity:8cursor:9--------------------------------&gt;\n\n从结果来看，remainingCapacity 的值应该随着 发布的数量 递减的；但是实际上它并没有发生任何变化。\n来看下ringBuffer.remainingCapacity() 这个方法：\n123456789/** * Get the remaining capacity for this ringBuffer. * * @return The number of slots remaining. */public long remainingCapacity()&#123;    return sequencer.remainingCapacity();&#125;\n\n这里面又使用 sequencer.remainingCapacity()这个方法来计算的。上面的例子中使用的是ProducerType.SINGLE，那来看SingleProducerSequencer 这个里面remainingCapacity的实现。\n1234567891011@Overridepublic long remainingCapacity()&#123;    //上次申请完毕的序列值    long nextValue = this.nextValue;    //计算当前已经消费到的序列值    long consumed = Util.getMinimumSequence(gatingSequences, nextValue);    //当前生产到的序列值    long produced = nextValue;    return getBufferSize() - (produced - consumed);&#125;\n\n来解释下这段代码的含义：\n假设当前 ringBuffer 的 bufferSize 是 8 ；上次申请到的序列号是 5，其实也就是说已经生产过占用的序列号是5；假设当前已经消费到的序列号是 3，那么剩余的容量为： 8-（5-2） &#x3D; 5；\n\n因为这里我们可以确定 bufferSize 和 produced 的值了，那么 remainingCapacity 的结果就取决于getMinimumSequence的计算结果了。\n123456789public static long getMinimumSequence(final Sequence[] sequences, long minimum)&#123;    for (int i = 0, n = sequences.length; i &lt; n; i++)    &#123;        long value = sequences[i].get();        minimum = Math.min(minimum, value);    &#125;    return minimum;&#125;\n\n这个方法是从 Sequence 数组中获取最小序列 。如果sequences 为空，则返回 minimum。回到上一步，看下sequences这个数组是从哪里过来的，它的值在哪里设置的。\n1long consumed = Util.getMinimumSequence(gatingSequences, nextValue);\n\ngatingSequences 是 SingleProducerSequencer 父类  AbstractSequencer 中的成员变量：\n1protected volatile Sequence[] gatingSequences = new Sequence[0];\n\ngatingSequences 是在下面这个方法里面来管理的。\n12345678/** * @see Sequencer#addGatingSequences(Sequence...) */@Overridepublic final void addGatingSequences(Sequence... gatingSequences)&#123;    SequenceGroups.addSequences(this, SEQUENCE_UPDATER, this, gatingSequences);&#125;\n\n这个方法的调用栈向前追溯有这几个地方调用了：\n\nWorkerPool来管理多个消费者；hangdlerEventsWith 这个方法也是用来设置消费者的。但是在上面的测试案例中我们是想通过不设定消费者 只设定生成者 来观察 环形队列的占用情况，所以gatingSequences 会一直是空的，因此在计算时会把 produced 的值作为 minimum 返回。这样每次计算就相当于：\n1return getBufferSize() - (produced - produced) === getBufferSize();\n\n也就验证了为何在不设定消费者的情况下，remainingCapacity 的值会一直保持不变。\nSOFATracer 中 Disruptor 实践SOFATracer中，AsyncCommonDigestAppenderManager 对 disruptor 进行了封装，用于处理外部组件的Tracer摘要日志。该部分借助 AsyncCommonDigestAppenderManager 的源码来分析下SOFATracer如何使用disruptor的。\nSOFATracer 中使用了两种不同的事件模型，一种是SOFATracer内部使用的 StringEvent , 一种是 外部扩展使用的 SofaTacerSpanEvent。这里以 SofaTacerSpanEvent 这种事件模型来分析。StringEvent 消息事件模型对应的是 AsyncCommonAppenderManager 类封装的disruptor。\nSofaTracerSpanEvent ( -&gt; LongEvent)定义消息事件模型，SofaTacerSpanEvent 和 前面 demo 中的 LongEvent 基本结构是一样的，主要是内部持有的消息数据不同，LongEvent 中是一个long类型的数据，SofaTacerSpanEvent中持有的是 SofaTracerSpan 。\n123456789public class SofaTracerSpanEvent &#123;    private volatile SofaTracerSpan sofaTracerSpan;    public SofaTracerSpan getSofaTracerSpan() &#123;        return sofaTracerSpan;    &#125;    public void setSofaTracerSpan(SofaTracerSpan sofaTracerSpan) &#123;        this.sofaTracerSpan = sofaTracerSpan;    &#125;&#125;\n\nConsumer ( -&gt; LongEventHandler)Consumer 是 AsyncCommonDigestAppenderManager 的内部类;实现了 EventHandler 接口，这个consumer就是作为消费者存在的。\n在AsyncCommonAppenderManager中也有一个，这个地方个人觉得可以抽出去，这样可以使得AsyncCommonDigestAppenderManager/AsyncCommonAppenderManager的代码看起来更干净；\n123456789101112131415161718192021222324252627282930313233343536373839private class Consumer implements EventHandler&lt;SofaTracerSpanEvent&gt; &#123;       //日志类型集合，非该集合内的日志类型将不会被处理        protected Set&lt;String&gt; logTypes = Collections.synchronizedSet(new HashSet&lt;String&gt;());        @Override        public void onEvent(SofaTracerSpanEvent event, long sequence, boolean endOfBatch)                                throws Exception &#123;            // 拿到具体的消息数据 sofaTracerSpan            SofaTracerSpan sofaTracerSpan = event.getSofaTracerSpan();            // 如果没有数据，则不做任何处理            if (sofaTracerSpan != null) &#123;                try &#123;                    String logType = sofaTracerSpan.getLogType();                    // 验证当前日志类型是否可以被当前consumer消费                    if (logTypes.contains(logType)) &#123;                        // 获取编码类型                        SpanEncoder encoder = contextEncoders.get(logType);                        //获取 appender                        TraceAppender appender = appenders.get(logType);                        // 对数据进行编码处理                        String encodedStr = encoder.encode(sofaTracerSpan);                        if (appender instanceof LoadTestAwareAppender) &#123;                            ((LoadTestAwareAppender) appender).append(encodedStr,                                TracerUtils.isLoadTest(sofaTracerSpan));                        &#125; else &#123;                            appender.append(encodedStr);                        &#125;                        // 刷新缓冲区，日志输出                        appender.flush();                    &#125;                &#125; catch (Exception e) &#123;                   // 异常省略                &#125;            &#125;        &#125;        public void addLogType(String logType) &#123;            logTypes.add(logType);        &#125;    &#125;\n\nSofaTracerSpanEventFactory （-&gt; LongEventFactory）用于产生消息事件的 Factory\n123456public class SofaTracerSpanEventFactory implements EventFactory&lt;SofaTracerSpanEvent&gt; &#123;    @Override    public SofaTracerSpanEvent newInstance() &#123;        return new SofaTracerSpanEvent();    &#125;&#125;\n\nConsumerThreadFactory (-&gt; LongEventThreadFactory )用来产生消费线程的 Factory。\n123456789101112131415public class ConsumerThreadFactory implements ThreadFactory &#123;    private String workName;    public String getWorkName() &#123;        return workName;    &#125;    public void setWorkName(String workName) &#123;        this.workName = workName;    &#125;    @Override    public Thread newThread(Runnable runnable) &#123;        Thread worker = new Thread(runnable, &quot;Tracer-AsyncConsumer-Thread-&quot; + workName);        worker.setDaemon(true);        return worker;    &#125;&#125;\n\n构建disruptordisruptor 的构建是在 AsyncCommonDigestAppenderManager 的构造函数中完成的。\n1234567891011121314151617181920212223242526272829303132333435363738394041public AsyncCommonDigestAppenderManager(int queueSize, int consumerNumber) &#123;    // 使用这个计算来保证realQueueSize是2的次幂（返回当前 大于等于queueSize的最小的2的次幂数 ）    int realQueueSize = 1 &lt;&lt; (32 - Integer.numberOfLeadingZeros(queueSize - 1));    //构建disruptor，使用的是 ProducerType.MULTI    //等待策略是 BlockingWaitStrategy    disruptor = new Disruptor&lt;SofaTracerSpanEvent&gt;(new SofaTracerSpanEventFactory(),        realQueueSize, threadFactory, ProducerType.MULTI, new BlockingWaitStrategy());    //消费者列表    this.consumers = new ArrayList&lt;Consumer&gt;(consumerNumber);        for (int i = 0; i &lt; consumerNumber; i++) &#123;        Consumer consumer = new Consumer();        consumers.add(consumer);        //设置异常处理程序        disruptor.setDefaultExceptionHandler(new ConsumerExceptionHandler());        //绑定消费者        disruptor.handleEventsWith(consumer);    &#125;    //是否允许丢弃，从配置文件获取    this.allowDiscard = Boolean.parseBoolean(SofaTracerConfiguration.getProperty(        SofaTracerConfiguration.TRACER_ASYNC_APPENDER_ALLOW_DISCARD, DEFAULT_ALLOW_DISCARD));        if (allowDiscard) &#123;        //是否记录丢失日志的数量        this.isOutDiscardNumber = Boolean.parseBoolean(SofaTracerConfiguration.getProperty(            SofaTracerConfiguration.TRACER_ASYNC_APPENDER_IS_OUT_DISCARD_NUMBER,            DEFAULT_IS_OUT_DISCARD_NUMBER));        //是否记录丢失日志的TraceId和RpcId        this.isOutDiscardId = Boolean.parseBoolean(SofaTracerConfiguration.getProperty(            SofaTracerConfiguration.TRACER_ASYNC_APPENDER_IS_OUT_DISCARD_ID,            DEFAULT_IS_OUT_DISCARD_ID));        //丢失日志的数量达到该阈值进行一次日志输出        this.discardOutThreshold = Long.parseLong(SofaTracerConfiguration.getProperty(            SofaTracerConfiguration.TRACER_ASYNC_APPENDER_DISCARD_OUT_THRESHOLD,            DEFAULT_DISCARD_OUT_THRESHOLD));        if (isOutDiscardNumber) &#123;            this.discardCount = new PaddedAtomicLong(0L);        &#125;    &#125;&#125;\n\n启动 disruptordisruptor的启动委托给了 AsyncCommonDigestAppenderManager 的start方法来执行。\n1234public void start(final String workerName) &#123;    this.threadFactory.setWorkName(workerName);    this.ringBuffer = this.disruptor.start();&#125;\n\n来看下，SOFATracer 中 具体是在哪里调用这个start 的：\n\n\nCommonTracerManager : 这个里面持有了AsyncCommonDigestAppenderManager 类的一个单例对象，并且是static 静态代码块中调用了start方法；这个用来输出普通日志。\nSofaTracerDigestReporterAsyncManager：这里类里面也是持有了AsyncCommonDigestAppenderManager 类的一个单例对像，并且提供了getSofaTracerDigestReporterAsyncManager方法来获取该单例，在这个方法中调用了start方法；该对象用来输出摘要日志。\n\n发布事件前面的demo中是通过一个for循环来发布事件的，在 SOFATracer 中 的事件发布无非就是当有Tracer日志需要输出时会触发发布，那么对应的就是日志的 append 操作，将日志 append 到环形缓冲区。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445public boolean append(SofaTracerSpan sofaTracerSpan) &#123;    long sequence = 0L;    //是否允许丢弃    if (allowDiscard) &#123;        try &#123;            //允许丢弃就使用tryNext尝试申请序列，申请不到抛出异常            sequence = ringBuffer.tryNext();        &#125; catch (InsufficientCapacityException e) &#123;            //是否输出丢失日志的TraceId和RpcId            if (isOutDiscardId) &#123;                SofaTracerSpanContext sofaTracerSpanContext = sofaTracerSpan                    .getSofaTracerSpanContext();                if (sofaTracerSpanContext != null) &#123;                    SynchronizingSelfLog.warn(&quot;discarded tracer: traceId[&quot;                                              + sofaTracerSpanContext.getTraceId()                                              + &quot;];spanId[&quot; + sofaTracerSpanContext.getSpanId()                                              + &quot;]&quot;);                &#125;            &#125;             //是否输出丢失日志的数量            if ((isOutDiscardNumber) &amp;&amp; discardCount.incrementAndGet() == discardOutThreshold) &#123;                discardCount.set(0);                if (isOutDiscardNumber) &#123;                    SynchronizingSelfLog.warn(&quot;discarded &quot; + discardOutThreshold + &quot; logs&quot;);                &#125;            &#125;            return false;        &#125;    &#125; else &#123;        // 不允许丢弃则使用next方法        sequence = ringBuffer.next();    &#125;    try &#123;        SofaTracerSpanEvent event = ringBuffer.get(sequence);        event.setSofaTracerSpan(sofaTracerSpan);    &#125; catch (Exception e) &#123;        SynchronizingSelfLog.error(&quot;fail to add event&quot;);        return false;    &#125;    //发布    ringBuffer.publish(sequence);    return true;&#125;\n\nSOFATracer 事件发布的调用逻辑：\n\n追溯调用的流程，可以知道当前 span 调用 finish时或者 SOFATracer中调用reportSpan时 就相当于发布了一个消息事件。\n小结本文对 SOFATracer 中使用 Disruptor 来进行日志输出的代码进行了简单的分析，更多内部细节原理可以自行看下SOFATracer的代码。SOFATracer 作为一种比较底层的中间件组件，在实际的业务开发中基本是无法感知的。但是作为技术来学习，还是有很多点可以挖一挖。\nSOFATracer GitHub 传送门。\n","slug":"sofa/sofa-tracer-disruptor","date":"2018-11-10T04:26:20.000Z","categories_index":"SOFA","tags_index":"分布式链路跟踪,Tracer,Disruptor","author_index":"glmapper"},{"id":"081a602eba3d6e39cf0949a624156da5","title":"聊一聊 RestTemplate","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903695981740046\n从 3.0 版本开始，Spring 提供了 RestTemplate 作为用于访问 Rest 服务的客户端，RestTemplate 提供了多种便捷访问远程 Http 服务的方法，能够大大提高客户端的编写效率。\n本篇文章将从 RestTemplate 提供的 API 入手，先来了解下 RestTemplate 的具体使用，然后再对其中涉及到的几个核心类进行分析，最后再来分析下 RestTemplate 执行的整个流程，篇幅比较长，建议先码为快！\n\n\n核心 API在平时的使用中，我们通常都是使用包装好的getForObject&#x2F;getForEntity，postForObject&#x2F;postForEntity&#x2F;postForLocation，put以及delete。\nget 请求处理getForEntity方法的返回值是一个ResponseEntity，ResponseEntity是Spring对HTTP请求响应的封装，包括了几个重要的元素，如响应码、contentType、contentLength、响应消息体等。\n\nurl：调用的服务的地址\nresponseType：返回的body类型\nuriVariables：有两种形式:\n可以用一个数字做占位符，最后是一个可变长度的参数，来一一替换前面的占位符\n也可以前面使用name&#x3D;{name}这种形式，最后一个参数是一个map，map的key即为前边占位符的名字，map的value为参数值\n\n\n\nresponseType 测试案例定义的一个controller资源：\n这里分别使用不同的 responseType 进行测试：\n\n结果：\n12getForEntity(responseType=Map.class):&#123;glmapper=hello glmapper&#125;getForEntity(responseType=String.class):&#123;&quot;glmapper&quot;:&quot;hello glmapper&quot;&#125;\n\nuriVariables 测试案例先来看下非map方式的，两个controller，两种不同方式的参数获取（本质上是一样的）\n\n使用占位符的方式：\n\n\n\n使用 map 的方式：\n\n\ngetForObjectgetForObject 函数实际上是对 getForEntity 函数的进一步封装，如果只关注返回的消息体的内容，对其他信息都不关注，那么就可以使用 getForObject。\n\n这里调用就比getForEntity要简单一点了，可以直接拿到对象：\n\ngetForObject 的几个重载方法和 getForEntity 基本是一样的。\npost 请求处理在RestTemplate中，POST请求可以通过如下三个方法来发起：postForEntity，postForObject，postForLocation。\npostForEntity 案例调用获取：\n\n1postForEntity(URI url, @Nullable Object request, Class&lt;T&gt; responseType)\n\n\n方法的第一参数表示要调用的服务的地址\n方法的第二个参数表示上传的参数\n方法的第三个参数表示返回的消息体的数据类型\n\npostForObject 案例和 getForObject 相对应，只关注返回的消息体。\n\npostForLocation 案例postForLocation也是提交新资源，提交成功之后，返回新资源的URI，postForLocation的参数和前面两种的参数基本一致，只不过该方法的返回值为Uri，这个只需要服务提供者返回一个Uri即可，该Uri表示新资源的位置。\n\n这里有点坑，我们需要把这个uri添加到response的header中，不然后面拿到的是null。\n\nexchangeexchange 方法和上述这些方法差别在于需要多一个请求类型的参数：\n\nAsyncRestTemplate 异步客户端RestTemplate的异步实现方式。所涉及到的API和RestTemplate基本一致。区别在于RestTemplate直接返回结果，而AsyncRestTemplate返回的是ListenableFuture。\n\nRestTemplate 拦截器Spring提供了ClientHttpRequestInterceptor和AsyncClientHttpRequestInterceptor两个接口，分别可以对RestTemplate和AsyncRestTemplate发起的请求进行拦截，并在其被发送至服务端之前修改请求或是增强相应的信息。\n\nClientHttpRequestInterceptor 拦截 RestTemplate\n\nAsyncClientHttpRequestInterceptor 拦截AsyncRestTemplate\n\n\n设置拦截器就是通过提供的 setInterceptors 设置即可：\n\n自定义 ResponseErrorHandlerResponseErrorHandler 接口定义了当response发生错误时需要进行的操作。这里我们自定义一个CustomResponseErrorHandler，当返回的code不是200时，就表示执行出错了。\n\n设置 ResponseErrorHandler：\n\n执行结果：\n\n处理流程下面来梳理下 RestTemplate 中请求处理的流程。下图中 XXXX 表示我们调用的 API 方法。大体流程就是：api 内部做一些请求相关的处理封装，然后交给 execute 方法执行，最后真正处理则是在 doExecute 方法中完成。\n下面以 getForEntity 方法的执行过程来分析：\n\ngetForEntity 方法：\n\n基于给定响应类型，返回一个请求回调实现，准备请求。\n基于给定响应类型，返回 ResponseEntity 的响应提取器。\n\nexecute 方法：\n\n这个方法里面是对url进行urlencode编码处理的，统一转为URL。这里我们也可以手动把参数进行网络编码。\n\ndoExecute是请求真正处理的方法，这里来重点看下这个方法的执行过程：\n\ncreateRequest\ndoWithRequest\nexecute\nhandleResponse\n\n1、createRequest这个方法的作用就是创建一个 ClientHttpRequest 对象。RestTemplate集成了 HttpAccessor这个抽象类，创建ClientHttpRequest的过程就是在其父类HttpAccessor中通过默认的 ClientHttpRequestFactory 实现类 SimpleClientHttpRequestFactory 完成具体的请求创建。\n\n\n1、创建 java.net.HttpURLConnection 对象\n\n2、设置 connection，包括 connectTimeout、setDoInput 等。\n\n3、bufferRequestBody 用于标志是否使用缓存流的形式，默认是 true。缺点是当发送大量数据时，比如 put&#x2F;post，存在内存消耗严重。该值可以通过 SimpleClientHttpRequestFactory#setBufferRequestBody来修改。\n\n\n\n\n\n\n\n\n\n\n\n不同版本的变更还是比较大的，大家在阅读源码时，还是从最新的代码来看。\n2、doWithRequestRequestCallback 封装了请求体和请求头对象。这里会遍历所有的 HttpMessageConverter，解析成所有支持的MediaType，放在allSupportedMediaTypes中。\n1request.getHeaders().setAccept(allSupportedMediaTypes);\nRestTemplate中对应了两个内部类的实现：\n\nAcceptHeaderRequestCallback.doWithRequest的处理。发送请求时，Http头部需要设置Accept字段，该字段表明了发送请求的这方接受的媒体类型（消息格式），也是响应端要返回的信息的媒体类型（消息格式）。根据postForEntity方法的第三个参数responseType，程序将选择适合的解析器XXXConverter，并依据该解析器找出所有支持的媒体类型。\n\nHttpEntityRequestCallback.doWithRequest的处理。如果是POST请求并且消息体存在时，除了设置Accept字段，还可能需要设置Content-Type字段，该字段表明了所发送请求的媒体类型（消息格式），也是响应端接受的媒体类型（消息格式）。根据postForEntity方法的第二个参数request，程序将选择适合的解析器XXXConverter，将请求消息写入输出流。\n\n\n3、execute这里会把请求头&#x2F;体封装到connect，然后发送请求。跟踪 execute 方法执行，定位到SimpleBufferingClientHttpRequest#executeInternal方法：\n这里是使用实例 SimpleBufferingClientHttpRequest 封装请求体和请求头。从代码中可以看到：\n\ndelete 时通过前面设置的 DoOutput参数和是否可以设置输出流来判断是否需要发送请求体如果是 delete 请求，那么很明显 DoOutput &#x3D; false，不会有封装请求体的过程，即不执行FileCopyUtils.copy(bufferedOutput, this.connection.getOutputStream())。\n\n4、handleResponse最后就是 response 的解析了，从代码来看，主要还是 Error 的解析。这里的ErrorHandler我们前面也提到，可以通过实现 ResponseErrorHandler 来自定义 异常处理。\n小结本篇先介绍了RestTemplate的API使用，挑了几个介绍了下，更多使用细节还是要针对不同的场景来决定。接着对拦截器，异步RestTemplate以及错误处理器做了简单的介绍并给出了案例。最后分析了下RestTemplate的执行流程，篇幅原因执行流程部分只是大概捋了捋，其中还是很多细节有时间再补充，这部分主要就是看底层是如何通信的，已经请求参数的传递等。\n","slug":"middleware/middleware-http-resttemplate","date":"2018-10-30T14:20:07.000Z","categories_index":"Middleware","tags_index":"spring,RestTemplate,http","author_index":"glmapper"},{"id":"23a4ce7fdfa388085850b04ca0698cfd","title":"聊一聊 Spring 中的扩展机制之 NamespaceHandler","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903665262657544\n前一篇 聊一聊 Spring 中的扩展机制（一） 中聊到了ApplicationListener、ApplicationContextAware、BeanFactoryAware三种机制。本篇将介绍 NamespaceHandler 的扩展使用。\n相信很多小伙伴对于这几个类都不陌生，基本基于java实现的RPC框架都会使用，比如 Dubbo , SOFARpc 等。本文先从几个小demo入手，了解下基本的概念和编程流程，然后分析下 SOFARpc 中是如何使用的。\n\n\nNamespaceHandlerNamespaceHandler 是 Spring 提供的 命名空间处理器。下面这张图中，除了乱入的本篇 demo 中涉及到的 BridgeNameSpaceHandler 之外，其他均为 Spring 自身提供的。\n\n因为这里我只引入了 bean 和 context 依赖，所以这也仅仅是一部分。图中我们常用的应该算是 AopNamespaceHandler。\n我们使用基于xml的spring配置时，可能需要配置如&lt;aop:config /&gt;这样的标签，在配置这个标签之前，通常我们需要引入这个aop所在的命名空间：\n1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/aophttp://www.springframework.org/schema/aop/spring-aop.xsdhttp://www.springframework.org/schema/contexthttp://www.springframework.org/schema/context/spring-context.xsd&quot; /&gt;\n\n关于AOP 可以了解下 聊一聊 AOP ：表现形式与基础概念，这里不过多解释，下面就按照 官方文档的流程 来写一个自定义xml，最终效果如下：\n12345&lt;bridge:application id=&quot;bridgeTestApplication&quot;                    name=&quot;bridgeTestApplication&quot;                      version=&quot;1.0&quot;                     organization=&quot;bridge.glmapper.com&quot;                    owner=&quot;leishu@glmapper&quot;/&gt;\n\n1、定义 xsd 文件关于 xsd 文件的语法规则不在本篇范围之内，有兴趣的同学可以自行google。下面这个文件很简单，定义的element name 为application，对应于 bridge:application中的application。attribute就是上面效果展示中对应的几个属性名。\n12345678910111213141516171819&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;&lt;xsd:schema xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;            xmlns:beans=&quot;http://www.springframework.org/schema/beans&quot;            xmlns:tool=&quot;http://www.springframework.org/schema/tool&quot;            xmlns=&quot;http://bridge.glmapper.com/schema/bridge&quot;            targetNamespace=&quot;http://bridge.glmapper.com/schema/bridge&quot;&gt;    &lt;xsd:import namespace=&quot;http://www.springframework.org/schema/beans&quot;/&gt;    &lt;xsd:complexType name=&quot;applicationType&quot;&gt;        &lt;xsd:attribute name=&quot;id&quot; type=&quot;xsd:ID&quot;/&gt;        &lt;xsd:attribute name=&quot;name&quot; type=&quot;xsd:string&quot; use=&quot;required&quot;/&gt;        &lt;xsd:attribute name=&quot;version&quot; type=&quot;xsd:string&quot;/&gt;        &lt;xsd:attribute name=&quot;owner&quot; type=&quot;xsd:string&quot;/&gt;        &lt;xsd:attribute name=&quot;organization&quot; type=&quot;xsd:string&quot;/&gt;    &lt;/xsd:complexType&gt;    &lt;xsd:element name=&quot;application&quot; type=&quot;applicationType&quot;/&gt;&lt;/xsd:schema&gt;\n2、编写 NamespaceHandler\n\n\n\n\n\n\n\n\nIn addition to the schema, we need a NamespaceHandler that will parse all elements of this specific namespace Spring encounters while parsing configuration files.\n用编写的这个 NamespaceHandler 来解析配置文件。\n具体说来NamespaceHandler会根据schema和节点名找到某个BeanDefinitionParser，然后由BeanDefinitionParser完成具体的解析工作。\nSpring提供了默认实现类NamespaceHandlerSupport和AbstractSingleBeanDefinitionParser，最简单的方式就是去继承这两个类。\n这里通过继承 NamespaceHandlerSupport 这个抽象类来完成。\n123456public class BridgeNamespaceHandler extends NamespaceHandlerSupport &#123;    public void init() &#123;        registerBeanDefinitionParser(&quot;application&quot;,         new ApplicationBeanDefinitionParser());    &#125;&#125;\n这里实际上只是注册了一个解析器，具体的 BeanDefinitionParser 才是将 XML元素映射到特定bean的。\n3、编写 BeanDefinitionParser这里直接通过实现BeanDefinitionParser接口的方式定义我们的BeanDefinitionParser实现类。关于AbstractSingleBeanDefinitionParser 的使用在 SPFARpc 中会涉及到。\n123456789101112131415161718192021222324252627public class ApplicationBeanDefinitionParser implements BeanDefinitionParser &#123;    public BeanDefinition parse(Element element, ParserContext parserContext) &#123;        //beanDefinition        RootBeanDefinition beanDefinition = new RootBeanDefinition();        beanDefinition.setBeanClass(ApplicationConfig.class);        beanDefinition.setLazyInit(false);        //解析id        String id = element.getAttribute(&quot;id&quot;);        beanDefinition.getPropertyValues().add(&quot;id&quot;, id);        //解析name        beanDefinition.getPropertyValues().add(&quot;name&quot;,        element.getAttribute(&quot;name&quot;));        //解析version        beanDefinition.getPropertyValues().add(&quot;version&quot;,        element.getAttribute(&quot;version&quot;));        //owner        beanDefinition.getPropertyValues().add(&quot;owner&quot;,        element.getAttribute(&quot;owner&quot;));        //organization        beanDefinition.getPropertyValues().add(&quot;organization&quot;,        element.getAttribute(&quot;organization&quot;));            parserContext.getRegistry().registerBeanDefinition(id, beanDefinition);        return beanDefinition;    &#125;&#125;\n\n这里我们需要了解的是开始解析自定义标签的时候，是通过BeanDefinitionParserDelegate-&gt;parseCustomElement方法来处理的，如下图所示：\n\n通过ele元素拿到当前namespaceUri，也就是在xsd中定义的命名空间，接着委托给 DefaultNamespaceResolver 得到具体的handler（BridgenamspaceHandler） ,然后执行parse 解析。\n4、配置 spring.handlers 和 spring.schmas1234http\\://bridge.glmapper.com/schema/bridge=com.glmapper.extention.namespacehandler.BridgeNamespaceHandlerhttp\\://bridge.glmapper.com/schema/bridge.xsd=META-INF/bridge.xsd\n\n配置这个其实是为了让Spring在解析xml的时候能够感知到我们的自定义元素，我们需要把NamespaceHandler和xsd文件放到位于META-INF目录下的spring.handlers 和 spring.schmas文件中。这样就可以在spring配置文件中使用我们自定义的标签了。如下：\n123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:bridge=&quot;http://bridge.glmapper.com/schema/bridge&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans.xsd       http://bridge.glmapper.com/schema/bridge       http://bridge.glmapper.com/schema/bridge.xsd&quot;&gt;           &lt;bridge:application id=&quot;bridgeTestApplication&quot;                    name=&quot;bridgeTestApplication&quot;                      version=&quot;1.0&quot;                     organization=&quot;bridge.glmapper.com&quot;                    owner=&quot;leishu@glmapper&quot;/&gt;&lt;/beans&gt;\n\n验证下从容器中获取我们的bean：\n123456789public static void main(String[] args) &#123;    ApplicationContext applicationContext = new    ClassPathXmlApplicationContext(&quot;classpath:bean.xml&quot;);        ApplicationConfig applicationConfig = (ApplicationConfig)    applicationContext.getBean(&quot;bridgeTestApplication&quot;);        System.out.println(&quot;applicationConfig = &quot;+applicationConfig);&#125;\n输出示例：\n1234567applicationConfig = ApplicationConfig &#123;    id=bridgeTestApplication,     name=&#x27;bridgeTestApplication&#x27;,     version=&#x27;1.0&#x27;,     owner=&#x27;leishu@glmapper&#x27;,     organization=&#x27;bridge.glmapper.com&#x27;&#125;\n整体来看，如果我们要实现自己的 xml 标签，仅需完成以下几步即可：\n\n1、定义 xsd 文件\n2、编写 NamespaceHandler \n3、编写 BeanDefinitionParser\n4、配置 spring.handlers 和 spring.schmas\n\nSOFARpc 中使用分析SOFARpc 中的 rpc.xsd 文件是集成在 sofaboot.xsd 文件中的，详细可见：sofa-boot\n\n\n\n\n\n\n\n\n\n\nxsd 文件这里不贴了，有点长 \nspring.handlers 和 spring.schmas先看下 spring.handlers 和 spring.schmas 配置：\n123456789http\\://sofastack.io/schema/sofaboot=com.alipay.sofa.infra.config.spring.namespace.handler.SofaBootNamespaceHandlerhttp\\://sofastack.io/schema/sofaboot.xsd=META-INF/com/alipay/sofa/infra/config/spring/namespace/schema/sofaboot.xsdhttp\\://sofastack.io/schema/rpc.xsd=META-INF/com/alipay/sofa/infra/config/spring/namespace/schema/rpc.xsd\n\n从 spring.handlers找到 NamespaceHandler : SofaBootNamespaceHandler。\nSofaBootNamespaceHandler源码如下，这里看出来，并不是像上面我们自己写的那种方式那样，会有一个 BeanDefinitionParser。这里其实设计的很巧妙，通过spi的方式来载入具体的BeanDefinitionParser。\n12345678910111213141516171819202122public class SofaBootNamespaceHandler extends NamespaceHandlerSupport &#123;    @Override    public void init() &#123;        ServiceLoader&lt;SofaBootTagNameSupport&gt; serviceLoaderSofaBoot =        ServiceLoader.load(SofaBootTagNameSupport.class);        //SOFABoot        for (SofaBootTagNameSupport tagNameSupport : serviceLoaderSofaBoot) &#123;            this.registerTagParser(tagNameSupport);        &#125;    &#125;    private void registerTagParser(SofaBootTagNameSupport tagNameSupport) &#123;        if (!(tagNameSupport instanceof BeanDefinitionParser)) &#123;            // log            return;        &#125;        String tagName = tagNameSupport.supportTagName();        registerBeanDefinitionParser(tagName, (BeanDefinitionParser)        tagNameSupport);    &#125;&#125;\n这里可以看出有 ReferenceDefinitionParser 和 ServiceDefinitionParser 两个解析类，分别对应服务引用和服务暴露。\n\n下面以ReferenceDefinitionParser为例，先看下它的类图：\n\n解析工作都是在 AbstractContractDefinitionParser 类中完成， ReferenceDefinitionParser 自己只是做了一些特殊处理【jvm-first，jvm服务】。\n小结本篇通过 NamespaceHandler 了解了如何去编写我们自定义的xml标签，从NamespaceHandler的角度可以很好的理解一些 RPC 框架中最基础的基于xml 方式的服务引用和暴露的实现思路。另外通过分析 SOFARpc ，也了解了在实际的工程组件中对于NamespaceHandler的扩展使用。\n本文代码：glmapper-spring-extention\n","slug":"spring/spring-extention-namespace-handler","date":"2018-08-26T15:53:52.000Z","categories_index":"spring","tags_index":"spring,spring 扩展机制","author_index":"glmapper"},{"id":"fff7a6707fa538995f040f2ec6d86c43","title":"聊一聊 Spring 中的扩展机制之 Listener & Awre","content":"\n\n\n\n\n\n\n\n\n之前 Spring 源码系列文章中大多是底层源码的分析，通过源码可以让我们能够清晰的了解 Spring 到底是什么，而不是停留于表面的认知。比如当我们要使用 @Autowired 注解时，可以拿到我们想要的 bean ,但是为什么可以是值得思考的。– 关于阅读源码\nSpring源码的阅读结合日常的使用，可以帮助我们更好的掌握这个庞大的技术体系，实际的开发工作中有很多地方可以借鉴它的一些思想来帮助我们更好的实现自己的业务逻辑。本篇将以扩展点为切入点，来了解下在Spring生命周期中扩展Spring中的Bean功能。\n\n\nApplicationListener 扩展ApplicationListener 其实是 spring 事件通知机制中核心概念；在java的事件机制中，一般会有三个概念：\n\nevent object : 事件对象\nevent source ：事件源，产生事件的地方\nevent listener ：监听事件并处理\n\nApplicationListener 继承自 java.util.EventListener ，提供了对于Spring中事件机制的扩展。\nApplicationListener 在实际的业务场景中使用的非常多，比如我一般喜欢在容器初始化完成之后来做一些资源载入或者一些组件的初始化。这里的容器指的就是Ioc容器，对应的事件是ContextRefreshedEvent 。\n1234567891011@Componentpublic class StartApplicationListener implementsApplicationListener&lt;ContextRefreshedEvent&gt; &#123;    @Override    public void onApplicationEvent(ContextRefreshedEvent    contextRefreshedEvent) &#123;       //初始化资源文件       //初始化组件 如：cache    &#125;&#125;\n上面这段代码会在容器刷新完成之后来做一些事情。下面通过自定义事件来看看怎么使用，在看具体的demo之前，先来了解下一些关注点。\n日常工作了，如果要使用 Spring 事件传播机制，我们需要关注的点有以下几点：\n\n事件类，这个用来描述事件本身一些属性，一般继承ApplicationEvent\n监听类，用来监听具体的事件并作出响应。需要实现 ApplicationListener 接口\n事件发布类，需要通过这个类将时间发布出去，这样才能被监听者监听到，需要实现ApplicationContextAware接口。\n将事件类和监听类交给Spring容器。\n\n那么下面就按照这个思路来看下demo的具体实现。\n事件类：UserRegisterEventUserRegisterEvent ，用户注册事件；这里作为事件对象，继承自 ApplicationEvent。\n12345678910111213141516171819/** * @description: 用户注册事件 * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class UserRegisterEvent extends ApplicationEvent &#123;    public String name;    public UserRegisterEvent(Object o) &#123;        super(o);    &#125;    public UserRegisterEvent(Object o, String name) &#123;        super(o);        this.name=name;    &#125;&#125;\n\n事件发布类：UserService用户注册服务，这里需要在用户注册时将注册事件发布出去，所以通过实现ApplicationEventPublisherAware接口，使UserService具有事件发布能力。\n\n\n\n\n\n\n\n\n\nApplicationEventPublisherAware:发布事件，也就是把某个事件告诉的所有与这个事件相关的监听器。\n123456789101112131415161718192021/** * @description: 用户注册服务，实现ApplicationEventPublisherAware接口 ，表明本身具有事件发布能力 * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class UserService implements ApplicationEventPublisherAware &#123;    private ApplicationEventPublisher applicationEventPublisher;    public void setApplicationEventPublisher(ApplicationEventPublisher    applicationEventPublisher) &#123;        this.applicationEventPublisher = applicationEventPublisher;    &#125;    public void register(String name) &#123;        System.out.println(&quot;用户：&quot; + name + &quot; 已注册！&quot;);        applicationEventPublisher.publishEvent(new UserRegisterEvent(name));    &#125;&#125;\n\n这里的UserService实际上是作为事件源存在的，通过register将用户注册事件传播出去。那么下面就是需要定义如何来监听这个事件，并且将事件进行消费处理掉，这里就是通过ApplicationListener来完成。\n监听类：BonusServerListener当用户触发注册操作时，向积分服务发送消息，为用户初始化积分。\n1234567891011121314/** * @description: BonusServerListener 积分处理，当用户注册时，给当前用户增加初始化积分 * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class BonusServerListener implementsApplicationListener&lt;UserRegisterEvent&gt; &#123;    public void onApplicationEvent(UserRegisterEvent event) &#123;        System.out.println(&quot;积分服务接到通知，给 &quot; + event.getSource() +        &quot; 增加积分...&quot;);    &#125;&#125;\n\n注册到容器中123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;       xsi:schemaLocation=&quot;        http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://www.springframework.org/schema/context        http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;            &lt;bean id=&quot;userService&quot; class=&quot;com.glmapper.extention.UserService&quot;/&gt;    &lt;bean id=&quot;bonusServerListener&quot;    class=&quot;com.glmapper.extention.BonusServerListener&quot;/&gt;    &lt;/beans&gt;\n客户端类12345678910111213141516/** * @description: 客户端类 * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class MainTest &#123;    public static void main(String[] args) &#123;        ApplicationContext context =new         ClassPathXmlApplicationContext(&quot;beans.xml&quot;);        UserService userService = (UserService)        context.getBean(&quot;userService&quot;);        //注册事件触发        userService.register(&quot;glmapper&quot;);    &#125;&#125;\n客户端类中，注册一个name为glmapper的用户，执行结果：\n12用户：glmapper 已注册！积分服务接到通知，给 glmapper 增加积分...\n现在来考虑另外一个问题，增加一个功能，用户注册之后给用户发一个邮件。这个其实就是增加一个监听类就可以，前提是这个监听者是监听当前事件的。\n12345678910111213/** * @description: 邮件服务监听器，当监听到用户的注册行为时，    给用户发送邮件通知 * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/25 */public class EmailServerListener implementsApplicationListener&lt;UserRegisterEvent&gt; &#123;    public void onApplicationEvent(UserRegisterEvent event) &#123;        System.out.println(&quot;邮件服务接到通知，给 &quot; + event.getSource() +        &quot; 发送邮件...&quot;);   \n这里如果将UserRegisterEvent换成UserLoginEvent，那么邮件服务将不会有任何行为。\n增加发送邮件监听类之后的执行结果：\n123用户：glmapper 已注册！邮件服务接到通知，给 glmapper 发送邮件...积分服务接到通知，给 glmapper 增加积分...\n\nSpring 的事件传播机制是基于观察者模式（Observer）实现的，它可以将 Spring Bean 的改变定义为事件 ApplicationEvent，通过 ApplicationListener 监听 ApplicationEvent 事件，一旦Spring Bean 使用 ApplicationContext.publishEvent( ApplicationEvent event )发布事件后，Spring 容器会通知注册在 容器中所有 ApplicationListener 接口的实现类，最后 ApplicationListener 接口实现类判断是否处理刚发布出来的 ApplicationEvent 事件。\nApplicationContextAware 扩展ApplicationContextAware中只有一个setApplicationContext方法。实现了ApplicationContextAware接口的类，可以在该Bean被加载的过程中获取Spring的应用上下文ApplicationContext，通过ApplicationContext可以获取Spring容器内的很多信息。\n这种一般在需要手动获取Bean的注入实例对象时会使用到。下面通过一个简单的demo来了解下。\nGlmapperApplicationContext 持有ApplicationContext对象，通过实现 ApplicationContextAware接口来给ApplicationContext做赋值。\n12345678910111213141516171819/** * @description: GlmapperApplicationContext * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/29 */public class GlmapperApplicationContext implementsApplicationContextAware &#123;    private  ApplicationContext applicationContext;    public void setApplicationContext(ApplicationContext    applicationContext) throws BeansException &#123;            this.applicationContext=applicationContext;    &#125;    public ApplicationContext getApplicationContext()&#123;        return applicationContext;    &#125;&#125;\n\n需要手动获取的bean:\n1234567891011/** * @description: HelloService * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/29 */public class HelloService &#123;    public void sayHello()&#123;        System.out.println(&quot;Hello Glmapper&quot;);    &#125;&#125;\n在配置文件中进行配置：\n12345&lt;bean id=&quot;helloService&quot;class=&quot;com.glmapper.extention.applicationcontextaware.HelloService&quot;/&gt;&lt;bean id=&quot;glmapperApplicationContext&quot;class=&quot;com.glmapper.extention.applicationcontextaware.GlmapperApplicationContext&quot;/&gt;\n\n客户端类调用：\n12345678910111213141516171819202122public class MainTest &#123;    public static void main(String[] args) &#123;        ApplicationContext context = new        ClassPathXmlApplicationContext(&quot;beans.xml&quot;);                HelloService helloService = (HelloService)        context.getBean(&quot;helloService&quot;);        helloService.sayHello();        //这里通过实现ApplicationContextAware接口的类来完成bean的获取        GlmapperApplicationContext glmapperApplicationContext =        (GlmapperApplicationContext) context.getBean(&quot;glmapperApplicationContext&quot;);                ApplicationContext applicationContext =        glmapperApplicationContext.getApplicationContext();                HelloService glmapperHelloService = (HelloService)        applicationContext.getBean(&quot;helloService&quot;);                glmapperHelloService.sayHello();    &#125;&#125;\n\nBeanFactoryAware 扩展我们知道BeanFactory是整个Ioc容器最顶层的接口，它规定了容器的基本行为。实现BeanFactoryAware接口就表明当前类具体BeanFactory的能力。\nBeanFactoryAware接口中只有一个setBeanFactory方法。实现了BeanFactoryAware接口的类，可以在该Bean被加载的过程中获取加载该Bean的BeanFactory，同时也可以获取这个BeanFactory中加载的其它Bean。\n来想一个问题，我们为什么需要通过BeanFactory的getBean来获取Bean呢？Spring已经提供了很多便捷的注入方式，那么通过BeanFactory的getBean来获取Bean有什么好处呢？来看一个场景。\n现在有一个HelloService，这个HelloService就是打招呼，我们需要通过不同的语言来实现打招呼，比如用中文，用英文。一般的做法是：\n1234567891011121314151617public interface HelloService &#123;    void sayHello();&#125;//英文打招呼实现public class GlmapperHelloServiceImpl implements HelloService &#123;    public void sayHello() &#123;        System.out.println(&quot;Hello Glmapper&quot;);    &#125;&#125;//中文打招呼实现public class LeishuHelloServiceImpl implements HelloService &#123;    public void sayHello() &#123;        System.out.println(&quot;你好，磊叔&quot;);    &#125;&#125;\n客户端类来调用务必会出现下面的方式：\n123456if (condition==&quot;英文&quot;)&#123;    glmapperHelloService.sayHello();&#125;if (condition==&quot;中文&quot;)&#123;    leishuHelloService.sayHello();&#125;\n如果有一天，老板说我们要做国际化，要实现全球所有的语言来问候。你是说好的，还是控制不住要动手呢？\n那么有没有什么方式可以动态的去决定我的客户端类到底去调用哪一种语言实现，而不是用过if-else方式来罗列呢？是的，对于这些需要动态的去获取对象的场景，BeanFactoryAware就可以很好的搞定。OK，来看代码改造：\n引入BeanFactoryAware：\n123456789101112131415161718192021222324252627282930/** * @description: 实现BeanFactoryAware ，让当前bean本身具有 BeanFactory 的能力 * * 实现 BeanFactoηAware 接口的 bean 可以直接访问 Spring 容器，被容器创建以后， * 它会拥有一个指向 Spring 容器的引用，可以利用该bean根据传入参数动态获取被spring工厂加载的bean * * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/7/29 */public class GlmapperBeanFactory implements BeanFactoryAware &#123;    private BeanFactory beanFactory;    public void setBeanFactory(BeanFactory beanFactory) throws    BeansException &#123;        this.beanFactory=beanFactory;    &#125;    /**     * 提供一个execute 方法来实现不同业务实现类的调度器方案。     * @param beanName     */    public void execute(String beanName)&#123;        HelloService helloService=(HelloService)        beanFactory.getBean(beanName);        helloService.sayHello();    &#125;&#125;\n\n这里为了逻辑方便理解，再加入一个HelloFacade 类,这个类的作用就是持有一个BeanFactoryAware的实例对象，然后通过HelloFacade实例对象的方法来屏蔽底层BeanFactoryAware实例的实现细节。\n12345678910public class HelloFacade &#123;    private GlmapperBeanFactory glmapperBeanFactory;    //调用glmapperBeanFactory的execute方法    public void sayHello(String beanName)&#123;        glmapperBeanFactory.execute(beanName);    &#125;    public void setGlmapperBeanFactory(GlmapperBeanFactory beanFactory)&#123;        this.glmapperBeanFactory = beanFactory;    &#125;&#125;\n客户端类\n1234567891011121314151617181920212223public class MainTest &#123;    public static void main(String[] args) &#123;        ApplicationContext context = new        ClassPathXmlApplicationContext(&quot;beans.xml&quot;);                HelloFacade helloFacade = (HelloFacade)        context.getBean(&quot;helloFacade&quot;);        GlmapperBeanFactory glmapperBeanFactory = (GlmapperBeanFactory)        context.getBean(&quot;glmapperBeanFactory&quot;);                //这里其实可以不通过set方法注入到helloFacade中，        //可以在helloFacade中通过autowired        //注入；这里在使用main方法来执行验证，所以就手动set进入了        helloFacade.setGlmapperBeanFactory(glmapperBeanFactory);        //这个只需要传入不同HelloService的实现类的beanName，        //就可以执行不同的业务逻辑        helloFacade.sayHello(&quot;glmapperHelloService&quot;);        helloFacade.sayHello(&quot;leishuHelloService&quot;);    &#125;&#125;\n可以看到在调用者（客户端）类中，只需要通过一个beanName就可以实现不同实现类的切换，而不是通过一堆if-else来判断。另外有的小伙伴可能会说，程序怎么知道用哪个beanName呢？其实这个也很简单，这个参数我们可以通过一些途径来拼接得到，比如使用一个prefix用来指定语言，prefix+HelloService就可以确定唯一的beanName。\n小结本来想着在一篇文章里面把扩展点都写一下的，但是实在太长了。后面差不多还有两篇。本系列中所有的demo可以在github获取，也欢迎小伙伴把能够想到的扩展点pr过来。\n\nglmapper-spring-extention\n\n","slug":"spring/spring-extention-listener-awre","date":"2018-08-19T15:14:24.000Z","categories_index":"spring","tags_index":"spring,spring 扩展机制","author_index":"glmapper"},{"id":"007bfdf0af7a404de7413e60d2f769a0","title":"Google Guava 在实际场景中的应用封装","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903624519188487\n\n\n\n\n\n\n\n\n\n毕竟西湖六月中，风光不与四时同。\n接天莲叶无穷碧，映日荷花别样红。\n晓出净慈寺送林子方-杨万里\n\n周末与小伙伴约了一波西湖，这个时间荷花开的正好…，在开始文章之前先放一张“佛系”美图来镇楼！！！\n最近这段时间用了下谷歌的 guava，自己封了一个缓存模板方案，特此记录，以备后续所需。\n\n\n一个缓存定时清除任务带来的GC问题为什么要从这个来说起，因为不说这个就没 guava 什么事了！\n最近项目中需要使用缓存来对一查查询频繁的数据做缓存处理；首先我们也不希望引入三方的如redis或者memcache这样的服务进来，其次是我们对于数据一致性的要求并不是很高，不需要集群内的查询接口共享到一份缓存数据；所以这样一来我们只要实现一个基于内存的缓存即可。\n最开始我并没有考虑使用guava来做这个事情，而是自己写了一套基于CurrentHashMap的缓存方案；这里需要明确一点，因为缓存在这个场景里面希望提供超时清除的能力，而基于所以在自己缓存框架中增加了定时清除过期数据的能力。\n这里我就直接把定时清楚的这段代码放上来：\n123456789101112131415161718192021222324252627 /** * 静态内部类来进行超时处理 */private class ClearCacheThread extends Thread &#123;    @Override    public void run() &#123;        while (true)&#123;            try &#123;                long now = System.currentTimeMillis();                Object[] keys = map.keySet().toArray();                for (Object key : keys) &#123;                    CacheEntry entry = map.get(key);                    if (now - entry.time &gt;= cacheTimeout) &#123;                        synchronized (map) &#123;                            map.remove(key);                            if (LOGGER.isDebugEnabled())&#123;                                LOGGER.debug(&quot;language cache timeout clear&quot;);                            &#125;                        &#125;                    &#125;                &#125;            &#125;catch (Exception e)&#123;                LOGGER.error(&quot;clear out time cache value error;&quot;,e);            &#125;        &#125;    &#125;&#125;\n\n这个线程是用来单独处理过期数据的。缓存初始化时就会触发这个线程的start方法开始执行。\n正式由于这段代码的不合理导致我在发布dev环境之后，机器GC触发的频次高的离谱。在尝试了不同的修复方案之后，最后选择放弃了；改用guava了！\n小伙伴们可以在下面留言来讨论下这里为什么会存在频繁GC的问题；我会把结论放在评论回复里面。\n\nguava为什么选用guava呢，很显然，是大佬推荐的！！！\n\n\n\n\n\n\n\n\n\nguava是谷歌提供的一个基于内存的缓存工具包，Guava Cache 提供了一种把数据（key-value对）缓存到本地（JVM）内存中的机制，适用于很少会改动的数据。Guava Cache 与 ConcurrentMap 很相似，但也不完全一样。最基本的区别是 ConcurrentMap 会一直保存所有添加的元素，直到显式地移除。相对地，Guava Cache 为了限制内存占用，通常都设定为自动回收元素。\n对于我们的场景，guava 提供的能力满足了我们的需要：\n\n数据改动小\n基于内存\n可以自动回收\n\n既然选择它了，我们还是有必要来先对它有个大致的了解；先来看看它提供的一些类和接口：\n\n\n\n接口&#x2F;类\n详细解释\n\n\n\nCache\n【I】;定义get、put、invalidate等操作，这里只有缓存增删改的操作，没有数据加载的操作。\n\n\nAbstractCache\n【C】;实现Cache接口。其中批量操作都是循环执行单次行为，而单次行为都没有具体定义。\n\n\nLoadingCache\n【I】;继承自Cache。定义get、getUnchecked、getAll等操作，这些操作都会从数据源load数据。\n\n\nAbstractLoadingCache\n【C】;继承自AbstractCache，实现LoadingCache接口。\n\n\nLocalCache\n【C】;整个guava cache的核心类，包含了guava cache的数据结构以及基本的缓存的操作方法。\n\n\nLocalManualCache\n【C】;LocalCache内部静态类，实现Cache接口。其内部的增删改缓存操作全部调用成员变量localCache（LocalCache类型）的相应方法。\n\n\nLocalLoadingCache\n【C】;LocalCache内部静态类，继承自LocalManualCache类，实现LoadingCache接口。其所有操作也是调用成员变量localCache（LocalCache类型）的相应方法\n\n\nCacheBuilder\n【C】;缓存构建器。构建缓存的入口，指定缓存配置参数并初始化本地缓存。CacheBuilder在build方法中，会把前面设置的参数，全部传递给LocalCache，它自己实际不参与任何计算\n\n\nCacheLoader\n【C】;用于从数据源加载数据，定义load、reload、loadAll等操作。\n\n\n整个来看的话，guava里面最核心的应该算是 LocalCache 这个类了。\n123@GwtCompatible(emulated = true)class LocalCache&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implementsConcurrentMap&lt;K, V&gt; \n\n关于这个类的源码这里就不细说了，直接来看下在实际应用中我的封装思路【封装满足我当前的需求，如果有小伙伴需要借鉴，可以自己在做扩展】\n12345678910111213141516private static final int            MAX_SIZE     = 1000;private static final int            EXPIRE_TIME  = 10;private static final int            DEFAULT_SIZE = 100;private int                         maxSize      = MAX_SIZE;private int                         expireTime   = EXPIRE_TIME;/** 时间单位（分钟） */private TimeUnit                    timeUnit     = TimeUnit.MINUTES;/** Cache初始化或被重置的时间  */private Date                        resetTime;/** 分别记录历史最多缓存个数及时间点*/private long                        highestSize  = 0;private Date                        highestTime;private volatile LoadingCache&lt;K, V&gt; cache;\n\n这里先是定义了一些常量和基本的属性信息，当然这些属性会提供set&amp;get方法，供实际使用时去自行设置。\n1234567891011121314151617181920212223242526272829303132333435363738public LoadingCache&lt;K, V&gt; getCache() &#123;    //使用双重校验锁保证只有一个cache实例    if(cache == null)&#123;        synchronized (this) &#123;            if(cache == null)&#123;                //CacheBuilder的构造函数是私有的，只能通过其静态方法newBuilder()来获得CacheBuilder的实例                cache = CacheBuilder.newBuilder()                        //设置缓存容器的初始容量为100                        .initialCapacity(DEFAULT_SIZE)                        //缓存数据的最大条目                        .maximumSize(maxSize)                        //定时回收:缓存项在给定时间内没有被写访问（创建或覆盖），则回收。                        .expireAfterWrite(expireTime, timeUnit)                        //启用统计-&gt;统计缓存的命中率等                        .recordStats()                        //设置缓存的移除通知                        .removalListener((notification)-&gt; &#123;                            if (LOGGER.isDebugEnabled())&#123;                                LOGGER.debug(&quot;&#123;&#125; was removed, cause is &#123;&#125;&quot; ,notification.getKey(), notification.getCause());                            &#125;                        &#125;)                        .build(new CacheLoader&lt;K, V&gt;() &#123;                            @Override                            public V load(K key) throws Exception &#123;                                return fetchData(key);                            &#125;                        &#125;);                this.resetTime = new Date();                this.highestTime = new Date();                if (LOGGER.isInfoEnabled())&#123;                    LOGGER.info(&quot;本地缓存&#123;&#125;初始化成功.&quot;, this.getClass().getSimpleName());                &#125;            &#125;        &#125;    &#125;    return cache;&#125;\n\n上面这段代码是整个缓存的核心，通过这段代码来生成我们的缓存对象【使用了单例模式】。具体的属性参数看注释。\n因为上面的那些都是封装在一个抽象类AbstractGuavaCache里面的，所以我又封装了一个CacheManger用来管理缓存，并对外提供具体的功能接口；在CacheManger中，我使用了一个静态内部类来创建当前默认的缓存。\n12345678910111213141516171819202122232425262728/** * 使用静态内部类实现一个默认的缓存，委托给manager来管理 * * DefaultGuavaCache 使用一个简单的单例模式 * @param &lt;String&gt; * @param &lt;Object&gt; */private static class DefaultGuavaCache&lt;String, Object&gt; extendsAbstractGuavaCache&lt;String, Object&gt; &#123;    private static AbstractGuavaCache cache = new DefaultGuavaCache();    /**     * 处理自动载入缓存，按实际情况载入     * 这里     * @param key     * @return     */    @Override    protected Object fetchData(String key) &#123;        return null;    &#125;    public static AbstractGuavaCache getInstance() &#123;        return DefaultGuavaCache.cache;    &#125;&#125;\n大概思路就是这样，如果需要扩展，我们只需要按照实际的需求去扩展AbstractGuavaCache这个抽象类就可以了。具体的代码贴在下面了。\n完整的两个类AbstractGuavaCache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137public abstract class AbstractGuavaCache&lt;K, V&gt; &#123;    protected final Logger              LOGGER       = LoggerFactory.getLogger(AbstractGuavaCache.class);    private static final int            MAX_SIZE     = 1000;    private static final int            EXPIRE_TIME  = 10;    /** 用于初始化cache的参数及其缺省值 */    private static final int            DEFAULT_SIZE = 100;    private int                         maxSize      = MAX_SIZE;    private int                         expireTime   = EXPIRE_TIME;    /** 时间单位（分钟） */    private TimeUnit                    timeUnit     = TimeUnit.MINUTES;    /** Cache初始化或被重置的时间  */    private Date                        resetTime;    /** 分别记录历史最多缓存个数及时间点*/    private long                        highestSize  = 0;    private Date                        highestTime;    private volatile LoadingCache&lt;K, V&gt; cache;    public LoadingCache&lt;K, V&gt; getCache() &#123;        //使用双重校验锁保证只有一个cache实例        if(cache == null)&#123;            synchronized (this) &#123;                if(cache == null)&#123;                    //CacheBuilder的构造函数是私有的，只能通过其静态方法ne                    //wBuilder()来获得CacheBuilder的实例                    cache = CacheBuilder.newBuilder()                            //设置缓存容器的初始容量为100                            .initialCapacity(DEFAULT_SIZE)                            //缓存数据的最大条目                            .maximumSize(maxSize)                            //定时回收:缓存项在给定时间内没有被写访问                            //（创建或覆盖），则回收。                            .expireAfterWrite(expireTime, timeUnit)                            //启用统计-&gt;统计缓存的命中率等                            .recordStats()                            //设置缓存的移除通知                            .removalListener((notification)-&gt; &#123;                                if (LOGGER.isDebugEnabled())&#123;                                   //...                                &#125;                            &#125;)                            .build(new CacheLoader&lt;K, V&gt;() &#123;                                @Override                                public V load(K key) throws Exception &#123;                                    return fetchData(key);                                &#125;                            &#125;);                    this.resetTime = new Date();                    this.highestTime = new Date();                    if (LOGGER.isInfoEnabled())&#123;                         //...                    &#125;                &#125;            &#125;        &#125;        return cache;    &#125;    /**     * 根据key从数据库或其他数据源中获取一个value，并被自动保存到缓存中。     *     * 改方法是模板方法，子类需要实现     *     * @param key     * @return value,连同key一起被加载到缓存中的。     */    protected abstract V fetchData(K key);    /**     * 从缓存中获取数据（第一次自动调用fetchData从外部获取数据），并处理异常     * @param key     * @return Value     * @throws ExecutionException     */    protected V getValue(K key) throws ExecutionException &#123;        V result = getCache().get(key);        if (getCache().size() &gt; highestSize) &#123;            highestSize = getCache().size();            highestTime = new Date();        &#125;        return result;    &#125;    public int getMaxSize() &#123;        return maxSize;    &#125;    public void setMaxSize(int maxSize) &#123;        this.maxSize = maxSize;    &#125;    public int getExpireTime() &#123;        return expireTime;    &#125;    public void setExpireTime(int expireTime) &#123;        this.expireTime = expireTime;    &#125;    public TimeUnit getTimeUnit() &#123;        return timeUnit;    &#125;    public void setTimeUnit(TimeUnit timeUnit) &#123;        this.timeUnit = timeUnit;    &#125;    public Date getResetTime() &#123;        return resetTime;    &#125;    public void setResetTime(Date resetTime) &#123;        this.resetTime = resetTime;    &#125;    public long getHighestSize() &#123;        return highestSize;    &#125;    public void setHighestSize(long highestSize) &#123;        this.highestSize = highestSize;    &#125;    public Date getHighestTime() &#123;        return highestTime;    &#125;    public void setHighestTime(Date highestTime) &#123;        this.highestTime = highestTime;    &#125;&#125;\n\nDefaultGuavaCacheManager123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class DefaultGuavaCacheManager &#123;    private static final Logger  LOGGER =    LoggerFactory.getLogger(DefaultGuavaCacheManager.class);   //缓存包装类    private static AbstractGuavaCache&lt;String, Object&gt; cacheWrapper;    /**     * 初始化缓存容器     */    public static boolean initGuavaCache() &#123;        try &#123;            cacheWrapper = DefaultGuavaCache.getInstance();            if (cacheWrapper != null) &#123;                return true;            &#125;        &#125; catch (Exception e) &#123;            LOGGER.error(&quot;Failed to init Guava cache;&quot;, e);        &#125;        return false;    &#125;    public static void put(String key, Object value) &#123;        cacheWrapper.getCache().put(key, value);    &#125;    /**     * 指定缓存时效     * @param key     */    public static void invalidate(String key) &#123;        cacheWrapper.getCache().invalidate(key);    &#125;    /**     * 批量清除     * @param keys     */    public static void invalidateAll(Iterable&lt;?&gt; keys) &#123;        cacheWrapper.getCache().invalidateAll(keys);    &#125;    /**     * 清除所有缓存项 ： 慎用     */    public static void invalidateAll() &#123;        cacheWrapper.getCache().invalidateAll();    &#125;    public static Object get(String key) &#123;        try &#123;            return cacheWrapper.getCache().get(key);        &#125; catch (Exception e) &#123;            LOGGER.error(&quot;Failed to get value from guava cache;&quot;, e);        &#125;        return null;    &#125;    /**     * 使用静态内部类实现一个默认的缓存，委托给manager来管理     *     * DefaultGuavaCache 使用一个简单的单例模式     * @param &lt;String&gt;     * @param &lt;Object&gt;     */    private static class DefaultGuavaCache&lt;String, Object&gt; extends    AbstractGuavaCache&lt;String, Object&gt; &#123;        private static AbstractGuavaCache cache = new DefaultGuavaCache();        /**         * 处理自动载入缓存，按实际情况载入         * @param key         * @return         */        @Override        protected Object fetchData(String key) &#123;            return null;        &#125;        public static AbstractGuavaCache getInstance() &#123;            return DefaultGuavaCache.cache;        &#125;    &#125;&#125;\n\n参考Google Guava官方教程（中文版）\n","slug":"middleware/middleware-cache-guava-practice","date":"2018-06-24T16:30:32.000Z","categories_index":"Middleware","tags_index":"cache,guava","author_index":"glmapper"},{"id":"633ee0890ad90f5dbecf1b679aef9739","title":"聊一聊 AOP：Advice 源码解析","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903624250769421\n在第一篇中的例子和概念介绍中我们对 Advice 有了一个初步的认知。在 Spring AOP 中，Advice 的作用就是用来描述 Spring AOP 围绕方法调用而注入的切面行为。本篇文章将从源码的角度来看一看 Advice 到底是什么样的？又是怎么完成通知的？\n\n\nAdvice 接口1234567891011package org.aopalliance.aop;/** * Tag interface for Advice. Implementations can be any type * of advice, such as Interceptors. * @author Rod Johnson * @version $Id: Advice.java,v 1.1 2004/03/19 17:02:16 johnsonr Exp $ */public interface Advice &#123;&#125;\nAdvice 接口的定义是在 org.aopalliance.aop 包下面的；从上面的代码中我们可以知道，Advice 接口并没有提供任何的方法；类似的接口定义还有java 中的如Serializable接口，这类接口一般称之为标识接口；标识接口对实现它的类没有任何的语义要求,仅仅是充当一个标示的作用,用来表明实现它的类属于一个特定的类型（从这种标识性角度来说，和注解其实挺像的）；\nSpring AOP中通过定义和使用这样一个统一的接口，为的就是能够为切面增强的织入功能做更多的细化和扩展。下面就对常见的三个Advice进行分析。\nBeforeAdvice12public interface BeforeAdvice extends Advice &#123;&#125;\n这个接口也是一个标识接口。看下 BeforeAdvice 的继承关系：\n\nMethodBeforeAdvice 是 BeforeAdvice 为待增强的目标方法设置的前置增强接口。\n1234public interface MethodBeforeAdvice extends BeforeAdvice &#123;    void before(Method method, Object[] args, Object target) throws    Throwable;&#125;\nMethodBeforeAdvice 中提供了一个回调函数 before(...) ；\n作为回调函数，before 方法的实现在 Advice 中被配置到目标方法后，会在调用目标方法时被回调。来看下before方法的几个参数：\n\nMethod method ：（ method being invoked）这个参数是目标方法的反射对象；\nObject[] args ：（arguments to the method）目标方法的输入参数；\nObject target ：（target of the method invocation）方法调用的目标\n\nAspectJMethodBeforeAdviceAspectJMethodBeforeAdvice 继承了 AbstractAspectJAdvice 抽象类，并实现了 MethodBeforeAdvice 接口。从 AspectJMethodBeforeAdvice 类中代码可以得知，AspectJMethodBeforeAdvice 重写 before 方法的实现是 通过调用父类的 invokeAdviceMethod 方法完成的。也就是说Spring AOP 的Advice包装了AspectJ的before方法。\n\nSpring AOP的实现后面再说，我们先自己来实现一个简单的通知。\n自定义 Advice实现 MethodBeforeAdvice定义我们自己的 GlmapperBeforeMethodAdvice ；这里实现 MethodBeforeAdvice 接口，然后重写 before 这个方法。\n1234567891011121314151617181920212223/** * @description: 自定义的 GlmapperBeforeMethodAdvice * @email: &lt;a href=&quot;glmapper_2018@163.com&quot;&gt;&lt;/a&gt; * @author: glmapper@leishu * @date: 18/6/23 */public class GlmapperBeforeMethodAdvice implementsMethodBeforeAdvice,MethodInterceptor &#123;    private static final Logger LOGGER =    LoggerFactory.getLogger(GlmapperBeforeMethodAdvice.class.getSimpleName());    @Override    public void before(Method method, Object[] args, Object target)     throws Throwable &#123;        LOGGER.info(&quot;invoke BeforeAdvice successfully...&quot;);    &#125;    @Override    public Object invoke(MethodInvocation invocation) throws Throwable &#123;        Object result=invocation.proceed();        return result;    &#125;&#125;\n\nOK，有了这个 GlmapperBeforeMethodAdvice ，再来看看怎么用它；同样本篇文章所使用的案例均使用前一篇博客中的那个脚手架来完成。\n12345678910111213141516171819202122232425262728293031&lt;!--我们的目标类--&gt;&lt;bean id=&quot;goodsService&quot;    class=&quot;com.glmapper.framerwork.service.impl.GoodsServiceImpl&quot;/&gt;&lt;!--我们自定义的Advice--&gt;&lt;bean id=&quot;glmapperBeforeMethodAdvice&quot;    class=&quot;com.glmapper.framerwork.Advice.GlmapperBeforeMethodAdvice&quot;&gt;&lt;/bean&gt;&lt;!-- 声明切入点adviser --&gt;&lt;bean id=&quot;adviser&quot;     class=&quot;org.springframework.aop.support.RegexpMethodPointcutAdvisor&quot;&gt;    &lt;!--这里使用我们自定义的advice--&gt;\t&lt;property name=&quot;advice&quot; ref=&quot;glmapperBeforeMethodAdvice&quot;&gt;&lt;/property&gt;\t&lt;!-- pattern指定queryAll方法作为切入点； \\. 这个是转义使用--&gt;\t&lt;property name=&quot;pattern&quot;\t    value=&quot;com\\.glmapper\\.framerwork\\.service\\.impl\\.GoodsServiceImpl\\.queryAll&quot;&gt;\t&lt;/property&gt;&lt;/bean&gt;&lt;!-- 定义代理对象 返回实例是目标对象 target属性指定的goodsService对象--&gt;&lt;bean id=&quot;proxyService&quot;class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt;\t&lt;property name=&quot;target&quot;&gt;\t    &lt;ref bean=&quot;goodsService&quot; /&gt;\t&lt;/property&gt;\t&lt;!--源码内固定的属性private String[] interceptorNames;  --&gt;\t&lt;property name=&quot;interceptorNames&quot;&gt;\t    &lt;value&gt;adviser&lt;/value&gt;\t&lt;/property&gt;&lt;/bean&gt;\n\n客户端部分，通过SpringContextUtil来拿代理对象；\n1234567891011@RequestMapping(&quot;/initPage&quot;)public ModelAndView initPage(HttpServletRequest request,\t\tHttpServletResponse response, ModelAndView view) &#123;    //获取代理bean    GoodsService proxyService= (GoodsService) SpringContextUtil.getBean(&quot;proxyService&quot;);    //调用    List&lt;Goods&gt; goods = proxyService.queryAll(10,10);    view.addObject(&quot;goodsList&quot;, goods);    view.setViewName(&quot;goodslist&quot;);    return view;&#125;\n日志输出满足我们的期望（如下）：\n同样的，在GlmapperBeforeMethodAdvice基础上再实现 AfterReturningAdvice 接口，重写afterReturning方法，就能实现后置通知。\n12345@Overridepublic void afterReturning(Object returnValue, Method method, Object[]args, Object target) throws Throwable &#123;    LOGGER.info(&quot;invoke AfterAdvice successfully...&quot;);&#125;\n\n这个方式在聊一聊 AOP ：表现形式与基础概念中有说道。\nAdvice 在 Aop 中的实现原理这里感觉没什么好说的，上面的案例其实就是Spring提供给我们使用的接口。因为MethodBeforeAdvice等都是继承自 AbstractAspectJAdvice 这个抽象类；我们就来看下这个抽象类里面的一些核心逻辑吧。我们按照AspectJMethodBeforeAdvice这里这个类里面before提供的线索来一步步分析。\n首先在AspectJMethodBeforeAdvice里before方法中调用的是这个逻辑：\n12345678910111213/** * Invoke the advice method. * @param jpMatch the JoinPointMatch that matched this execution join point * @param returnValue the return value from the method execution (may be null) * @param ex the exception thrown by the method execution (may be null) * @return the invocation result * @throws Throwable in case of invocation failure */protected Object invokeAdviceMethod(JoinPointMatch jpMatch, ObjectreturnValue, Throwable ex) throws Throwable &#123;\treturn invokeAdviceMethodWithGivenArgs(argBinding(getJoinPoint(),\tjpMatch, returnValue, ex));&#125;\n\n这里 argBinding 方法的作用是获取方法执行连接点上的参数，并将一组参数输出给Advice方法。\n继续来看invokeAdviceMethodWithGivenArgs这个方法：\n1234567891011121314151617181920212223protected Object invokeAdviceMethodWithGivenArgs(Object[] args) throwsThrowable &#123;    //保存一份参数副本    Object[] actualArgs = args;    //验证下参数是否不存在    if (this.aspectJAdviceMethod.getParameterTypes().length == 0) &#123;    \tactualArgs = null;    &#125;    try &#123;        //设置下方法的访问权限    \tReflectionUtils.makeAccessible(this.aspectJAdviceMethod);    \t// invoke执行；这里先通过aspectInstanceFactory对像拿到我们的目标对象实例，然后再进行invoke调用执行    \treturn this.aspectJAdviceMethod.invoke(this.aspectInstanceFactory.getAspectInstance(), actualArgs);    &#125;    catch (IllegalArgumentException ex) &#123;    \tthrow new AopInvocationException(&quot;Mismatch on arguments to advice method [&quot; +    \t\t\tthis.aspectJAdviceMethod + &quot;]; pointcut expression [&quot; +    \t\t\tthis.pointcut.getPointcutExpression() + &quot;]&quot;, ex);    &#125;    catch (InvocationTargetException ex) &#123;    \tthrow ex.getTargetException();    &#125;&#125;\n\n上面这段代码其实就是通过反射的方式执行了我们的目标方法。我们再回过头来看下我们的目标方法到底在哪里去进行增强的；这里我们通过配置文件来看：\n123456789101112&lt;!-- 代理对象 返回实例是目标对象 target属性指定的AOPservice对象--&gt;&lt;bean id=&quot;proxyService&quot;class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt;\t&lt;property name=&quot;target&quot;&gt;\t\t&lt;ref bean=&quot;goodsService&quot; /&gt;\t&lt;/property&gt;\t&lt;!--源码内固定的属性private String[] interceptorNames;  --&gt;\t&lt;property name=&quot;interceptorNames&quot;&gt;\t\t&lt;value&gt;adviser&lt;/value&gt;\t&lt;/property&gt;&lt;/bean&gt;\n\n代理对象proxyService实现上是ProxyFactoryBean产生的；这里就不在阐述BeanFactory和FactoryBean的区别了。\n从上面的配置文件我们可以简单的了解到，代理对象实际上是我们目标对象+adviser共同组成；而在adviser里面又包括了我们的通知。\nProxyFactoryBean继承了FactoryBean，我们知道FactoryBean也是用来生成bean的，但是它生成的bean是通过其getObject方法来获取的。OK，那我们来看下ProxyFactoryBean的getObject方法：\n1234567891011121314151617181920212223/** * Return a proxy. Invoked when clients obtain beans from this factory bean. * Create an instance of the AOP proxy to be returned by this factory. * The instance will be cached for a singleton, and create on each call to * &#123;@code getObject()&#125; for a proxy. * @return a fresh AOP proxy reflecting the current state of this factory */@Overridepublic Object getObject() throws BeansException &#123;    //初始化Advisor链    initializeAdvisorChain();    //如果是单例，则获取单例对象    if (isSingleton()) &#123;    \treturn getSingletonInstance();    &#125;    else &#123;    \tif (this.targetName == null) &#123;    \t\tlogger.warn(&quot;Using non-singleton proxies with singleton targets is often undesirable. &quot; +    \t\t\t\t&quot;Enable prototype proxies by setting the &#x27;targetName&#x27; property.&quot;);    \t&#125;    \treturn newPrototypeInstance();    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n返回一个代理。当客户端从这个工厂bean获取bean时调用。创建该工厂返回的AOP代理的一个实例。该实例将被缓存为一个单例，并在每次调用时创建。\ninitializeAdvisorChain：创建 advisor（拦截器）链。每次添加新的 prototype 实例时，源自 BeanFactory 的 Advisor 都将被刷新。通过工厂 API 以编程方式添加的拦截器不受此类更改的影响。（译注）；其实就是根据我们配置的interceptorNames来初始化我们的advisor（拦截器）链，用来增强我们的目标调用方法。\n下面是getSingletonInstance这个方法：\n123456789101112131415161718192021222324/** * Return the singleton instance of this class&#x27;s proxy object, * lazily creating it if it hasn&#x27;t been created already. * @return the shared singleton proxy */private synchronized Object getSingletonInstance() &#123;    if (this.singletonInstance == null) &#123;        //创建目标对象的代理    \tthis.targetSource = freshTargetSource();    \tif (this.autodetectInterfaces &amp;&amp; getProxiedInterfaces().length == 0 &amp;&amp; !isProxyTargetClass()) &#123;        \t// Rely on AOP infrastructure to tell us what interfaces to proxy.        \t//获取目标类        \tClass&lt;?&gt; targetClass = getTargetClass();        \tif (targetClass == null) &#123;        \t\tthrow new FactoryBeanNotInitializedException(&quot;Cannot determine target class for proxy&quot;);        \t&#125;        \tsetInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.proxyClassLoader));    \t&#125;    \t// Initialize the shared singleton instance.    \tsuper.setFrozen(this.freezeProxy);    \tthis.singletonInstance = getProxy(createAopProxy());    &#125;    return this.singletonInstance;&#125;\n\n上面代码最核心的是getProxy这个方法，这里方式有两个方式，一个是cglib，另外一种是jdk动态代理：\n\n这里我们以默认的动态代理的方式来说：(org.springframework.aop.framework.JdkDynamicAopProxy类中)\n1234567891011@Overridepublic Object getProxy(ClassLoader classLoader) &#123;    if (logger.isDebugEnabled()) &#123;    \tlogger.debug(&quot;Creating JDK dynamic proxy: target source is &quot; +    \tthis.advised.getTargetSource());    &#125;    Class&lt;?&gt;[] proxiedInterfaces =    AopProxyUtils.completeProxiedInterfaces(this.advised);    findDefinedEqualsAndHashCodeMethods(proxiedInterfaces);    return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);&#125;\n\n这个方法返回的就是指定接口的代理类实例，该接口将方法调用分派给指定的调用处理程序。到此整个AOP代理生成逻辑就完了。\n总结代理类中其实包括了 AOP 增强的那部分逻辑的，这个其实从上面的配置文件中就很清楚的可以看出来；所以从 Adivce 这个角度来说，它其实会被包在 advisor 中，然后在被传递到代理对象中，代理对象除了拥有我们目标对象的能力之外，还包括了 Adivce 的能力；通过这种方式就实现了增强。\n\n\n\n\n\n\n\n\n\n关于 Advice 就到这里了，下一章会来单独说一下 PointCut 。\n","slug":"spring/spring-aop-advice-analysis","date":"2018-06-23T10:41:25.000Z","categories_index":"spring","tags_index":"spring,aop","author_index":"glmapper"},{"id":"740732400e76d891c8b7f2d184b75bcc","title":"聊一聊 AOP ：表现形式与基础概念","content":"\n\n\n\n\n\n\n\n\n原文：https://juejin.cn/post/6844903623101513735\n\n\n\n\n\n\n\n\n\naop 终于提上日程来写一写了。\n本系列分为 上、中、下三篇。上篇主要是介绍如果使用 AOP ，提供了demo和配置方式说明；中篇来对实现 AOP 的技术原理进行分析；下篇主要针对Spring中对于AOP的实现进行源码分析。\n\n\n目录\n从一个例子说起\n基于代理的方式 \n纯POJO切面 配置方式\nAspectJ 注解方式\nAspectJ XML 配置方式\n表达式说明\n\n\n基础概念\nAOP概念\nTarget Object\n织入（Weave\nProxy\nIntroduction\nAspect\nJoinpoint\nPointcut\nAdvice\n概念\n分类\n\n\n关系\n\n\n一些坑\n\n项目地址项目地址：glmapper-ssm-parent\n这个项目里面包含了下面几种 AOP 实现方式的所有代码，有兴趣的同学可以fork跑一下。这个demo中列举了4中方式的实现：\n\n基于代码的方式\n基于纯POJO类的方式\n基于Aspect注解的方式\n基于注入式Aspect的方式\n\n目前我们经常用到的是基于Aspect注解的方式的方式。下面来一个个了解下不同方式的表现形式。\n基于代理的方式这种方式看起来很好理解，但是配置起来相当麻烦；小伙伴们可以参考项目来看，这里只贴出比较关键的流程代码。\n1、首先定义一个接口：GoodsService12345678910public interface GoodsService &#123;\t/**\t * 查询所有商品信息\t * \t * @param offset 查询起始位置\t * @param limit 查询条数\t * @return\t */\tList&lt;Goods&gt; queryAll(int offset,int limit);&#125;\n\n2、GoodsService 实现类123456789101112@Service@Qualifier(&quot;goodsService&quot;)public class GoodsServiceImpl implements GoodsService &#123;\t@Autowired \tprivate GoodsDao goodsDao;\t\tpublic List&lt;Goods&gt; queryAll(int offset, int limit) &#123;\t\tSystem.out.println(&quot;执行了queryAll方法&quot;);\t\tList&lt;Goods&gt; list = new ArrayList&lt;Goods&gt;();\t\treturn list;\t&#125;&#125;\n\n3、定义一个通知类 LoggerHelper，该类继承 MethodBeforeAdvice和 AfterReturningAdvice。123456789101112131415//通知类 LoggerHelperpublic class LoggerHelper implements MethodBeforeAdvice,AfterReturningAdvice &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(LoggerHelper.class);    //MethodBeforeAdvice的before方法实现    public void before(Method method, Object[] objects, Object o) throws Throwable &#123;        LOGGER.info(&quot;before current time:&quot;+System.currentTimeMillis());    &#125;    //AfterReturningAdvice的afterReturning方法实现    public void afterReturning(Object o, Method method,    Object[] objects, Object o1) throws Throwable &#123;        LOGGER.info(&quot;afterReturning current time:&quot;+System.currentTimeMillis());    &#125;&#125;\n\n4、重点，这个配置需要关注下。这个项目里面我是配置在applicationContext.xml文件中的。12345678910111213141516171819202122232425262728&lt;!-- 定义被代理者 --&gt;&lt;bean id=&quot;goodsServiceImpl&quot; class=&quot;com.glmapper.framerwork.service.impl.GoodsServiceImpl&quot;&gt;&lt;/bean&gt;&lt;!-- 定义通知内容，也就是切入点执行前后需要做的事情 --&gt;&lt;bean id=&quot;loggerHelper&quot; class=&quot;com.glmapper.framerwork.aspect.LoggerHelper&quot;&gt;&lt;/bean&gt;&lt;!-- 定义切入点位置 --&gt;&lt;bean id=&quot;loggerPointcut&quot; class=&quot;org.springframework.aop.support.JdkRegexpMethodPointcut&quot;&gt;\t&lt;property name=&quot;pattern&quot; value=&quot;.*query.*&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 使切入点与通知相关联，完成切面配置 --&gt;&lt;!-- 从这里可以帮助我们理解Advisor，advice和pointcut之间的关系--&gt;&lt;!--adivce和pointcut是Advisor的两个属性--&gt;&lt;bean id=&quot;loggerHelperAdvisor&quot; class=&quot;org.springframework.aop.support.DefaultPointcutAdvisor&quot;&gt;\t&lt;property name=&quot;advice&quot; ref=&quot;loggerHelper&quot;&gt;&lt;/property&gt;\t&lt;property name=&quot;pointcut&quot; ref=&quot;loggerPointcut&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 设置代理 --&gt;&lt;bean id=&quot;proxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt;\t&lt;!-- 代理的对象 ，也就是目标类--&gt;\t&lt;property name=&quot;target&quot; ref=&quot;goodsServiceImpl&quot;&gt;&lt;/property&gt;\t&lt;!-- 使用切面 --&gt;\t&lt;property name=&quot;interceptorNames&quot; value=&quot;loggerHelperAdvisor&quot;&gt;&lt;/property&gt;\t&lt;!-- 代理接口，商品接口 --&gt;\t&lt;property name=&quot;proxyInterfaces&quot; value=&quot;com.glmapper.framerwork.service.GoodsService&quot;&gt;&lt;/property&gt;&lt;/bean&gt;\n\n5、使用：注解注入方式1234567891011121314151617181920@Controller@RequestMapping(&quot;/buy&quot;)public class BuyController &#123;    @Autowired    private OrderService orderService;    //因为我们已经在配置文件中配置了proxy，    //所以这里可以直接注入拿到我们的代理类    @Autowired    private GoodsService proxy;        @RequestMapping(&quot;/initPage&quot;)    public ModelAndView initPage(HttpServletRequest request,    \tHttpServletResponse response, ModelAndView view) &#123;    //这里使用proxy执行了*query*,    List&lt;Goods&gt; goods = proxy.queryAll(10,10);    view.addObject(&quot;goodsList&quot;, goods);    view.setViewName(&quot;goodslist&quot;);    return view;    &#125;&#125;\n6、使用：工具类方式手动获取bean这个方式是通过一个SpringContextUtil工具类来获取代理对象的。\n12345678910@RequestMapping(&quot;/initPage&quot;)public ModelAndView initPage(HttpServletRequest request,\tHttpServletResponse response, ModelAndView view) &#123;    //这里通过工具类来拿，效果一样的。    GoodsService proxy= (GoodsService) SpringContextUtil.getBean(&quot;proxy&quot;);    List&lt;Goods&gt; goods = proxy.queryAll(10,10);    view.addObject(&quot;goodsList&quot;, goods);    view.setViewName(&quot;goodslist&quot;);    return view;&#125;\n\n7、SpringContextUtil 类的定义这个还是有点坑的，首先SpringContextUtil是继承ApplicationContextAware这个接口，我们希望能够SpringContextUtil可以被Spring容器直接管理，所以，需要使用 @Component 标注。标注了之后最关键的是它得能够被我们配置的注入扫描扫到（亲自踩的坑，我把它放在一个扫不到的包下面，一直debug都是null；差点砸电脑…）\n12345678910111213141516171819202122232425262728293031323334@Componentpublic class SpringContextUtil implements ApplicationContextAware &#123;    // Spring应用上下文环境    private static ApplicationContext applicationContext;    /**     * 实现ApplicationContextAware接口的回调方法，设置上下文环境     *     * @param applicationContext     */    public void setApplicationContext(ApplicationContext applicationContext) &#123;        SpringContextUtil.applicationContext = applicationContext;    &#125;    /**     * @return ApplicationContext     */    public static ApplicationContext getApplicationContext() &#123;        return applicationContext;    &#125;    /**     * 获取对象     * 这里重写了bean方法，起主要作用     * @param name     * @return Object 一个以所给名字注册的bean的实例     * @throws BeansException     */    public static Object getBean(String name) throws BeansException &#123;        return applicationContext.getBean(name);    &#125;&#125;\n\n8、运行结果12345678921:04:47.940 [http-nio-8080-exec-7] INFO c.g.framerwork.aspect.LoggerHelper - before currenttime:1529413487940执行了queryAll方法21:04:47.940 [http-nio-8080-exec-7] INFO c.g.framerwork.aspect.LoggerHelper - afterReturning currenttime:1529413487940\n\n上面就是最最经典的方式，就是通过代理的方式来实现AOP的过程。\n纯POJO切面 aop:config注意这里和LoggerHelper的区别，这里的LoggerAspect并没有继承任何接口或者抽象类。\n1、POJO 类定义123456789101112131415161718/** * @description: [描述文本] * @email: &lt;a href=&quot;guolei.sgl@antfin.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/6/20 */public class LoggerAspect &#123;    private static final Logger LOGGER =    LoggerFactory.getLogger(LoggerHelper.class);    public void before()&#123;        LOGGER.info(&quot;before current time:&quot;+System.currentTimeMillis());    &#125;    public void afterReturning() &#123;        LOGGER.info(&quot;afterReturning current time:&quot;+System.currentTimeMillis());    &#125;&#125; \n2、配置文件123456789101112131415161718&lt;!-- 定义通知内容，也就是切入点执行前后需要做的事情 --&gt;&lt;bean id=&quot;loggerAspect&quot;      class=&quot;com.glmapper.framerwork.aspect.LoggerAspect&quot;&gt;&lt;/bean&gt;&lt;aop:config&gt;    &lt;!--定义切面--&gt;    &lt;aop:aspect ref=&quot;loggerAspect&quot;&gt;    \t&lt;aop:pointcut id=&quot;loggerPointCut&quot;  expression=    \t&quot;execution(* com.glmapper.framerwork.service.impl.*.*(..)) &quot; /&gt;    \t&lt;!-- 定义 Advice --&gt;    \t&lt;!-- 前置通知 --&gt;    \t&lt;aop:before pointcut-ref=&quot;loggerPointCut&quot; method=&quot;before&quot; /&gt;    \t&lt;!-- 后置通知 --&gt;    \t&lt;aop:after-returning pointcut-ref=&quot;loggerPointCut&quot;    \tmethod=&quot;afterReturning&quot;/&gt;    &lt;/aop:aspect&gt;&lt;/aop:config&gt;\n\n注意这里LoggerAspect中的before和afterReturning如果有参数，这里需要处理下，否则会报 0 formal unbound in pointcut 异常。\n@AspectJ 注解驱动方式这种方式是最简单的一种实现，直接使用 @Aspect 注解标注我们的切面类即可。\n1、定义切面类，并使用 @Aspect 进行标注123456789101112131415161718192021222324/** * @description: 使用Aspect注解驱动的方式 * @email: &lt;a href=&quot;guolei.sgl@antfin.com&quot;&gt;&lt;/a&gt; * @author: guolei.sgl * @date: 18/6/20 */@Aspectpublic class LoggerAspectInject &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(LoggerAspectInject.class);    @Pointcut(&quot;execution(* com.glmapper.framerwork.service.impl.*.*(..))&quot;)    public void cutIn()&#123;&#125;    @Before(&quot;cutIn()&quot;)    public void before()&#123;        LOGGER.info(&quot;before current time:&quot;+System.currentTimeMillis());    &#125;    @AfterReturning(&quot;cutIn()&quot;)    public void AfterReturning()&#123;        LOGGER.info(&quot;afterReturning current time:&quot;+System.currentTimeMillis());    &#125;&#125;\n\n2、使用方式1：配置文件方式声明 bean123456789&lt;aop:aspectj-autoproxy /&gt;&lt;!-- 定义通知内容，也就是切入点执行前后需要做的事情 --&gt;&lt;bean id=&quot;loggerAspectInject&quot;    class=&quot;com.glmapper.framerwork.aspect.LoggerAspectInject&quot;&gt;&lt;/bean&gt;&lt;!-- 定义被代理者 --&gt;&lt;bean id=&quot;goodsServiceImpl&quot;    class=&quot;com.glmapper.framerwork.service.impl.GoodsServiceImpl&quot;&gt;&lt;/bean&gt;\n\n3、客户端使用：1234567891011121314151617181920@Controller@RequestMapping(&quot;/buy&quot;)public class BuyController &#123;    @Autowired    private OrderService orderService;        @RequestMapping(&quot;/initPage&quot;)    public ModelAndView initPage(HttpServletRequest request,    \t\tHttpServletResponse response, ModelAndView view) &#123;        //通过SpringContextUtil手动获取 代理bean    \tGoodsService goodsService=(GoodsService)    \tSpringContextUtil.getBean(&quot;goodsServiceImpl&quot;);        \tList&lt;Goods&gt; goods = goodsService.queryAll(10,10);    \tview.addObject(&quot;goodsList&quot;, goods);    \tview.setViewName(&quot;goodslist&quot;);    \treturn view;    &#125;&#125;\n\n4、使用方式2：使用@component注解托管给IOC1234567891011121314151617181920@Aspect@Component //这里加上了Component注解，就不需要在xml中配置了public class LoggerAspectInject &#123;    private static final Logger LOGGER =    LoggerFactory.getLogger(LoggerAspectInject.class);    @Pointcut(&quot;execution(* com.glmapper.framerwork.service.impl.*.*(..))&quot;)    public void cutIn()&#123;&#125;    @Before(&quot;cutIn()&quot;)    public void before()&#123;        LOGGER.info(&quot;before current time:&quot;+System.currentTimeMillis());    &#125;    @AfterReturning(&quot;cutIn()&quot;)    public void AfterReturning()&#123;        LOGGER.info(&quot;afterReturning current time:&quot;+System.currentTimeMillis());    &#125;&#125;\n5、客户端代码：1234567891011121314151617181920@Controller@RequestMapping(&quot;/buy&quot;)public class BuyController &#123;    @Autowired    private OrderService orderService;    //直接注入    @Autowired    private GoodsService goodsService;        @RequestMapping(&quot;/initPage&quot;)    public ModelAndView initPage(HttpServletRequest request,    \t\tHttpServletResponse response, ModelAndView view) &#123;    \t    \tList&lt;Goods&gt; goods = goodsService.queryAll(10,10);    \tview.addObject(&quot;goodsList&quot;, goods);    \tview.setViewName(&quot;goodslist&quot;);    \treturn view;    &#125;&#125;\n\n6、比较完整的一个LoggerAspectInject，在实际工程中可以直接参考123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @description: aop * @email: &lt;a href=&quot;henugl@1992.163.com&quot;&gt;&lt;/a&gt; * @author: glmapper@磊叔 * @date: 18/6/4 */@Aspect@Componentpublic class LoggerAspectInject &#123;    private static final Logger LOGGER= LoggerFactory.getLogger(LoggerAspectInject.class);        @Pointcut(&quot;execution(* com.glmapper.book.web.controller.*.*(..))&quot;)    public void cutIn()&#123;    &#125;    @Around(&quot;cutIn()&quot;)   // 定义Pointcut，名称即下面的标识&quot;aroundAdvice    public Object aroundAdvice(ProceedingJoinPoint poin)&#123;        System.out.println(&quot;环绕通知&quot;);        Object object = null;        try&#123;            object = poin.proceed();        &#125;catch (Throwable e)&#123;            e.printStackTrace();        &#125;        return object;    &#125;    // 定义 advise    //这个方法只是一个标识，相当于在配置文件中定义了pointcut的id,此方法没有返回值和参数    @Before(&quot;cutIn()&quot;)    public void beforeAdvice()&#123;        System.out.println(&quot;前置通知&quot;);    &#125;    @After(&quot;cutIn()&quot;)    public void afterAdvice()&#123;        System.out.println(&quot;后置通知&quot;);    &#125;    @AfterReturning(&quot;cutIn()&quot;)    public void afterReturning()&#123;        System.out.println(&quot;后置返回 &quot;);    &#125;    @AfterThrowing(&quot;cutIn()&quot;)    public void afterThrowing()&#123;        System.out.println(&quot;后置异常&quot;);    &#125;&#125;\n\n关于命名切入点：上面的例子中cutIn方法可以被称之为命名切入点，命名切入点可以被其他切入点引用，而匿名切入点是不可以的。只有@AspectJ支持命名切入点，而Schema风格不支持命名切入点。如下所示，@AspectJ使用如下方式引用命名切入点：\n12345678@Pointcut(&quot;execution(* com.glmapper.book.web.controller.*.*(..))&quot;)public void cutIn()&#123;&#125;//引入命名切入点@Before(&quot;cutIn()&quot;)public void beforeAdvice()&#123;    System.out.println(&quot;前置通知&quot;);&#125;\n\n注入式 AspectJ 切面这种方式我感觉是第二种和第三种的结合的一种方式。\n1、定义切面类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/*** @description: 注入式 也是一种通过XML方式配置的方式* @email: &lt;a href=&quot;guolei.sgl@antfin.com&quot;&gt;&lt;/a&gt;* @author: guolei.sgl* @date: 18/6/20*/public class LoggerAspectHelper &#123;    private static final Logger LOGGER = LoggerFactory.getLogger(LoggerAspectHelper.class);        /**     * 调动方法前执行     * @param point     * @throws Throwable     */    public void doBefore(JoinPoint point) throws Throwable &#123;        LOGGER.info(&quot;before current time:&quot;+System.currentTimeMillis());    &#125;        /**     * 在调用方法前后执行     * @param point     * @return     * @throws Throwable     */    public Object doAround(ProceedingJoinPoint point) throws Throwable    &#123;        LOGGER.info(&quot;around current time:&quot;+System.currentTimeMillis());        if(point.getArgs().length&gt;0) &#123;            return point.proceed(point.getArgs());        &#125;else&#123;            return point.proceed();        &#125;    &#125;        /**     * 在调用方法之后执行     * @param point     * @throws Throwable     */    public void doAfter(JoinPoint point) throws Throwable    &#123;        LOGGER.info(&quot;after current time:&quot;+System.currentTimeMillis());    &#125;        /**     * 异常通知     * @param point     * @param ex     */    public void doThrowing(JoinPoint point, Throwable ex)    &#123;        LOGGER.info(&quot;throwing current time:&quot;+System.currentTimeMillis());    &#125;&#125;\n\n2、XML 配置12345678910111213141516171819&lt;bean id=&quot;loggerAspectHelper&quot;        class=&quot;com.glmapper.framerwork.aspect.LoggerAspectHelper&quot;&gt;&lt;/bean&gt;&lt;aop:config&gt;    &lt;aop:aspect id=&quot;configAspect&quot; ref=&quot;loggerAspectHelper&quot;&gt;    \t&lt;!--配置com.glmapper.framerwork.service.imp    \t包下所有类或接口的所有方法 --&gt;    \t&lt;aop:pointcut id=&quot;cutIn&quot; expression=    \t&quot;execution(* com.glmapper.framerwork.service.impl.*.*(..))&quot; /&gt;    \t    \t&lt;aop:before   pointcut-ref=&quot;cutIn&quot; method=&quot;doBefore&quot; /&gt;    \t&lt;aop:after    pointcut-ref=&quot;cutIn&quot; method=&quot;doAfter&quot; /&gt;    \t&lt;aop:around   pointcut-ref=&quot;cutIn&quot; method=&quot;doAround&quot; /&gt;    \t&lt;aop:after-throwing pointcut-ref=&quot;cutIn&quot;     \t    method=&quot;doThrowing&quot; throwing=&quot;ex&quot; /&gt;    \t    &lt;/aop:aspect&gt;&lt;/aop:config&gt;\n\n3、结果123456723:39:48.756 [http-nio-8080-exec-4] INFO  c.g.f.aspect.LoggerAspectHelper- before current time:152950918875623:39:48.757 [http-nio-8080-exec-4] INFO  c.g.f.aspect.LoggerAspectHelper- around current time:1529509188757excute queryAll method...23:39:48.757 [http-nio-8080-exec-4] INFO  c.g.f.aspect.LoggerAspectHelper- after current time:1529509188757\n\n表达式\n从上面的例子中我们都是使用一些正则表达式来指定我们的切入点的。在实际的使用中，不仅仅是execution，还有其他很多种类型的表达式。下面就列举一些：\n1、execution用于匹配方法执行的连接点;\n1execution(* com.glmapper.book.web.controller.*.*(..))\n\n\nexecution（）表达式的主体；\n第一个 “*” 符号表示返回值的类型任意；\ncom.glmapper.book.web.controller       AOP所切的服务的包名，即，我们的业务部分\n包名后面的”.”\t表示当前包及子包\n第二个”*”\t表示类名，即所有类\n.*(..) 表示任何方法名，括号表示参数，两个点表示任何参数类型\n\n2、within用于匹配指定类型内的方法执行;\n123456//如果在com.glmapper.book.web.controller包或其下的任何子包中//定义了该类型，则在Web层中有一个连接点。within(com.glmapper.book.web.controller..*)@Pointcut(&quot;within(com.glmapper.book.web.controller..*)&quot;)public void cutIn()&#123;&#125;\n@within：用于匹配所以持有指定注解类型内的方法；\n12345678910/** * @description: 注解定义 * @email: &lt;a href=&quot;henugl@1992.163.com&quot;&gt;&lt;/a&gt; * @author: glmapper@磊叔 * @date: 18/6/4 */@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD,ElementType.FIELD&#125;)public @interface AuthAnnotation &#123;&#125;\n\n任何目标对象对应的类型持有AuthAnnotation注解的类方法；必须是在目标对象上声明这个注解，在接口上声明的对它不起作用。\n12345@within(com.glmapper.book.common.annotaion.AuthAnnotation)//所有被@AdviceAnnotation标注的类都将匹配@Pointcut(&quot;@within(com.glmapper.book.common.annotaion.AuthAnnotation)&quot;) public void cutIn()&#123;&#125;\n\n3、this用于匹配当前AOP代理对象类型的执行方法；注意是AOP代理对象的类型匹配，这样就可能包括引入接口也类型匹配；this中使用的表达式必须是类型全限定名，不支持通配符；\n12345678//当前目标对象（非AOP对象）实现了 UserService 接口的任何方法this(com.glmapper.book.web.service.UserService)//用于向通知方法中传入代理对象的引用。@Before(&quot;cutIn() &amp;&amp; this(proxy)&quot;)public void beforeAdvice(ProceedingJoinPoint poin,Object proxy)&#123;    System.out.println(&quot;前置通知&quot;);&#125;\n4、target用于匹配当前目标对象类型的执行方法；注意是目标对象的类型匹配，这样就不包括引入接口也类型匹配；target中使用的表达式必须是类型全限定名，不支持通配符；\n12345678//当前目标对象（非AOP对象）实现了 UserService 接口的任何方法target(com.glmapper.book.web.service.UserService)//用于向通知方法中传入代理对象的引用。@Before(&quot;cutIn() &amp;&amp; target(proxy)&quot;)public void beforeAdvice(ProceedingJoinPoint poin,Object proxy)&#123;    System.out.println(&quot;前置通知&quot;);&#125;\n@target：用于匹配当前目标对象类型的执行方法，其中目标对象持有指定的注解；任何目标对象持有Secure注解的类方法；这个和@within一样必须是在目标对象上声明这个注解，在接口上声明的对它同样不起作用。\n1234@target(com.glmapper.book.common.annotaion.AuthAnnotation)@Pointcut(&quot;@target(com.glmapper.book.common.annotaion.AuthAnnotation)&quot;)public void cutIn()&#123;&#125;\n\n5、args用于匹配当前执行的方法传入的参数为指定类型的执行方法；参数类型列表中的参数必须是类型全限定名，通配符不支持；args属于动态切入点，这种切入点开销非常大，非特殊情况最好不要使用；\n12345678910//任何一个以接受“传入参数类型为java.io.Serializable”开头，//且其后可跟任意个任意类型的参数的方法执行，//args指定的参数类型是在运行时动态匹配的args (java.io.Serializable,..)//用于将参数传入到通知方法中。@Before(&quot;cutIn() &amp;&amp; args(age,username)&quot;)public void beforeAdvide(JoinPoint point, int age, String username)&#123;  //...&#125;\n\n@args：用于匹配当前执行的方法传入的参数持有指定注解的执行；任何一个只接受一个参数的方法，且方法运行时传入的参数持有注解AuthAnnotation；动态切入点，类似于arg指示符；\n123456@args (com.glmapper.book.common.annotaion.AuthAnnotation)@Before(&quot;@args(com.glmapper.book.common.annotaion.AuthAnnotation)&quot;)public void beforeAdvide(JoinPoint point)&#123;  //...&#125;\n\n6、@annotation使用“@annotation(注解类型)”匹配当前执行方法持有指定注解的方法；注解类型也必须是全限定类型名；\n1234567//当前执行方法上持有注解 AuthAnnotation将被匹配@annotation(com.glmapper.book.common.annotaion.AuthAnnotation)//匹配连接点被它参数指定的AuthAnnotation注解的方法。//也就是说，所有被指定注解标注的方法都将匹配。@Pointcut(&quot;@annotation(com.glmapper.book.common.annotaion.AuthAnnotation)&quot;)public void cutIn()&#123;&#125;\n\n\n\n\n\n\n\n\n\n还有一种是bean的方式，没用过。有兴趣可以看看。\n例子在下面说到的基础概念部分对应给出。\n基础概念基础概念部分主要将 AOP 中的一些概念点捋一捋，这部分主要参考了官网上的一些解释。\nAOPAOP(Aspect-Oriented Programming)， 即 面向切面编程, 它与 OOP( Object-Oriented Programming, 面向对象编程) 相辅相成, 提供了与 OOP 不同的抽象软件结构的视角。在 OOP 中,我们以类(class)作为我们的基本单元, 而 AOP 中的基本单元是 **Aspect(切面)**。\n横切关注点(Cross Cutting Concern)：独立服务，如系统日志。如果不是独立服务（就是与业务耦合比较强的服务）就不能横切了。通常这种独立服务需要遍布系统各个角落，遍布在业务流程之中。\nTarget Object目标对象。织入 advice 的目标对象。 目标对象也被称为 advised object。因为 Spring AOP 使用运行时代理的方式来实现 aspect, 因此 adviced object 总是一个代理对象(proxied object)；注意， adviced object 指的不是原来的类, 而是织入 advice 后所产生的代理类。\n织入（Weave）即Advice应用在JoinPoint的过程，这个过程叫织入。从另外一个角度老说就是将 aspect 和其他对象连接起来, 并创建 adviced object 的过程。\n根据不同的实现技术， AOP织入有三种方式:\n\n编译器织入，这要求有特殊的Java编译器\n类装载期织入， 这需要有特殊的类装载器\n动态代理织入, 在运行期为目标类添加增强( Advice )生成子类的方式。\n\nSpring 采用动态代理织入, 而AspectJ采用编译器织入和类装载期\n代理Spring AOP默认使用代理的是标准的JDK动态代理。这使得任何接口（或一组接口）都可以代理。\nSpring AOP也可以使用CGLIB代理。如果业务对象不实现接口，则默认使用CGLIB。对接口编程而不是对类编程是一种很好的做法；业务类通常会实现一个或多个业务接口。在一些特殊的情况下，即需要通知的接口上没有声明的方法，或者需要将代理对象传递给具体类型的方法，有可能强制使用CGLIB。\nIntroductions我们知道Java语言本身并非是动态的，就是我们的类一旦编译完成，就很难再为他添加新的功能。但是在一开始给出的例子中，虽然我们没有向对象中添加新的方法，但是已经向其中添加了新的功能。这种属于向现有的方法添加新的功能，那能不能为一个对象添加新的方法呢？答案肯定是可以的，使用introduction就能够实现。\nintroduction：动态为某个类增加或减少方法。为一个类型添加额外的方法或字段。Spring AOP 允许我们为 目标对象 引入新的接口(和对应的实现)。\nAspect切面：通知和切入点的结合。\n切面实现了cross-cutting（横切）功能。最常见的是logging模块、方法执行耗时模块，这样，程序按功能被分为好几层，如果按传统的继承的话，商业模型继承日志模块的话需要插入修改的地方太多，而通过创建一个切面就可以使用AOP来实现相同的功能了，我们可以针对不同的需求做出不同的切面。\n而将散落于各个业务对象之中的Cross-cutting concerns 收集起来，设计各个独立可重用的对象，这些对象称之为Aspect；在上面的例子中我们根据不同的配置方式，定义了四种不同形式的切面。\nJoinpointAspect 在应用程序执行时加入业务流程的点或时机称之为 Joinpoint ，具体来说，就是 Advice 在应用程序中被呼叫执行的时机，这个时机可能是某个方法被呼叫之前或之后（或两者都有），或是某个异常发生的时候。\nJoinpoint &amp; ProceedingJoinPoint环绕通知 &#x3D; 前置+目标方法执行+后置通知，proceed方法就是用于启动目标方法执行的。\n环绕通知 ProceedingJoinPoint 执行 proceed 方法 的作用是让目标方法执行 ，这 也是环绕通知和前置、后置通知方法的一个最大区别。\nProceedingjoinpoint 继承了 JoinPoint 。是在JoinPoint的基础上暴露出 proceed 这个方法。proceed很重要，这个是aop代理链执行的方法；暴露出这个方法，就能支持aop:around 这种切面（其他的几种切面只需要用到JoinPoint，这跟切面类型有关）， 能决定是否走代理链还是走自己拦截的其他逻辑。\n在环绕通知的方法中是需要返回一个Object类型对象的，如果把环绕通知的方法返回类型是void，将会导致一些无法预估的情况，比如：404。\nPointcut匹配 join points 的谓词。Advice与切入点表达式相关联, 并在切入点匹配的任何连接点上运行。（例如，具有特定名称的方法的执行）。由切入点表达式匹配的连接点的概念是AOP的核心，Spring默认使用AspectJ切入点表达式语言。\n在 Spring 中, 所有的方法都可以认为是 Joinpoint, 但是我们并不希望在所有的方法上都添加 Advice, 而 Pointcut 的作用就是提供一组规则(使用 AspectJ pointcut expression language 来描述) 来匹配Joinpoint, 给满足规则的Joinpoint 添加 Advice。\nPointcut 和 Joinpoint在 Spring AOP 中, 所有的方法执行都是 join point。 而 point cut 是一个描述信息，它修饰的是 join point， 通过 point cut，我们就可以确定哪些 join point 可以被织入 Advice。 因此 join point 和 point cut 本质上就是两个不同维度上的东西。\nadvice 是在 join point 上执行的, 而 point cut 规定了哪些 join point 可以执行哪些 advice。\nAdvice概念Advice 是我们切面功能的实现，它是切点的真正执行的地方。比如像前面例子中打印时间的几个方法（被@Before等注解标注的方法都是一个通知）；Advice 在 Jointpoint 处插入代码到应用程序中。\n分类BeforeAdvice，AfterAdvice，区别在于Advice在目标方法之前调用还是之后调用，Throw Advice 表示当目标发生异常时调用Advice。\n\nbefore advice： 在 join point 前被执行的 advice. 虽然 before advice 是在 join point 前被执行, 但是它并不能够阻止 join     point 的执行, 除非发生了异常(即我们在 before advice 代码中, 不能人为地决定是否继续执行 join point 中的代码)\nafter return advice： 在一个 join point 正常返回后执行的 advice\nafter throwing advice： 当一个 join point 抛出异常后执行的 advice\nafter(final) advice： 无论一个 join point 是正常退出还是发生了异常, 都会被执行的 advice.\naround advice：在 join point 前和 joint point 退出后都执行的 advice. 这个是最常用的 advice.\n\nAdvice、JoinPoint、PointCut 关系\n下面这张图是在网上一位大佬的博客里发现的，可以帮助我们更好的理解这些概念之间的关系。\n\n上面是对于AOP中涉及到的一些基本概念及它们之间的关系做了简单的梳理。\n一些坑在调试程序过程中出现的一些问题记录\n1、使用AOP拦截controller层的服务成功，但是页面报错4041234@Around(&quot;cutIn()&quot;)public void aroundAdvice(ProceedingJoinPoint poin) &#123;    System.out.println(&quot;环绕通知&quot;);&#125;\n这里需要注意的是再使用环绕通知时，需要给方法一个返回值。\n12345@Around(&quot;cutIn()&quot;)public Object aroundAdvice(ProceedingJoinPoint poin) throws Throwable &#123;    System.out.println(&quot;环绕通知&quot;);    return poin.proceed();&#125;\n\n2、0 formal unbound in pointcut在spring 4.x中 提供了aop注解方式 带参数的方式。看下面例子：\n1234567@Pointcut(value = &quot;execution(* com.glmapper.framerwork.service.impl.*(int,int)) &amp;&amp; args(i,j)&quot;)  public void cutIn(int i, int j) &#123;&#125;    @Before(value=&quot;cutIn(i, j)&quot;,argNames = &quot;i,j&quot;)  public void beforeMethod( int i, int j) &#123;      System.out.println(&quot;---------begins with &quot; + i + &quot;-&quot; +j);  &#125;  \n比如说这里，Before中有两个int类型的参数，如果此时我们在使用时没有给其指定参数，那么就会抛出：Caused by: java.lang.IllegalArgumentException: error at ::0 formal unbound in pointcut 异常信息。\n本来是想放在一篇里面的，但是实在太长了，就分开吧；周末更新下\n","slug":"spring/spring-aop-form-concept","date":"2018-06-20T16:43:21.000Z","categories_index":"spring","tags_index":"spring,aop","author_index":"glmapper"},{"id":"4394df75e93e562a0f93dd0d5cccdf72","title":"聊一聊 session 和 cookie","content":"本来是想写 aop 设计机制的，但是最近被 session 这个东西搞得有点头大，所以就抽点时间来整理下关于 session 的一些东西。\n\n\n目录\n从http协议的无状态性说起\n无连接和无状态\n持久连接\nhttp无状态\n如何保持状态信息\n\n\nCookie\nCookie机制原理\nCookie在servlet-api中的定义\nCookie属性\n创建Cookie\nCookie更新\nCookie删除\n从请求中获取Cookie\nCookie同源与跨域\nCookie数量&amp;大小限制及处理策略\n\n\nSession\nsession机制原理\nHttpSession\n创建session\n生命周期\nsession的有效期\n分布式session\n\n\n\n从http协议的无状态性说起HTTP是一种无状态协议。关于这个无状态之前我也不太理解，因为HTTP底层是TCP，既然是TCP，就是长连接，这个过程是保持连接状态的，又为什么说http是无状态的呢？先来搞清楚这两个概念：\n无连接和无状态\n无连接\n  每次连接只处理一个请求，服务端处理完客户端一次请求，等到客户端作出回应之后便断开连接；\n\n无状态\n  是指服务端对于客户端每次发送的请求都认为它是一个新的请求，上一次会话和下一次会话没有联系；\n\n\n无连接的维度是连接，无状态的维度是请求；http是基于tcp的，而从http1.1开始默认使用持久连接；在这个连接过程中，客户端可以向服务端发送多次请求，但是各个请求之间的并没有什么联系；这样来考虑，就很好理解无状态这个概念了。\n持久连接持久连接，本质上是客户端与服务器通信的时候，建立一个持久化的TCP连接，这个连接不会随着请求结束而关闭，通常会保持连接一段时间。\n现有的持久连接类型有两种：HTTP&#x2F;1.0+的keep-alive和HTTP&#x2F;1.1的persistent。\n\nHTTP&#x2F;1.0+的keep-alive\n\n先来开一张图：\n这张图是请求www.baidu.com时的请求头信息。这里面我们需要注意的是：\n1connection: keep-alive\n我们每次发送一个HTTP请求，会附带一个connection:keep-alive，这个参数就是声明一个持久连接。\n\nHTTP&#x2F;1.1的persistent\n\nHTTP&#x2F;1.1的持久连接默认是开启的，只有首部中包含connection：close，才会事务结束之后关闭连接。当然服务器和客户端仍可以随时关闭持久连接。\n当发送了connection：close首部之后客户端就没有办法在那条连接上发送更多的请求了。当然根据持久连接的特性，一定要传输正确的content-length。\n还有根据HTTP&#x2F;1.1的特性，是不应该和HTTP&#x2F;1.0客户端建立持久连接的。最后，一定要做好重发的准备。\nhttp无状态OK，首先来明确下，这个状态的主体指的是什么？应该是信息，这些信息是由服务端所维护的与客户端交互的信息（也称为状态信息）；因为HTTP本身是不保存任何用户的状态信息的，所以HTTP是无状态的协议。\n如何保持状态信息在聊这个这个问题之前，我们来考虑下为什么http自己不来做这个事情：也就是让http变成有状态的。\n\nhttp本身来实现状态维护\n  从上面关于无状态的理解，如果现在需要让http自己变成有状态的，就意味着http协议需要保存交互的状态信息；暂且不说这种方式是否合适，但从维护状态信息这一点来说，代价就很高，因为既然保存了状态信息，那后续的一些行为必定也会受到状态信息的影响。\n  从历史角度来说，最初的http协议只是用来浏览静态文件的，无状态协议已经足够，这样实现的负担也很轻。但是随着web技术的不断发展，越来越多的场景需要状态信息能够得以保存；一方面是http本身不会去改变它的这种无状态的特性（至少目前是这样的），另一方面业务场景又迫切的需要保持状态；那么这个时候就需要来“装饰”一下http，引入一些其他机制来实现有状态。\n\ncookie和session体系\n  通过引入cookie和session体系机制来维护状态信息。即用户第一次访问服务器的时候，服务器响应报头通常会出现一个Set-Cookie响应头，这里其实就是在本地设置一个cookie，当用户再次访问服务器的时候，http会附带这个cookie过去，cookie中存有sessionId这样的信息来到服务器这边确认是否属于同一次会话。\n\n\nCookie cookie是由服务器发送给客户端（浏览器）的小量信息，以{key：value}的形式存在。\nCookie机制原理 客户端请求服务器时，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。而客户端浏览器会把Cookie保存起来。当浏览器再请求 服务器时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器通过检查该Cookie来获取用户状态。\n 我们通过看下servlet-api中Cookie类的定义及属性，来更加具体的了解Cookie。\nCookie在servlet-api中的定义123456789101112131415161718public class Cookie implements Cloneable, Serializable &#123;    private static final long serialVersionUID = -6454587001725327448L;    private static final String TSPECIALS;    private static final String LSTRING_FILE =    &quot;javax.servlet.http.LocalStrings&quot;;    private static ResourceBundle lStrings =    ResourceBundle.getBundle(&quot;javax.servlet.http.LocalStrings&quot;);    private String name;    private String value;    private String comment;    private String domain;    private int maxAge = -1;    private String path;    private boolean secure;    private int version = 0;    private boolean isHttpOnly = false;    //....省略其他方法&#125;\nCookie属性\n\n\n属性\n解释\n\n\n\nname\ncookie 的名字，Cookie 一旦创建，名称便不可更改\n\n\nvalue\ncookie 值\n\n\ncomment\n该Cookie的用处说明。浏览器显示Cookie信息的时候显示该说明\n\n\ndomain\n可以访问该Cookie的域名。如果设置为“.baidu.com”，则所有以“baidu.com”结尾的域名都可以访问该Cookie；第一个字符必须为“.”\n\n\nmaxAge\nCookie失效的时间，单位秒。正数: 则超过maxAge秒之后失效。负数: 该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie。0: 表示删除该 Cookie。\n\n\npath\n该 Cookie的使用路径。path设置时，其以“&#x2F;”结尾。例如：path&#x3D;&#x2F;，说明本域名下contextPath都可以访问该Cookie; path&#x3D;&#x2F;app&#x2F;，则只有contextPath为“&#x2F;app”的程序可以访问该Cookie\n\n\nsecure\n该Cookie是否仅被使用安全协议传输。这里的安全协议包括HTTPS，SSL等。默认为false。\n\n\nversion\n该Cookie使用的版本号，在servlet规范中默认是 0；0 表示遵循Netscape的Cookie规范，目前大多数用的都是这种规范；1 表示遵循W3C的RFC2109规范；规范过于严格，实施起来很难。\n\n\nisHttpOnly\nHttpOnly属性是用来限制非HTTP协议程序接口对客户端Cookie进行访问；也就是说如果想要在客户端取到httponly的Cookie的唯一方法就是使用AJAX，将取Cookie的操作放到服务端，接收客户端发送的ajax请求后将取值结果通过HTTP返回客户端。这样能有效的防止XSS攻击。\n\n\n上述的这些属性，除了 name 与 value 属性会被提交外，其他的属性对于客户端来说都是不可读的，也是不可被提交的。\n创建Cookie12345Cookie cookie = new Cookie(&quot;cookieSessionId&quot;,&quot;qwertyuiop&quot;);cookie.setDomain(&quot;.baidu.com&quot;);             // 设置域名cookie.setPath(&quot;/&quot;);                        // 设置路径cookie.setMaxAge(Integer.MAX_VALUE);        // 设置有效期为永久response.addCookie(cookie);                 // 回写到客户端\n创建Cookie只能通过上述方式来创建，因为在Cookie类中只提供了这样一个构造函数。\n123456789101112131415161718192021222324252627//Cookie的构造函数public Cookie(String name, String value) &#123;    if (name != null &amp;&amp; name.length() != 0) &#123;        //判断下是不是token        //判断是不是和Cookie的属性字段重复        if (this.isToken(name) &amp;&amp; !name.equalsIgnoreCase(&quot;Comment&quot;) &amp;&amp;        !name.equalsIgnoreCase(&quot;Discard&quot;) &amp;&amp;        !name.equalsIgnoreCase(&quot;Domain&quot;) &amp;&amp;        !name.equalsIgnoreCase(&quot;Expires&quot;) &amp;&amp;        !name.equalsIgnoreCase(&quot;Max-Age&quot;) &amp;&amp;        !name.equalsIgnoreCase(&quot;Path&quot;) &amp;&amp;        !name.equalsIgnoreCase(&quot;Secure&quot;) &amp;&amp;        !name.equalsIgnoreCase(&quot;Version&quot;) &amp;&amp; !name.startsWith(&quot;$&quot;)) &#123;            this.name = name;            this.value = value;        &#125; else &#123;            String errMsg =            lStrings.getString(&quot;err.cookie_name_is_token&quot;);            Object[] errArgs = new Object[]&#123;name&#125;;            errMsg = MessageFormat.format(errMsg, errArgs);            throw new IllegalArgumentException(errMsg);        &#125;    &#125; else &#123;        throw new IllegalArgumentException(lStrings.getString        (&quot;err.cookie_name_blank&quot;));    &#125;&#125;\n\nCookie更新在源码中可以知道，Cookie本身并没有提供修改的方法；在实际应用中，一般通过使用相同name的Cookie来覆盖原来的Cookie,以达到更新的目的。\n但是这个修改的前提是需要具有相同domain，path的 Set-Cookie 消息头\n12Cookie cookie = new Cookie(&quot;cookieSessionId&quot;,&quot;new-qwertyuiop&quot;);response.addCookie(cookie);\nCookie删除与Cookie更新一样，Cookie本身也没有提供删除的方法；但是从前面分析Cookie属性时了解到，删除Cookie可以通过将maxAge设置为0即可。\n123Cookie cookie = new Cookie(&quot;cookieSessionId&quot;,&quot;new-qwertyuiop&quot;);cookie.setMaxAge(0);response.addCookie(cookie);\n\n上面的删除是我们自己可控的；但是也存在一些我们不可控或者说无意识情况下的删除操作：\n\n如果maxAge是负值，则cookie在浏览器关闭时被删除\n持久化cookie在到达失效日期时会被删除\n浏览器中的 cookie 数量达到上限，那么 cookie 会被删除以为新建的 cookie 创建空间。\n\n其实很多情况下，我们关注的都是后者。关于数量上限后面会说到。\n从请求中获取Cookie1Cookie[] cookies = request.getCookies();\nCookie同源与跨域我们知道浏览器的同源策略：\n\n\n\n\n\n\n\n\n\nURL由协议、域名、端口和路径组成，如果两个URL的协议、域名和端口相同，则表示他们同源。浏览器的同源策略，限制了来自不同源的”document”或脚本，对当前”document”读取或设置某些属性。 \n对于Cookie来说，Cookie的同源只关注域名，是忽略协议和端口的。所以一般情况下，https://localhost:80/和http://localhost:8080/的Cookie是共享的。\nCookie是不可跨域的；在没有经过任何处理的情况下，二级域名不同也是不行的。(wenku.baidu.com和baike.baidu.com)。\nCookie数量&amp;大小限制及处理策略\n\n\n\nIE6.0\nIE7.0&#x2F;8.0\nOpera\nFF\nSafari\nChrome\n\n\n\n个数&#x2F;个\n20&#x2F;域\n50&#x2F;域\n30&#x2F;域\n50&#x2F;域\n无限制\n53&#x2F;域\n\n\n大小&#x2F;Byte\n4095\n4095\n4096\n4097\n4097\n4097\n\n\n注：数据来自网络，仅供参考\n因为浏览器对于Cookie在数量上是有限制的，如果超过了自然会有一些剔除策略。在这篇文章中Browser cookie restrictions提到的剔除策略如下：\n\n\n\n\n\n\n\n\n\nThe least recently used (LRU) approach automatically kicks out the oldest cookie when the cookie limit has been reached in order to allow the newest cookie some space. Internet Explorer and Opera use this approach.\n最近最少使用（LRU）方法：在达到cookie限制时自动地剔除最老的cookie，以便腾出空间给许最新的cookie。Internet Explorer和Opera使用这种方法。\n\n\n\n\n\n\n\n\n\nFirefox does something strange: it seems to randomly decide which cookies to keep although the last cookie set is always kept. There doesn’t seem to be any scheme it’s following at all. The takeaway? Don’t go above the cookie limit in Firefox.\nFirefox决定随机删除Cookie集中的一个Cookie，并没有什么章法。所以最好不要超过Firefox中的Cookie限制。\n超过大小长度的话就是直接被截取丢弃；\nSessionCookie机制弥补了HTTP协议无状态的不足。在Session出现之前，基本上所有的网站都采用Cookie来跟踪会话。\n与Cookie不同的是，session是以服务端保存状态的。\nsession机制原理当客户端请求创建一个session的时候，服务器会先检查这个客户端的请求里是否已包含了一个session标识 - sessionId，\n\n如果已包含这个sessionId，则说明以前已经为此客户端创建过session，服务器就按照sessionId把这个session检索出来使用（如果检索不到，可能会新建一个）\n如果客户端请求不包含sessionId，则为此客户端创建一个session并且生成一个与此session相关联的sessionId\n\nsessionId的值一般是一个既不会重复，又不容易被仿造的字符串，这个sessionId将被在本次响应中返回给客户端保存。保存sessionId的方式大多情况下用的是cookie。\nHttpSessionHttpSession和Cookie一样，都是javax.servlet.http下面的；Cookie是一个类，它描述了Cookie的很多内部细节。而HttpSession是一个接口，它为session的实现提供了一些行为约束。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public interface HttpSession &#123;    /**     * 返回session的创建时间     */    public long getCreationTime();    /**     * 返回一个sessionId,唯一标识     */    public String getId();    /**     *返回客户端最后一次发送与该 session 会话相关的请求的时间     *自格林尼治标准时间 1970 年 1 月 1 日午夜算起，以毫秒为单位。     */    public long getLastAccessedTime();    /**     * 返回当前session所在的ServletContext     */    public ServletContext getServletContext();    public void setMaxInactiveInterval(int interval);    /**     * 返回 Servlet 容器在客户端访问时保持 session     * 会话打开的最大时间间隔     */    public int getMaxInactiveInterval();    public HttpSessionContext getSessionContext();    /**     * 返回在该 session会话中具有指定名称的对象，     * 如果没有指定名称的对象，则返回 null。     */    public Object getAttribute(String name);    public Object getValue(String name);    /**     * 返回 String 对象的枚举，String 对象包含所有绑定到该 session     * 会话的对象的名称。     */        public Enumeration&lt;String&gt; getAttributeNames();    public String[] getValueNames();    public void setAttribute(String name, Object value);    public void putValue(String name, Object value);    public void removeAttribute(String name);    public void removeValue(String name);    /**     * 指示该 session 会话无效，并解除绑定到它上面的任何对象。     */    public void invalidate();    /**     * 如果客户端不知道该 session 会话，或者如果客户选择不参入该     * session 会话，则该方法返回 true。     */    public boolean isNew();&#125;\n\n创建session创建session的方式是通过request来创建；\n1234// 1、创建Session对象HttpSession session = request.getSession(); // 2、创建Session对象HttpSession session = request.getSession(true); \n这两种是一样的；如果session不存在，就新建一个；如果是false的话，标识如果不存在就返回null；\n生命周期session的生命周期指的是从Servlet容器创建session对象到销毁的过程。Servlet容器会依据session对象设置的存活时间，在达到session时间后将session对象销毁。session生成后，只要用户继续访问，服务器就会更新session的最后访问时间，并维护该session。\n之前在单进程应用中，session我一般是存在内存中的，不会做持久化操作或者说使用三方的服务来存session信息，如redis。但是在分布式场景下，这种存在本机内存中的方式显然是不适用的，因为session无法共享。这个后面说。\nsession的有效期session一般在内存中存放，内存空间本身大小就有一定的局限性，因此session需要采用一种过期删除的机制来确保session信息不会一直累积，来防止内存溢出的发生。\nsession的超时时间可以通过maxInactiveInterval属性来设置。\n如果我们想让session失效的话，也可以当通过调用session的invalidate()来完成。\n分布式session首先是为什么会有这样的概念出现？\n先考虑这样一个问题，现在我的应用需要部署在3台机器上。是不是出现这样一种情况，我第一次登陆，请求去了机器1，然后再机器1上创建了一个session；但是我第二次访问时，请求被路由到机器2了，但是机器2上并没有我的session信息，所以得重新登录。当然这种可以通过nginx的IP HASH负载策略来解决。对于同一个IP请求都会去同一个机器。\n但是业务发展的越来越大，拆分的越来越多，机器数不断增加；很显然那种方案就不行了。那么这个时候就需要考虑是不是应该将session信息放在一个独立的机器上，所以分布式session要解决的问题其实就是分布式环境下的session共享的问题。\n\n上图中的关于session独立部署的方式有很多种，可以是一个独立的数据库服务，也可以是一个缓存服务(redis，目前比较常用的一种方式，即使用Redis来作为session缓存服务器)。\n参考\nhttps://www.cnblogs.com/icelin/p/3974935.html\nhttps://www.nczonline.net/blog/2008/05/17/browser-cookie-restrictions/\nhttps://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE\n\n","slug":"middleware/middleware-http-session-cookie","date":"2018-05-12T21:10:25.000Z","categories_index":"Middleware","tags_index":"http,session,cookie","author_index":"glmapper"},{"id":"123d621baee081af1f177335cc7a300f","title":"关于 Mybatis 中 SQL 语句的整理","content":"随着业务的发展，越来越多的应用系统都从一个大的系统分拆成多个小的系统，各个系统之间通过一定的通信协议进行数据交换。这样就会导致一些小的应用系统自己不用去进行数据库的操作，只需要进行一些rpc调用或者缓存就可以拿到数据进行展示。我之前参与的一个项目就是这样的情况，而我也是将近7个多月的时间没有写过一行SQL。\n近期参与的一个项目的数据大多都市基于数据库来进行数据交互的，所以免不了的要写大量的 SQL，所以本篇就总结一下一些 SQL 的基本写法，以备后用。\n\n\n建表123456CREATE TABLE IF NOT EXISTS `user_test` (  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;自增长id&#x27;,  `user_name` varchar(128) NOT NULL COMMENT &#x27;用户名&#x27;,   PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#x27;用户表&#x27;;\n\n查询\n简单的查询\n\n123&lt;select id=&quot;queryUserByName&quot; resultMap=&quot;userMap&quot; parameterType=&quot;java.lang.String&quot;&gt;\tSELECT * FROM user_test WHERE user_name = #&#123;userName&#125; &lt;/select&gt;\n需要注意的是如果这里不指定parameterType，则默认会识别处理；如果指定了类型，则传入的值就需要和当前指定的类型保持一致，不然就会出现数据类型转换异常。\n\n简单分页查询\n\n1234567&lt;select id=&quot;queryUsersList&quot; resultMap=&quot;userMap&quot;&gt;    SELECT * FROM user_test WHERE 1=1         &lt;if test=&quot;keyword != null and keyword != &#x27;&#x27;&quot; &gt;            AND user_name LIKE concat(&#x27;%&#x27;,#&#123;keyword&#125;,&#x27;%&#x27;)        &lt;/if&gt;    LIMIT #&#123;currentPage&#125;,#&#123;pageSize&#125;&lt;/select&gt;\n\n\nleft join\n\napp_info表和app_verion表分别存储的是应用信息和应用版本信息。现在要根据appId和versionId查出一个应用的具体信息【包括信息信息和版本信息】\n12345678&lt;select id=&quot;getAppDetail&quot; resultMap=&quot;appDeatilMap&quot;&gt;    \tselect  m.id id,\t\tm.app_name appName,\t\tn.version version,\t\tfrom app_info m\t\tLEFT JOIN app_version n ON m.id = n.app_id \t\twhere m.id = #&#123;appId&#125; and n.id = #&#123;versionId&#125;    &lt;/select&gt;\n\n\n查询条件是list\n\n12345678910111213141516&lt;select id=&quot;queryAppByAppNames&quot; resultMap=&quot;AppMap&quot; parameterType=&quot;java.util.List&quot;&gt;\tselect \t\ta.app_name appName,\t\tb.version version\tfrom starter_info a,starter_version b \twhere \t\ta.id = b.app_id \t\tand a.id in \t\t(        \t\tselect id from app_info where app_name in         \t\t&lt;foreach collection=&quot;list&quot; item=&quot;item&quot; index=&quot;index&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt;        \t\t\t#&#123;item&#125;        \t\t&lt;/foreach&gt;\t\t)&lt;/select&gt;\n\n更新\n简单的更新\n\n1234567&lt;update id=&quot;updateApp&quot; parameterType=&quot;java.util.List&quot;&gt;    UPDATE app_info        SET             app_name = #&#123;appName&#125;        WHERE             app_id = #&#123;appId&#125;&lt;/update&gt;\n\n\n批量更新\n\n有这样一个需求，把 app_info表中id 为1，2，3的app的app_name改为appName1，appName2，appName3;\n使用 case ..when ..then 这样的语法结构来完成：\ncase 是当前的条件，when表示条件值，then后面是当前目前更新字段的值；\n\n\n\n\n\n\n\n\n\n下面的说明：当前id&#x3D;#{item.appId}时,app_name&#x3D;#{item.appName}\n1234567891011&lt;update id=&quot;updateApps&quot; parameterType=&quot;java.util.List&quot;&gt;\tUPDATE app_info set app_name =\t&lt;foreach collection=&quot;applList&quot; item=&quot;item&quot; index=&quot;index&quot; separator=&quot; &quot; open=&quot;case ID&quot; close=&quot;end&quot;&gt;\t\twhen #&#123;item.appId,jdbcType=INTEGER&#125; then #&#123;item.appName,jdbcType=INTEGER&#125;\t&lt;/foreach&gt;\t\twhere id in\t&lt;foreach collection=&quot;appList&quot; index=&quot;index&quot; item=&quot;item&quot; separator=&quot;,&quot; open=&quot;(&quot; close=&quot;)&quot;&gt;\t\t#&#123;item.appId,jdbcType=INTEGER&#125;\t&lt;/foreach&gt;&lt;/update&gt;\n\nOK，现在于这样的需要：\n根据应用类型的不同，更新不同的运行环境配置；\n123456789101112131415161718192021222324252627282930313233&#123;    [        &#123;            &quot;appType&quot;:&quot;applet&quot;,            &quot;cpu&quot;:5,            &quot;memory&quot;:4,            &quot;card&quot;:3,            &quot;nums&quot;:2,            &quot;network&quot;:1,            &quot;isInUse&quot;:1        &#125;,        &#123;            &quot;appType&quot;:&quot;bs&quot;,            &quot;cpu&quot;:5,            &quot;memory&quot;:4,            &quot;card&quot;:3,            &quot;nums&quot;:2,            &quot;network&quot;:1,            &quot;isInUse&quot;:1        &#125;,        &#123;            &quot;appType&quot;:&quot;cs&quot;,            &quot;cpu&quot;:5,            &quot;memory&quot;:4,            &quot;card&quot;:3,            &quot;nums&quot;:2,            &quot;network&quot;:1,            &quot;isInUse&quot;:1        &#125;,        //有几个放几个    ]&#125;\n\ntrim 属性说明 \n\n1.prefix,suffix 表示在trim标签包裹的部分的前面或者后面添加内容 \n2.如果同时有prefixOverrides,suffixOverrides 表示会用prefix,suffix覆盖Overrides中的内容。 \n3.如果只有prefixOverrides,suffixOverrides 表示删除开头的或结尾的xxxOverides指定的内容。\n\n12345678910111213141516171819202122232425262728293031323334353637383940&lt;update id=&quot;updateBatchApp&quot; parameterType=&quot;java.util.List&quot;&gt;\tUPDATE app_info\t&lt;trim prefix=&quot;set&quot; suffixOverrides=&quot;,&quot;&gt;\t\t&lt;trim prefix=&quot;cpu = case&quot; suffix=&quot;end,&quot;&gt;\t\t\t&lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt;\t\t\t\t&lt;if test=&quot;item != null&quot;&gt;\t\t\t\t\twhen app_type =#&#123;item.appType&#125; then #&#123;item.cpu&#125;\t\t\t\t&lt;/if&gt;\t\t\t&lt;/foreach&gt;\t\t&lt;/trim&gt;\t\t&lt;trim prefix=&quot;memory = case&quot; suffix=&quot;end,&quot;&gt;\t\t\t&lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt;\t\t\t\t&lt;if test=&quot;item != null&quot;&gt;\t\t\t\t\twhen app_type =#&#123;item.appType&#125; then #&#123;item.memory&#125;\t\t\t\t&lt;/if&gt;\t\t\t&lt;/foreach&gt;\t\t&lt;/trim&gt;\t\t&lt;trim prefix=&quot;card = case&quot; suffix=&quot;end,&quot;&gt;\t\t\t&lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt;\t\t\t\twhen app_type =#&#123;item.appType&#125; then #&#123;item.card&#125;\t\t\t&lt;/foreach&gt;\t\t&lt;/trim&gt;\t\t&lt;trim prefix=&quot;nums = case&quot; suffix=&quot;end,&quot;&gt;\t\t\t&lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt;\t\t\t\twhen app_type =#&#123;item.appType&#125; then #&#123;item.nums&#125;\t\t\t&lt;/foreach&gt;\t\t&lt;/trim&gt;\t\t&lt;trim prefix=&quot;network = case&quot; suffix=&quot;end,&quot;&gt;\t\t\t&lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt;\t\t\t\twhen app_type =#&#123;item.appType&#125; then #&#123;item.network&#125;\t\t\t&lt;/foreach&gt;\t\t&lt;/trim&gt;\t\t&lt;trim prefix=&quot;is_in_use = case&quot; suffix=&quot;end,&quot;&gt;\t\t\t&lt;foreach collection=&quot;modelList&quot; item=&quot;item&quot; index=&quot;index&quot;&gt;\t\t\t\twhen app_type =#&#123;item.appType&#125; then #&#123;item.isInUse&#125;\t\t\t&lt;/foreach&gt;\t\t&lt;/trim&gt;\t&lt;/trim&gt;\twhere app_id = #&#123;appId&#125;&lt;/update&gt;\n\n\n\n\n\n\n\n\n\n\n关于性能问题没做研究，之前看过关于不同更新语句写法的一篇性能的分析，大家有兴趣可以看下：批量更新数据两种方法效率对比\n删除\n简单删除\n\n1DELETE FROM app_info where id = #&#123;id&#125;\n\n\n批量删除\n\n123456&lt;delete id=&quot;deleteApps&quot; parameterType=&quot;java.util.List&quot;&gt;\tDELETE FROM app_info where  app_id in     \t&lt;foreach item=&quot;item&quot; collection=&quot;appIds&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt;            #&#123;item&#125;        &lt;/foreach&gt;&lt;/delete&gt;\n\n时间字符串 order by不知道各位是否遇到过，之前的前辈们在项目中将时间用字符串的方式存在DB中，而不是使用DATE,然后有一天你的前辈走了，你的主管说查出来按时间来排序….；呵呵，好！！！\n1234567&lt;select id=&quot;querySysParamList&quot; resultMap=&quot;sysParamDO&quot;&gt;    SELECT * FROM app_info WHERE 1=1        &lt;if test=&quot;keyword != null and keyword != &#x27;&#x27;&quot; &gt;            AND app_name LIKE concat(&#x27;%&#x27;,#&#123;keyword&#125;,&#x27;%&#x27;)        &lt;/if&gt;    ORDER BY DATE_FORMAT(update_time,&#x27;%H %k %I %r %T %S %w&#x27;) DESC&lt;/select&gt;\n\n\n\n\n\n\n\n\n\n\n\n字符串转为日期格式 SELECT DATE_FORMAT(‘2011-09-20 08:30:45’,   ‘%Y-%m-%d %H:%i:%S’);\n\n\n\n\n\n\n\n\n\n把日期转为字符串格式 SELECT DATE_FORMAT(NOW(),   ‘%Y-%m-%d %H:%i:%S’);\n附：\n123456789101112131415161718192021222324252627%M 月名字(January……December) %W 星期名字(Sunday……Saturday) %D 有英语前缀的月份的日期(1st, 2nd, 3rd, 等等。） %Y 年, 数字, 4 位 %y 年, 数字, 2 位 %a 缩写的星期名字(Sun……Sat) %d 月份中的天数, 数字(00……31) %e 月份中的天数, 数字(0……31) %m 月, 数字(01……12) %c 月, 数字(1……12) %b 缩写的月份名字(Jan……Dec) %j 一年中的天数(001……366) %H 小时(00……23) %k 小时(0……23) %h 小时(01……12) %I 小时(01……12) %l 小时(1……12) %i 分钟, 数字(00……59)                                        %r 时间,12 小时(hh:mm:ss [AP]M) %T 时间,24 小时(hh:mm:ss) %S 秒(00……59) %s 秒(00……59) %p AM或PM %w 一个星期中的天数(0=Sunday ……6=Saturday ） %U 星期(0……52), 这里星期天是星期的第一天 %u 星期(0……52), 这里星期一是星期的第一天 %% 一个文字“%”。\n\n\n先记录这些，有坑再补！\n参考\nhttp://www.runoob.com/sql/sql-tutorial.html\n\n","slug":"middleware/middleware-data-mybatis-sql","date":"2018-04-17T09:37:54.000Z","categories_index":"Middleware","tags_index":"mysql,mybatis,sql","author_index":"glmapper"},{"id":"08a5071a80b0f5201a84d06e57924a87","title":"日志？聊一聊 slf4j","content":"作为一个 Java 程序员，肯定对于日志记录不会陌生，无论项目大小，日志记录都是必须的；因为好的日志可以很容易的帮助我们定位一些生产问题。\n\n\n\n\n\n\n\n\n\n我怀念的是  无话不说    System.out.println(“这里是重要的日志”);我怀念的是  一起作梦    System.err.println(“这里是错误的日志”);\n对于日常开发来说，其实 System.out.println 挺好用的，但是为什么在实际的开发应用中不使用这个来输出日志呢?\n\n\n\n\n\n\n\n\n\n\n\nSystem.out.println()除了使用方便一点之外，其他感觉真的没有什么多大的用处。方便在哪儿呢？在Eclipse中你只需要输入syso【IDEA中输出sout即可】，然后按下代码提示键，这个方法就会自动出来了，相信这也是很多Java新手对它钟情的原因，因为我一开始也是这么干的，直到…【此处省略泪水】。那缺点又在哪儿了呢？这个就太多了，比如日志打印不可控制、打印时间无法确定、不能添加过滤器、日志没有级别区分……\n记得我最开始接触的是log4j，log4j作为Apache的一个开放源代码的项目，通过使用log4j，我们可以控制日志信息输送的目的地是控制台、文件等我们期望它输出到的地方；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。重要的是，这些可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。\n确实，log4j作为最先比较流行的日志框架，给我们在应用开发和维护带来了很大的便捷，那么为什么这样优秀的框架最后还是慢慢的走下“神坛”呢？而逐渐被logback代替呢？下面是摘自网上一位大佬对于这个问题的解释：\n\n\n\n\n\n\n\n\n\n无论从设计上还是实现上，Logback相对log4j而言有了相对多的改进。不过尽管难以一一细数，这里还是列举部分理由为什么选择logback而不是log4j。牢记logback与log4j在概念上面是很相似的，它们都是有同一群开发者建立。\n\n更快的执行速度\n  基于我们先前在log4j上的工作，logback 重写了内部的实现，在某些特定的场景上面，甚至可以比之前的速度快上10倍。在保证logback的组件更加快速的同时，同时所需的内存更加少。\n\n充分的测试\n  Logback 历经了几年，数不清小时数的测试。尽管log4j也是测试过的，但是Logback的测试更加充分，跟log4j不在同一个级别。我们认为，这正是人们选择Logback而不是log4j的最重要的原因。人们都希望即使在恶劣的条件下，你的日记框架依然稳定而可靠。\n\n\nslf4j log4j logback\n\n\n\n\n\n\n\n\nslf4j:The Simple Logging Facade for Java 即java的简单日志门面\n简答的讲就是 slf4j 是一系列的日志接口，slf4j作为一个日志的抽象行为存在，但是并没有提供真正的实现。\nslf4j 为各种日志框架提供了一个统一的界面，使用户可以用统一的接口记录日志，但是动态地决定真正的实现框架。logback，log4j，common-logging等框架都实现了这些接口。\nslf4j 源码分析想了很久都不知道从哪里开头写比较合适，slf4j包中总共29个类【1.7.21版本】，不可能一一列举。所以就从我们熟知的这个语句来说。\n12private static final Logger logger =LoggerFactory.getLogger(DemoTest.class);\n上面这段代码其实就是我们平时在代码里面申明一个日志对象的常用方式。\n先来看下Logger接口提供的方法；\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package org.slf4j;public interface Logger &#123;    //根Logger    String ROOT_LOGGER_NAME = &quot;ROOT&quot;;    String getName();    //判断记录器Trace跟踪是否激活;Trace跟踪激活后一般会打印比较详细的信息。    boolean isTraceEnabled();    //trace级别    void trace(String var1);    void trace(String var1, Object var2);    void trace(String var1, Object var2, Object var3);    void trace(String var1, Object... var2);    void trace(String var1, Throwable var2);    boolean isTraceEnabled(Marker var1);    void trace(Marker var1, String var2);    void trace(Marker var1, String var2, Object var3);    void trace(Marker var1, String var2, Object var3, Object var4);    void trace(Marker var1, String var2, Object... var3);    void trace(Marker var1, String var2, Throwable var3);    //进行预先判断，提升系统性能    boolean isDebugEnabled();    void debug(String var1);    void debug(String var1, Object var2);    void debug(String var1, Object var2, Object var3);    void debug(String var1, Object... var2);    void debug(String var1, Throwable var2);    boolean isDebugEnabled(Marker var1);    void debug(Marker var1, String var2);    void debug(Marker var1, String var2, Object var3);    void debug(Marker var1, String var2, Object var3, Object var4);    void debug(Marker var1, String var2, Object... var3);    void debug(Marker var1, String var2, Throwable var3);    //info级别    boolean isInfoEnabled();    void info(String var1);    void info(String var1, Object var2);    void info(String var1, Object var2, Object var3);    void info(String var1, Object... var2);    void info(String var1, Throwable var2);    boolean isInfoEnabled(Marker var1);    void info(Marker var1, String var2);    void info(Marker var1, String var2, Object var3);    void info(Marker var1, String var2, Object var3, Object var4);    void info(Marker var1, String var2, Object... var3);    void info(Marker var1, String var2, Throwable var3);    //warn级别    boolean isWarnEnabled();    void warn(String var1);    void warn(String var1, Object var2);    void warn(String var1, Object... var2);    void warn(String var1, Object var2, Object var3);    void warn(String var1, Throwable var2);    boolean isWarnEnabled(Marker var1);    void warn(Marker var1, String var2);    void warn(Marker var1, String var2, Object var3);    void warn(Marker var1, String var2, Object var3, Object var4);    void warn(Marker var1, String var2, Object... var3);    void warn(Marker var1, String var2, Throwable var3);    //error级别    boolean isErrorEnabled();    void error(String var1);    void error(String var1, Object var2);    void error(String var1, Object var2, Object var3);    void error(String var1, Object... var2);    void error(String var1, Throwable var2);    boolean isErrorEnabled(Marker var1);    void error(Marker var1, String var2);    void error(Marker var1, String var2, Object var3);    void error(Marker var1, String var2, Object var3, Object var4);    void error(Marker var1, String var2, Object... var3);    void error(Marker var1, String var2, Throwable var3);&#125;\nisXXXXEnabled以isDebugEnabled来说明下这个isXXXXEnabled方法的作用。\n\n\n\n\n\n\n\n\n\nlogger.debug(“the debug msg is “ +doMethod());\n\n\n\n\n\n\n\n\n\n假设我们的日志级别设置为info,那这句话不会输出日志，但这个方法还是会调用（预判断作用）。要调用这个方法，必须提供参数。doMethod()方法返回的结果就是参数的一部分。doMethod()要执行n秒钟，n秒钟后，进入到debug()方法里；\n\n\n\n\n\n\n\n\n\n但是日志级别为info。结果是日志虽然没有输出，却花费了n秒钟来构造参数。很显然这里得不偿失的。尽管实际应用中几乎不可能有这种花n秒钟来构造这样一个参数的情况，但如果并发数大的话，这样写还是会影响系统的性能的。这个时候，就应该写成:\n123if(logger.isDebugEnabled())&#123;    logger.debug(&quot;the debug msg is &quot; + doMethod());&#125; \n\n接下来说LoggerFactory这个类；先从getLogger这个方法为入口来看下：\n1234567891011121314151617public static Logger getLogger(String name) &#123;    ILoggerFactory iLoggerFactory = getILoggerFactory();    return iLoggerFactory.getLogger(name);&#125;public static Logger getLogger(Class&lt;?&gt; clazz) &#123;    Logger logger = getLogger(clazz.getName());    if (DETECT_LOGGER_NAME_MISMATCH) &#123;        Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass();        if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123;            Util.report(String.format(&quot;Detected logger name mismatch. Given name: \\&quot;%s\\&quot;; computed name: \\&quot;%s\\&quot;.&quot;, logger.getName(), autoComputedCallingClass.getName()));            Util.report(&quot;See http://www.slf4j.org/codes.html#loggerNameMismatch for an explanation&quot;);        &#125;    &#125;    return logger;&#125;\ngetLogger方法提供了两种重载方式，一种是传入一个name，用于标注当前日志的名字。另外一个是提供一个Class对象，其实里面也是通过clazz.getName()来作为日志的名称。\n从上面的代码中可以比较明显的看到ILoggerFactory这个接口。\n12345package org.slf4j;public interface ILoggerFactory &#123;    Logger getLogger(String var1);&#125;\nILoggerFactory这个接口实际上就是为不同接入的日志实现提供了统一的顶层类型；每个日志框架都需要实现ILoggerFactory接口，来说明自己是怎么提供Logger的。像log4j、logback能够提供父子层级关系的Logger，就是在ILoggerFactory的实现类里实现的。同时，它们也需要实现Logger接口，以完成记录日志。\nlogback中的实现12public class LoggerContext extends ContextBase implementsILoggerFactory, LifeCycle\n上面提到过，对于不同的日志框架的实现都实现了ILoggerFactory接口。\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 @Overridepublic final Logger getLogger(final String name) &#123;    if (name == null) &#123;        throw new IllegalArgumentException(&quot;name argument cannot be null&quot;);    &#125;    // if we are asking for the root logger, then let us return it without    // wasting time    if (Logger.ROOT_LOGGER_NAME.equalsIgnoreCase(name)) &#123;        return root;    &#125;    int i = 0;    Logger logger = root;    // check if the desired logger exists, if it does, return it    // without further ado.    Logger childLogger = (Logger) loggerCache.get(name);    // if we have the child, then let us return it without wasting time    if (childLogger != null) &#123;        return childLogger;    &#125;    // if the desired logger does not exist, them create all the loggers    // in between as well (if they don&#x27;t already exist)    String childName;    while (true) &#123;        int h = LoggerNameUtil.getSeparatorIndexOf(name, i);        if (h == -1) &#123;            childName = name;        &#125; else &#123;            childName = name.substring(0, h);        &#125;        // move i left of the last point        i = h + 1;        synchronized (logger) &#123;            childLogger = logger.getChildByName(childName);            if (childLogger == null) &#123;                childLogger = logger.createChildByName(childName);                loggerCache.put(childName, childLogger);                incSize();            &#125;        &#125;        logger = childLogger;        if (h == -1) &#123;            return childLogger;        &#125;    &#125;&#125;\n\n关于logback的源码可以参考这个系列的文章：logback源码系列文章\n遇到过的坑我自己在日志这块遇到的最多的坑就是日志jar的依赖冲突；因为项目用到的很多框架或者三方依赖中可能自己都集成了日志框架，有的时候我们自己的项目中也会有自己的一套日志方案，所以就很大程度上导致了这种依赖冲突的发生。幸运的是，项目中关于日志包的依赖冲突解决也是很容易排除的【idea和eclipse都很方便排查】\n另外一个就是使用slf4j之后，同时引入了不同的框架实现；比如同时引入了log4j和logback。\n从上面getLogger的方法中可以看到，在获取Logger的时候都需要去先取得ILoggerFactory：\n123456789101112131415161718192021222324252627ILoggerFactory iLoggerFactory = getILoggerFactory();public static ILoggerFactory getILoggerFactory() &#123;    if (INITIALIZATION_STATE == 0) &#123;        Class var0 = LoggerFactory.class;        synchronized(LoggerFactory.class) &#123;            if (INITIALIZATION_STATE == 0) &#123;                INITIALIZATION_STATE = 1;                //初始化                performInitialization();            &#125;        &#125;    &#125;    switch(INITIALIZATION_STATE) &#123;    case 1:        return SUBST_FACTORY;    case 2:        throw new IllegalStateException(&quot;org.slf4j.LoggerFactory could not be successfully initialized. See also http://www.slf4j.org/codes.html#unsuccessfulInit&quot;);    case 3:        return StaticLoggerBinder.getSingleton().getLoggerFactory();    case 4:        return NOP_FALLBACK_FACTORY;    default:        throw new IllegalStateException(&quot;Unreachable code&quot;);    &#125;&#125;\n\n在getILoggerFactory中会通过performInitialization方法来做初始化判断；而在performInitialization中又调用了bind方法，bind方法中的异常或者错误信息打印很多情况下我们都会遇到：\n123456789101112131415161718192021222324252627282930313233343536373839404142private static final void bind() &#123;    String msg;    try &#123;        Set&lt;URL&gt; staticLoggerBinderPathSet = null;        if (!isAndroid()) &#123;            staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet();            reportMultipleBindingAmbiguity(staticLoggerBinderPathSet);        &#125;        StaticLoggerBinder.getSingleton();        INITIALIZATION_STATE = 3;        reportActualBinding(staticLoggerBinderPathSet);        fixSubstituteLoggers();        replayEvents();        SUBST_FACTORY.clear();    &#125; catch (NoClassDefFoundError var2) &#123;        msg = var2.getMessage();        if (!messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123;            failedBinding(var2);            throw var2;        &#125;        INITIALIZATION_STATE = 4;        Util.report(&quot;Failed to load class \\&quot;org.slf4j.impl.StaticLoggerBinder\\&quot;.&quot;);        Util.report(&quot;Defaulting to no-operation (NOP) logger implementation&quot;);        Util.report(&quot;See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.&quot;);    &#125; catch (NoSuchMethodError var3) &#123;        msg = var3.getMessage();        if (msg != null &amp;&amp; msg.contains(&quot;org.slf4j.impl.StaticLoggerBinder.getSingleton()&quot;)) &#123;            INITIALIZATION_STATE = 2;            Util.report(&quot;slf4j-api 1.6.x (or later) is incompatible with this binding.&quot;);            Util.report(&quot;Your binding is version 1.5.5 or earlier.&quot;);            Util.report(&quot;Upgrade your binding to version 1.6.x.&quot;);        &#125;        throw var3;    &#125; catch (Exception var4) &#123;        failedBinding(var4);        throw new IllegalStateException(&quot;Unexpected initialization failure&quot;, var4);    &#125;&#125;\n\nreportMultipleBindingAmbiguity方法用来提示多重绑定，并通过日志告诉你具体是有那几个绑定了。\n\n\n\n\n\n\n\n\n\n Class path contains multiple SLF4J bindings.\nreportActualBinding这个是绑定成功的时候，会通过日志显示具体绑定成功的是哪一个日志框架\n\n\n\n\n\n\n\n\n\nActual binding is of type [XXXX]\n关于StaticLoggerBinder从下面这个异常说起：\n123SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder forfurther details.\n\n这个问题是因为加载类文件org.slf4j.impl.StaticLoggerBinder时失败；为什么呢？下面是官网对于这个原因的解释：\n\n\n\n\n\n\n\n\n\nThis error is reported when the org.slf4j.impl.StaticLoggerBinder class could not be loaded into memory. This happens when no appropriate SLF4J binding could be found on the class path. Placing one (and only one) of slf4j-nop.jar, slf4j-simple.jar, slf4j-log4j12.jar, slf4j-jdk14.jar or logback-classic.jar on the class path should solve the problem.\n\n\n\n\n\n\n\n\n\n这个错误发生的原因是StaticLoggerBinder类不能被加载到内存中。发生这种情况时,无法找到合适的SLF4J绑定类路径。slf4j-nop放置一个(且只有一个)。slf4j-simple jar。slf4j-log4j12 jar。slf4j-jdk14 jar。jar或logback-classic。jar的类路径应该解决这个问题。\n也就是说没有找到具体的日志框架来绑定实现。所以我们需要引入一个具体的日志实现jar就可以了。\n网上看到的一片关于slf4j的文章，感觉挺好的，分享给大家：slf4j源码剖析\n\n\n\n\n\n\n\n\n\n新的环境还在适应中，博客的更新频次也直线下降，慢慢学，慢慢写吧。也希望小伙伴们多多见谅！\n","slug":"middleware/middleware-log-slf4j","date":"2018-04-15T13:24:52.000Z","categories_index":"Middleware","tags_index":"log,slf4j","author_index":"glmapper"},{"id":"33cd3345dbbaff282fcbe2e14cfaf78c","title":"Spring 源码系列-依赖注入","content":"在Spring源码系列-BeanDefinition文章中大概分析了一下 Bean 的载入，其实这个过程就是在Ioc容器中建立BeanDefinition的数据映射。但是对于Bean的实例化并未涉及，在之前的分析中也提到，bean的实例化是在依赖注入是才具体完成。\n\n\n关于依赖注入关于Spring，我们最先想到的就两个Ioc和Aop；然后关于Ioc我们又能牵扯出两个：控制反转和依赖注入。控制反转和依赖注入在网上被无数大神亦或菜鸟解读过，这里就不罗列那些概念了，直接看：\n不使用Spring\n1234567public class UserService &#123;    //手动new一个    UserDao userDao = new UserDaoImpl();    public int insertUser(String userName) &#123;    \treturn userDao.insertUser(userName);    &#125;&#125;\n使用Spring(以注解方式)\n1234567public class UserService &#123;    @Autowired    private UserDao userDao;    public int insertUser(String userName) &#123;    \treturn userDao.insertUser(userName);    &#125;&#125;\n\n看起来貌似没有啥很大的改变，区别呢？\n我们先来分析下在一个类中这两种申明的区别：\nUserDao userDao;\nuserDao是UserDao类型的引用名称。仅仅是声明了一个变量引用名称。并没有做实例化，userDao的实例化可以通过set方法进行设置（Spring中之前常用的就是set方法注入）；当我们初始化持有userDao的这个类时我们还不知道userDao到底具体指向哪个堆中的对象地址。\nUserDao userDao = new UserDaoImpl();\n而这个，申明一个变量名称，并将userDao直接指向new UserDaoImpl()创建的对象。\n我们来看Spring中关于注入之后对象地址以及不使用注入方式对象的地址：\n1、直接注入2、注入覆盖了我自己的对象3、自己手动new\n通过上面三幅图可以明显的看出，自己手动new的对象没有使用代理的方式，而托管给Spring注入的对象均是通过动态代理来完成的。\n关于动态代理：《猪弟拱Java》连载番外篇：Java代理（中）\n总结：当某个角色(可能是一个Java实例，调用者)需要另一个角色(另一个Java实例，被调用者)的协助时，在未使用Spring来管理Bean的程序设计过程中，通常由调用者来创建被调用者的实例。但在Spring里，创建被调用者的工作不再由调用者来完成，因此称为控制反转;创建被调用者实例的工作通常由Spring容器来完成，然后注入调用者，因此也称为依赖注入。\n三个问题那么现在要考虑问题就是，什么时候会触发我们的依赖注入呢？Bean的实例化是否必须在依赖注入时才能完成呢？在Spring中又是通过哪些类来完成注入工作的呢？\n1、什么时候会触发我们的依赖注入\n答：用户第一次向容器获取Bean的时候出发。\n2、Bean的实例化是否必须在依赖注入时才能完成\n这个其实不是必须的，咱们都知道BeanDefinition中有lazy-init这样一个属性，我们可以通过控制这个属性的设置来让容器完成对Bean的预实例化。预实例化就是说它的依赖注入是在实例化过程中完成的。\n第一和第二个问题将会在分析第三个问题的时候慢慢的细化分析。所以第三个问题其实没啥鸟用，但也是最最最核心的，就是为了引出后面关于一些具体类的分析的。\ngetBean在Spring源码系列：BeanFactory的创建文章中我们谈到了BeanFactory这容器，这个里面提供了注入的实现接口。其具体的实现还需要从AbstractBeanFactory和DefaultListableBeanFactory中来看。今天就先撸一下AbstractBeanFactory这个类中的getBean这个方法。\ngetBeangetBean提供了四个重载方法，如下：\n12345678910111213141516171819//通过name获取Bean@Overridepublic Object getBean(String name) throws BeansException &#123;\treturn doGetBean(name, null, null, false);&#125;//通过name和类型获取Bean@Overridepublic &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException &#123;\treturn doGetBean(name, requiredType, null, false);&#125;//通过name和对象参数获取Bean@Overridepublic Object getBean(String name, Object... args) throws BeansException &#123;\treturn doGetBean(name, null, args, false);&#125;//通过name、类型和参数获取Beanpublic &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType, Object... args) throws BeansException &#123;\treturn doGetBean(name, requiredType, args, false);&#125;\n\n从这四个重载方法的方法体中可以看出，他们都是通过doGetBean来实现的。所以doGetBean其实才是真正获取Bean的地方，也是触发依赖注入发生的地方。（这个方法比较长，分段来说）\ndoGetBean先来看下方法的定义：\n1234@SuppressWarnings(&quot;unchecked&quot;)\tprotected &lt;T&gt; T doGetBean(\tfinal String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly)\tthrows BeansException &#123;\n\nname 要检索的bean的名称\nrequiredType 要检索的bean所需的类型\nargs 使用显式参数创建bean实例时使用的参数（仅在创建新实例时应用，而不是在检索现有实例时应用）\ntypeCheckOnly 是否为类型检查而获得实例，而不是实际使用\n\n12345678//返回bean名称，剥离工厂引用前缀，并将别名解析为规范名称。final String beanName = transformedBeanName(name);//声明当前需要返回的bean对象Object bean;// 先从缓存中获取bean，处理已经被创建的单例模式的bean，//对于此类bean的请求不需要重复的创建(singleton)Object sharedInstance = getSingleton(beanName);\n\n如果当前获取到的sharedInstance不为null并且参数为空，则进行FactoryBean的相关处理，并获取FactoryBean的处理结果。\n1234567891011121314if (sharedInstance != null &amp;&amp; args == null) &#123;\tif (logger.isDebugEnabled()) &#123;\t    //返回指定的singleton bean是否正在创建（在整个工厂内）。\t\tif (isSingletonCurrentlyInCreation(beanName)) &#123;\t\t\tlogger.debug(&quot;Returning eagerly cached instance of singleton bean &#x27;&quot; \t\t\t+ beanName +&quot;&#x27; that is not fully initialized yet - a consequence of a circular reference&quot;);\t\t&#125;\t\telse &#123;\t\t\tlogger.debug(&quot;Returning cached instance of singleton bean &#x27;&quot; + beanName + &quot;&#x27;&quot;);\t\t&#125;\t&#125;\t//完成FactoryBean的相关处理，并用来获取FactoryBean的处理结果\tbean = getObjectForBeanInstance(sharedInstance, name, beanName, null);&#125;\n如果当前获取到的sharedInstance为null，我们再来看下做了哪些处理（下面的都在一个大的else里面）：\n123else &#123;    //分解到下面&#125;\n\n1234//在当前线程中，返回指定的prototype bean是否正在创建。if (isPrototypeCurrentlyInCreation(beanName)) &#123;\tthrow new BeanCurrentlyInCreationException(beanName);&#125;\n\n下面这段的作用是对Ioc容器中的BeanDefinition是否存在进行检测，先是检测当前BeanFactory中是否能够获取到，如果取不到则继续到双亲容器中进行尝试获取，如果双亲还是取不到，则继续向上一级父容器中尝试获取。\n1234567891011121314// 检查该工厂是否存在bean定义。BeanFactory parentBeanFactory = getParentBeanFactory();if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123;\t// 如果没有，则继续检查父类\tString nameToLookup = originalBeanName(name);\tif (args != null) &#123;\t\t// 用明确的参数代表父项。\t\treturn (T) parentBeanFactory.getBean(nameToLookup, args);\t&#125;\telse &#123;\t\t// 如果没有args - &gt;委托给标准的getBean方法。\t\treturn parentBeanFactory.getBean(nameToLookup, requiredType);\t&#125;&#125;\n将指定的bean标记为已经创建（或即将创建）；这里允许bean工厂优化其缓存以重复创建指定的bean。\n123if (!typeCheckOnly) &#123;\tmarkBeanAsCreated(beanName);&#125;\n\n先根据beanName来获取BeanDefinition，然后获取当前bean的所有依赖bean，这里是通过递归调用getBean来完成，直到没有任何依赖的bean为止。\n12345678910111213141516final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);//检查给定的合并bean定义，可能抛出验证异常。checkMergedBeanDefinition(mbd, beanName, args);// 保证当前bean依赖的bean的初始化。String[] dependsOn = mbd.getDependsOn();if (dependsOn != null) &#123;\tfor (String dep : dependsOn) &#123;\t\tif (isDependent(beanName, dep)) &#123;\t\t\tthrow new BeanCreationException(mbd.getResourceDescription(), beanName,\t\t\t&quot;Circular depends-on relationship between &#x27;&quot; + beanName + &quot;&#x27; and &#x27;&quot; + dep + &quot;&#x27;&quot;);\t\t&#125;\t\tregisterDependentBean(dep, beanName);\t\t//递归处理依赖bean\t\tgetBean(dep);\t&#125;&#125;\n下面这段就是创建一个bean实例；这里通过调用getSingleton方法来创建一个单例bean实例；从代码中可以看到，getSingleton的调用是通过getObject这个回调函数来间接调用createBean完成的。\n12345678910111213141516171819if (mbd.isSingleton()) &#123;\tsharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123;\t//回调函数getObject\t\t@Override\t\tpublic Object getObject() throws BeansException &#123;\t\t\ttry &#123;\t\t\t    //创建bean\t\t\t\treturn createBean(beanName, mbd, args);\t\t\t&#125;\t\t\tcatch (BeansException ex) &#123;\t\t\t\t//发生异常则销毁\t\t\t\tdestroySingleton(beanName);\t\t\t\tthrow ex;\t\t\t&#125;\t\t&#125;\t&#125;);\t//获取给定bean实例的对象，无论是bean实例本身，还是FactoryBean创建的对象。\tbean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125;\n下面是创建prototype bean\n123456789101112else if (mbd.isPrototype()) &#123;    Object prototypeInstance = null;    try &#123;    \tbeforePrototypeCreation(beanName);    \t//创建prototype bean    \tprototypeInstance = createBean(beanName, mbd, args);    &#125;    finally &#123;    \tafterPrototypeCreation(beanName);    &#125;    bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);&#125;\n最后是对创建的bean进行类型检查，没有问题就返回已经创建好的bean；此时这个bean是包含依赖关系的bean\n1234567891011121314if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123;\ttry &#123;\t\treturn getTypeConverter().convertIfNecessary(bean, requiredType);\t&#125;\tcatch (TypeMismatchException ex) &#123;\t\tif (logger.isDebugEnabled()) &#123;\t\t\tlogger.debug(&quot;Failed to convert bean &#x27;&quot; + name + &quot;&#x27; to required type &#x27;&quot; +\t\t\t\t\tClassUtils.getQualifiedName(requiredType) + &quot;&#x27;&quot;, ex);\t\t&#125;\t\tthrow new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());\t&#125;&#125;//返回beanreturn (T) bean;\n\ngetBean是依赖注入的起点，从上面的分析可以看出，bean的创建都是通过createBean来完成具体的创建的。createBean的具体实现是在AbstractAutowireCapableBeanFactory中的，这里createBean不仅仅负责创建bean，还需要完成对bean的初始化。\ncreateBeangetBean 是依赖注入的起点，bean 的创建都是通过 createBean 来完成具体的创建的。createBean 的具体实现是在AbstractAutowireCapableBeanFactory 中的。\n这个方法是 AbstractAutowireCapableBeanFactory 这个类的中心方法，其作用就是创建一个bean实例，填充bean实例，后置处理等。\n在createBean中主要做了三件事：\n\n判断需要创建的Bean是否可以实例化，这个类是否可以通过类装载器来载入\n是否配置了后置处理器相关处理（如果配置了则返回一个代理）\n创建Bean\n\n具体来看方法：\n123456789101112131415161718192021222324252627282930313233343536373839404142protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException &#123;\tif (logger.isDebugEnabled()) &#123;\t\tlogger.debug(&quot;Creating instance of bean &#x27;&quot; + beanName + &quot;&#x27;&quot;);\t&#125;\tRootBeanDefinition mbdToUse = mbd;\t// Make sure bean class is actually resolved at this point, and\t// clone the bean definition in case of a dynamically resolved Class\t// which cannot be stored in the shared merged bean definition.\t//判断需要创建的Bean是否可以实例化，这个类是否可以通过类装载器来载入\tClass&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName);\tif (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123;\t\tmbdToUse = new RootBeanDefinition(mbd);\t\tmbdToUse.setBeanClass(resolvedClass);\t&#125;\t// Prepare method overrides.\ttry &#123;\t\tmbdToUse.prepareMethodOverrides();\t&#125;\tcatch (BeanDefinitionValidationException ex) &#123;\t\t//异常：Validation of method overrides failed\t&#125;\ttry &#123;\t\t// Give BeanPostProcessors a chance to return a proxy instead of the target \t\t//bean instance.\t\t//是否配置了后置处理器相关处理（如果配置了则返回一个代理）\t\tObject bean = resolveBeforeInstantiation(beanName, mbdToUse);\t\tif (bean != null) &#123;\t\t\treturn bean;\t\t&#125;\t&#125;\tcatch (Throwable ex) &#123;\t    //异常:BeanPostProcessor before instantiation of bean failed\t&#125;    //创建Bean\tObject beanInstance = doCreateBean(beanName, mbdToUse, args);\tif (logger.isDebugEnabled()) &#123;\t\tlogger.debug(&quot;Finished creating instance of bean &#x27;&quot; + beanName + &quot;&#x27;&quot;);\t&#125;\treturn beanInstance;&#125;\n\n从上面的代码中可以看到，创建bean是交给doCreateBean方法来创建的。继续看doCreateBean这个方法：（这里面涉及到一个BeanWrapper这个接口，小伙伴可以移步了解一下《Spring源码系列：BeanWrapper》）\n代码 1：\n123456789101112131415// 用BeanWrapper来持有创建出来的Bean对象BeanWrapper instanceWrapper = null;//如果是单例的话，则先把缓存中的同名bean清除if (mbd.isSingleton()) &#123;\tinstanceWrapper = this.factoryBeanInstanceCache.remove(beanName);&#125;//实际创建的交给createBeanInstance来完成，//bean的生成，这里会使用默认的类生成器，包装成BeanWrapperImpl类，//为了下面的populateBean方法的属性注入做准备  if (instanceWrapper == null) &#123;\tinstanceWrapper = createBeanInstance(beanName, mbd, args);&#125;final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null);Class&lt;?&gt; beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null);mbd.resolvedTargetType = beanType;\n代码 2： \n允许后处理器修改合并的bean定义。\n1234567891011synchronized (mbd.postProcessingLock) &#123;    if (!mbd.postProcessed) &#123;    \ttry &#123;    \t\tapplyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);    \t&#125;    \tcatch (Throwable ex) &#123;    \t//异常：Post-processing of merged bean definition failed    \t&#125;    \tmbd.postProcessed = true;    &#125;    &#125;\n\n代码 3 ：\n即使被BeanFactoryAware等生命周期接口触发，也要尽快地缓存singletons 以便能够解析循环引用。\n1234567891011121314boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;\t\tisSingletonCurrentlyInCreation(beanName));if (earlySingletonExposure) &#123;\tif (logger.isDebugEnabled()) &#123;\t\tlogger.debug(&quot;Eagerly caching bean &#x27;&quot; + beanName +\t\t\t\t&quot;&#x27; to allow for resolving potential circular references&quot;);\t&#125;\taddSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() &#123;\t\t@Override\t\tpublic Object getObject() throws BeansException &#123;\t\t\treturn getEarlyBeanReference(beanName, mbd, bean);\t\t&#125;\t&#125;);&#125;\n\n代码 4:\n这里是对bean的初始化的地方，一般情况下依赖注入就在这里发生；这个exposedObject变量保存的是在初始化处理完以后返回的作为依赖注入完成之后的bean。\n123456789101112131415161718// Initialize the bean instance.Object exposedObject = bean;try &#123;\tpopulateBean(beanName, mbd, instanceWrapper);\tif (exposedObject != null) &#123;\t\texposedObject = initializeBean(beanName, exposedObject, mbd);\t&#125;&#125;catch (Throwable ex) &#123;    //抛出\tif (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException)\t    ex).getBeanName())) &#123;\t\tthrow (BeanCreationException) ex;\t&#125;\telse &#123;\t//异常:Initialization of bean failed\t&#125;&#125;\n\n代码 5:\n这里是注册bean\n12345678try &#123;\tregisterDisposableBeanIfNecessary(beanName, bean, mbd);&#125;catch (BeanDefinitionValidationException ex) &#123;    //异常处理&#125;//返回结果return exposedObject;\n\n上面的5个代码段均是doCreateBean中的处理逻辑，有兴趣的小伙伴可以自行查阅源码。从上面的代码中我们依然没有得到具体创建的过程，因为在doCreateBean中又依赖：createBeanInstance和populateBean两个方法。\n在createBeanInstance中生成了Bean所包含的java对象。来看是怎么生成的：\n12345678910111213141516171819202122232425262728293031323334353637383940414243protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) &#123;\t// 确保bean类实际上已经解析过了，可以实例化\tClass&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);\tif (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123;\t\t//异常：Bean class isn&#x27;t public, and non-public access not allowed:beanName\t&#125;     //1. 使用工厂方法来进行bean的实例化\tif (mbd.getFactoryMethodName() != null)  &#123;\t\treturn instantiateUsingFactoryMethod(beanName, mbd, args);\t&#125;\t// 重新创建相同的bean时快捷方式...\tboolean resolved = false;\tboolean autowireNecessary = false;\tif (args == null) &#123;\t\tsynchronized (mbd.constructorArgumentLock) &#123;\t\t\tif (mbd.resolvedConstructorOrFactoryMethod != null) &#123;\t\t\t\tresolved = true;\t\t\t\tautowireNecessary = mbd.constructorArgumentsResolved;\t\t\t&#125;\t\t&#125;\t&#125;\tif (resolved) &#123;\t\tif (autowireNecessary) &#123;\t\t\treturn autowireConstructor(beanName, mbd, null, null);\t\t&#125;\t\telse &#123;\t\t\treturn instantiateBean(beanName, mbd);\t\t&#125;\t&#125;\t// 2.需要确定构造函数...,使用构造函数进行bean实例化\tConstructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);\tif (ctors != null ||\t\t\tmbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR ||\t\t\tmbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args))  &#123;\t\treturn autowireConstructor(beanName, mbd, ctors, args);\t&#125;\t//3.没有特殊的处理：只需使用无参数构造函数。（默认构造函数）\treturn instantiateBean(beanName, mbd);&#125;\n\n从上面这段代码可以看出，对象的生成有许多不同的方式，有通过工厂的，也有通过容器的autowire特性生成的。当然这些生成方式都是由相关的BeanDefinition来指定的。\nSpring中配置Bean的方式我们常用的一种是通过xml文件来配置，还有就是通过注解的方式来配置。\n\ndemo1\n\n123&lt;bean id=&quot;user&quot; class=&quot;com.glmapper.test.User&quot;&gt;  &lt;property name=&quot;name&quot; value=&quot;glmapper&quot;&gt;&lt;/property&gt;       &lt;/bean&gt;\n\n这种方式，通过class提供的权限定名，spring就可以利用反射机制创建这个bean。\n\ndemo2\n\n123&lt;bean id=&quot;user&quot; class=&quot;com.glmapper.test.UserFactory&quot; factory-method=&quot;getUser&quot;&gt;    &lt;constructor-arg value=&quot;glmapper&quot;&gt;&lt;/constructor-arg&gt;           &lt;/bean&gt;\n这种是利用静态工厂方法来创建的，提供的class并非是类的权限定名， 而是静态工厂的全类名；除此之外还需要指定获取bean的方法（此处是getUser）和参数（参数是glmapper）。\n\ndemo3\n\n123456789101112131415161718192021222324252627&lt;bean id=&quot;userFactory&quot; class=&quot;com.glmapper.test.UserInstanceFactory&quot;&gt;    &lt;!--用一个集合来保存我当前的对象实例--&gt;    &lt;property name=&quot;map&quot;&gt;        &lt;map&gt;            &lt;entry key=&quot;user1&quot;&gt;                &lt;bean class=&quot;com.glmapper.test.User&quot;&gt;                    &lt;property name=&quot;name&quot; value=&quot;glmapper1&quot;&gt;&lt;/property&gt;                        &lt;/bean&gt;            &lt;/entry&gt;                &lt;entry key=&quot;user2&quot;&gt;                &lt;bean class=&quot;com.glmapper.test.User&quot;&gt;                    &lt;property name=&quot;name&quot; value=&quot;glmapper2&quot;&gt;&lt;/property&gt;                   &lt;/bean&gt;            &lt;/entry&gt;        &lt;/map&gt;      &lt;/property&gt; &lt;/bean&gt;  //实例1 &lt;bean id=&quot;user1&quot; factory-bean=&quot;userFactory&quot; factory-method=&quot;getUserInstance&quot;&gt;    &lt;constructor-arg value=&quot;user1&quot;&gt;&lt;/constructor-arg&gt;            &lt;/bean&gt;//实例2 &lt;bean id=&quot;user2&quot; factory-bean=&quot;userFactory&quot; factory-method=&quot;getUserInstance&quot;&gt;    &lt;constructor-arg value=&quot;user2&quot;&gt;&lt;/constructor-arg&gt;            &lt;/bean\n\n这种方式和静态工厂的区别在于我们需要先实例化一个工厂对象，然后才能使用这个工厂对象来创建我们的bean。getUserInstance通过key值来获取我们已经实例化好的对象（当然方式有很多，此处以map来举个例子）。关于注解的和使用FactoryBean接口的这里就暂时不说，后期再聊\nOK，继续来分钟，上面说到的是以工厂方法创建bean，具体的源码有点长，这里就不放了，大概思路就如上面所提到的那几种方式。接下来看下常见的使用instantiateBean方式（使用它的默认构造函数）来构建bean的代码：\n1234567891011121314151617181920212223242526protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &#123;\ttry &#123;\t\tObject beanInstance;\t\tfinal BeanFactory parent = this;\t    //获取系统安全接口。\t    //如果已经为当前应用程序建立了安全管理器，则返回该安全管理器; \t    //否则，返回null。\t\tif (System.getSecurityManager() != null) &#123;\t\t\tbeanInstance = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123;\t\t\t\t@Override\t\t\t\tpublic Object run() &#123;\t\t\t\t\treturn getInstantiationStrategy().instantiate(mbd, beanName, parent);\t\t\t\t&#125;\t\t\t&#125;, getAccessControlContext());\t\t&#125;\t\telse &#123;\t\t\tbeanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent);\t\t&#125;\t\tBeanWrapper bw = new BeanWrapperImpl(beanInstance);\t\tinitBeanWrapper(bw);\t\treturn bw;\t&#125;\tcatch (Throwable ex) &#123;\t\t//异常：Instantiation of bean failed\t&#125;&#125;\n可以看出，上面的创建都是通过：\n1getInstantiationStrategy().instantiate(mbd, beanName, parent);\n这样一段代码来完成的，是的，这里已经快接近真相了。从语义上来分析，先是获取了一种策略，然后利用当前获取的策略再去执行实例化。OK，我们看下getInstantiationStrategy()拿到的是什么：\n123456//返回实例化策略用于创建bean实例。protected InstantiationStrategy getInstantiationStrategy() &#123;\treturn this.instantiationStrategy;&#125;//默认的实例化测试是使用CGLIB代理private InstantiationStrategy instantiationStrategy = new CglibSubclassingInstantiationStrategy();\n看到这里我们清楚了，默认构造函数的情况下，在spring中会使用Cglib来进行bean的实例化（关于cglib此处不再赘述）。我们看下CglibSubclassingInstantiationStrategy这个类的申明：\n1public class CglibSubclassingInstantiationStrategy extends SimpleInstantiationStrategy \n它继承自SimpleInstantiationStrategy ，这个又是什么鬼呢？\nSimpleInstantiationStrategy是Spring用来生成Bean对象的默认类，在这个类中提供了两种实例化java对象的方法，一种是基于java自身反射机制的BeanUtils，还有一种就是基于Cglib。\n如何创建的就不说了；到这里createBeanInstance就说完了（Bean已经创建了）；但是仅仅是创建，spring还没有处理它们，比如说bean对象的属性，依赖关系等等。这些就是上面提到的另外一个方法populateBean；\n这个方法其实就做了一件事：使用bean定义中的属性值在给定的BeanWrapper中填充bean实例。分段来看：下面这段代码是先将BeanDefinition中设置的property值封装成PropertyValues，然后检测我们的BeanWrapper是否为Null，如果为null则抛出异常或者跳过当前空实例赋值阶段\n1234567891011//获取到BeanDefinition中设置的property值，封装成PropertyValuesPropertyValues pvs = mbd.getPropertyValues();if (bw == null) &#123;\tif (!pvs.isEmpty()) &#123;\t//异常：Cannot apply property values to null instance\t&#125;\telse &#123;\t// Skip property population phase for null instance.\t    return;\t&#125;&#125;\n\n下面这段代码的意思是给任何InstantiationAwareBeanPostProcessors提供在设置属性之前修改bean状态的机会。 \n12345678910111213141516boolean continueWithPropertyPopulation = true;if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123;    for (BeanPostProcessor bp : getBeanPostProcessors()) &#123;    \tif (bp instanceof InstantiationAwareBeanPostProcessor) &#123;    \t\tInstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;    \t\tif (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123;    \t\t\tcontinueWithPropertyPopulation = false;    \t\t\tbreak;    \t\t&#125;    \t&#125;    &#125;&#125;if (!continueWithPropertyPopulation) &#123;\treturn;&#125;\n\n下面就是对具体注入方式的处理：\n1234567891011121314151617//处理autowire的注入；可以根据bean的名称和类型来注入if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME ||\tmbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123;    MutablePropertyValues newPvs = new MutablePropertyValues(pvs);    // 则根据名称添加基于自动装配的属性值。    if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123;    \tautowireByName(beanName, mbd, bw, newPvs);    &#125;        // 根据类型添加基于自动装配的属性值。    if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123;    \tautowireByType(beanName, mbd, bw, newPvs);    &#125;        pvs = newPvs;&#125;\n两个判断条件，在满足的情况下做的处理分别是：\n\n在工厂将给定属性值应用到给定的bean后，对其进行后处理。 允许检查所有的依赖关系是否被满足，例如基于bean属性设置器上的“Required”注解。还允许替换要应用的属性值，通常通过创建基于原始PropertyValues的新MutablePropertyValues实例，添加或删除特定值。\n执行依赖性检查\n\n123456789101112131415161718192021222324//返回这个工厂是否拥有一个InstantiationAwareBeanPostProcessorboolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();//返回依赖检查代码。boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);if (hasInstAwareBpps || needsDepCheck) &#123;//从给定的BeanWrapper中提取一组已过滤的PropertyDescriptors，//不包括在被忽略的依赖性接口上定义的被忽略的依赖类型或属性（译注）。\tPropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);\tif (hasInstAwareBpps) &#123;    \tfor (BeanPostProcessor bp : getBeanPostProcessors()) &#123;        \tif (bp instanceof InstantiationAwareBeanPostProcessor) &#123;        \t\tInstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;        \t\tpvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);        \t\tif (pvs == null) &#123;        \t\t\treturn;        \t\t&#125;        \t&#125;    \t&#125;\t&#125;\tif (needsDepCheck) &#123;\t\tcheckDependencies(beanName, mbd, filteredPds, pvs);\t&#125;&#125;\n\n最后是对属性进行注入：\n1applyPropertyValues(beanName, mbd, bw, pvs);\n这个方法描述的是对属性进行解析然后注入的过程；先来分析下applyPropertyValues的申明：\n12protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs)\n\nbeanName bean名称\nmbd 合并的bean definition\nbw 包装目标对象的BeanWrapper\npvs 新的属性值\n\n代码分段来看：\n\n参数验证\n123if (pvs == null || pvs.isEmpty()) &#123;\treturn;&#125;\npvs参数处理\n1234567891011121314151617if (pvs instanceof MutablePropertyValues) &#123;    mpvs = (MutablePropertyValues) pvs;    if (mpvs.isConverted()) &#123;    \t// 使用预先转换后的值。    \ttry &#123;    \t\tbw.setPropertyValues(mpvs);    \t\treturn;    \t&#125;    \tcatch (BeansException ex) &#123;    \t\t//异常：Error setting property values    \t&#125;    &#125;    original = mpvs.getPropertyValueList();    &#125;    else &#123;    original = Arrays.asList(pvs.getPropertyValues());    &#125;\n\nvalueResolver来解析BeanDefinition\n12BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter);\n为解析值创建一个副本，注入到bean中的是副本的数据\n12// Create a deep copy, resolving any references for values.List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;PropertyValue&gt;(original.size());\n遍历处理\n123456789101112131415161718192021222324252627282930313233343536boolean resolveNecessary = false;for (PropertyValue pv : original) &#123;    //返回此持有者是否已经包含转换后的值（true），还是需要转换值（false）。    if (pv.isConverted()) &#123;    \tdeepCopy.add(pv);    &#125;       else &#123;    \tString propertyName = pv.getName();    \tObject originalValue = pv.getValue();    \t//看下面的注释resolveValueIfNecessary    \tObject resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue);    \tObject convertedValue = resolvedValue;    \tboolean convertible = bw.isWritableProperty(propertyName) &amp;&amp;    \t\t\t!PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName);    \tif (convertible) &#123;    \t\tconvertedValue = convertForProperty(resolvedValue, propertyName, bw, converter);    \t&#125;    \t// 可能将转换的值存储在合并的bean定义中，以避免为每个创建的bean实例重新转换。    \tif (resolvedValue == originalValue) &#123;    \t\tif (convertible) &#123;    \t\t\tpv.setConvertedValue(convertedValue);    \t\t&#125;    \t\tdeepCopy.add(pv);    \t&#125;    \telse if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp;    \t\t\t!((TypedStringValue) originalValue).isDynamic() &amp;&amp;    \t\t\t!(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &#123;    \t\tpv.setConvertedValue(convertedValue);    \t\tdeepCopy.add(pv);    \t&#125;    \telse &#123;    \t\tresolveNecessary = true;    \t\tdeepCopy.add(new PropertyValue(pv, convertedValue));    \t&#125;    &#125;&#125;\nresolveValueIfNecessary 给定一个PropertyValue，返回一个value，必要时解析对工厂中其他bean的引用。value可以是：\n\n一个BeanDefinition，它导致创建一个相应的新的bean实例。 Singleton标志和这样的”inner beans”的名字被忽略：内部beans是匿名原型。\n\nRuntimeBeanReference(必须解析)\n\nManagedList\n\nManagedSet\n\nManagedMap\n\n一个普通的对象或null，在这种情况下，它是孤立的。\n\n\n下面这段代码时依赖注入发生的地方，其实际上是在BeanWrapperImpl中来完成。\n123456try &#123;    bw.setPropertyValues(new MutablePropertyValues(deepCopy));&#125;catch (BeansException ex) &#123;    //异常：Error setting property values&#125;\n上面说到 spring 是通过 BeanDefinitionValueResolver 来解析 BeanDefinition 的，然后再注入到 property 中，关于这个过程见下一小节。\n属性注入前面文章中对依赖注入的触发和bean的创建做了学习记录，本文将来记录一下bean的属性注入过程。Bean的属性注入发生在BeanDefinitionValueResolver这个类中，BeanDefinitionValueResolver这类是用于bean工厂实现的Helper类，职责就是将bean定义对象中包含的值解析为应用于目标bean实例的实际值。\nBeanDefinitionValueResolver类中的resolveValueIfNecessary()方法包含了对所有注入类型的处理。所以本文主要围绕这个方法展开来说。\nresolveValueIfNecessary方法resolveValueIfNecessary():给定一个PropertyValue，返回一个value，解析对工厂中其他bean的引用。 value可能是：\n\nRuntimeBeanReference : 在解析到依赖的Bean的时侯，解析器会依据依赖bean的name创建一个RuntimeBeanReference对像，将这个对像放入BeanDefinition的MutablePropertyValues中。\nManagedList：用来保存它所管理的List元素，它可以包含运行时期的bean引用(将被解析为bean对象). \nManagedSet ：用来保存它所管理的set值，它可以包含运行时期的bean引用(将被解析为bean对象) \nManagedMap ：用来保存它所管理的map值，它可以包含运行时期的bean引用(将被解析为bean对象)\n\n1、方法申明\nargName ：为其定义的参数的名称\nvalue   ：要解析的值对象\n1public Object resolveValueIfNecessary(Object argName, Object value)\n2、RuntimeBeanReference\n当在beanfactory中作为另外一个bean的引用时，作为属性值对象，将在运行时进行解析。 RuntimeBeanReference是在对BeanDefinition进行解析时生成的数据对象。\n1234if (value instanceof RuntimeBeanReference) &#123;    RuntimeBeanReference ref = (RuntimeBeanReference) value;    return resolveReference(argName, ref);&#125;\n\n3、RuntimeBeanNameReference\n当在beanfactory中作为另外一个bean名称的引用时，作为属性值对象，将在运行时进行解析。 \n12345678else if (value instanceof RuntimeBeanNameReference) &#123;    String refName = ((RuntimeBeanNameReference) value).getBeanName();    refName = String.valueOf(doEvaluate(refName));    if (!this.beanFactory.containsBean(refName)) &#123;        //异常：Invalid bean name &#x27;&quot; + refName + &quot;&#x27; in bean reference for &quot; + argName    &#125;    return refName;&#125;\n\n4、BeanDefinitionHolder\n解析BeanDefinitionHolder：包含具有名称和别名的BeanDefinition。BeanDefinitionHolder就是使用名称或者别名来保存BeanDefinition的。\n1234else if (value instanceof BeanDefinitionHolder) &#123;    BeanDefinitionHolder bdHolder = (BeanDefinitionHolder) value;    return resolveInnerBean(argName, bdHolder.getBeanName(), bdHolder.getBeanDefinition());&#125;\n\n5、BeanDefinition\n解析纯粹的BeanDefinition\n1234567else if (value instanceof BeanDefinition) &#123;    // Resolve plain BeanDefinition, without contained name: use dummy name.    BeanDefinition bd = (BeanDefinition) value;    String innerBeanName = &quot;(inner bean)&quot; + BeanFactoryUtils.GENERATED_BEAN_NAME_SEPARATOR +    \t\tObjectUtils.getIdentityHexString(bd);    return resolveInnerBean(argName, innerBeanName, bd);    &#125;\n\n6、ManagedArray\n包含运行时期的bean引用(将被解析为bean对象)\n1234567891011121314151617181920212223else if (value instanceof ManagedArray) &#123;    // May need to resolve contained runtime references.    ManagedArray array = (ManagedArray) value;    Class&lt;?&gt; elementType = array.resolvedElementType;    if (elementType == null) &#123;    \tString elementTypeName = array.getElementTypeName();    \tif (StringUtils.hasText(elementTypeName)) &#123;        \ttry &#123;        \t\telementType = ClassUtils.forName(elementTypeName,        \t\tthis.beanFactory.getBeanClassLoader());        \t\tarray.resolvedElementType = elementType;        \t&#125;        \tcatch (Throwable ex) &#123;        \t\t// Improve the message by showing the context.        \t\t//异常：Error resolving array type for &quot; + argName        \t&#125;    \t&#125;    \telse &#123;    \t\telementType = Object.class;    \t&#125;    &#125;    return resolveManagedArray(argName, (List&lt;?&gt;) value, elementType);&#125;\n7、ManagedList，ManagedSet，ManagedMap\n包含运行时期的bean引用(将被解析为bean对象)\n123456789101112//对ManagedList进行解析else if (value instanceof ManagedList) &#123;    return resolveManagedList(argName, (List&lt;?&gt;) value);&#125;//对ManagedSet进行解析else if (value instanceof ManagedSet) &#123;    return resolveManagedSet(argName, (Set&lt;?&gt;) value);&#125;//对ManagedMap进行解析else if (value instanceof ManagedMap) &#123;    return resolveManagedMap(argName, (Map&lt;?, ?&gt;) value);&#125;\n8、ManagedProperties\nManagedProperties表示的是一个spring管理的属性实例，它支持父&#x2F;子 definition的合并。\n1234567891011121314151617//对ManagedProperties进行解析else if (value instanceof ManagedProperties) &#123;    Properties original = (Properties) value;    Properties copy = new Properties();    for (Map.Entry&lt;Object, Object&gt; propEntry : original.entrySet()) &#123;    \tObject propKey = propEntry.getKey();    \tObject propValue = propEntry.getValue();    \tif (propKey instanceof TypedStringValue) &#123;    \t\tpropKey = evaluate((TypedStringValue) propKey);    \t&#125;    \tif (propValue instanceof TypedStringValue) &#123;    \t\tpropValue = evaluate((TypedStringValue) propValue);    \t&#125;    \tcopy.put(propKey, propValue);    &#125;    return copy;&#125;\n9、TypedStringValue\nTypedStringValue保存的是一个类型的属性值。\n1234567891011121314151617181920//对TypedStringValue进行解析else if (value instanceof TypedStringValue) &#123;    // Convert value to target type here.    TypedStringValue typedStringValue = (TypedStringValue) value;    Object valueObject = evaluate(typedStringValue);    try &#123;    \tClass&lt;?&gt; resolvedTargetType = resolveTargetType(typedStringValue);    \tif (resolvedTargetType != null) &#123;    \t\treturn this.typeConverter.convertIfNecessary(valueObject, resolvedTargetType);    \t&#125;    \telse &#123;    \t\treturn valueObject;    \t&#125;    &#125;    catch (Throwable ex) &#123;    \t// Improve the message by showing the context.    \tthrow new BeanCreationException(    \t//异常：Error converting typed String value for &quot; + argName    &#125;&#125;\n10、作为表达式进行评估\n将给定的值作为表达式进行评估。\n123else &#123;    return evaluate(value);&#125;\n\n在完成上述解析之后，已经为我们的依赖注入做好了准备。这是真正把Bean对象设置到它所依赖的另一个Bean的属性中去的地方，可以看到，处理的属性也是各式各样的。具体属性的注入是在之前提到的BeanWrapper接口的实现类BeanWrapperImpl的setPropertyValue方法来完成。\nsetPropertyValue方法a、方法声明这个方法是私有的，是BeanWrapperImpl实际处理的方法，其对外也提供了setPropertyValue的其它重载方法来提供服务。\n12private void setPropertyValue(PropertyTokenHolder tokens, PropertyValue pv)    throws BeansException\n\nb、PropertyTokenHolder是BeanWrapperImpl的内部类12345private static class PropertyTokenHolder &#123;    public String canonicalName;    public String actualName;    public String[] keys;&#125;\n在setPropertyValue方法中会根据tokens变量是否为null,有两个不同的分支。其中当tokens为null时，则会对属性名进行递归调用分析处理，返回分析处理后的BeanWrapImpl对象nestedBw。如果nestedBw&#x3D;&#x3D;this,则会设置pv的resolvedTokens属性值，最后将调用nestedBw对象的设置属性值方法设置属性。来具体看看：\nc、其中当tokens为null时，即对集合类的域进行注入1234567891011121314// 设置tokens的索引和keysPropertyTokenHolder getterTokens = new PropertyTokenHolder();getterTokens.canonicalName = tokens.canonicalName;getterTokens.actualName = tokens.actualName;getterTokens.keys = new String[tokens.keys.length - 1];System.arraycopy(tokens.keys, 0, getterTokens.keys, 0, tokens.keys.length - 1);Object propValue;//getPropertyValue用来获取Bean中对对象注入的引用；try &#123;\tpropValue = getPropertyValue(getterTokens);&#125;catch (NotReadablePropertyException ex) &#123;//异常：Cannot access indexed value in property referenced &#125;\n\n1、propValue为null\npropValue为null\n12345678910111213if (propValue == null) &#123;    // 空值映射的情况    if (this.autoGrowNestedPaths) &#123;    \t// TODO: cleanup, this is pretty hacky    \tint lastKeyIndex = tokens.canonicalName.lastIndexOf(&#x27;[&#x27;);    \tgetterTokens.canonicalName = tokens.canonicalName.substring(0, lastKeyIndex);    \tpropValue = setDefaultValue(getterTokens);    &#125;    else &#123;    //异常：Cannot access indexed value in property referenced &quot; +\t&quot;in indexed property path &#x27;&quot; + propertyName + &quot;&#x27;: returned null&quot;    &#125;&#125;\n\n2、对array进行注入\n对array进行注入\n1234567891011121314151617if (propValue.getClass().isArray()) &#123;    PropertyDescriptor pd = getCachedIntrospectionResults().getPropertyDescriptor(actualName);    Class requiredType = propValue.getClass().getComponentType();    int arrayIndex = Integer.parseInt(key);    Object oldValue = null;    try &#123;    \tif (isExtractOldValueForEditor() &amp;&amp; arrayIndex &lt; Array.getLength(propValue)) &#123;    \t\toldValue = Array.get(propValue, arrayIndex);    \t&#125;    \tObject convertedValue = convertIfNecessary(propertyName, oldValue, pv.getValue(),    \t\t\trequiredType, TypeDescriptor.nested(property(pd), tokens.keys.length));    \tArray.set(propValue, arrayIndex, convertedValue);    &#125;    catch (IndexOutOfBoundsException ex) &#123;    //异常：Invalid array index in property path &#x27;&quot; + propertyName    &#125;&#125;\n\n2、对list进行注入\n对list进行注入\n123456789101112131415161718192021222324252627282930313233else if (propValue instanceof List) &#123;    PropertyDescriptor pd = getCachedIntrospectionResults().getPropertyDescriptor(actualName);    Class requiredType = GenericCollectionTypeResolver.getCollectionReturnType(    \t\tpd.getReadMethod(), tokens.keys.length);    List list = (List) propValue;    int index = Integer.parseInt(key);    Object oldValue = null;    if (isExtractOldValueForEditor() &amp;&amp; index &lt; list.size()) &#123;    \toldValue = list.get(index);    &#125;    Object convertedValue = convertIfNecessary(propertyName, oldValue, pv.getValue(),    \t\trequiredType, TypeDescriptor.nested(property(pd), tokens.keys.length));    int size = list.size();    if (index &gt;= size &amp;&amp; index &lt; this.autoGrowCollectionLimit) &#123;    \tfor (int i = size; i &lt; index; i++) &#123;    \t\ttry &#123;    \t\t\tlist.add(null);    \t\t&#125;    \t\tcatch (NullPointerException ex) &#123;    \t\t    //异常：InvalidPropertyException    \t\t&#125;    \t&#125;    \tlist.add(convertedValue);    &#125;    else &#123;    \ttry &#123;    \t\tlist.set(index, convertedValue);    \t&#125;    \tcatch (IndexOutOfBoundsException ex) &#123;    \t\t//异常：Invalid list index in property path &#x27;&quot; + propertyName + &quot;&#x27;&quot;    \t&#125;    &#125;&#125;\n\n2、对map进行注入\n对map进行注入\n1234567891011121314151617181920else if (propValue instanceof Map) &#123;    PropertyDescriptor pd = getCachedIntrospectionResults().getPropertyDescriptor(actualName);    Class mapKeyType = GenericCollectionTypeResolver.getMapKeyReturnType(    \t\tpd.getReadMethod(), tokens.keys.length);    Class mapValueType = GenericCollectionTypeResolver.getMapValueReturnType(    \t\tpd.getReadMethod(), tokens.keys.length);    Map map = (Map) propValue;    //重要提示：不要在这里传递完整的属性名称    TypeDescriptor typeDescriptor = (mapKeyType != null ?    \t\tTypeDescriptor.valueOf(mapKeyType) : TypeDescriptor.valueOf(Object.class));    Object convertedMapKey = convertIfNecessary(null, null, key, mapKeyType, typeDescriptor);    Object oldValue = null;    if (isExtractOldValueForEditor()) &#123;    \toldValue = map.get(convertedMapKey);    &#125;    // 在这里传递完整的属性名称和旧值，因为希望对map值有完整的转换能力。    Object convertedMapValue = convertIfNecessary(propertyName, oldValue, pv.getValue(),    \t\tmapValueType, TypeDescriptor.nested(property(pd), tokens.keys.length));    map.put(convertedMapKey, convertedMapValue);&#125;\n其中当tokens不为null时，即对非集合类的域进行注入这里是核心的地方，取得注入属性的set方法，通过反射机制，把对象注入进去。\n123final Method writeMethod = (pd instanceof GenericTypeAwarePropertyDescriptor ?    ((GenericTypeAwarePropertyDescriptor) pd).getWriteMethodForActualAccess() :    pd.getWriteMethod());\n\n总结通过上面的几篇分析我们大概的熟悉了Bean创建和对象依赖注入的一个过程，在这个过程中，spring需要根据Beandefinition中的信息来递归完成依赖注入。并且这些递归的入口都是getBean这个方法。\n一个递归是在上下文体系中查找需要的Bean和创建Bean的递归调用；\n另一个递归是在依赖注入时通过递归调用容器的getBean方法，得到当前Bean的依赖Bean，同时也触发对依赖Bean的创建和注入。\n在对Bean的属性进行依赖注入时解析的过程也是一个递归的过程。这样就可以根据依赖关系，一层一层的完成Bean的创建和注入，直到最后完成当前Bean的创建。\n总结依赖注入调用过程\n如前几篇文章所述，依赖注入是由 getBean 来触发的；然后涉及到 bean 实例的创建、依赖关系的建立、属性注入等子过程。\n\ngetBean 方法触发依赖注入\ndoGetBean 从容器中查找Bean（BeanFactory链，当前容器-&gt;双亲容器-双亲容器…）\n\n当然，在获取到某个Bean的时候也会通过递归的方式来依赖注入依赖的bean\n\ncreateBeanInstance 生成了Bean所包含的Java对象，Spring中用SimpleInstantiationStrategy类来生成Bean对象的实例，实例化Java对象的方法有两种（CGlib是默认方式）：\n\n通过BeanUtils，它使用了JVM的反射功能来生成Java对象实例\n用CGLIB来生成，CGLIB是一种常用的字节码生成器的类库\n\n\npopulateBean 设置Bean对象的依赖关系\n\nresolveValueIfNecessary 注入类型的处理；解析不同类型的属性\n\nsetPropertyValues 属性注入\n\n\n关于lazy-initIoc 容器的初始化过程中，主要的工作就是对BeanDefinition的定位、载入、解析和注册；但是就像之前说过的，此时依赖注入还没有发生。在getBean 方法提到，依赖注入发生在应用第一次向容器获取 Bean 的时候；也就是上面说到的通过 getBean 来触发。\n当然，依赖注入也可以在容器初始化的过程中就完成。这个就是lazy-init属性的存在意义了。就是说我们可以通过设置Bean的lazy-init属性来控制预实例化的过程。\n预实例化：在初始化容器时完成Bean的依赖注入\n这种做法的好处在于提高了我们第一次获取Bean的的效率，但是它也降低了容器初始化的速度。（这个其实很好理解的，因为第一次获取Bean的时候，依赖注入已经完成了，直接拿过来用就行）\n关于lazy-init属性的处理也是在wac.refresh这个方法中完成的，具体是在finishBeanFactoryInitialization方法中。如果继续追溯的话，最终是交给DefaultListableBeanFactory容器中的preInstantiateSingletons方法中完成。\nlazy-init这种实例化方式就是通过将依赖注入委托给容器来处理，而不是在用户第一向容器申请的Bean的时候完成依赖注入，不同的阶段，也有不同的优劣。\n参考\n《Spring技术内幕》\n\nhttps://www.cnblogs.com/davidwang456/p/4213652.html\n\n\n","slug":"spring/spring-ioc-dependency-inject","date":"2018-02-07T02:24:12.000Z","categories_index":"spring","tags_index":"spring,依赖注入,Ioc","author_index":"glmapper"},{"id":"8260d6d08a83b75824bdeb2a713c7b70","title":"Spring 源码系列-BeanDefinition","content":"Bean的定义主要由 BeanDefinition 来描述的。作为Spring中用于包装Bean的数据结构，今天就来看看它的面纱下的真容吧\n\nBeanDefinition 类定义首先就是BeanDefinition的类定义：\n1public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement\n对，没错，这货是个接口，而不是类，是不是有点莫名奇妙呢？我们都知道在JAVA中，接口是不能用来new出新的对象的，那么在Spring中，到底将XML解析出来的Bean包装成了什么呢？（这个密等下揭开）\n先来看看BeanDefinition一个继承结构吧（均是与BeanDefinition有直接关联的类或者接口）！\n从类图中可以看出，BeanDefinition继承了AttributeAccessor和BeanMetadataElement两个接口；一个一个看。\nAttributeAccessorAttributeAccessor 接口定义了最基本的对任意对象的元数据的修改或者获取，主要方法有：\n1234567891011//将name定义的属性设置为提供的value值。如果value的值为null，则该属性为&#123;@link #removeAttribute removed&#125;。//通常，用户应该注意通过使用完全限定的名称（可能使用类或包名称作为前缀）来防止与其他元数据属性重叠。void setAttribute(String name, Object value);//获取标识为name的属性的值。Object getAttribute(String name);//删除标识为name的属性，并返回属性值Object removeAttribute(String name);//如果名为name的属性是否存在，存在返回true，否则返回false。boolean hasAttribute(String name);//返回所有属性的名称。String[] attributeNames();\nBeanMetadataElementBeanMetadataElement 接口提供了一个 getResource() 方法,用来传输一个可配置的源对象。\n12//返回此元数据元素的配置源对象（可能为null）。Object getSource();\n\nBeanDifinition 源码分析一个BeanDefinition描述了一个bean的实例，包括属性值，构造方法参数值和继承自它的类的更多信息。BeanDefinition仅仅是一个最简单的接口，主要功能是允许BeanFactoryPostProcessor 例如PropertyPlaceHolderConfigure 能够检索并修改属性值和别的bean的元数据（译注）。\n123456789101112131415//标准单例作用域的作用域标识符：“singleton”。//对于扩展的bean工厂可能支持更多的作用域。String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON;//标准原型作用域的范围标识符：“prototype”。//对于扩展的bean工厂可能支持更多的作用域。String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE;//表示BeanDefinition是应用程序主要部分的角色提示。 通常对应于用户定义的bean。int ROLE_APPLICATION = 0;//表示BeanDefinition是某些大型配置的支持部分的角色提示，通常是一个外部ComponentDefinition。//当查看某个特定的ComponentDefinition时，认为bean非常重要，//以便在查看应用程序的整体配置时能够意识到这一点。int ROLE_SUPPORT = 1; //1实际上就是说，我这个Bean是用户的，是从配置文件中过来的。//角色提示表明一个BeanDefinition是提供一个完全背景的角色，并且与最终用户没有关系。//这个提示用于注册完全是ComponentDefinition内部工作的一部分的beanint ROLE_INFRASTRUCTURE = 2; //2就是我这Bean是Spring自己的，和你用户没有一毛钱关系。\n\n上面是BeanDifinition的一些基本属性信息，一个就是标识下当前Bean的作用域，另外就是标识一下这个Bean是内部的还是外部的。下面来看这个接口为其子类都提供了哪些具体的行为方法：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//如果父类存在，设置这个bean定义的父定义的名称。void setParentName(String parentName);//如果父类存在，则返回当前Bean的父类的名称String getParentName();//指定此bean定义的bean类名称。//类名称可以在bean factory后期处理中修改，通常用它的解析变体替换原来的类名称。void setBeanClassName(String beanClassName);//返回此bean定义的当前bean类名称。//需要注意的是，这不一定是在运行时使用的实际类名，以防子类定义覆盖/继承其父类的类名。//此外，这可能只是调用工厂方法的类，或者它 在调用方法的工厂bean引用的情况下甚至可能是空的。//因此，不要认为这是在运行时定义的bean类型，而只是将其用于在单独的bean定义级别进行解析。String getBeanClassName();//覆盖此bean的目标范围，指定一个新的范围名称。void setScope(String scope);//返回此bean的当前目标作用域的名称，如果没有确定，返回nullString getScope();//设置这个bean是否应该被延迟初始化。如果&#123;false&#125;，那么这个bean将在启动时由bean工厂实例化，//这些工厂执行单例的立即初始化。//懒加载 &lt;bean lazy-init=&quot;true/false&quot;&gt;void setLazyInit(boolean lazyInit);//返回这个bean是否应该被延迟初始化，即不是在启动时立即实例化。只适用于单例bean。boolean isLazyInit();//设置这个bean依赖被初始化的bean的名字。 bean工厂将保证这些bean首先被初始化。//&lt;bean depends-on=&quot;&quot;&gt;void setDependsOn(String... dependsOn);//返回这个bean依赖的bean名称。String[] getDependsOn();//设置这个bean是否是获得自动装配到其他bean的候选人。//需要注意是，此标志旨在仅影响基于类型的自动装配。//它不会影响按名称的显式引用，即使指定的bean没有标记为autowire候选，也可以解决这个问题。//因此，如果名称匹配，通过名称的自动装配将注入一个bean。void setAutowireCandidate(boolean autowireCandidate);//返回这个bean是否是自动装配到其他bean的候选者。就是是否在其他类中使用autowired来注入当前Bean的//是否为被自动装配 &lt;bean autowire-candidate=&quot;true/false&quot;&gt;boolean isAutowireCandidate();//是否为主候选bean    使用注解：@Primaryvoid setPrimary(boolean primary);//返回这个bean是否是主要的autowire候选者。boolean isPrimary();//指定要使用的工厂bean（如果有的话）。 这是调用指定的工厂方法的bean的名称。void setFactoryBeanName(String factoryBeanName);//返回工厂bean的名字，如果有的话。String getFactoryBeanName();//如果有的话，指定工厂方法。//这个方法先将通过构造函数参数被调用，或者如果参数，将调用该方法的无参数构造。//方法将在指定的工厂bean（如果有的话）上被调用，或者作为本地bean类的静态方法被调用。void setFactoryMethodName(String factoryMethodName);//如果存在，返回工厂方法名String getFactoryMethodName();//返回此bean的构造函数参数值。ConstructorArgumentValues getConstructorArgumentValues();//获取普通属性集合MutablePropertyValues getPropertyValues();//是否是单例的boolean isSingleton();//是否是多例的boolean isPrototype();//是否是抽象类boolean isAbstract();//获取这个bean的应用int getRole();//返回对bean定义的可读描述。String getDescription();//返回该bean定义来自的资源的描述String getResourceDescription();//返回原始的BeanDefinition;如果没有，则返回null。允许检索装饰的bean定义（如果有的话）。//注意，这个方法返回直接的发起者。 迭代原始链，找到用户定义的原始BeanDefinition。BeanDefinition getOriginatingBeanDefinition();\n\n从上面的属性和方法分析可以看出，BeanDefinition 对于一个Bean的描述做了较为完整的一套约束。这为后续的子类提供的最基本的职责和属性。\nbeanFactory 创建Spring的Ioc容器其实就是一个bean的关系网，依赖于core，bean，context三个组件来构建的。在spring中最核心的就是对于bean的管理。而bean又依托于我们的容器。本文将从顶层分析一下spring中beanFactory的具体创建过程，为后续的bean的生命周期提供一个基础。\nBeanFactory的继承体系从上图可以看到，BeanFactory有三个子类：\n\nListableBeanFactory\nHierarchicalBeanFactory\nAutowireCapableBeanFactory\n\n（上述三个类的子类体系小伙伴们可以自己对着源码看下，实在太多）\n看下上图中最底层的DefaultListableBeanFactory类的定义：\n12public class DefaultListableBeanFactory extends AbstractAutowireCapableBeanFactory\timplements ConfigurableListableBeanFactory, BeanDefinitionRegistry, Serializable\n这个其实就是BeanFactory的默认实现类，它直接或者间接的实现了所有的接口。其实在看spring源码的时候都会遇到类似的设计模式，对于某一个具体的功能，通常都会定义很多层的接口，层层包装，层层委托。这种做法的好处就是，对于不同的场合都会有特定的接口；这样一来就可以在spring内部对对象的传递和转化操作都会有一些访问限制。\n例如ListableBeanFactory接口表示这些Bean是可列表的，而HierarchicalBeanFactory表示的是这些Bean是有继承关系的，也就是每个Bean有可能有父Bean。AutowireCapableBeanFactory接口定义Bean的自动装配规则。这四个接口共同定义了Bean的集合、Bean之间的关系、以及Bean行为。\nBeanFactory的创建在之前的文章中说过了容器的刷新过程。BeanFactory的创建也在wac.refresh()方法中。具体看下到底是通过哪些子类来完成的：\n12// 通知子类刷新内部的bean工厂。ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();\n1.AbstractApplicationContext中的obtainFreshBeanFactory\n下面是obtainFreshBeanFactory的方法逻辑：\n12345678910protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123;    //这个是具体创建的方法，由子类实现\trefreshBeanFactory();\t//获取BeanFactory实例对象（ConfigurableListableBeanFactory类型的）\tConfigurableListableBeanFactory beanFactory = getBeanFactory();\tif (logger.isDebugEnabled()) &#123;\t\tlogger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory);\t&#125;\treturn beanFactory;&#125;\nrefreshBeanFactory并未有具体的实现逻辑，这个方法主要是通过委托给子类的refreshBeanFactory方法来实现，在AbstractApplicationContext中refreshBeanFactory是一个抽象模板方法：\n1protected abstract void refreshBeanFactory() throws BeansException, IllegalStateException;\n\n2.refreshBeanFactory方法(AbstractRefreshableApplicationContext类中)：\n下面只注释与beanFactory创建相关的代码\n1234567891011121314151617181920212223protected final void refreshBeanFactory() throws BeansException &#123;    //是否已经有BeanFactory了    if (hasBeanFactory()) &#123;        //销毁原有的Bean    \tdestroyBeans();    \t//关闭工厂    \tcloseBeanFactory();    &#125;    try &#123;        //创建一个新的beanFactory    \tDefaultListableBeanFactory beanFactory = createBeanFactory();    \tbeanFactory.setSerializationId(getId());    \tcustomizeBeanFactory(beanFactory);    \tloadBeanDefinitions(beanFactory);    \tsynchronized (this.beanFactoryMonitor) &#123;    \t\tthis.beanFactory = beanFactory;    \t&#125;    &#125;    catch (IOException ex) &#123;    \tthrow new ApplicationContextException(&quot;I/O error parsing bean definition     \tsource for &quot; + getDisplayName(), ex);    &#125;&#125;\n这个方法是实现执行这个上下文的底层bean工厂的实际刷新，如果有的话之前有BeanFactory存在，则关闭以前的bean工厂。并为上下文生命周期的下一个阶段初始化一个新鲜的bean工厂。\n3.createBeanFactory(AbstractRefreshableApplicationContext类中)\n123protected DefaultListableBeanFactory createBeanFactory() &#123;\treturn new DefaultListableBeanFactory(getInternalParentBeanFactory());&#125;\n这个方法就是为当前上下文创建一个内部的bean工厂。每次调用refresh()方法是都会创建尝试创建。默认实现是创建一个DefaultListableBeanFactory。并通过getInternalParentBeanFactory（）获取内部bean工厂来作为父级bean工厂。可以在子类中重写，例如自定义DefaultListableBeanFactory的设置。\ngetInternalParentBeanFactory（AbstractApplicationContext类中）\n1234protected BeanFactory getInternalParentBeanFactory() &#123;\treturn (getParent() instanceof ConfigurableApplicationContext) ?\t((ConfigurableApplicationContext) getParent()).getBeanFactory() : getParent();&#125;\n4.DefaultListableBeanFactory的构造函数\n1234567/** * 通过给定的父类创建一个新的DefaultListableBeanFactory容器 * @param parentBeanFactory the parent BeanFactory */public DefaultListableBeanFactory(BeanFactory parentBeanFactory) &#123;\tsuper(parentBeanFactory);&#125;\nsuper(parentBeanFactory)调用的是AbstractAutowireCapableBeanFactory的构造函数\n123456789/** * 通过给定的父类构建新的AbstractAutowireCapableBeanFactory * @param parentBeanFactory parent bean factory, or &#123;@code null&#125; if none */public AbstractAutowireCapableBeanFactory(BeanFactory parentBeanFactory) &#123;\tthis();\t//设置父工厂\tsetParentBeanFactory(parentBeanFactory);&#125;\nthis(),还是AbstractAutowireCapableBeanFactory的构造函数：\n123456789/** * 构建一个新的AbstractAutowireCapableBeanFactory. */public AbstractAutowireCapableBeanFactory() &#123;\tsuper();\tignoreDependencyInterface(BeanNameAware.class);\tignoreDependencyInterface(BeanFactoryAware.class);\tignoreDependencyInterface(BeanClassLoaderAware.class);&#125;\nsuper()  ;     AbstractBeanFactory的构造函数\n12345/** * 构建一个新的 AbstractBeanFactory. */public AbstractBeanFactory() &#123;&#125;\n\nBeanDefinition 载入（上）继上一篇BeanFactory的创建之后，其实就是BeanDefinition载入了。同样也是在AbstractRefreshableApplicationContext类的refreshBeanFactory方法中完成：\n//创建默认的DefaultListableBeanFactory工厂DefaultListableBeanFactory beanFactory = createBeanFactory();//设置IdbeanFactory.setSerializationId(getId());//这个方法其实就是设置了allowBeanDefinitionOverriding和allowCircularReferences两个属性customizeBeanFactory(beanFactory);//调用子类的加载bean定义方法，这里会调用XmlWebApplicationContext子类的复写方法loadBeanDefinitions(beanFactory);\n这里的loadBeanDefinitions也是一个抽象方法，AbstractRefreshableApplicationContext类中并没有给出具体的实现，二是通过子类XmlWebApplicationContext的loadBeanDefinitions完成具体实现。\nprotected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory)         throws BeansException, IOException &#123;    //创建XmlBeanDefinitionReader，并通过回调设置到BeanFactory中    XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);    //为XmlBeanDefinitionReader配置Environment    beanDefinitionReader.setEnvironment(getEnvironment());    //为XmlBeanDefinitionReader配置ResourceLoader，    //因为DefaultResourceLoader是父类，所以this可以直接被使用    beanDefinitionReader.setResourceLoader(this);    beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this));    // 允许子类提供reader的自定义初始化，然后继续实际加载bean定义。    initBeanDefinitionReader(beanDefinitionReader);    loadBeanDefinitions(beanDefinitionReader);&#125;\ninitBeanDefinitionReader初始化用于加载此上下文的bean定义的bean定义读取器；默认实现是空的。然后下面通过重载的loadBeanDefinitions来做具体的bean解析（这里用到的是XmlBeanDefinitionReader这个解析器）；使用给定的XmlBeanDefinitionReader加载bean definitions。\nprotected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws IOException &#123;    String[] configLocations = getConfigLocations();    //遍历xml文件    if (configLocations != null) &#123;        for (String configLocation : configLocations) &#123;            reader.loadBeanDefinitions(configLocation);        &#125;    &#125;&#125;\n此时会将我们的applicationContext.xml读入（当然如何还有其他的spring配置文件，同样会一块拿到路径），如下图所示：然后继续通过loadBeanDefinitions的重载方法继续委托调用。最后交给AbstractBeanDefinitionReader的loadBeanDefinitions来完成；这个代码比较长，拆开一步一步来说，先看下整体的：\npublic int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123;    //获取ResourceLoader资源定位器    ResourceLoader resourceLoader = getResourceLoader();    //如果定位器为null，则抛出异常    if (resourceLoader == null) &#123;        throw new BeanDefinitionStoreException(                \"Cannot import bean definitions from location [\" + location + \"]: no ResourceLoader available\");    &#125;    //是否是ResourcePatternResolver类型的定位器    if (resourceLoader instanceof ResourcePatternResolver) &#123;        // Resource pattern matching available.        try &#123;            Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location);            int loadCount = loadBeanDefinitions(resources);            if (actualResources != null) &#123;                for (Resource resource : resources) &#123;                    actualResources.add(resource);                &#125;            &#125;            if (logger.isDebugEnabled()) &#123;                logger.debug(\"Loaded \" + loadCount + \" bean definitions from location pattern [\" + location + \"]\");            &#125;            return loadCount;        &#125;        catch (IOException ex) &#123;            throw new BeanDefinitionStoreException(                    \"Could not resolve bean definition resource pattern [\" + location + \"]\", ex);        &#125;    &#125;    //非ResourcePatternResolver类型的    else &#123;        // Can only load single resources by absolute URL.        Resource resource = resourceLoader.getResource(location);        int loadCount = loadBeanDefinitions(resource);        if (actualResources != null) &#123;            actualResources.add(resource);        &#125;        if (logger.isDebugEnabled()) &#123;            logger.debug(\"Loaded \" + loadCount + \" bean definitions from location [\" + location + \"]\");        &#125;        return loadCount;    &#125;&#125;\n上面的代码中需要说明下为什么要判断当前resourceLoader是否是ResourcePatternResolver类型的，因为ResourceLoader只是提供了对classpath前缀的支持。而ResourcePatternResolver提供了对classpath*前缀的支持。也就是说ResourceLoader提供classpath下单资源文件的载入，而ResourcePatternResolver提供多资源文件的载入。先看下假如是ResourcePatternResolver类型的（略去了部分log代码）：\ntry &#123;    //先得到我们的resources    Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location);    //解析并返回beanDefinition的数量    int loadCount = loadBeanDefinitions(resources);    //加载过程中已经被解析过的实际的Resource的填充集合    if (actualResources != null) &#123;        for (Resource resource : resources) &#123;            actualResources.add(resource);        &#125;    &#125;    return loadCount;&#125;catch (IOException ex) &#123;    throw new BeanDefinitionStoreException(        \"Could not resolve bean definition resource pattern [\" + location + \"]\", ex);&#125;\n非ResourcePatternResolver类型情况：\n// Can only load single resources by absolute URL.//只能通过绝对URL加载单个资源Resource resource = resourceLoader.getResource(location);//解析并返回beanDefinition的数量int loadCount = loadBeanDefinitions(resource);if (actualResources != null) &#123;    actualResources.add(resource);&#125;return loadCount;\n然后继续通过重载方法loadBeanDefinitions(Resource… resources)来解析（AbstractBeanDefinitionReader类中）\npublic int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123;    Assert.notNull(resources, \"Resource array must not be null\");    //初始化beanDefiniton个数    int counter = 0;    //遍历当前资源数组    for (Resource resource : resources) &#123;        //解析具体resource中的bean        counter += loadBeanDefinitions(resource);    &#125;    return counter;&#125;\n然后交给子类XmlBeanDefinitionReader中的loadBeanDefinitions(Resource resource)方法：\npublic int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException &#123;    return loadBeanDefinitions(new EncodedResource(resource));&#125;\n继续通过重载方法loadBeanDefinitions(EncodedResource encodedResource)执行，这个方法我们只关注最核心的代码：\n//获取输入流InputStream inputStream = encodedResource.getResource().getInputStream();try &#123;    //资源读取inputSource    InputSource inputSource = new InputSource(inputStream);    if (encodedResource.getEncoding() != null) &#123;        inputSource.setEncoding(encodedResource.getEncoding());    &#125;    //委托给doLoadBeanDefinitions来完成    return doLoadBeanDefinitions(inputSource, encodedResource.getResource());&#125;finally &#123;    inputStream.close();&#125;\ndoLoadBeanDefinitions是XmlBeanDefinitionReader中的方法，来看核心代码：\n//解析成符合w3c标准的DocumentDocument doc = doLoadDocument(inputSource, resource);//继续交给registerBeanDefinitions来处理return registerBeanDefinitions(doc, resource);\n这个时候已经将loadBeanDefinitions换成registerBeanDefinitions了，也就是载入并注册；registerBeanDefinitions同样也是XmlBeanDefinitionReader中的方法：\npublic int registerBeanDefinitions(Document doc, Resource resource) throwsBeanDefinitionStoreException &#123;    //得到documentReader用来读取document文档    BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();    //注册之前的bean个数    int countBefore = getRegistry().getBeanDefinitionCount();    //解析并注册bean    documentReader.registerBeanDefinitions(doc, createReaderContext(resource));    return getRegistry().getBeanDefinitionCount() - countBefore;&#125;\n仍然没有处理，继续交给BeanDefinitionDocumentReader的registerBeanDefinitions方法来完成：\n//这个实现根据“spring-beans”XSD（或DTD）解析bean定义。public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) &#123;    this.readerContext = readerContext;    logger.debug(\"Loading bean definitions\");    Element root = doc.getDocumentElement();    doRegisterBeanDefinitions(root);&#125;\n还是没处理，又细化一步，交给DefaultBeanDefinitionDocumentReader的doRegisterBeanDefinitions(Element root)方法：\nprotected void doRegisterBeanDefinitions(Element root) &#123;    BeanDefinitionParserDelegate parent = this.delegate;    this.delegate = createDelegate(getReaderContext(), root, parent);    if (this.delegate.isDefaultNamespace(root)) &#123;        String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);        if (StringUtils.hasText(profileSpec)) &#123;            String[] specifiedProfiles = StringUtils.tokenizeToStringArray(                    profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);            if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123;                if (logger.isInfoEnabled()) &#123;                    logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec +                            \"] not matching: \" + getReaderContext().getResource());                &#125;                return;            &#125;        &#125;    &#125;    preProcessXml(root);    parseBeanDefinitions(root, this.delegate);    postProcessXml(root);    this.delegate = parent;&#125;\n任何嵌套的&lt;beans&gt;元素都将导致此方法的递归。 为了正确传播和保存&lt;beans&gt; default- *属性，请跟踪当前（父）委托，该委托可能为null。 为了回退的目的，创建一个引用父对象的新（子）委托，然后最终重置this.delegate回到它的原始（父）引用。这个行为模仿了一堆委托，而实际上并不需要一个委托。（翻译的有点蹩脚，大概意思就是这）\n所以说DefaultBeanDefinitionDocumentReader自己也没干这事，又给了BeanDefinitionParserDelegate，然后就是preProcessXml()、parseBeanDefinitions()、postProcessXml()方法；其中preProcessXml()和postProcessXml()默认是空方法，自己没有实现。具体解析在parseBeanDefinitions(root, this.delegate)中完成。\nBeanDefinitionParserDelegate用于将 Document 的内容转成 BeanDefinition实例；BeanDefinitionDocumentReader 本身不具备该功能而是交给了该类来完成。\nprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123;    //查看定义的命名空间是否为默认的命名空间    if (delegate.isDefaultNamespace(root)) &#123;        NodeList nl = root.getChildNodes();        for (int i = 0; i &lt; nl.getLength(); i++) &#123;            Node node = nl.item(i);            if (node instanceof Element) &#123;                Element ele = (Element) node;                if (delegate.isDefaultNamespace(ele)) &#123;                    parseDefaultElement(ele, delegate);                &#125;                else &#123;                    delegate.parseCustomElement(ele);                &#125;            &#125;        &#125;    &#125;    else &#123;        delegate.parseCustomElement(root);    &#125;&#125;\n这个方法就是解析文档中根目录下的元素：“import”，“alias”，“bean”。\nprivate void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123;    //解析一个“import”元素，并将给定资源的bean定义加载到bean工厂中。    if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123;        importBeanDefinitionResource(ele);    &#125;    //处理给定的别名元素，向注册表注册别名。    else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123;        processAliasRegistration(ele);    &#125;    //处理给定的bean元素，解析bean定义并将其注册到注册表中。    else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123;        processBeanDefinition(ele, delegate);    &#125;    //在给定的根&lt;beans /&gt;元素内注册每个bean定义。    else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123;        // recurse        doRegisterBeanDefinitions(ele);    &#125;&#125;\n先来看processBeanDefinition这个方法；\nBeanDefinitionHolder是一个BeanDefinition的持有者，其定义了一下变量，并对以下变量提供get和set操作。这个在后面的说道BeanDefinition体系的时候再聊。\nprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123;    //获取一个BeanDefinitionHolder    BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);    if (bdHolder != null) &#123;        //首先根据自定义属性进行装饰。        //基于自定义嵌套元素进行装饰。        bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);        try &#123;            // 注册最终装饰的实例。            BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder,            getReaderContext().getRegistry());        &#125;        catch (BeanDefinitionStoreException ex) &#123;            getReaderContext().error(\"Failed to register bean definition with name '\" +                    bdHolder.getBeanName() + \"'\", ele, ex);        &#125;        // 发送注册事件。        getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));    &#125;&#125;\n接着看registerBeanDefinition这个方法：通过给定的bean工厂注册给定的bean definition 。\npublic static void registerBeanDefinition(    BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)    throws BeanDefinitionStoreException &#123;    // 在主名称下注册bean定义。    String beanName = definitionHolder.getBeanName();    registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());    // 如果有的话，注册bean名称的别名，    String[] aliases = definitionHolder.getAliases();    if (aliases != null) &#123;        for (String alias : aliases) &#123;            registry.registerAlias(beanName, alias);        &#125;    &#125;&#125;\nregisterBeanDefinition里面又通过调用BeanDefinitionRegistry接口的实现DefaultListableBeanFactory来完成具体的注册过程。\n\n\n\nBeanDefinition载入（中）上面对于一些细节问题没有进行细究，比如说元素属性值的处理，构造函数的处理等等。本篇就学习记录一下相关点。\n首先来看下是在哪个地方具体生成BeanDefinitiond的。下面是方法请求的顺序。\n\n\nDefaultBeanDefinitionDocumentReader.parseDefaultElement\n\n\n\nDefaultBeanDefinitionDocumentReader.processBeanDefinition\n\n\n\nBeanDefinitionParserDelegate.parseBeanDefinitionElement\n\n\n\n关于元素的解析绝大多数都是在 BeanDefinitionParserDelegate 及其子类中完成的。OK，来看下 parseBeanDefinitionElement 这个方法：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public AbstractBeanDefinition parseBeanDefinitionElement(\t\tElement ele, String beanName, BeanDefinition containingBean) &#123;\tthis.parseState.push(new BeanEntry(beanName));\tString className = null;\t//在这里是读取&lt;bean&gt;的class名字，然后载入到BeanDefinition中，并未做实例化\tif (ele.hasAttribute(CLASS_ATTRIBUTE)) &#123;\t\tclassName = ele.getAttribute(CLASS_ATTRIBUTE).trim();\t&#125;\ttry &#123;\t\tString parent = null;\t\tif (ele.hasAttribute(PARENT_ATTRIBUTE)) &#123;\t\t\tparent = ele.getAttribute(PARENT_ATTRIBUTE);\t\t&#125;\t\t//生成BeanDefinition对象\t\tAbstractBeanDefinition bd = createBeanDefinition(className, parent);\t\t//解析当前bean的属性\t\tparseBeanDefinitionAttributes(ele, beanName, containingBean, bd);\t\t//设置description信息\t\tbd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));\t\t//对bean的元素信息进行解析\t\tparseMetaElements(ele, bd);\t\tparseLookupOverrideSubElements(ele, bd.getMethodOverrides());\t\tparseReplacedMethodSubElements(ele, bd.getMethodOverrides());\t\t//解析bean的构造函数设置\t\tparseConstructorArgElements(ele, bd);\t\t//解析property设置\t\tparsePropertyElements(ele, bd);\t\tparseQualifierElements(ele, bd);\t\tbd.setResource(this.readerContext.getResource());\t\tbd.setSource(extractSource(ele));\t\treturn bd;\t&#125;\t//异常1：ClassNotFoundException\tcatch (ClassNotFoundException ex) &#123;\t\terror(&quot;Bean class [&quot; + className + &quot;] not found&quot;, ele, ex);\t&#125;\t//异常2：NoClassDefFoundError\tcatch (NoClassDefFoundError err) &#123;\t\terror(&quot;Class that bean class [&quot; + className + &quot;] depends on not found&quot;, ele, err);\t&#125;\t//其他未知错误\tcatch (Throwable ex) &#123;\t\terror(&quot;Unexpected failure during bean definition parsing&quot;, ele, ex);\t&#125;\tfinally &#123;\t\tthis.parseState.pop();\t&#125;\treturn null;&#125;\n\n此处我们以解析property为例，看下具体的处理细节：\n12345678910111213//解析给定bean元素的属性子元素。public void parsePropertyElements(Element beanEle, BeanDefinition bd) &#123;    //获取子元素节点    NodeList nl = beanEle.getChildNodes();    //遍历    for (int i = 0; i &lt; nl.getLength(); i++) &#123;    \tNode node = nl.item(i);    \t//是否包含property标识    \tif (isCandidateElement(node) &amp;&amp; nodeNameEquals(node, PROPERTY_ELEMENT)) &#123;    \t\tparsePropertyElement((Element) node, bd);    \t&#125;    &#125;&#125;\n接着是执行具体property,在parsePropertyElement中完成：\n12345678910111213141516171819202122232425262728//解析一个property元素。public void parsePropertyElement(Element ele, BeanDefinition bd) &#123;      //首先获取到property的名称\tString propertyName = ele.getAttribute(NAME_ATTRIBUTE);\t//检查是否有name\tif (!StringUtils.hasLength(propertyName)) &#123;\t\terror(&quot;Tag &#x27;property&#x27; must have a &#x27;name&#x27; attribute&quot;, ele);\t\treturn;\t&#125;\tthis.parseState.push(new PropertyEntry(propertyName));\ttry &#123;\t   //验证在同一个bean中存在同名的property，存在的话就不解析了，直接返回\t\tif (bd.getPropertyValues().contains(propertyName)) &#123;\t\t\terror(&quot;Multiple &#x27;property&#x27; definitions for property &#x27;&quot; + propertyName + &quot;&#x27;&quot;, ele);\t\t\treturn;\t\t&#125;\t\t//解析出property的值\t\tObject val = parsePropertyValue(ele, bd, propertyName);\t\t//封装成PropertyValue对象\t\tPropertyValue pv = new PropertyValue(propertyName, val);\t\tparseMetaElements(ele, pv);\t\tpv.setSource(extractSource(ele));\t\tbd.getPropertyValues().addPropertyValue(pv);\t&#125;\tfinally &#123;\t\tthis.parseState.pop();\t&#125;&#125;\n在parsePropertyValue中，是对所有的property子元素进行具体解析的。我们知道property中除了单值之外，还会包括如：list，set，map，prop等集合元素；这些都会被封装成对应的Managerd对象。比如：ManagedList等。不同的集合类型页同样对应一种解析方法，比如解析list的是使用parseListElement。这些解析都是在BeanDefinitionParserDelegate类中完成的。这个后面我会抽一篇来学习BeanDefinitionParserDelegate这个类。\nBean的载入过程就是这样通过层层解析来完成的，但是对于目前的Ioc容器来说，仅仅是完成了对Bean对象管理的一些数据准备工作，也就是初始化工作，目前的BeanDefginiton中包含的就是一些静态的配置信息，Bean的实例化还没有进行，这个实例化的过程是在依赖注入时候完成的。\nBeanDefinition载入(下)在BeanDefinition载入(上)中已经大概捋了一下解析过程，本篇将记录一下bean的注册过程。\nbean的注册就是DefaultListableBeanFactory中registerBeanDefinition方法来完成的。那我就来看registerBeanDefinition这个方法的具体逻辑。\n1、beanDefinition类型判断和验证\n这里的验证主要是验证不能将静态工厂方法与方法重写相结合(静态工厂方法必须创建实例);\nif (beanDefinition instanceof AbstractBeanDefinition) &#123;    try &#123;        ((AbstractBeanDefinition) beanDefinition).validate();    &#125;    catch (BeanDefinitionValidationException ex) &#123;        throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(),        beanName,\"Validation of bean definition failed\", ex);    &#125;&#125;\n2、尝试从beanDefinitionMap中获取老的bean\n这里就是先根据beanName从beanDefinitionMap去取BeanDefinition，并将结果给oldBeanDefinition。\nBeanDefinition oldBeanDefinition;oldBeanDefinition = this.beanDefinitionMap.get(beanName);\n3、beanDefinitionMap中已经存在名为beanName的Beandefinition\n如果当前beanDefinitionMap中已经存在名为beanName的Beandefinition了(即检查是否有相同名称的beanDefinition已经在Ioc容器中注册过了)。，如果有，则进行以下具体策略：\n\n如果不允许bean被覆盖，则直接抛出不能重新注册，bean已经存在这样的异常信息\n使用框架生成的Bean来代替用户自定义的bean\n覆盖原有的Beandefinition\n\nif (oldBeanDefinition != null) &#123;    if (!isAllowBeanDefinitionOverriding()) &#123;        //省略异常代码    &#125;    else if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) &#123;        //省略异常代码    &#125;    else if (!beanDefinition.equals(oldBeanDefinition)) &#123;        //提示覆盖log信息    &#125;    else &#123;        //提示覆盖log信息    &#125;    //覆盖原有的Beandefinition    this.beanDefinitionMap.put(beanName, beanDefinition);&#125;\n4、beanDefinitionMap不存在名为beanName的Beandefinition\n//检查bean的创建阶段是否已经开始，也就是说是否已经创建了if (hasBeanCreationStarted()) &#123;    //Cannot modify startup-time collection elements anymore (for stable iteration)    // 无法修改启动时间收集元素（用于稳定迭代）（译注）    //注册过程需要保证数据的一致性，所有需要加锁同步    synchronized (this.beanDefinitionMap) &#123;        //注册到beanDefinitionMap中        this.beanDefinitionMap.put(beanName, beanDefinition);        //下面就是将当前beanName存放到beanDefinitionNames中        List&lt;String&gt; updatedDefinitions = new ArrayList&lt;String&gt;(        this.beanDefinitionNames.size() + 1);        updatedDefinitions.addAll(this.beanDefinitionNames);        updatedDefinitions.add(beanName);        this.beanDefinitionNames = updatedDefinitions;        //如果单例模式的bean名单中有该bean的name，那么移除掉它。        //也就是说着，将一个原本是单例模式的bean重新注册成一个普通的bean        if (this.manualSingletonNames.contains(beanName)) &#123;            Set&lt;String&gt; updatedSingletons = new            LinkedHashSet&lt;String&gt;(this.manualSingletonNames);            updatedSingletons.remove(beanName);            this.manualSingletonNames = updatedSingletons;        &#125;    &#125;&#125;// 仍处于启动阶段，bean还没有开始注册else &#123;    // Still in startup registration phase    this.beanDefinitionMap.put(beanName, beanDefinition);    this.beanDefinitionNames.add(beanName);    this.manualSingletonNames.remove(beanName);&#125;this.frozenBeanDefinitionNames = null;\n5、执行缓存清除\n\n1：oldBeanDefinition如果存在，且执行到了这里也没有抛出异常，说明该BeanDefinition已经被覆盖，缓存需要更新。\n2：如果是单例模式的bean对象则Set中包含该beanName，执行到这里说明该BeanDefinition已经从一个单例模式的bean变为了一个普通的bean，所以缓存也需要更新。\n\nif (oldBeanDefinition != null || containsSingleton(beanName)) &#123;    resetBeanDefinition(beanName);&#125;\nOK，我们来看下resetBeanDefinition这个方法:\n这个方法的作用就是重置给定bean的所有bean定义缓存，包括从它派生的bean的缓存。\nprotected void resetBeanDefinition(String beanName) &#123;    // 如果已经创建，则删除给定bean的合并bean定义。    clearMergedBeanDefinition(beanName);    // 如果有的话，从singleton 高速缓存中删除相应的bean。    //但是这也不是必须的，而只是为了覆盖上下文的默认bean    //（就是从manualSingletonNames中移除）    destroySingleton(beanName);    //递归的方式来 重置具有给定bean作为父项的所有bean定义。    for (String bdName : this.beanDefinitionNames) &#123;        if (!beanName.equals(bdName)) &#123;            BeanDefinition bd = this.beanDefinitionMap.get(bdName);            if (beanName.equals(bd.getParentName())) &#123;                resetBeanDefinition(bdName);            &#125;        &#125;    &#125;&#125;\nBean的注册就到这里了","slug":"spring/spring-ioc-bean-definition","date":"2018-02-07T02:24:11.000Z","categories_index":"spring","tags_index":"spring,依赖注入,Ioc,BeanDefinition","author_index":"glmapper"},{"id":"670500c2d4f523a72ee6e1b2edadead0","title":"Spring 源码系列-BeanWrapper","content":"BeanWrapper 是 Spring 提供的一个用来操作javaBean 属性的工具，使用它可以直接修改一个对象的属性。\n\n\n对于 bean 属性的操作，大家熟知的主要有下面这些工具类：\n\n1.Apache 的 BeanUtils 和 PropertyUtils\n2.cglib 的 BeanMap 和 BeanCopier\n3.spring 的 BeanUtils\n\nSpring 中 BeanWrapper 的主要功能在于：\n\n1.支持设置嵌套属性\n2.支持属性值的类型转换（设置ConversionService）\n3.提供分析和操作标准JavaBean的操作：获取和设置属性值（单独或批量），获取属性描述符以及查询属性的可读性&#x2F;可写性的能力。\n\nBeanWrapper 本身是一个接口，它提供了一整套处理 Bean 的方法。源码如下：\n1234567891011121314public interface BeanWrapper extends ConfigurablePropertyAccessor &#123;\t //为数组和集合自动增长指定一个限制。在普通的BeanWrapper上默认是无限的。\tvoid setAutoGrowCollectionLimit(int autoGrowCollectionLimit);\t//返回数组和集合自动增长的限制。\tint getAutoGrowCollectionLimit();    //如果有的话,返回由此对象包装的bean实例\tObject getWrappedInstance();\t//返回被包装的JavaBean对象的类型。\tClass&lt;?&gt; getWrappedClass();\t//获取包装对象的PropertyDescriptors（由标准JavaBeans自省确定）。\tPropertyDescriptor[] getPropertyDescriptors();\t//获取包装对象的特定属性的属性描述符。\tPropertyDescriptor getPropertyDescriptor(String propertyName) throws InvalidPropertyException;&#125;\n\n上面的 BeanWrapper 是基于4.3.6 版本的，这个接口在 4.1 版本之后略有改动。BeanWrapperImpl 是 BeanWrapper 的实现类，BeanWrapperImpl 的父类是 AbstractNestablePropertyAccessor，通过这个使得 BeanWrapper 具有处理属性的能力。\n下面是一个使用 BeanWrapper 包装对象的例子：\n1234567891011121314151617181920212223242526272829303132package com.glmapper.spring.test;import org.springframework.beans.BeanWrapper;import org.springframework.beans.PropertyAccessorFactory;import org.springframework.beans.PropertyValue;/** * BeanWrapper 测试类 */public class BeanWrapperTest &#123;    public static void main(String[] args) &#123;        User user=new User();        //通过PropertyAccessorFactory将user对象封装成BeanWrapper        BeanWrapper bw=PropertyAccessorFactory.forBeanPropertyAccess(user);        //方式一：直接对属性值进行设置        bw.setPropertyValue(&quot;userName&quot;, &quot;张三&quot;);        //方式二：通过PropertyValue进行设置        PropertyValue pv=new PropertyValue(&quot;userName&quot;,&quot;李四&quot;);        bw.setPropertyValue(pv);                        System.out.println(user.getUserName());    &#125;&#125;//一个User类class User&#123;    private String userName;    public String getUserName() &#123;        return userName;    &#125;    public void setUserName(String userName) &#123;        this.userName = userName;    &#125;&#125;\n在 Spring 中，有很多 Bean 属性的操作都是通过 BeanWrapper 来完成的，比如常见的 HttpServletBean 的属性设置就是。\n注：本文摘自我的博客园文章，进行了一些包装，放在Spring源码系列中。Spring中的 BeanWrapper\n","slug":"spring/spring-ioc-bean-wrapper","date":"2018-02-07T02:24:10.000Z","categories_index":"spring","tags_index":"spring,依赖注入,Ioc,BeanWrapper","author_index":"glmapper"},{"id":"d76bc5d4a8a8d04159939df448b6792a","title":"一个朋友圈泛型问题引发的“案子”","content":"昨天朋友圈问了一个问题：\n对于下面的 list，何如在 list 添加一个 Integer 型整数？\n1ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();\n\n\n\n有这样几种回答：\n\n1.不知道（非专业回答）\n2.硬塞（非专业回答）\n3.把String 改成Integer再添加（违背了问题初衷）\n4.把String改成Object，可以加任意类型（违背了问题初衷）\n5.String换成通配符\n6.反射\n\n对于 1、2 就不说了，属于搞事情的！3、4、5 三种方式违背了问题的初衷，如果可以改，那我们直接 new 三个 ArrayList 就可以了。6 反射，这个是无限接近的，那么这个和反射有什么关系呢？下来看下下面几个例子：\n1234567891011121314public static void main(String[] args) &#123;    ArrayList list=new ArrayList();    ArrayList&lt;String&gt; str_list=new ArrayList&lt;String&gt;();    ArrayList&lt;Integer&gt; int_list=new ArrayList&lt;Integer&gt;();    ArrayList&lt;Object&gt; obj_list=new ArrayList&lt;Object&gt;();    //对象比较    System.out.println(list == str_list);    System.out.println(list == int_list);    System.out.println(list == obj_list);    //对象的运行时class比较    System.out.println(list.getClass() == str_list.getClass());    System.out.println(list.getClass() == int_list.getClass());    System.out.println(list.getClass() == obj_list.getClass());&#125;\n结果：\n123456falsefalsefalsetruetruetrue\n其实上面三个很容易理解，不同对象在内存中的地址肯定是不同的，因此均为false;下面三个均为true?是的，确实为true,这就引出了朋友圈的那个问题。为什么不同的三个对象，他们的getClass是一样的，不应该是有三个不同的hashCode吗？这个其实就是泛型编译时和运行时的问题。对于泛型来说，泛型只在编译阶段有效，编译之后，集合的泛型是去泛型化的；原因：由于JVM泛型的擦除机制，在运行时JVM是不知道泛型信息的。因此：java集合中的泛型，是来约束用户的错误输入的，只在编译时有效；在回到问题最初，我们怎么才能将一个Integer对像放入上面定义的list中呢？既然集合中的泛型是编译时有效的，那我我们就可以通过绕过编译的方式进行插入。那么如何绕过编译时的校验呢？答案就是用反射；我们知道JAVA反射机制是指：“在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。OK，再来看程序：\n123456789ArrayList&lt;String&gt; str_list=new ArrayList&lt;String&gt;();//获取类信息Class c=str_list.getClass();//获取add方法Method m=c.getMethod(&quot;add&quot;, Object.class);//运行时调用add方法m.invoke(str_list, 20);//输出当前str_listSystem.out.println(str_list);\n结果：\n1[20]\n\n从结果可以看出，我们完成了在 list 中添加 Integer 的任务。【泛型、反射、编译时、运行时】\n\n\n\n\n\n\n\n\n\n大家周末愉快！\n","slug":"java/java-base-generic-reflect-usage","date":"2017-11-26T05:11:42.000Z","categories_index":"JAVA","tags_index":"泛型,java,反射","author_index":"glmapper"}]